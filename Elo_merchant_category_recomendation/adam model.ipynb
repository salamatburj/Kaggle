{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "import fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv='train.csv'\n",
    "test_csv='test.csv'\n",
    "hist_csv = 'C:/Users/user/Documents/Salamat/ELO/historical_transactions.csv'\n",
    "new_csv = 'C:/Users/user/Documents/Salamat/ELO/new_merchant_transactions.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(df):\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y':1, 'N':0})\n",
    "    return df\n",
    "\n",
    "def read_data(input_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_trans(history):\n",
    "    history.purchase_date = pd.DatetimeIndex(history.purchase_date).astype(np.int) * 1e-9\n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1': ['mean'],\n",
    "        'category_2_2': ['mean'],\n",
    "        'category_2_3': ['mean'],\n",
    "        'category_2_4': ['mean'],\n",
    "        'category_2_5': ['mean'],\n",
    "        'category_3_A': ['mean'],\n",
    "        'category_3_B': ['mean'],\n",
    "        'category_3_C': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['min', 'max'],\n",
    "        'month_diff': ['mean'],\n",
    "        'weekend': ['sum', 'mean'],\n",
    "    }\n",
    "    for col in ['month','hour','weekofyear','dayofweek','year']:\n",
    "        agg_func[col] = ['nunique']\n",
    "    \n",
    "    \n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    df = history.groupby('card_id').size()\n",
    "    df.name = 'transactions_count'\n",
    "    agg_history = agg_history.join(df)\n",
    "\n",
    "    return agg_history\n",
    "\n",
    "def agg_per_month(history):\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "            'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "            'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "            }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    \n",
    "    return final_group\n",
    "\n",
    "def convert(train_csv, test_csv, hist_csv, new_csv, out_prefix, nrows=None):\n",
    "    # read train/test\n",
    "    train = read_data(train_csv)\n",
    "    test = read_data(test_csv)\n",
    "    target = train.target.values\n",
    "    train.drop('target', axis=1, inplace=True)\n",
    "\n",
    "    # read hist/new\n",
    "    hist_trans = pd.read_csv(hist_csv, parse_dates=['purchase_date'], nrows=nrows)\n",
    "    new_trans = pd.read_csv(new_csv, parse_dates=['purchase_date'], nrows=nrows)\n",
    "    hist_trans = binarize(hist_trans)\n",
    "    new_trans = binarize(new_trans)\n",
    "\n",
    "    # fill missing values\n",
    "    hist_trans.category_2 = hist_trans.category_2.fillna(0).astype(int)\n",
    "    new_trans.category_2 = new_trans.category_2.fillna(0).astype(int)\n",
    "    hist_trans.category_3 = hist_trans.category_3.fillna('A')\n",
    "    new_trans.category_3 = new_trans.category_3.fillna('A')\n",
    "    hist_trans.merchant_id = hist_trans.merchant_id.fillna('M_ID_00a6ca8a8a')\n",
    "    new_trans.merchant_id = new_trans.merchant_id.fillna('M_ID_00a6ca8a8a')\n",
    "    \n",
    "\n",
    "    # add datetime features\n",
    "    for df in [hist_trans, new_trans]:\n",
    "        df['year'] = df.purchase_date.dt.year\n",
    "        df['weekofyear'] = df.purchase_date.dt.weekofyear\n",
    "        df['month'] = df.purchase_date.dt.month\n",
    "        df['dayofweek'] = df.purchase_date.dt.dayofweek\n",
    "        df['weekend'] = (df.purchase_date.dt.weekday >= 5).astype(int)\n",
    "        df['hour'] = df.purchase_date.dt.hour\n",
    "        df['month_diff'] = (datetime.datetime.today() - df.purchase_date).dt.days // 30\n",
    "        df['month_diff'] += df.month_lag\n",
    "    # feature engineering\n",
    "    hist_trans = pd.get_dummies(hist_trans, columns=['category_2', 'category_3'])\n",
    "    new_trans = pd.get_dummies(new_trans, columns=['category_2', 'category_3'])\n",
    "\n",
    "    auth_mean = hist_trans.groupby('card_id').agg({'authorized_flag': ['sum', 'mean']})\n",
    "    auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns]\n",
    "\n",
    "    authed_trans = hist_trans[hist_trans.authorized_flag == 1]\n",
    "    hist_trans = hist_trans[hist_trans.authorized_flag == 0]\n",
    "\n",
    "    hist_trans['purchase_month'] = hist_trans['purchase_date'].dt.month\n",
    "    authed_trans['purchase_month'] = authed_trans['purchase_date'].dt.month\n",
    "    new_trans['purchase_month'] = new_trans['purchase_date'].dt.month\n",
    "\n",
    "    hist = agg_trans(hist_trans)\n",
    "    hist.columns = [f'hist_{c}' for c in hist.columns]\n",
    "    authed = agg_trans(authed_trans)\n",
    "    authed.columns = [f'auth_{c}' for c in authed.columns]\n",
    "    new = agg_trans(new_trans)\n",
    "    new.columns = [f'new_{c}' for c in new.columns]\n",
    "\n",
    "    final_group = agg_per_month(hist_trans)\n",
    "\n",
    "    train = train.join(hist, on='card_id')\n",
    "    train = train.join(authed, on='card_id')\n",
    "    train = train.join(new, on='card_id')\n",
    "    train = train.join(final_group, on='card_id')\n",
    "    train = train.join(auth_mean, on='card_id')\n",
    "    test = test.join(hist, on='card_id')\n",
    "    test = test.join(authed, on='card_id')\n",
    "    test = test.join(new, on='card_id')\n",
    "    test = test.join(final_group, on='card_id')\n",
    "    test = test.join(auth_mean, on='card_id')\n",
    "    print(train.shape, test.shape)\n",
    "\n",
    "    np.savetxt(f'{out_prefix}.target.txt', target)\n",
    "    train.to_csv(f'{out_prefix}.tr.csv', index=False)\n",
    "    test.to_csv(f'{out_prefix}.te.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 163) (123623, 163)\n"
     ]
    }
   ],
   "source": [
    "convert(train_csv, test_csv, hist_csv, new_csv, 'adam_solution', nrows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(prefix, out_submit):\n",
    "    target = np.loadtxt(f'{prefix}.target.txt')\n",
    "    train = pd.read_csv(f'{prefix}.tr.csv', index_col=0)\n",
    "    test = pd.read_csv(f'{prefix}.te.csv', index_col=0)\n",
    "    features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "    categorical_feats = [c for c in features if 'feature_' in c]\n",
    "\n",
    "    param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 150, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         #\"nthread\": 4,\n",
    "         #\"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    tr_data = lgb.Dataset(train[features], label=target, categorical_feature=categorical_feats)\n",
    "\n",
    "    clf = lgb.train(param, tr_data, 3000, verbose_eval=200)\n",
    "    y_pred = clf.predict(test[features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        'card_id': test.card_id,\n",
    "        'target': y_pred\n",
    "    }).to_csv(out_submit, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(prefix, out_pred):\n",
    "    target = np.loadtxt(f'{prefix}.target.txt')\n",
    "    target_outlier = (target < -33).astype(int)\n",
    "    train = pd.read_csv(f'{prefix}.tr.csv', index_col=0)\n",
    "    test = pd.read_csv(f'{prefix}.te.csv', index_col=0)\n",
    "    features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "    categorical_feats = [c for c in features if 'feature_' in c]\n",
    "\n",
    "    param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 150, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         'scale_pos_weight': 15\n",
    "         #\"nthread\": 4,\n",
    "         #\"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    tr_data = lgb.Dataset(train[features], label=target_outlier, categorical_feature=categorical_feats)\n",
    "\n",
    "    clf = lgb.train(param, tr_data, 1000, verbose_eval=200)\n",
    "    y_pred = clf.predict(test[features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        'card_id': test.card_id,\n",
    "        'target': y_pred\n",
    "    }).to_csv(out_submit, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_bk(prefix, out_submit):\n",
    "    target = np.loadtxt(f'{prefix}.target.txt')\n",
    "    train = pd.read_csv(f'{prefix}.tr.csv')\n",
    "    test = pd.read_csv(f'{prefix}.te.csv')\n",
    "    features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "    categorical_feats = [c for c in features if 'feature_' in c]\n",
    "\n",
    "    lgbr = LGBMRegressor(n_estimators=1000, n_jobs=32)\n",
    "    lgbr.fit(train[features], target)\n",
    "\n",
    "    y_pred = lgbr.predict(test[features])\n",
    "\n",
    "    pd.DataFrame({\n",
    "        'card_id': test.card_id,\n",
    "        'target': y_pred\n",
    "    }).to_csv(out_submit, index=False)\n",
    "\n",
    "# def main():\n",
    "#     pass\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     fire.Fire({\n",
    "#         'convert': convert,\n",
    "#         'model': model\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1190: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "prefix='adam_solution'\n",
    "out_submit='with_outliers'\n",
    "model(prefix, out_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1190: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "prefix='adam_solution'\n",
    "out_submit='outliers_pred'\n",
    "outlier(prefix, out_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers=pd.read_csv('outliers_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_sorted=outliers.sort_values('target',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4133, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_sorted[outliers_sorted.target>0.5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_adam=pd.read_csv('outlier_prob.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78078</th>\n",
       "      <td>0.862953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118268</th>\n",
       "      <td>0.860737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>0.860169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96354</th>\n",
       "      <td>0.858382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104991</th>\n",
       "      <td>0.857541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88754</th>\n",
       "      <td>0.854475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>0.845360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57626</th>\n",
       "      <td>0.845235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20556</th>\n",
       "      <td>0.844683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59178</th>\n",
       "      <td>0.844309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "78078   0.862953\n",
       "118268  0.860737\n",
       "5008    0.860169\n",
       "96354   0.858382\n",
       "104991  0.857541\n",
       "88754   0.854475\n",
       "6026    0.845360\n",
       "57626   0.845235\n",
       "20556   0.844683\n",
       "59178   0.844309"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_adam.sort_values(0,ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_adam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_idx=outliers_adam.sort_values(0,ascending=False).head(10).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_idx=outliers_sorted.head(10).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_idx=set(sent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_idx=set(calc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5008, 6026, 57626, 78078, 88754, 96354, 104991, 118268}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_idx.intersection(calc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>C_ID_be92f84f5c</td>\n",
       "      <td>0.860618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78078</th>\n",
       "      <td>C_ID_922f9c5ea6</td>\n",
       "      <td>0.858936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96354</th>\n",
       "      <td>C_ID_b237ce01cb</td>\n",
       "      <td>0.853038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88754</th>\n",
       "      <td>C_ID_02871a2207</td>\n",
       "      <td>0.851883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104991</th>\n",
       "      <td>C_ID_86ddafb51c</td>\n",
       "      <td>0.850811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118268</th>\n",
       "      <td>C_ID_3420e285b9</td>\n",
       "      <td>0.849455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100556</th>\n",
       "      <td>C_ID_70c457436a</td>\n",
       "      <td>0.844050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32446</th>\n",
       "      <td>C_ID_ac114ef831</td>\n",
       "      <td>0.843812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>C_ID_91cc0c06ca</td>\n",
       "      <td>0.841243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57626</th>\n",
       "      <td>C_ID_944c62886f</td>\n",
       "      <td>0.839210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id    target\n",
       "5008    C_ID_be92f84f5c  0.860618\n",
       "78078   C_ID_922f9c5ea6  0.858936\n",
       "96354   C_ID_b237ce01cb  0.853038\n",
       "88754   C_ID_02871a2207  0.851883\n",
       "104991  C_ID_86ddafb51c  0.850811\n",
       "118268  C_ID_3420e285b9  0.849455\n",
       "100556  C_ID_70c457436a  0.844050\n",
       "32446   C_ID_ac114ef831  0.843812\n",
       "6026    C_ID_91cc0c06ca  0.841243\n",
       "57626   C_ID_944c62886f  0.839210"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=outliers_sorted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.634833162655337"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=outliers_sorted.shape[0]\n",
    "np.sqrt(T)*(3.731-3.678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
