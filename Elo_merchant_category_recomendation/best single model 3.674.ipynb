{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6df55b542f152882e00385a0f73198f4e3bc4316"
   },
   "source": [
    "**FEEL FREE TO UPVOTE**  （＾ｖ＾）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "b00db406434116eaef1206208331f97fe0542872"
   },
   "outputs": [],
   "source": [
    "#with li's idea with threshold , we can got 3.670 now\n",
    "#without li's idea, we can got 3.675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "09e0aca6b56b5baa7b76ba12dce4473242d8fc8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in range(10)]\n",
    "a[0:int(10 * 0.2 + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "337eacd2e6e13207d06cb90f9f8cd352d300b323"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a1c283f79b92bb5545678a70050e0f901e01cbe9",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elo-merchant-category-recommendation', 'elomerchantfeatures']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9219539f35e830dd6f90b8a643d0fdc04d98ced2"
   },
   "outputs": [],
   "source": [
    "df_merchant = pd.read_csv('../../ELO/merchants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_hist_trans = pd.read_csv('../../ELO/historical_transactions.csv')\n",
    "df_new_merchant_trans = pd.read_csv('../../ELO/new_merchant_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "252db1c4842288dc2c4c5a116daa5674073c6daf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n",
      "Mem. usage decreased to 114.20 Mb (45.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_hist_trans = reduce_mem_usage(df_hist_trans)\n",
    "df_new_merchant_trans = reduce_mem_usage(df_new_merchant_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "795c83a0713bc5d21122d425c298aedb5c39dd15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14693.91878841306"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test) / len(df_train)  * 24000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "fb4fe83c7fffe6b7ed4a309ebe4dbd224a10503e"
   },
   "outputs": [],
   "source": [
    "# for df in [df_new_merchant_trans,df_hist_trans]:\n",
    "#     df['purchase_amount'].clip(upper = 1.5, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "ecfe9daddbe8d162846929b0d2f749f5e6a1c524"
   },
   "outputs": [],
   "source": [
    "#使用countVectorizer对category特征进行处理，别人号称可以提升 千分之3\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# cv = CountVectorizer(token_pattern='\\w{1,}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e944bbd9d23a99ea40ceda141d78fb03f6db0f2"
   },
   "source": [
    "**Purchasing Journeys**\n",
    "\n",
    "[An Introduction to Predictive Customer Lifetime Value Modeling](https://www.datascience.com/blog/intro-to-predictive-modeling-for-customer-lifetime-value)\n",
    "\n",
    "![](https://d2mxuefqeaa7sj.cloudfront.net/s_60ECB163AE4078E84C49514ED5D5B38C222B9C0EA718BEA3759DABF297034DEB_1488169955068_file.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "86e05f51244a327e8d196d39e2b04a0e94d98279"
   },
   "outputs": [],
   "source": [
    "hist_monthly_perchase_cnts = df_hist_trans.groupby('card_id').month_lag.value_counts().unstack()\n",
    "hist_monthly_perchase_cnts.fillna(0, inplace=True)\n",
    "hist_monthly_perchase_cnts.columns = [f'hist_per_cnts_month_lag{col}' for col in hist_monthly_perchase_cnts.columns]\n",
    "new_merchant_monthly_perchase_cnts = df_new_merchant_trans.groupby('card_id').month_lag.value_counts().unstack()\n",
    "new_merchant_monthly_perchase_cnts.fillna(0, inplace=True)\n",
    "new_merchant_monthly_perchase_cnts.columns = [f'new_merchant_per_cnts_month_lag{col}' for col in new_merchant_monthly_perchase_cnts.columns]\n",
    "df_train = df_train.join(hist_monthly_perchase_cnts, on='card_id')\n",
    "df_train = df_train.join(new_merchant_monthly_perchase_cnts, on='card_id')\n",
    "df_test = df_test.join(hist_monthly_perchase_cnts, on='card_id')\n",
    "df_test = df_test.join(new_merchant_monthly_perchase_cnts, on='card_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "c410f537770efe831cb5b0206c3224b41e1f53a2"
   },
   "outputs": [],
   "source": [
    "# 结果会从 3.675 变成 3.679 ，so sad\n",
    "# i = 0\n",
    "# aggs = {}\n",
    "# aggs['purchase_amount'] = ['mean']\n",
    "# for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "#     df['purchase_amount'] = df['purchase_amount'].astype(np.float32)\n",
    "#     df_month_purchase_cnts = df.groupby(['card_id','month_lag']).agg(aggs).unstack()\n",
    "#     df_month_purchase_cnts.fillna(0, inplace = True)\n",
    "#     df_train = df_train.join(df_month_purchase_cnts, on = 'card_id')\n",
    "#     df_test = df_test.join(df_month_purchase_cnts, on = 'card_id')\n",
    "#     if i == 0:\n",
    "#         prefix = 'hist_'\n",
    "#     else:\n",
    "#         prefix = 'new_merchant_'\n",
    "#     i += 1\n",
    "#     df_train.columns = [prefix + c[0] + c[1] + str(c[2]) if type(c) is tuple else c for c in df_train.columns ]\n",
    "#     df_test.columns = [prefix + c[0] + c[1] + str(c[2]) if type(c) is tuple else c for c in df_test.columns ]\n",
    "#     del df_month_purchase_cnts\n",
    "#     gc.collect()\n",
    "#     time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4bdcf9c97640b83ed14aca50aa012dd88471d55e"
   },
   "outputs": [],
   "source": [
    "df_hist_trans.purchase_date=pd.to_datetime(df_hist_trans.purchase_date)\n",
    "pur_date=df_hist_trans[df_hist_trans.month_lag==0].groupby('card_id').purchase_date.max()\n",
    "card_id_nan_unique=df_hist_trans[df_hist_trans.card_id.isin(pur_date.index)==False].card_id.unique()\n",
    "df=pd.DataFrame(card_id_nan_unique)\n",
    "df['month_lag_date']=pd.to_datetime('2018-02') # Seetting all nan values to 2018 Feb\n",
    "df.set_index(0,inplace=True)\n",
    "new_map=df.month_lag_date\n",
    "method=pur_date.append(new_map)\n",
    "del df,pur_date\n",
    "gc.collect()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "71f89a3b8a93b2f2feb2cd0a45f860cde33687be"
   },
   "outputs": [],
   "source": [
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "#     df['category_2'].fillna(1.0,inplace=True)\n",
    "#     df['category_3'].fillna('A',inplace=True)\n",
    "#     df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\n",
    "    #修改特征\n",
    "    df['category_2'].fillna(-1,inplace=True)\n",
    "    df['category_3'].fillna('other',inplace=True)\n",
    "    df['merchant_id'].fillna('other',inplace=True)\n",
    "#     df.loc[df['installments'].isin([999,-1]),'installments'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "dda90662d05e22310dd713df106ea07f4b8bccfc"
   },
   "outputs": [],
   "source": [
    "def get_new_columns(name,aggs):\n",
    "    #for for 写法 nice\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "690ba01a38f524e9345b419200f588f937bc067a"
   },
   "outputs": [],
   "source": [
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['year'] = df['purchase_date'].dt.year\n",
    "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "    df['month'] = df['purchase_date'].dt.month\n",
    "    df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "    df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n",
    "    df['hour'] = df['purchase_date'].dt.hour\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "    df['category_1'] = df['category_1'].map({'Y':1, 'N':0}) \n",
    "    #https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/73244\n",
    "    ##Think about this part!\n",
    "    ## This line of code may be missleading since there is no single ref date. \n",
    "    df['month_diff'] = ((datetime.datetime(2018,6,1) - df['purchase_date']).dt.days)//30 # original code\n",
    "    df['month_diff'] += df['month_lag']\n",
    "    \n",
    "    ## removing 'month_diff' reduces LB score to 3.682\n",
    "    ## This line of code can be also missleading since for new merchant hist it might be negative. But why we care about it.\n",
    "    #df['month_diff'] = ((df['card_id'].map(method) - df['purchase_date']).dt.days)//30 # method that I used in my code\n",
    "    \n",
    "    ##But we already have mongth lag for each purchase! So we don't really need it!\n",
    "    ### month_diff seems to be important feature think more about it\n",
    "    \n",
    "    # This makes it even more irrelevant for my case since it will be equal to zero in most of the cases.So, let's remove it for my case\n",
    "    #df['month_diff'] += df['month_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "52d785dd8bb1eac029fbdeeaae93ffffedc71210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.to_datetime('2018-12-30')-pd.to_datetime('2019-12-30')).days//30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "80aadb70cf47be8cf45b681d73214ace43fe8d1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#因为根据auth_flag 将特征分成了两部分，这里聚合一个全局的auth_flag 特征\n",
    "aggs = {}\n",
    "aggs['purchase_amount'] = ['sum']\n",
    "# aggs['installments'] = ['sum','max','min','mean','var','median']\n",
    "aggs['authorized_flag'] = ['sum', 'mean','std']\n",
    "aggs['card_id'] = ['size']\n",
    "auth_flag = df_hist_trans.groupby(['card_id']).agg(aggs)\n",
    "auth_flag.columns = get_new_columns('auth_flag',aggs)\n",
    "auth_flag.reset_index(inplace=True)\n",
    "df_train = df_train.merge(auth_flag,on='card_id',how='left')\n",
    "df_test = df_test.merge(auth_flag,on='card_id',how='left')\n",
    "del auth_flag\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "49db45166453de5e0509d5e43d52604344954744"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对 authorized_flag进行结果编码\n",
    "aggs = {}\n",
    "for col in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "    df_hist_trans[col+'_auth_mean'] = df_hist_trans.groupby([col])['authorized_flag'].transform('mean')\n",
    "    df_hist_trans[col+'_auth_sum'] = df_hist_trans.groupby([col])['authorized_flag'].transform('sum') \n",
    "    aggs[col+'_auth_mean'] = ['mean']\n",
    "    aggs[col+'_auth_sum'] = ['sum'] \n",
    "auth_encoder = df_hist_trans.groupby(['card_id']).agg(aggs)\n",
    "auth_encoder.columns = get_new_columns('auth_encoder',aggs)\n",
    "auth_encoder.reset_index(inplace=True)\n",
    "df_train = df_train.merge(auth_encoder,on='card_id',how='left')\n",
    "df_test = df_test.merge(auth_encoder,on='card_id',how='left')\n",
    "del auth_encoder\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "5b08ce613977fc59acfdac57c208ba71db6a5ea3"
   },
   "outputs": [],
   "source": [
    "def aggregate_per_month(prefix,history,agg_func):\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = [prefix + '_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = [prefix + '_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True) \n",
    "    return final_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "508c91c2f30371a3bb5a8e5daac36f43749c55c7"
   },
   "outputs": [],
   "source": [
    "#对授权码 进行按月聚合\n",
    "agg_func = {'authorized_flag': [ 'sum', 'mean','median']}\n",
    "final_group =  aggregate_per_month('agg_per_month_total',df_hist_trans,agg_func) \n",
    "df_train = df_train.merge(final_group,on='card_id',how='left')\n",
    "df_test = df_test.merge(final_group,on='card_id',how='left')\n",
    "del final_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "6dfd525f8227507cad2d8d3a6144bb1708f7e462"
   },
   "outputs": [],
   "source": [
    "authorized_transactions = df_hist_trans[df_hist_trans['authorized_flag'] == 1]\n",
    "df_hist_trans = df_hist_trans[df_hist_trans['authorized_flag'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "22f8b5af830b7591197956f40b8b575d1e75c713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2516909, 33)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "53204f1e1752f4e51d96e7c05360898ababc655d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_func = {'purchase_amount': [ 'sum', 'mean', 'min', 'max', 'std']}\n",
    "final_group =  aggregate_per_month('agg_per_month_auth',authorized_transactions,agg_func) \n",
    "df_train = df_train.merge(final_group,on='card_id',how='left')\n",
    "df_test = df_test.merge(final_group,on='card_id',how='left')\n",
    "del final_group\n",
    "final_group =  aggregate_per_month('agg_per_month_hist',df_hist_trans,agg_func) \n",
    "df_train = df_train.merge(final_group,on='card_id',how='left')\n",
    "df_test = df_test.merge(final_group,on='card_id',how='left')\n",
    "del final_group\n",
    "final_group =  aggregate_per_month('agg_per_month_hist_new',df_new_merchant_trans,agg_func) \n",
    "df_train = df_train.merge(final_group,on='card_id',how='left')\n",
    "df_test = df_test.merge(final_group,on='card_id',how='left')\n",
    "del final_group\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "6bc6f16f1dbf38bcb45a9345fd1e789b23f0efb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['outliers'] = 0\n",
    "df_train.loc[df_train['target'] < -30, 'outliers'] = 1\n",
    "df_train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "ddf1d5bb0ade2b22b0f072c208c1506ea64503ea"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for df in [authorized_transactions,df_hist_trans]:\n",
    "    aggs = {}\n",
    "    for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id',\n",
    "                'state_id','city_id']:\n",
    "        aggs[col] = ['nunique']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var','median']\n",
    "    aggs['installments'] = ['sum','max','min','mean','var','median']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var','median']\n",
    "    \n",
    "    ## I also remove this part since it is also irrelevant since it is equivelent to month_lag. But it makes it worser\n",
    "    aggs['month_diff'] = ['mean','median']\n",
    "#     aggs['authorized_flag'] = ['sum', 'mean','median']\n",
    "    aggs['weekend'] = ['sum', 'mean']\n",
    "    aggs['category_1'] = ['sum', 'mean']\n",
    "    aggs['card_id'] = ['size']\n",
    "    #产生交叉特征，内存有问题\n",
    "    features = ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id'\n",
    "               ,'merchant_id']\n",
    "#     for coli in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "#         for colj in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "#             df[coli + colj] = df[coli].astype(str) + df[colj].astype(str)\n",
    "#             features.append(coli + colj)\n",
    "    for col in features:\n",
    "        df[col+'_mean'] = df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        df[col+'_sum'] = df.groupby([col])['purchase_amount'].transform('sum') \n",
    "        aggs[col+'_mean'] = ['mean']\n",
    "        aggs[col+'_sum'] = ['sum'] \n",
    "#         添加特征，使用outlier进行编码\n",
    "#         outliers_mean = df.groupby([col])['outliers'].mean()\n",
    "#         outliers_sum = df.groupby([col])['outliers'].sum()\n",
    "#         df[col+'_outliers_mean'] = df[col].map(outliers_mean)\n",
    "#         df[col+'_outliers_sum'] = df[col].map(outliers_sum)\n",
    "#         aggs[col+'_outliers_mean'] = ['mean']\n",
    "#         aggs[col+'_outliers_sum'] =['sum']   \n",
    "        \n",
    "    if i == 0:\n",
    "        prefix = 'auth_hist'\n",
    "    else:\n",
    "        prefix = 'hist'\n",
    "    new_columns = get_new_columns(prefix,aggs)\n",
    "    i += 1\n",
    "    # df_hist_trans.sort_values(['card_id','purchase_date'],inplace = True)\n",
    "\n",
    "    df_hist_trans_group = df.groupby('card_id').agg(aggs)\n",
    "    df_hist_trans_group.columns = new_columns\n",
    "    df_hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "    df_hist_trans_group[prefix + '_purchase_date_diff'] = (df_hist_trans_group[prefix + '_purchase_date_max'] - df_hist_trans_group[prefix + '_purchase_date_min']).dt.days\n",
    "    df_hist_trans_group[prefix + '_purchase_date_average'] = df_hist_trans_group[prefix + '_purchase_date_diff']/df_hist_trans_group[prefix + '_card_id_size']\n",
    "    ###Think about below line of code  \n",
    "    ###up to now for history means month_lag_0 to purdate_min\n",
    "#     df_hist_trans_group[prefix + '_purchase_date_uptonow'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group[prefix + '_purchase_date_max']).dt.days\n",
    "    ### This is new feature but I change the name to the old name since it makes more sense. Total number of days from first purchase to month lag 0 (until promotion)\n",
    "    df_hist_trans_group[prefix + '_purchase_date_uptonow'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group[prefix + '_purchase_date_min']).dt.days\n",
    "    ### This is old feature but I change the name to [prefix + '_first_purchase'] from [prefix + '_purchase_date_uptonow']\n",
    "    ### since it makes more sense. Number of days for the last purchase from month_lag_0\n",
    "    df_hist_trans_group[prefix + '_first_purchase'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group[prefix + '_purchase_date_max']).dt.days\n",
    "    #下面这个特征考虑了：有的人可能购买频率较低，但是还是忠实粉丝的情况\n",
    "#     df_hist_trans_group[prefix + '_purchase_date_uptonow_ave'] =  df_hist_trans_group[prefix + '_purchase_date_uptonow']/df_hist_trans_group[prefix + '_purchase_date_average']\n",
    "    #每一个card中未授权消费次数\n",
    "#     df_hist_trans_group[prefix + '_unauthorized_number'] = df_hist_trans_group[prefix + '_card_id_size'] - df_hist_trans_group[prefix + '_authorized_flag_sum']\n",
    "    #最近活跃时间，确实是一个强特征，感觉可以再挖出来几个特征，比如最近5次消费时间，最近10次消费时间，如果值比较小，说明最近很活跃\n",
    "    #没有效果\n",
    "    # grouped =  df_hist_trans.groupby('card_id')['purchase_date']\n",
    "    # df_hist_trans_group['hist_purchase_5thdate_uptonow'] =  (datetime.datetime.today() -grouped.shift(5)).dt.days\n",
    "    # df_hist_trans_group['hist_purchase_3thdate_uptonow'] =  (datetime.datetime.today() -grouped.shift(3)).dt.days\n",
    "    # df_hist_trans_group['hist_purchase_10thdate_uptonow'] =  (datetime.datetime.today() -grouped.shift(10)).dt.days\n",
    "    df_train = df_train.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "    df_test = df_test.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "    del df_hist_trans_group\n",
    "    gc.collect()\n",
    "    time.sleep(5)\n",
    "    #内存问题，暂时先放弃\n",
    "#     for col in ['subsector_id','merchant_category_id','state_id','city_id']:\n",
    "#         df[col]=df[col].astype(str)\n",
    "#         grouped = df[['card_id',col]].groupby('card_id')[col].aggregate(lambda x: ' '.join(x))\n",
    "#         cv_fit=cv.fit_transform(grouped)\n",
    "#         cv_df = pd.DataFrame(cv_fit.toarray())\n",
    "#         print(i,col)\n",
    "#         if i == 1:\n",
    "#             cv_df.columns = ['auth' + '_' + col + \"_\" + str(c) for c in cv_df.columns]\n",
    "#         elif i == 2:\n",
    "#              cv_df.columns = ['hist' + '_' + col + \"_\" + str(c) for c in cv_df.columns]\n",
    "#         cv_df['card_id'] = grouped.index\n",
    "#         df_train = df_train.merge(cv_df,on='card_id',how='left')\n",
    "#         df_test = df_test.merge(cv_df,on='card_id',how='left')\n",
    "#         del cv_df,grouped\n",
    "#         gc.collect()\n",
    "    del df\n",
    "    gc.collect()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "71cd4c771352a36807b366ebdf305469ee22a485"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_per_cnts_month_lag-13</th>\n",
       "      <th>hist_per_cnts_month_lag-12</th>\n",
       "      <th>hist_per_cnts_month_lag-11</th>\n",
       "      <th>hist_per_cnts_month_lag-10</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_merchant_category_id_mean_mean</th>\n",
       "      <th>hist_merchant_category_id_sum_sum</th>\n",
       "      <th>hist_city_id_mean_mean</th>\n",
       "      <th>hist_city_id_sum_sum</th>\n",
       "      <th>hist_merchant_id_mean_mean</th>\n",
       "      <th>hist_merchant_id_sum_sum</th>\n",
       "      <th>hist_purchase_date_diff</th>\n",
       "      <th>hist_purchase_date_average</th>\n",
       "      <th>hist_purchase_date_uptonow</th>\n",
       "      <th>hist_first_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.846728</td>\n",
       "      <td>1.144478e+07</td>\n",
       "      <td>17.928541</td>\n",
       "      <td>7.615314e+07</td>\n",
       "      <td>12.858409</td>\n",
       "      <td>337518.250000</td>\n",
       "      <td>164.0</td>\n",
       "      <td>12.615385</td>\n",
       "      <td>224.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.988992</td>\n",
       "      <td>2.014900e+06</td>\n",
       "      <td>16.378971</td>\n",
       "      <td>6.238182e+07</td>\n",
       "      <td>1.745633</td>\n",
       "      <td>8938.264648</td>\n",
       "      <td>299.0</td>\n",
       "      <td>27.181818</td>\n",
       "      <td>334.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316483</td>\n",
       "      <td>1.042644e+06</td>\n",
       "      <td>7.287305</td>\n",
       "      <td>5.252981e+05</td>\n",
       "      <td>-0.559304</td>\n",
       "      <td>-1012.340759</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>368.0</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.685194</td>\n",
       "      <td>2.026175e+06</td>\n",
       "      <td>2.260627</td>\n",
       "      <td>8.374476e+05</td>\n",
       "      <td>0.144859</td>\n",
       "      <td>1023.051819</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0   \n",
       "3            2017-09  C_ID_186d6a6901          4          3          0   \n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  hist_per_cnts_month_lag-13  hist_per_cnts_month_lag-12  \\\n",
       "0 -0.820283                         0.0                         0.0   \n",
       "1  0.392913                         0.0                        21.0   \n",
       "2  0.688056                         6.0                         6.0   \n",
       "3  0.142495                         0.0                         0.0   \n",
       "4 -0.159749                         0.0                         0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-11  hist_per_cnts_month_lag-10  \\\n",
       "0                         0.0                         0.0   \n",
       "1                        22.0                        13.0   \n",
       "2                         5.0                         7.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "          ...           hist_merchant_category_id_mean_mean  \\\n",
       "0         ...                                     13.846728   \n",
       "1         ...                                      2.988992   \n",
       "2         ...                                      1.316483   \n",
       "3         ...                                           NaN   \n",
       "4         ...                                      3.685194   \n",
       "\n",
       "   hist_merchant_category_id_sum_sum  hist_city_id_mean_mean  \\\n",
       "0                       1.144478e+07               17.928541   \n",
       "1                       2.014900e+06               16.378971   \n",
       "2                       1.042644e+06                7.287305   \n",
       "3                                NaN                     NaN   \n",
       "4                       2.026175e+06                2.260627   \n",
       "\n",
       "   hist_city_id_sum_sum  hist_merchant_id_mean_mean  hist_merchant_id_sum_sum  \\\n",
       "0          7.615314e+07                   12.858409             337518.250000   \n",
       "1          6.238182e+07                    1.745633               8938.264648   \n",
       "2          5.252981e+05                   -0.559304              -1012.340759   \n",
       "3                   NaN                         NaN                       NaN   \n",
       "4          8.374476e+05                    0.144859               1023.051819   \n",
       "\n",
       "   hist_purchase_date_diff  hist_purchase_date_average  \\\n",
       "0                    164.0                   12.615385   \n",
       "1                    299.0                   27.181818   \n",
       "2                     56.0                   28.000000   \n",
       "3                      NaN                         NaN   \n",
       "4                     37.0                    7.400000   \n",
       "\n",
       "   hist_purchase_date_uptonow  hist_first_purchase  \n",
       "0                       224.0                 59.0  \n",
       "1                       334.0                 34.0  \n",
       "2                       368.0                312.0  \n",
       "3                         NaN                  NaN  \n",
       "4                        38.0                  1.0  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "f7f5625db40db4395374991124fb796c9decd60b"
   },
   "outputs": [],
   "source": [
    "aggs = {}\n",
    "#添加特征\n",
    "for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id',\n",
    "            'state_id','city_id']:\n",
    "    aggs[col] = ['nunique']\n",
    "    \n",
    "aggs['purchase_amount'] = ['sum','max','min','mean','var','median']\n",
    "aggs['installments'] = ['sum','max','min','mean','var','median']\n",
    "aggs['purchase_date'] = ['max','min']\n",
    "aggs['month_lag'] = ['max','min','mean','var','median']\n",
    "\n",
    "### Now we also need to remove from here since we already have month_lag\n",
    "aggs['month_diff'] = ['mean','median']\n",
    "\n",
    "\n",
    "aggs['weekend'] = ['sum', 'mean']\n",
    "aggs['authorized_flag'] = ['sum', 'mean','median']\n",
    "aggs['category_1'] = ['sum', 'mean']\n",
    "aggs['card_id'] = ['size']\n",
    "\n",
    "#添加特征   \n",
    "features = ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id'\n",
    "               ,'merchant_id']\n",
    "#产生交叉特征，内存有问题\n",
    "# for coli in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "#     for colj in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "#         df_new_merchant_trans[coli + colj] = df_new_merchant_trans[coli].astype(str) + df_new_merchant_trans[colj].astype(str)\n",
    "#         features.append(coli + colj)\n",
    "for col in features:\n",
    "    df_new_merchant_trans[col+'_mean'] = df_new_merchant_trans.groupby([col])['purchase_amount'].transform('mean')\n",
    "    df_new_merchant_trans[col+'_sum'] = df_new_merchant_trans.groupby([col])['purchase_amount'].transform('sum')\n",
    "    aggs[col+'_mean'] = ['mean']\n",
    "    aggs[col+'_sum'] = ['sum']\n",
    "    #添加特征，使用outlier进行编码\n",
    "#     outliers_mean = df.groupby([col])['outliers'].mean()\n",
    "#     outliers_sum = df.groupby([col])['outliers'].sum()\n",
    "#     df[col+'_outliers_mean'] = df[col].map(outliers_mean)\n",
    "#     df[col+'_outliers_sum'] = df[col].map(outliers_sum)\n",
    "#     aggs[col+'_outliers_mean'] = ['mean']\n",
    "#     aggs[col+'_outliers_sum'] =['sum']   \n",
    "    \n",
    "new_columns = get_new_columns('new_hist',aggs)\n",
    "# df_new_merchant_trans.sort_values(['card_id','purchase_date'],inplace = True)\n",
    "df_hist_trans_group = df_new_merchant_trans.groupby('card_id').agg(aggs)\n",
    "df_hist_trans_group.columns = new_columns\n",
    "df_hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "df_hist_trans_group['new_hist_purchase_date_diff'] = (df_hist_trans_group['new_hist_purchase_date_max'] - df_hist_trans_group['new_hist_purchase_date_min']).dt.days\n",
    "df_hist_trans_group['new_hist_purchase_date_average'] = df_hist_trans_group['new_hist_purchase_date_diff']/df_hist_trans_group['new_hist_card_id_size']\n",
    "\n",
    "\n",
    "# it is fine for new mech transaction history. This means total number of days from month_lag_0 ti kast purchase\n",
    "df_hist_trans_group['new_hist_purchase_date_uptonow'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group['new_hist_purchase_date_max']).dt.days\n",
    "\n",
    "# new feature for the first purchase.This means total number of days from month_lag_0 to first purchase.\n",
    "df_hist_trans_group['new_hist_first_purchase'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group['new_hist_purchase_date_min']).dt.days\n",
    "\n",
    "#下面这个特征考虑了：有的人可能购买频率较低，但是还是忠实粉丝的情况\n",
    "# df_hist_trans_group['new_hist_purchase_date_uptonow_ave'] =  df_hist_trans_group['new_hist_purchase_date_uptonow']/df_hist_trans_group['new_hist_purchase_date_average']\n",
    "\n",
    "#每一个card中未授权消费次数\n",
    "df_hist_trans_group['new_hist_unauthorized_number'] = df_hist_trans_group['new_hist_card_id_size'] - df_hist_trans_group['new_hist_authorized_flag_sum']\n",
    "# grouped = df_new_merchant_trans.groupby('card_id')['purchase_date']\n",
    "# df_hist_trans_group['new_hist_purchase_5thdate_uptonow'] =  (datetime.datetime.today() - grouped.shift(5)).dt.days\n",
    "# df_hist_trans_group['new_hist_purchase_3thdate_uptonow'] =  (datetime.datetime.today() - grouped.shift(3)).dt.days\n",
    "# df_hist_trans_group['new_hist_purchase_10thdate_uptonow'] =  (datetime.datetime.today() - grouped.shift(10)).dt.days\n",
    "\n",
    "df_train = df_train.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "df_test = df_test.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "del df_hist_trans_group\n",
    "gc.collect()\n",
    "del df_new_merchant_trans\n",
    "gc.collect()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "ce2082fc1fb0e3f8f7d27fc166aa7a8351b65504"
   },
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['dayofweek'] = df['first_active_month'].dt.dayofweek\n",
    "    df['weekofyear'] = df['first_active_month'].dt.weekofyear\n",
    "    df['month'] = df['first_active_month'].dt.month\n",
    "    df['elapsed_time'] = (df['card_id'].map(method) - df['first_active_month']).dt.days\n",
    "    # 3.678，so bad\n",
    "#     # add some interaction features\n",
    "#     df['feature_1_hist_month_lag_max'] = df['hist_month_lag_max'] * df['feature_1']\n",
    "#     df['feature_2_hist_month_lag_max'] = df['hist_month_lag_max'] * df['feature_2']\n",
    "#     df['feature_3_hist_month_lag_max'] = df['hist_month_lag_max'] * df['feature_3']\n",
    "#     df['feature_1_auth_hist_month_lag_max'] = df['auth_hist_month_lag_max'] * df['feature_1']\n",
    "#     df['feature_2_auth_hist_month_lag_max'] = df['auth_hist_month_lag_max'] * df['feature_2']\n",
    "#     df['feature_3_auth_hist_month_lag_max'] = df['auth_hist_month_lag_max'] * df['feature_3']\n",
    "    \n",
    "    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['new_hist_first_buy'] = (df['new_hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    #添加特征\n",
    "    df['auth_hist_first_buy'] = (df['auth_hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    #修改特征\n",
    "    for f in ['hist_purchase_date_max','hist_purchase_date_min','new_hist_purchase_date_max',\\\n",
    "                     'new_hist_purchase_date_min','auth_hist_purchase_date_max','auth_hist_purchase_date_min']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "    for f in ['auth_encoder_category_2_auth_sum_sum','auth_encoder_category_3_auth_sum_sum',\n",
    "            'auth_encoder_state_id_auth_sum_sum','auth_encoder_subsector_id_auth_sum_sum',\n",
    "            'auth_encoder_merchant_category_id_auth_sum_sum','auth_encoder_city_id_auth_sum_sum']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "    #上面auth_flag已经聚合过了card_id_size ,purchase_amount\n",
    "#     df['card_id_total'] = df['new_hist_card_id_size']+df['hist_card_id_size']  + df['auth_hist_card_id_size']\n",
    "#     df['purchase_amount_total'] = df['new_hist_purchase_amount_sum']+df['hist_purchase_amount_sum']+df['auth_hist_purchase_amount_sum']\n",
    "#添加特征\n",
    "\n",
    "for f in ['feature_1','feature_2','feature_3','month','dayofweek']:\n",
    "    order_label1 = df_train.groupby([f])['outliers'].mean()\n",
    "    df_train[f+'_outliers_mean'] = df_train[f].map(order_label1)\n",
    "    df_test[f+'_outliers_mean'] = df_test[f].map(order_label1)\n",
    "    \n",
    "    order_label2 = df_train.groupby([f])['outliers'].sum()\n",
    "    df_train[f+'_outliers_sum'] = df_train[f].map(order_label2)\n",
    "    df_test[f+'_outliers_sum'] = df_test[f].map(order_label2)\n",
    "    \n",
    "#     order_label1 = df_train.groupby([f])['target'].mean()\n",
    "#     df_train[f+'_target_mean'] = df_train[f].map(order_label1) \n",
    "#     df_test[f+'_target_sum'] = df_test[f].map(order_label1)\n",
    "#     order_label2 = df_train.gorupby([f])['target'].sum()\n",
    "#     df_train[f+'_target_sum'] = df_train[f].map(order_label2)\n",
    "#     df_test[f+'_target_sum'] = df_test[f].map(order_label2)\n",
    " \n",
    "# get_dummies 似乎有一点点不良影响\n",
    "df_train = pd.get_dummies(df_train,columns =['feature_1','feature_2'])\n",
    "df_test = pd.get_dummies(df_test,columns =['feature_1','feature_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "3877e4f1418facb4da080ba31ef8ebae1724e7b1"
   },
   "outputs": [],
   "source": [
    "#首次购买的时间居然早于首次激活的时间，进行调整\n",
    "df_train.loc[df_train['auth_hist_first_buy'] < 0, 'auth_hist_first_buy'] = -1\n",
    "df_train.loc[df_train['hist_first_buy'] < 0, 'hist_first_buy'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c09ca241a4936e388b2f6e35f52dd32440a867f5"
   },
   "source": [
    "## Read features from merchant, because of memory problems, we extract this features seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../ELO/merchants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>merchant_group_id</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>subsector_id</th>\n",
       "      <th>numerical_1</th>\n",
       "      <th>numerical_2</th>\n",
       "      <th>category_1</th>\n",
       "      <th>most_recent_sales_range</th>\n",
       "      <th>most_recent_purchases_range</th>\n",
       "      <th>avg_sales_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_sales_lag6</th>\n",
       "      <th>avg_purchases_lag6</th>\n",
       "      <th>active_months_lag6</th>\n",
       "      <th>avg_sales_lag12</th>\n",
       "      <th>avg_purchases_lag12</th>\n",
       "      <th>active_months_lag12</th>\n",
       "      <th>category_4</th>\n",
       "      <th>city_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>category_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M_ID_838061e48c</td>\n",
       "      <td>8353</td>\n",
       "      <td>792</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.32</td>\n",
       "      <td>13.916667</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>242</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M_ID_9339d880ad</td>\n",
       "      <td>3184</td>\n",
       "      <td>840</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>1.291667</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M_ID_e726bbae1e</td>\n",
       "      <td>447</td>\n",
       "      <td>690</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>-82.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.13</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-82.13</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M_ID_a70e9c5f81</td>\n",
       "      <td>5026</td>\n",
       "      <td>792</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M_ID_64456c37ce</td>\n",
       "      <td>2228</td>\n",
       "      <td>222</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>12</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       merchant_id  merchant_group_id  merchant_category_id  subsector_id  \\\n",
       "0  M_ID_838061e48c               8353                   792             9   \n",
       "1  M_ID_9339d880ad               3184                   840            20   \n",
       "2  M_ID_e726bbae1e                447                   690             1   \n",
       "3  M_ID_a70e9c5f81               5026                   792             9   \n",
       "4  M_ID_64456c37ce               2228                   222            21   \n",
       "\n",
       "   numerical_1  numerical_2 category_1 most_recent_sales_range  \\\n",
       "0    -0.057471    -0.057471          N                       E   \n",
       "1    -0.057471    -0.057471          N                       E   \n",
       "2    -0.057471    -0.057471          N                       E   \n",
       "3    -0.057471    -0.057471          Y                       E   \n",
       "4    -0.057471    -0.057471          Y                       E   \n",
       "\n",
       "  most_recent_purchases_range  avg_sales_lag3     ...      avg_sales_lag6  \\\n",
       "0                           E           -0.40     ...               -2.25   \n",
       "1                           E           -0.72     ...               -0.74   \n",
       "2                           E          -82.13     ...              -82.13   \n",
       "3                           E             NaN     ...                 NaN   \n",
       "4                           E             NaN     ...                 NaN   \n",
       "\n",
       "   avg_purchases_lag6  active_months_lag6  avg_sales_lag12  \\\n",
       "0           18.666667                   6            -2.32   \n",
       "1            1.291667                   6            -0.57   \n",
       "2          260.000000                   2           -82.13   \n",
       "3            4.666667                   6              NaN   \n",
       "4            0.361111                   6              NaN   \n",
       "\n",
       "   avg_purchases_lag12  active_months_lag12  category_4  city_id state_id  \\\n",
       "0            13.916667                   12           N      242        9   \n",
       "1             1.687500                   12           N       22       16   \n",
       "2           260.000000                    2           N       -1        5   \n",
       "3             3.833333                   12           Y       -1       -1   \n",
       "4             0.347222                   12           Y       -1       -1   \n",
       "\n",
       "   category_2  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         5.0  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "62a813635bbff22db55814cf946a12d19c0cdae9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merchants' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-98259bfb4553>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#df_merchants = pd.read_pickle('../input/elomerchantfeatures/merchant_features.pickle')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_merchants\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'card_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_merchants' is not defined"
     ]
    }
   ],
   "source": [
    "# df_merchants = pd.read_pickle('../input/elomerchantfeatures/merchant_features.pickle')\n",
    "# for df in [df_train, df_test]:\n",
    "#     df = df.merge(df_merchants, on = 'card_id', how = 'left')\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "c4f20f27679889542acfd60d1f1ac381b201ac43"
   },
   "outputs": [],
   "source": [
    "exclude_features = []\n",
    "exclude_features += ['card_id', 'first_active_month','target','outliers']\n",
    "df_train_columns = [c for c in df_train.columns if c not in exclude_features ]\n",
    "target = df_train['target']\n",
    "# del df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "b7ff07b98323cf30f11ec6130f5c64e6c4db0aac",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dd3d768b0cad2f5460669484486a5a5a69e55a3"
   },
   "source": [
    "## Above is the same with wang, I call it wang's features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9eeb8e81b00e7d9ae10d7fd1ad5fbc3bc408a8c0"
   },
   "source": [
    "## train a model with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "d666d1510ad92d28727fc4a65112a97cf1f5bc65"
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 48,\n",
    "         \"random_state\": 4950}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c566cca59ed284536317ec6a074ec22cff693340"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "5533d7e021e26dade8620dedd5167aafbb0cae70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 1986 0.010928600907965332\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65119\tvalid_1's rmse: 3.70999\n",
      "[200]\ttraining's rmse: 3.56314\tvalid_1's rmse: 3.67614\n",
      "[300]\ttraining's rmse: 3.5084\tvalid_1's rmse: 3.66502\n",
      "[400]\ttraining's rmse: 3.46922\tvalid_1's rmse: 3.65881\n",
      "[500]\ttraining's rmse: 3.43617\tvalid_1's rmse: 3.65474\n",
      "[600]\ttraining's rmse: 3.40929\tvalid_1's rmse: 3.6531\n",
      "[700]\ttraining's rmse: 3.38638\tvalid_1's rmse: 3.65237\n",
      "[800]\ttraining's rmse: 3.36389\tvalid_1's rmse: 3.6516\n",
      "[900]\ttraining's rmse: 3.34424\tvalid_1's rmse: 3.65155\n",
      "[1000]\ttraining's rmse: 3.32375\tvalid_1's rmse: 3.65048\n",
      "[1100]\ttraining's rmse: 3.3053\tvalid_1's rmse: 3.65008\n",
      "[1200]\ttraining's rmse: 3.28758\tvalid_1's rmse: 3.6496\n",
      "[1300]\ttraining's rmse: 3.27057\tvalid_1's rmse: 3.64981\n",
      "[1400]\ttraining's rmse: 3.25379\tvalid_1's rmse: 3.64983\n",
      "[1500]\ttraining's rmse: 3.23826\tvalid_1's rmse: 3.65035\n",
      "[1600]\ttraining's rmse: 3.22167\tvalid_1's rmse: 3.64937\n",
      "[1700]\ttraining's rmse: 3.20571\tvalid_1's rmse: 3.64915\n",
      "[1800]\ttraining's rmse: 3.19022\tvalid_1's rmse: 3.6488\n",
      "[1900]\ttraining's rmse: 3.17624\tvalid_1's rmse: 3.64849\n",
      "[2000]\ttraining's rmse: 3.16128\tvalid_1's rmse: 3.64887\n",
      "[2100]\ttraining's rmse: 3.14745\tvalid_1's rmse: 3.64804\n",
      "[2200]\ttraining's rmse: 3.13281\tvalid_1's rmse: 3.64807\n",
      "[2300]\ttraining's rmse: 3.11884\tvalid_1's rmse: 3.64822\n",
      "[2400]\ttraining's rmse: 3.10555\tvalid_1's rmse: 3.64779\n",
      "[2500]\ttraining's rmse: 3.0923\tvalid_1's rmse: 3.64779\n",
      "[2600]\ttraining's rmse: 3.0795\tvalid_1's rmse: 3.64769\n",
      "[2700]\ttraining's rmse: 3.0648\tvalid_1's rmse: 3.64701\n",
      "[2800]\ttraining's rmse: 3.05185\tvalid_1's rmse: 3.64733\n",
      "[2900]\ttraining's rmse: 3.03904\tvalid_1's rmse: 3.64784\n",
      "[3000]\ttraining's rmse: 3.02641\tvalid_1's rmse: 3.64778\n",
      "[3100]\ttraining's rmse: 3.01355\tvalid_1's rmse: 3.64768\n",
      "[3200]\ttraining's rmse: 3.00097\tvalid_1's rmse: 3.64765\n",
      "[3300]\ttraining's rmse: 2.98871\tvalid_1's rmse: 3.64823\n",
      "Early stopping, best iteration is:\n",
      "[2730]\ttraining's rmse: 3.06057\tvalid_1's rmse: 3.64685\n",
      "fold 1 1986 0.010928600907965332\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65027\tvalid_1's rmse: 3.70766\n",
      "[200]\ttraining's rmse: 3.56172\tvalid_1's rmse: 3.67567\n",
      "[300]\ttraining's rmse: 3.50923\tvalid_1's rmse: 3.66448\n",
      "[400]\ttraining's rmse: 3.4694\tvalid_1's rmse: 3.65799\n",
      "[500]\ttraining's rmse: 3.43845\tvalid_1's rmse: 3.65546\n",
      "[600]\ttraining's rmse: 3.41185\tvalid_1's rmse: 3.65321\n",
      "[700]\ttraining's rmse: 3.38756\tvalid_1's rmse: 3.65211\n",
      "[800]\ttraining's rmse: 3.36473\tvalid_1's rmse: 3.65176\n",
      "[900]\ttraining's rmse: 3.34381\tvalid_1's rmse: 3.65186\n",
      "[1000]\ttraining's rmse: 3.32508\tvalid_1's rmse: 3.65184\n",
      "[1100]\ttraining's rmse: 3.30575\tvalid_1's rmse: 3.65149\n",
      "[1200]\ttraining's rmse: 3.2873\tvalid_1's rmse: 3.65157\n",
      "[1300]\ttraining's rmse: 3.27076\tvalid_1's rmse: 3.6515\n",
      "[1400]\ttraining's rmse: 3.25354\tvalid_1's rmse: 3.652\n",
      "[1500]\ttraining's rmse: 3.23597\tvalid_1's rmse: 3.65207\n",
      "[1600]\ttraining's rmse: 3.22036\tvalid_1's rmse: 3.65279\n",
      "[1700]\ttraining's rmse: 3.20448\tvalid_1's rmse: 3.65297\n",
      "[1800]\ttraining's rmse: 3.18958\tvalid_1's rmse: 3.65334\n",
      "Early stopping, best iteration is:\n",
      "[1220]\ttraining's rmse: 3.28429\tvalid_1's rmse: 3.65125\n",
      "fold 2 1986 0.010928600907965332\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64789\tvalid_1's rmse: 3.72377\n",
      "[200]\ttraining's rmse: 3.5585\tvalid_1's rmse: 3.6937\n",
      "[300]\ttraining's rmse: 3.50406\tvalid_1's rmse: 3.68113\n",
      "[400]\ttraining's rmse: 3.46484\tvalid_1's rmse: 3.67501\n",
      "[500]\ttraining's rmse: 3.43299\tvalid_1's rmse: 3.67086\n",
      "[600]\ttraining's rmse: 3.40707\tvalid_1's rmse: 3.66754\n",
      "[700]\ttraining's rmse: 3.38343\tvalid_1's rmse: 3.66583\n",
      "[800]\ttraining's rmse: 3.363\tvalid_1's rmse: 3.66522\n",
      "[900]\ttraining's rmse: 3.34202\tvalid_1's rmse: 3.66382\n",
      "[1000]\ttraining's rmse: 3.32339\tvalid_1's rmse: 3.66375\n",
      "[1100]\ttraining's rmse: 3.30551\tvalid_1's rmse: 3.66376\n",
      "[1200]\ttraining's rmse: 3.28865\tvalid_1's rmse: 3.66311\n",
      "[1300]\ttraining's rmse: 3.27216\tvalid_1's rmse: 3.66269\n",
      "[1400]\ttraining's rmse: 3.25503\tvalid_1's rmse: 3.66238\n",
      "[1500]\ttraining's rmse: 3.23912\tvalid_1's rmse: 3.66267\n",
      "[1600]\ttraining's rmse: 3.22236\tvalid_1's rmse: 3.66238\n",
      "[1700]\ttraining's rmse: 3.20547\tvalid_1's rmse: 3.66174\n",
      "[1800]\ttraining's rmse: 3.18946\tvalid_1's rmse: 3.66219\n",
      "[1900]\ttraining's rmse: 3.17522\tvalid_1's rmse: 3.66136\n",
      "[2000]\ttraining's rmse: 3.16204\tvalid_1's rmse: 3.66167\n",
      "[2100]\ttraining's rmse: 3.14702\tvalid_1's rmse: 3.6619\n",
      "[2200]\ttraining's rmse: 3.13217\tvalid_1's rmse: 3.66164\n",
      "[2300]\ttraining's rmse: 3.11684\tvalid_1's rmse: 3.66182\n",
      "[2400]\ttraining's rmse: 3.10246\tvalid_1's rmse: 3.66245\n",
      "[2500]\ttraining's rmse: 3.08808\tvalid_1's rmse: 3.66208\n",
      "Early stopping, best iteration is:\n",
      "[1907]\ttraining's rmse: 3.17427\tvalid_1's rmse: 3.66131\n",
      "fold 3 1986 0.010928600907965332\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65298\tvalid_1's rmse: 3.70127\n",
      "[200]\ttraining's rmse: 3.56492\tvalid_1's rmse: 3.66399\n",
      "[300]\ttraining's rmse: 3.51136\tvalid_1's rmse: 3.65164\n",
      "[400]\ttraining's rmse: 3.47073\tvalid_1's rmse: 3.64436\n",
      "[500]\ttraining's rmse: 3.43919\tvalid_1's rmse: 3.63913\n",
      "[600]\ttraining's rmse: 3.41165\tvalid_1's rmse: 3.63596\n",
      "[700]\ttraining's rmse: 3.38803\tvalid_1's rmse: 3.63386\n",
      "[800]\ttraining's rmse: 3.36528\tvalid_1's rmse: 3.63282\n",
      "[900]\ttraining's rmse: 3.34481\tvalid_1's rmse: 3.63317\n",
      "[1000]\ttraining's rmse: 3.32574\tvalid_1's rmse: 3.63335\n",
      "[1100]\ttraining's rmse: 3.30663\tvalid_1's rmse: 3.6334\n",
      "[1200]\ttraining's rmse: 3.28898\tvalid_1's rmse: 3.63368\n",
      "[1300]\ttraining's rmse: 3.27186\tvalid_1's rmse: 3.63356\n",
      "[1400]\ttraining's rmse: 3.25528\tvalid_1's rmse: 3.63369\n",
      "Early stopping, best iteration is:\n",
      "[818]\ttraining's rmse: 3.36188\tvalid_1's rmse: 3.63231\n",
      "fold 4 1986 0.010928600907965332\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6511\tvalid_1's rmse: 3.71407\n",
      "[200]\ttraining's rmse: 3.56308\tvalid_1's rmse: 3.68003\n",
      "[300]\ttraining's rmse: 3.50944\tvalid_1's rmse: 3.66393\n",
      "[400]\ttraining's rmse: 3.47188\tvalid_1's rmse: 3.65694\n",
      "[500]\ttraining's rmse: 3.43965\tvalid_1's rmse: 3.65203\n",
      "[600]\ttraining's rmse: 3.41292\tvalid_1's rmse: 3.64939\n",
      "[700]\ttraining's rmse: 3.38953\tvalid_1's rmse: 3.64799\n",
      "[800]\ttraining's rmse: 3.3681\tvalid_1's rmse: 3.64649\n",
      "[900]\ttraining's rmse: 3.34767\tvalid_1's rmse: 3.64588\n",
      "[1000]\ttraining's rmse: 3.32884\tvalid_1's rmse: 3.64524\n",
      "[1100]\ttraining's rmse: 3.31034\tvalid_1's rmse: 3.64473\n",
      "[1200]\ttraining's rmse: 3.29188\tvalid_1's rmse: 3.64388\n",
      "[1300]\ttraining's rmse: 3.27515\tvalid_1's rmse: 3.64228\n",
      "[1400]\ttraining's rmse: 3.25894\tvalid_1's rmse: 3.64199\n",
      "[1500]\ttraining's rmse: 3.24276\tvalid_1's rmse: 3.64206\n",
      "[1600]\ttraining's rmse: 3.22753\tvalid_1's rmse: 3.64102\n",
      "[1700]\ttraining's rmse: 3.21313\tvalid_1's rmse: 3.6412\n",
      "[1800]\ttraining's rmse: 3.19768\tvalid_1's rmse: 3.64074\n",
      "[1900]\ttraining's rmse: 3.18192\tvalid_1's rmse: 3.64115\n",
      "[2000]\ttraining's rmse: 3.16721\tvalid_1's rmse: 3.64136\n",
      "[2100]\ttraining's rmse: 3.15251\tvalid_1's rmse: 3.64155\n",
      "[2200]\ttraining's rmse: 3.13817\tvalid_1's rmse: 3.6413\n",
      "[2300]\ttraining's rmse: 3.1239\tvalid_1's rmse: 3.64196\n",
      "[2400]\ttraining's rmse: 3.10925\tvalid_1's rmse: 3.64208\n",
      "Early stopping, best iteration is:\n",
      "[1808]\ttraining's rmse: 3.19645\tvalid_1's rmse: 3.6406\n",
      "fold 5 1986 0.010928600907965332\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64721\tvalid_1's rmse: 3.73232\n",
      "[200]\ttraining's rmse: 3.55796\tvalid_1's rmse: 3.70477\n",
      "[300]\ttraining's rmse: 3.50355\tvalid_1's rmse: 3.69347\n",
      "[400]\ttraining's rmse: 3.46363\tvalid_1's rmse: 3.68753\n",
      "[500]\ttraining's rmse: 3.43135\tvalid_1's rmse: 3.68449\n",
      "[600]\ttraining's rmse: 3.40324\tvalid_1's rmse: 3.68425\n",
      "[700]\ttraining's rmse: 3.37887\tvalid_1's rmse: 3.68306\n",
      "[800]\ttraining's rmse: 3.35664\tvalid_1's rmse: 3.68321\n",
      "[900]\ttraining's rmse: 3.33653\tvalid_1's rmse: 3.68326\n",
      "[1000]\ttraining's rmse: 3.31688\tvalid_1's rmse: 3.68307\n",
      "[1100]\ttraining's rmse: 3.29858\tvalid_1's rmse: 3.68302\n",
      "[1200]\ttraining's rmse: 3.27948\tvalid_1's rmse: 3.68372\n",
      "[1300]\ttraining's rmse: 3.26281\tvalid_1's rmse: 3.68328\n",
      "[1400]\ttraining's rmse: 3.24618\tvalid_1's rmse: 3.6824\n",
      "[1500]\ttraining's rmse: 3.23017\tvalid_1's rmse: 3.68231\n",
      "[1600]\ttraining's rmse: 3.21393\tvalid_1's rmse: 3.68288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\ttraining's rmse: 3.19923\tvalid_1's rmse: 3.68295\n",
      "[1800]\ttraining's rmse: 3.18288\tvalid_1's rmse: 3.68333\n",
      "[1900]\ttraining's rmse: 3.16814\tvalid_1's rmse: 3.68358\n",
      "[2000]\ttraining's rmse: 3.15454\tvalid_1's rmse: 3.68429\n",
      "Early stopping, best iteration is:\n",
      "[1455]\ttraining's rmse: 3.23687\tvalid_1's rmse: 3.68199\n",
      "fold 6 1986 0.010928600907965332\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65556\tvalid_1's rmse: 3.68767\n",
      "[200]\ttraining's rmse: 3.56991\tvalid_1's rmse: 3.63553\n",
      "[300]\ttraining's rmse: 3.51812\tvalid_1's rmse: 3.61766\n",
      "[400]\ttraining's rmse: 3.47902\tvalid_1's rmse: 3.60634\n",
      "[500]\ttraining's rmse: 3.44717\tvalid_1's rmse: 3.60011\n",
      "[600]\ttraining's rmse: 3.4196\tvalid_1's rmse: 3.59561\n",
      "[700]\ttraining's rmse: 3.39553\tvalid_1's rmse: 3.5927\n",
      "[800]\ttraining's rmse: 3.3727\tvalid_1's rmse: 3.58985\n",
      "[900]\ttraining's rmse: 3.35251\tvalid_1's rmse: 3.58857\n",
      "[1000]\ttraining's rmse: 3.33275\tvalid_1's rmse: 3.58791\n",
      "[1100]\ttraining's rmse: 3.31424\tvalid_1's rmse: 3.58752\n",
      "[1200]\ttraining's rmse: 3.29752\tvalid_1's rmse: 3.58716\n",
      "[1300]\ttraining's rmse: 3.28048\tvalid_1's rmse: 3.58667\n",
      "[1400]\ttraining's rmse: 3.26303\tvalid_1's rmse: 3.58555\n",
      "[1500]\ttraining's rmse: 3.2474\tvalid_1's rmse: 3.58628\n",
      "[1600]\ttraining's rmse: 3.23144\tvalid_1's rmse: 3.58603\n",
      "[1700]\ttraining's rmse: 3.21564\tvalid_1's rmse: 3.5858\n",
      "[1800]\ttraining's rmse: 3.19957\tvalid_1's rmse: 3.58573\n",
      "[1900]\ttraining's rmse: 3.18337\tvalid_1's rmse: 3.58522\n",
      "[2000]\ttraining's rmse: 3.16786\tvalid_1's rmse: 3.58501\n",
      "[2100]\ttraining's rmse: 3.15325\tvalid_1's rmse: 3.58533\n",
      "[2200]\ttraining's rmse: 3.13885\tvalid_1's rmse: 3.58468\n",
      "[2300]\ttraining's rmse: 3.12491\tvalid_1's rmse: 3.58448\n",
      "[2400]\ttraining's rmse: 3.1112\tvalid_1's rmse: 3.58457\n",
      "[2500]\ttraining's rmse: 3.09728\tvalid_1's rmse: 3.58487\n",
      "[2600]\ttraining's rmse: 3.08349\tvalid_1's rmse: 3.58457\n",
      "[2700]\ttraining's rmse: 3.06975\tvalid_1's rmse: 3.58501\n",
      "[2800]\ttraining's rmse: 3.05653\tvalid_1's rmse: 3.58406\n",
      "[2900]\ttraining's rmse: 3.0436\tvalid_1's rmse: 3.5841\n",
      "[3000]\ttraining's rmse: 3.02916\tvalid_1's rmse: 3.58414\n",
      "[3100]\ttraining's rmse: 3.01653\tvalid_1's rmse: 3.58412\n",
      "[3200]\ttraining's rmse: 3.00337\tvalid_1's rmse: 3.58423\n",
      "[3300]\ttraining's rmse: 2.99114\tvalid_1's rmse: 3.58462\n",
      "[3400]\ttraining's rmse: 2.979\tvalid_1's rmse: 3.58516\n",
      "Early stopping, best iteration is:\n",
      "[2848]\ttraining's rmse: 3.05038\tvalid_1's rmse: 3.58367\n",
      "fold 7 1987 0.010934043560084964\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64904\tvalid_1's rmse: 3.72626\n",
      "[200]\ttraining's rmse: 3.55927\tvalid_1's rmse: 3.6976\n",
      "[300]\ttraining's rmse: 3.50552\tvalid_1's rmse: 3.68449\n",
      "[400]\ttraining's rmse: 3.46817\tvalid_1's rmse: 3.67721\n",
      "[500]\ttraining's rmse: 3.43559\tvalid_1's rmse: 3.67193\n",
      "[600]\ttraining's rmse: 3.4086\tvalid_1's rmse: 3.66867\n",
      "[700]\ttraining's rmse: 3.38506\tvalid_1's rmse: 3.66601\n",
      "[800]\ttraining's rmse: 3.36305\tvalid_1's rmse: 3.66443\n",
      "[900]\ttraining's rmse: 3.34295\tvalid_1's rmse: 3.66398\n",
      "[1000]\ttraining's rmse: 3.32437\tvalid_1's rmse: 3.66354\n",
      "[1100]\ttraining's rmse: 3.30497\tvalid_1's rmse: 3.66265\n",
      "[1200]\ttraining's rmse: 3.28751\tvalid_1's rmse: 3.6623\n",
      "[1300]\ttraining's rmse: 3.27058\tvalid_1's rmse: 3.66286\n",
      "[1400]\ttraining's rmse: 3.25256\tvalid_1's rmse: 3.66366\n",
      "[1500]\ttraining's rmse: 3.23641\tvalid_1's rmse: 3.6637\n",
      "[1600]\ttraining's rmse: 3.22092\tvalid_1's rmse: 3.66401\n",
      "[1700]\ttraining's rmse: 3.20523\tvalid_1's rmse: 3.6646\n",
      "[1800]\ttraining's rmse: 3.18962\tvalid_1's rmse: 3.66455\n",
      "Early stopping, best iteration is:\n",
      "[1245]\ttraining's rmse: 3.27994\tvalid_1's rmse: 3.66212\n",
      "fold 8 1987 0.010934043560084964\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65432\tvalid_1's rmse: 3.69638\n",
      "[200]\ttraining's rmse: 3.56621\tvalid_1's rmse: 3.6565\n",
      "[300]\ttraining's rmse: 3.5136\tvalid_1's rmse: 3.63981\n",
      "[400]\ttraining's rmse: 3.47474\tvalid_1's rmse: 3.63006\n",
      "[500]\ttraining's rmse: 3.44334\tvalid_1's rmse: 3.62332\n",
      "[600]\ttraining's rmse: 3.41644\tvalid_1's rmse: 3.6198\n",
      "[700]\ttraining's rmse: 3.39162\tvalid_1's rmse: 3.61697\n",
      "[800]\ttraining's rmse: 3.36971\tvalid_1's rmse: 3.61498\n",
      "[900]\ttraining's rmse: 3.34822\tvalid_1's rmse: 3.6138\n",
      "[1000]\ttraining's rmse: 3.32839\tvalid_1's rmse: 3.61268\n",
      "[1100]\ttraining's rmse: 3.31131\tvalid_1's rmse: 3.61152\n",
      "[1200]\ttraining's rmse: 3.29391\tvalid_1's rmse: 3.61143\n",
      "[1300]\ttraining's rmse: 3.27624\tvalid_1's rmse: 3.61064\n",
      "[1400]\ttraining's rmse: 3.26048\tvalid_1's rmse: 3.61041\n",
      "[1500]\ttraining's rmse: 3.24494\tvalid_1's rmse: 3.61041\n",
      "[1600]\ttraining's rmse: 3.22715\tvalid_1's rmse: 3.61018\n",
      "[1700]\ttraining's rmse: 3.21247\tvalid_1's rmse: 3.60917\n",
      "[1800]\ttraining's rmse: 3.19765\tvalid_1's rmse: 3.60901\n",
      "[1900]\ttraining's rmse: 3.18267\tvalid_1's rmse: 3.60876\n",
      "[2000]\ttraining's rmse: 3.16772\tvalid_1's rmse: 3.60848\n",
      "[2100]\ttraining's rmse: 3.15332\tvalid_1's rmse: 3.6084\n",
      "[2200]\ttraining's rmse: 3.13866\tvalid_1's rmse: 3.60864\n",
      "[2300]\ttraining's rmse: 3.12439\tvalid_1's rmse: 3.60849\n",
      "[2400]\ttraining's rmse: 3.11065\tvalid_1's rmse: 3.6083\n",
      "[2500]\ttraining's rmse: 3.09642\tvalid_1's rmse: 3.60834\n",
      "[2600]\ttraining's rmse: 3.08294\tvalid_1's rmse: 3.60826\n",
      "[2700]\ttraining's rmse: 3.06943\tvalid_1's rmse: 3.60773\n",
      "[2800]\ttraining's rmse: 3.05618\tvalid_1's rmse: 3.60775\n",
      "[2900]\ttraining's rmse: 3.04373\tvalid_1's rmse: 3.608\n",
      "[3000]\ttraining's rmse: 3.03077\tvalid_1's rmse: 3.60793\n",
      "[3100]\ttraining's rmse: 3.01821\tvalid_1's rmse: 3.60738\n",
      "[3200]\ttraining's rmse: 3.00607\tvalid_1's rmse: 3.60799\n",
      "[3300]\ttraining's rmse: 2.99309\tvalid_1's rmse: 3.60765\n",
      "[3400]\ttraining's rmse: 2.98122\tvalid_1's rmse: 3.60745\n",
      "[3500]\ttraining's rmse: 2.96866\tvalid_1's rmse: 3.60778\n",
      "[3600]\ttraining's rmse: 2.95674\tvalid_1's rmse: 3.60762\n",
      "[3700]\ttraining's rmse: 2.94416\tvalid_1's rmse: 3.60801\n",
      "Early stopping, best iteration is:\n",
      "[3115]\ttraining's rmse: 3.01621\tvalid_1's rmse: 3.60724\n",
      "fold 9 1987 0.010934043560084964\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64772\tvalid_1's rmse: 3.72192\n",
      "[200]\ttraining's rmse: 3.55824\tvalid_1's rmse: 3.69191\n",
      "[300]\ttraining's rmse: 3.50451\tvalid_1's rmse: 3.68106\n",
      "[400]\ttraining's rmse: 3.46458\tvalid_1's rmse: 3.67391\n",
      "[500]\ttraining's rmse: 3.43265\tvalid_1's rmse: 3.66956\n",
      "[600]\ttraining's rmse: 3.40524\tvalid_1's rmse: 3.66696\n",
      "[700]\ttraining's rmse: 3.38049\tvalid_1's rmse: 3.66504\n",
      "[800]\ttraining's rmse: 3.3591\tvalid_1's rmse: 3.66394\n",
      "[900]\ttraining's rmse: 3.33836\tvalid_1's rmse: 3.66362\n",
      "[1000]\ttraining's rmse: 3.31947\tvalid_1's rmse: 3.66325\n",
      "[1100]\ttraining's rmse: 3.3009\tvalid_1's rmse: 3.663\n",
      "[1200]\ttraining's rmse: 3.28324\tvalid_1's rmse: 3.66267\n",
      "[1300]\ttraining's rmse: 3.26538\tvalid_1's rmse: 3.66226\n",
      "[1400]\ttraining's rmse: 3.24813\tvalid_1's rmse: 3.66196\n",
      "[1500]\ttraining's rmse: 3.23232\tvalid_1's rmse: 3.6616\n",
      "[1600]\ttraining's rmse: 3.21622\tvalid_1's rmse: 3.66127\n",
      "[1700]\ttraining's rmse: 3.20111\tvalid_1's rmse: 3.66114\n",
      "[1800]\ttraining's rmse: 3.18528\tvalid_1's rmse: 3.6608\n",
      "[1900]\ttraining's rmse: 3.17045\tvalid_1's rmse: 3.66094\n",
      "[2000]\ttraining's rmse: 3.15564\tvalid_1's rmse: 3.66061\n",
      "[2100]\ttraining's rmse: 3.13995\tvalid_1's rmse: 3.66064\n",
      "[2200]\ttraining's rmse: 3.12541\tvalid_1's rmse: 3.66073\n",
      "[2300]\ttraining's rmse: 3.11133\tvalid_1's rmse: 3.66098\n",
      "[2400]\ttraining's rmse: 3.0979\tvalid_1's rmse: 3.6609\n",
      "[2500]\ttraining's rmse: 3.08347\tvalid_1's rmse: 3.66146\n",
      "[2600]\ttraining's rmse: 3.07015\tvalid_1's rmse: 3.66136\n",
      "[2700]\ttraining's rmse: 3.05579\tvalid_1's rmse: 3.66147\n",
      "Early stopping, best iteration is:\n",
      "[2185]\ttraining's rmse: 3.12751\tvalid_1's rmse: 3.66048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6428849229128195"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=4950)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "    \n",
    "    # cal the outlier ratio for each fold\n",
    "    cur_fold= df_train.iloc[trn_idx]\n",
    "    number_outliers = len(cur_fold[cur_fold['outliers'] == 1])\n",
    "    total = len(cur_fold)\n",
    "    print(\"fold %s %s %s\" % (fold_,number_outliers, number_outliers / total))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][df_train_columns], label=target.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 600)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.sqrt(mean_squared_error(oof, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15612edf08d0fc342930a49c3da8cd76b7c81820"
   },
   "outputs": [],
   "source": [
    "### LB: 3.676\n",
    "y_pred = clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration)\n",
    "single_pd = pd.DataFrame({\n",
    "        'card_id': df_test.card_id,\n",
    "        'target': predictions\n",
    "})\n",
    "single_pd.to_csv('wang_newest_with_purchase_journeys.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
