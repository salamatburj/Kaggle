{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6df55b542f152882e00385a0f73198f4e3bc4316"
   },
   "source": [
    "Changing feature enginering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4590)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "3f389b05b579223e6833cc0a824c8256d037a3f3"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max(\n",
    "            )\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/train.csv')\n",
    "df_test = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/test.csv')\n",
    "df_hist_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/historical_transactions.csv')\n",
    "df_new_merchant_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/new_merchant_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "d349a4ebccd9cb8250ff796f0d631ad9a73dffc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n",
      "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n",
      "Mem. usage decreased to 114.20 Mb (45.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train=reduce_mem_usage(df_train)\n",
    "df_test=reduce_mem_usage(df_test)\n",
    "df_hist_trans=reduce_mem_usage(df_hist_trans)\n",
    "df_new_merchant_trans=reduce_mem_usage(df_new_merchant_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4bb2197eb33a2851d8d70f1fe098ef0563597999"
   },
   "source": [
    "Count number of purchases made in each merchant. We will use it to fill NaN values by most frequent merchant id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "601820a5d56bb7d5684175b9984400d0f97e50ff"
   },
   "source": [
    "Chech weather we have NaN values in the following categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "17c82db187a7750f9aca86e338fd2e1683ec3d66",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag         False\n",
       "card_id                 False\n",
       "city_id                 False\n",
       "category_1              False\n",
       "installments            False\n",
       "category_3               True\n",
       "merchant_category_id    False\n",
       "merchant_id              True\n",
       "month_lag               False\n",
       "purchase_amount         False\n",
       "purchase_date           False\n",
       "category_2               True\n",
       "state_id                False\n",
       "subsector_id            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "bcd8ba3e3b9d0b11ea0229956debcee205969e56",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag         False\n",
       "card_id                 False\n",
       "city_id                 False\n",
       "category_1              False\n",
       "installments            False\n",
       "category_3               True\n",
       "merchant_category_id    False\n",
       "merchant_id              True\n",
       "month_lag               False\n",
       "purchase_amount         False\n",
       "purchase_date           False\n",
       "category_2               True\n",
       "state_id                False\n",
       "subsector_id            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f05ab92acdc570ee3ae892b7186df1e0cc05ecb4"
   },
   "source": [
    "It seems that 'category_2' , 'category_3' and 'mechant_id' has Nan values in historical and new mechant transactions. Now, let's count values in each of this categories for historical transactions. Let's start with 'category_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "481a00592daff8f169851827aa23e6e4ec2cfb8e",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    15177199\n",
       " 3.0     3911795\n",
       " 5.0     3725915\n",
       "NaN      2652864\n",
       " 4.0     2618053\n",
       " 2.0     1026535\n",
       "Name: category_2, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.category_2.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f57f38eb78442539e3945bb7fca178e6bc1906ae"
   },
   "source": [
    "There is 2652864 Nan values in 'category_2'. Now, let's check if in each 'card_id' 'category_2' have only 'Nan' unique value and change it to the most frequent values found in the whole history transacations. Most frequent seems to be 1.(in the above cell).\n",
    "\n",
    "In order to check we can use groupby and sum function. By setting min_count=1, we can get nan value for sum of nan array, if we didn't it will give zero by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "10ba14f38d5912f51d117141ac3e3df501f00618"
   },
   "outputs": [],
   "source": [
    "group_cat2=df_hist_trans.groupby(['card_id']).category_2.sum(min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "000bd8781d10b5d64f7cebfe185fe89ad296877a"
   },
   "source": [
    "Now let's select those who have non-values only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "d36829fe5eb68d7bd7aafebc632b42abd09901bd"
   },
   "outputs": [],
   "source": [
    "group_cat2_nan=group_cat2[group_cat2.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "e31c9828aebedcb98261fea2b990506cc63fe9f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_001b4c5151   NaN\n",
       "C_ID_001c09a36b   NaN\n",
       "C_ID_0028e15a78   NaN\n",
       "C_ID_002b706ded   NaN\n",
       "C_ID_0030e0945f   NaN\n",
       "Name: category_2, dtype: float16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cat2_nan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18a8ec540fe8d4444d9eb3a53158799a5d5e2c4b"
   },
   "source": [
    "I am setting index as 'card_id'. In order to , change 'category_2' values. I tried just by using \n",
    "df_hist_trans.loc[df_hist_trans.card_id.isin(group_cat2_nan.index)].category_2=1\n",
    "or \n",
    "df_hist_trans[df_hist_trans.card_id.isin(group_cat2_nan.index)].category_2\n",
    "and you can check by\n",
    "df_hist_trans.loc[df_hist_trans.card_id.isin(group_cat2_nan.index)].category_2\n",
    "or\n",
    "df_hist_trans.loc[df_hist_trans.card_id.isin(group_cat2_nan.index)].category_2\n",
    "You will see that values do not change. Both of this methods gives copy from the dataframe so we can't change it. It seems when you use masking(df_hist_trans.card_id.isin(group_cat2_nan.index)) you will have copy. \n",
    "Therefore, I decided to call from index and index will be 'card_id'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "dc15c593d833a09a4b72b4714eae2e127a127224"
   },
   "outputs": [],
   "source": [
    "df_hist_trans[df_hist_trans.card_id.isin(group_cat2_nan.index)].category_2=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "c3a4377a7dfc0eb3bff42251a48ad0bcd2aa29aa",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15207   NaN\n",
       "15208   NaN\n",
       "15209   NaN\n",
       "15210   NaN\n",
       "15211   NaN\n",
       "Name: category_2, dtype: float16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans[df_hist_trans.card_id.isin(group_cat2_nan.index)].category_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86429d3c9b2272729b8755e9daf4cee6b13b5051"
   },
   "source": [
    "You can see that it doesn't work. So , let's change index of df_hist_trans to 'card_id'. Call dataframe from their respective indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "30b5350b5928ea6e8cc46a49b824ad6b5f3dffa3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_hist_trans.set_index('card_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "49e9b8cd0906aebd178a04916b386777ad8360e9"
   },
   "outputs": [],
   "source": [
    "df_hist_trans.loc[group_cat2_nan.index,'category_2']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "0150514fe63eed35badef8e20ee18f7f9ae83e66",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.loc[group_cat2_nan.index,'category_2'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b48b6d5fbb92bb264545dac7b9cd953d0f321a5c"
   },
   "source": [
    "Now, we only changed the once which have only NaN values in 'category_2'. Let's check how many nan are still there. So nan values are reduced by 115446."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "7973d86538ae649c30b5e0d7a74a526e8ed25d1b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    15327456\n",
       " 3.0     3911795\n",
       " 5.0     3725915\n",
       " 4.0     2618053\n",
       "NaN      2502607\n",
       " 2.0     1026535\n",
       "Name: category_2, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.category_2.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6587b251a9053dee27b669ee486097f859b52883"
   },
   "source": [
    "Now let's reset_index and groupby 'card_id' and 'category' . We can look at number of counts in each category of 'category_2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "633e28186286a8a5945f8f665314878c983902bf"
   },
   "outputs": [],
   "source": [
    "df_hist_trans.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "9d600174cf2125c86f6fedbafc6e9622faa10a9e"
   },
   "outputs": [],
   "source": [
    "category_2_count=df_hist_trans.groupby(['card_id','category_2']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "dc8a124789c5e8e131d556d0cac929621dde4c0a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th>category_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C_ID_00007093c1</th>\n",
       "      <th>3.0</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C_ID_0001238066</th>\n",
       "      <th>1.0</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C_ID_0001506ef0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">C_ID_0001793786</th>\n",
       "      <th>1.0</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_000183fdda</th>\n",
       "      <th>1.0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            authorized_flag  city_id  category_1  \\\n",
       "card_id         category_2                                         \n",
       "C_ID_00007093c1 3.0                     120      120         120   \n",
       "                5.0                       1        1           1   \n",
       "C_ID_0001238066 1.0                      95       95          95   \n",
       "                5.0                      20       20          20   \n",
       "C_ID_0001506ef0 1.0                       2        2           2   \n",
       "                3.0                      64       64          64   \n",
       "C_ID_0001793786 1.0                      11       11          11   \n",
       "                2.0                      76       76          76   \n",
       "                3.0                      15       15          15   \n",
       "C_ID_000183fdda 1.0                       7        7           7   \n",
       "\n",
       "                            installments  category_3  merchant_category_id  \\\n",
       "card_id         category_2                                                   \n",
       "C_ID_00007093c1 3.0                  120         120                   120   \n",
       "                5.0                    1           1                     1   \n",
       "C_ID_0001238066 1.0                   95          94                    95   \n",
       "                5.0                   20          19                    20   \n",
       "C_ID_0001506ef0 1.0                    2           2                     2   \n",
       "                3.0                   64          64                    64   \n",
       "C_ID_0001793786 1.0                   11          11                    11   \n",
       "                2.0                   76          76                    76   \n",
       "                3.0                   15          15                    15   \n",
       "C_ID_000183fdda 1.0                    7           7                     7   \n",
       "\n",
       "                            merchant_id  month_lag  purchase_amount  \\\n",
       "card_id         category_2                                            \n",
       "C_ID_00007093c1 3.0                 120        120              120   \n",
       "                5.0                   1          1                1   \n",
       "C_ID_0001238066 1.0                  95         95               95   \n",
       "                5.0                  20         20               20   \n",
       "C_ID_0001506ef0 1.0                   2          2                2   \n",
       "                3.0                  64         64               64   \n",
       "C_ID_0001793786 1.0                  11         11               11   \n",
       "                2.0                  76         76               76   \n",
       "                3.0                  15         15               15   \n",
       "C_ID_000183fdda 1.0                   7          7                7   \n",
       "\n",
       "                            purchase_date  state_id  subsector_id  \n",
       "card_id         category_2                                         \n",
       "C_ID_00007093c1 3.0                   120       120           120  \n",
       "                5.0                     1         1             1  \n",
       "C_ID_0001238066 1.0                    95        95            95  \n",
       "                5.0                    20        20            20  \n",
       "C_ID_0001506ef0 1.0                     2         2             2  \n",
       "                3.0                    64        64            64  \n",
       "C_ID_0001793786 1.0                    11        11            11  \n",
       "                2.0                    76        76            76  \n",
       "                3.0                    15        15            15  \n",
       "C_ID_000183fdda 1.0                     7         7             7  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_2_count.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72e5f449124eda1363bce455e8ff0be1fbd469f6"
   },
   "source": [
    "We need only one column(since all of them are same) let's choose 'authorized_flag'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "f461ca2ada8addea24bffd71ad362e2c5f0b7565"
   },
   "outputs": [],
   "source": [
    "category_2_count=category_2_count.authorized_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "5225035904eb2c73734c870c853d8ef3f07330af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id          category_2\n",
       "C_ID_00007093c1  3.0           120\n",
       "                 5.0             1\n",
       "C_ID_0001238066  1.0            95\n",
       "                 5.0            20\n",
       "C_ID_0001506ef0  1.0             2\n",
       "                 3.0            64\n",
       "C_ID_0001793786  1.0            11\n",
       "                 2.0            76\n",
       "                 3.0            15\n",
       "C_ID_000183fdda  1.0             7\n",
       "                 2.0             1\n",
       "                 3.0           131\n",
       "                 5.0             1\n",
       "C_ID_00024e244b  1.0             3\n",
       "                 3.0            67\n",
       "C_ID_0002709b5a  1.0             1\n",
       "                 2.0            52\n",
       "                 5.0            14\n",
       "C_ID_00027503e2  1.0             3\n",
       "                 3.0            39\n",
       "Name: authorized_flag, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_2_count.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68de402f2218dbd9c765428e40fdf5f8f89827a3"
   },
   "source": [
    "We will need only index of maximum values. We can do it by groupby(level=0), level=0 is 'card_id' in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "3a4605710425f5b54f29da1d72a69629c87f64a5"
   },
   "outputs": [],
   "source": [
    "category_2_count_max=category_2_count.groupby(level=0).idxmax()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24e4c2450ea2b9f31a163845a18911fe5df7c432"
   },
   "source": [
    "Now we need only second part of the tuple. Finally, we will obtain Series object with corresponding max count of categories for each 'card_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "49dec6e22b6d58bb1b854ad8d507de68afec73a3"
   },
   "outputs": [],
   "source": [
    "category_2_count_max=category_2_count_max.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "aa47b2db47171ec51cd775d12ca3fc1476bd6695",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1    3.0\n",
       "C_ID_0001238066    1.0\n",
       "C_ID_0001506ef0    3.0\n",
       "C_ID_0001793786    2.0\n",
       "C_ID_000183fdda    3.0\n",
       "Name: authorized_flag, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_2_count_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5059999b14d7bb9be38759dd413c77b27a54a17"
   },
   "source": [
    "Now, we can input most frequent 'category_2' value for each non value in certain 'card_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "8d5f635c3f7f89b59ae514fc1b74a150095920ef",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703331</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.733128</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.720386</td>\n",
       "      <td>2017-08-09 22:04:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>2017-09-02 10:06:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.722865</td>\n",
       "      <td>2017-03-10 01:14:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authorized_flag  city_id category_1  installments category_3  \\\n",
       "card_id                                                                        \n",
       "C_ID_4e6213e9bc               Y       88          N             0          A   \n",
       "C_ID_4e6213e9bc               Y       88          N             0          A   \n",
       "C_ID_4e6213e9bc               Y       88          N             0          A   \n",
       "C_ID_4e6213e9bc               Y       88          N             0          A   \n",
       "C_ID_4e6213e9bc               Y       88          N             0          A   \n",
       "\n",
       "                 merchant_category_id      merchant_id  month_lag  \\\n",
       "card_id                                                             \n",
       "C_ID_4e6213e9bc                    80  M_ID_e020e9b302         -8   \n",
       "C_ID_4e6213e9bc                   367  M_ID_86ec983688         -7   \n",
       "C_ID_4e6213e9bc                    80  M_ID_979ed661fc         -6   \n",
       "C_ID_4e6213e9bc                   560  M_ID_e6d5ae8ea6         -5   \n",
       "C_ID_4e6213e9bc                    80  M_ID_e020e9b302        -11   \n",
       "\n",
       "                 purchase_amount        purchase_date  category_2  state_id  \\\n",
       "card_id                                                                       \n",
       "C_ID_4e6213e9bc        -0.703331  2017-06-25 15:33:07         1.0        16   \n",
       "C_ID_4e6213e9bc        -0.733128  2017-07-15 12:10:45         1.0        16   \n",
       "C_ID_4e6213e9bc        -0.720386  2017-08-09 22:04:29         1.0        16   \n",
       "C_ID_4e6213e9bc        -0.735352  2017-09-02 10:06:26         1.0        16   \n",
       "C_ID_4e6213e9bc        -0.722865  2017-03-10 01:14:19         1.0        16   \n",
       "\n",
       "                 subsector_id  \n",
       "card_id                        \n",
       "C_ID_4e6213e9bc            37  \n",
       "C_ID_4e6213e9bc            16  \n",
       "C_ID_4e6213e9bc            37  \n",
       "C_ID_4e6213e9bc            34  \n",
       "C_ID_4e6213e9bc            37  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.set_index('card_id',inplace=True)\n",
    "df_hist_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe549905dbd62328f431a307b821ab494da8a0e4"
   },
   "source": [
    "Let's check what where value counts before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "b4d68db6bf4e2697eb1611820abef1c9d529b60d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    15327456\n",
       " 3.0     3911795\n",
       " 5.0     3725915\n",
       " 4.0     2618053\n",
       "NaN      2502607\n",
       " 2.0     1026535\n",
       "Name: category_2, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.category_2.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6fef03476e2162b2b52056f6122a015948de2c25"
   },
   "source": [
    "Fill nan values according to given series by using fillna function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "e72255f63cacec29661a3a3d8305e2731256e538",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hist_trans.category_2=df_hist_trans.category_2.fillna(category_2_count_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d92c7eb03d17d133c11ccf0f28e840a0a9f9d853"
   },
   "source": [
    "Finally, we get rid of all nan values for 'category_2' . Now, we can try same for 'category_3' and 'merchant_id'. Also, we need to do same for 'df_new_merchant_trans'. Finally, let's check if there is any nan values in category_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "0fe58472be59b5b6de088db800c3b5e88a87b452",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    16804879\n",
       "3.0     4289903\n",
       "5.0     4050578\n",
       "4.0     2793190\n",
       "2.0     1173811\n",
       "Name: category_2, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.category_2.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c29c30ab4cf68f7bb12c373c46950950dbdd8660"
   },
   "source": [
    "Let's do same for 'category_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "e7c6a9a8c5420d572b258be200b1951ca41f80c2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A      15411747\n",
       "B      11677522\n",
       "C       1844933\n",
       "NaN      178159\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "494dbbc775ac8ea7828ceaf29722f69dbf29edc2"
   },
   "source": [
    "Let's change 'A' , 'B', 'C' to numerical values in order to be able to use sum(min_counts=1) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "3bb5216c063d192351cf8ed549900837516d2f3f"
   },
   "outputs": [],
   "source": [
    "d_cat3={'A':1,'B':2,'C':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "cedd8419b07dd529b9ae12da4469b4d5307265ba"
   },
   "outputs": [],
   "source": [
    "df_hist_trans.category_3=df_hist_trans.category_3.map(d_cat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_uuid": "2f3e88b0a49d6975f5fbe3c75bc3818d2522b607"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703331</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.733128</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.720386</td>\n",
       "      <td>2017-08-09 22:04:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>2017-09-02 10:06:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e6213e9bc</th>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.722865</td>\n",
       "      <td>2017-03-10 01:14:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authorized_flag  city_id category_1  installments  category_3  \\\n",
       "card_id                                                                         \n",
       "C_ID_4e6213e9bc               Y       88          N             0         1.0   \n",
       "C_ID_4e6213e9bc               Y       88          N             0         1.0   \n",
       "C_ID_4e6213e9bc               Y       88          N             0         1.0   \n",
       "C_ID_4e6213e9bc               Y       88          N             0         1.0   \n",
       "C_ID_4e6213e9bc               Y       88          N             0         1.0   \n",
       "\n",
       "                 merchant_category_id      merchant_id  month_lag  \\\n",
       "card_id                                                             \n",
       "C_ID_4e6213e9bc                    80  M_ID_e020e9b302         -8   \n",
       "C_ID_4e6213e9bc                   367  M_ID_86ec983688         -7   \n",
       "C_ID_4e6213e9bc                    80  M_ID_979ed661fc         -6   \n",
       "C_ID_4e6213e9bc                   560  M_ID_e6d5ae8ea6         -5   \n",
       "C_ID_4e6213e9bc                    80  M_ID_e020e9b302        -11   \n",
       "\n",
       "                 purchase_amount        purchase_date  category_2  state_id  \\\n",
       "card_id                                                                       \n",
       "C_ID_4e6213e9bc        -0.703331  2017-06-25 15:33:07         1.0        16   \n",
       "C_ID_4e6213e9bc        -0.733128  2017-07-15 12:10:45         1.0        16   \n",
       "C_ID_4e6213e9bc        -0.720386  2017-08-09 22:04:29         1.0        16   \n",
       "C_ID_4e6213e9bc        -0.735352  2017-09-02 10:06:26         1.0        16   \n",
       "C_ID_4e6213e9bc        -0.722865  2017-03-10 01:14:19         1.0        16   \n",
       "\n",
       "                 subsector_id  \n",
       "card_id                        \n",
       "C_ID_4e6213e9bc            37  \n",
       "C_ID_4e6213e9bc            16  \n",
       "C_ID_4e6213e9bc            37  \n",
       "C_ID_4e6213e9bc            34  \n",
       "C_ID_4e6213e9bc            37  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    15411747\n",
       " 2.0    11677522\n",
       " 3.0     1844933\n",
       "NaN       178159\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "402934a2ac491065b853fdcbd3b6580ed29800bc"
   },
   "outputs": [],
   "source": [
    "group_cat3=df_hist_trans.groupby(['card_id']).category_3.sum(min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cat3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This means that we don't have any card_id which have only NaN values in category_3. So we can jump to changing nan values in each card id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1    2.0\n",
       "C_ID_0001238066    2.0\n",
       "C_ID_0001506ef0    1.0\n",
       "C_ID_0001793786    1.0\n",
       "C_ID_000183fdda    2.0\n",
       "Name: authorized_flag, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.reset_index(inplace=True)\n",
    "category_3_count=df_hist_trans.groupby(['card_id','category_3']).count()\n",
    "category_3_count=category_3_count.authorized_flag\n",
    "category_3_count_max=category_3_count.groupby(level=0).idxmax()\n",
    "category_3_count_max=category_3_count_max.apply(lambda x: x[1])\n",
    "category_3_count_max.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check again what was before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    15411747\n",
       " 2.0    11677522\n",
       " 3.0     1844933\n",
       "NaN       178159\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.set_index('card_id',inplace=True)\n",
    "df_hist_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15412531\n",
       "2.0    11833535\n",
       "3.0     1866295\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.category_3=df_hist_trans.category_3.fillna(category_3_count_max)\n",
    "df_hist_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    15412531\n",
       "B    11833535\n",
       "C     1866295\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cat3_inv={1.0:\"A\",2.0:\"B\",3.0:\"C\"}\n",
    "df_hist_trans.category_3=df_hist_trans.category_3.map(d_cat3_inv)\n",
    "df_hist_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do it for merchant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M_ID_00a6ca8a8a    1115097\n",
       "M_ID_e5374dabc0     428619\n",
       "M_ID_9139332ccc     361385\n",
       "M_ID_50f575c681     183894\n",
       "M_ID_fc7d7969c3     177040\n",
       "Name: merchant_id, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_hist_trans.set_index('card_id',inplace=True)\n",
    "df_hist_trans.merchant_id.value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1    M_ID_9400cf2342\n",
       "C_ID_0001238066    M_ID_d17aabd756\n",
       "C_ID_0001506ef0    M_ID_b1fc88154d\n",
       "C_ID_0001793786    M_ID_923d57de8d\n",
       "C_ID_000183fdda    M_ID_f9cfe0a43b\n",
       "Name: authorized_flag, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.reset_index(inplace=True)\n",
    "merchant_id_count=df_hist_trans.groupby(['card_id','merchant_id']).count()\n",
    "merchant_id_count=merchant_id_count.authorized_flag\n",
    "merchant_id_count_max=merchant_id_count.groupby(level=0).idxmax()\n",
    "merchant_id_count_max=merchant_id_count_max.apply(lambda x: x[1])\n",
    "merchant_id_count_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check again what was before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M_ID_00a6ca8a8a    1115097\n",
       "M_ID_e5374dabc0     428619\n",
       "M_ID_9139332ccc     361385\n",
       "M_ID_50f575c681     183894\n",
       "M_ID_fc7d7969c3     177040\n",
       "M_ID_5ba019a379     170935\n",
       "NaN                 138481\n",
       "M_ID_f86439cec0     110341\n",
       "M_ID_1f4773aa76     106476\n",
       "M_ID_86be58d7e0      97259\n",
       "M_ID_98b342c0e3      93394\n",
       "M_ID_d855771cd9      84377\n",
       "M_ID_6f274b9340      81072\n",
       "M_ID_cd2c0b07e9      80179\n",
       "M_ID_57df19bf28      76750\n",
       "M_ID_b9dcf28cb9      75487\n",
       "M_ID_b98db225f5      70384\n",
       "M_ID_445742726b      68499\n",
       "M_ID_2637773dd2      66836\n",
       "M_ID_82a30d9203      65853\n",
       "Name: merchant_id, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.set_index('card_id',inplace=True)\n",
    "df_hist_trans.merchant_id.value_counts(dropna=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M_ID_00a6ca8a8a    1130790\n",
       "M_ID_e5374dabc0     433318\n",
       "M_ID_9139332ccc     364256\n",
       "M_ID_50f575c681     185941\n",
       "M_ID_fc7d7969c3     177967\n",
       "Name: merchant_id, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.merchant_id=df_hist_trans.merchant_id.fillna(merchant_id_count_max)\n",
    "df_hist_trans.merchant_id.value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's check if any nan values left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag         False\n",
       "city_id                 False\n",
       "category_1              False\n",
       "installments            False\n",
       "category_3              False\n",
       "merchant_category_id    False\n",
       "merchant_id             False\n",
       "month_lag               False\n",
       "purchase_amount         False\n",
       "purchase_date           False\n",
       "category_2              False\n",
       "state_id                False\n",
       "subsector_id            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hist_trans.to_csv('C:/Users/user/Documents/Salamat/ELO/historical_transactions_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's do same for new merchant transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new_merchant_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/new_merchant_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag         False\n",
       "card_id                 False\n",
       "city_id                 False\n",
       "category_1              False\n",
       "installments            False\n",
       "category_3               True\n",
       "merchant_category_id    False\n",
       "merchant_id              True\n",
       "month_lag               False\n",
       "purchase_amount         False\n",
       "purchase_date           False\n",
       "category_2               True\n",
       "state_id                False\n",
       "subsector_id            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    1058242\n",
       " 3.0     289525\n",
       " 5.0     259266\n",
       " 4.0     178590\n",
       "NaN      111745\n",
       " 2.0      65663\n",
       "Name: category_2, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.category_2.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cat2=df_new_merchant_trans.groupby(['card_id']).category_2.sum(min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_000cfb6503   NaN\n",
       "C_ID_000f6fea6a   NaN\n",
       "C_ID_000f7e3e49   NaN\n",
       "C_ID_0017dadfd5   NaN\n",
       "C_ID_001b43d48f   NaN\n",
       "Name: category_2, dtype: float16"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cat2_nan=group_cat2[group_cat2.isnull()]\n",
    "group_cat2_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.set_index('card_id',inplace=True)\n",
    "df_new_merchant_trans.loc[group_cat2_nan.index,'category_2']=1\n",
    "df_new_merchant_trans.loc[group_cat2_nan.index,'category_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    1077518\n",
       " 3.0     289525\n",
       " 5.0     259266\n",
       " 4.0     178590\n",
       "NaN       92469\n",
       " 2.0      65663\n",
       "Name: category_2, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.category_2.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th>category_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C_ID_00007093c1</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C_ID_0001238066</th>\n",
       "      <th>1.0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_0001506ef0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">C_ID_0001793786</th>\n",
       "      <th>1.0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_000183fdda</th>\n",
       "      <th>3.0</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            authorized_flag  city_id  category_1  \\\n",
       "card_id         category_2                                         \n",
       "C_ID_00007093c1 1.0                       1        1           1   \n",
       "                3.0                       1        1           1   \n",
       "C_ID_0001238066 1.0                      20       20          20   \n",
       "                5.0                       3        3           3   \n",
       "C_ID_0001506ef0 3.0                       2        2           2   \n",
       "C_ID_0001793786 1.0                      15       15          15   \n",
       "                2.0                       8        8           8   \n",
       "                3.0                       5        5           5   \n",
       "                5.0                       1        1           1   \n",
       "C_ID_000183fdda 3.0                      11       11          11   \n",
       "\n",
       "                            installments  category_3  merchant_category_id  \\\n",
       "card_id         category_2                                                   \n",
       "C_ID_00007093c1 1.0                    1           1                     1   \n",
       "                3.0                    1           1                     1   \n",
       "C_ID_0001238066 1.0                   20          19                    20   \n",
       "                5.0                    3           3                     3   \n",
       "C_ID_0001506ef0 3.0                    2           2                     2   \n",
       "C_ID_0001793786 1.0                   15          15                    15   \n",
       "                2.0                    8           8                     8   \n",
       "                3.0                    5           5                     5   \n",
       "                5.0                    1           1                     1   \n",
       "C_ID_000183fdda 3.0                   11          10                    11   \n",
       "\n",
       "                            merchant_id  month_lag  purchase_amount  \\\n",
       "card_id         category_2                                            \n",
       "C_ID_00007093c1 1.0                   1          1                1   \n",
       "                3.0                   1          1                1   \n",
       "C_ID_0001238066 1.0                  20         20               20   \n",
       "                5.0                   3          3                3   \n",
       "C_ID_0001506ef0 3.0                   1          2                2   \n",
       "C_ID_0001793786 1.0                  15         15               15   \n",
       "                2.0                   8          8                8   \n",
       "                3.0                   5          5                5   \n",
       "                5.0                   1          1                1   \n",
       "C_ID_000183fdda 3.0                  11         11               11   \n",
       "\n",
       "                            purchase_date  state_id  subsector_id  \n",
       "card_id         category_2                                         \n",
       "C_ID_00007093c1 1.0                     1         1             1  \n",
       "                3.0                     1         1             1  \n",
       "C_ID_0001238066 1.0                    20        20            20  \n",
       "                5.0                     3         3             3  \n",
       "C_ID_0001506ef0 3.0                     2         2             2  \n",
       "C_ID_0001793786 1.0                    15        15            15  \n",
       "                2.0                     8         8             8  \n",
       "                3.0                     5         5             5  \n",
       "                5.0                     1         1             1  \n",
       "C_ID_000183fdda 3.0                    11        11            11  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.reset_index(inplace=True)\n",
    "category_2_count=df_new_merchant_trans.groupby(['card_id','category_2']).count()\n",
    "category_2_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1    1.0\n",
       "C_ID_0001238066    1.0\n",
       "C_ID_0001506ef0    3.0\n",
       "C_ID_0001793786    1.0\n",
       "C_ID_000183fdda    3.0\n",
       "Name: authorized_flag, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_2_count=category_2_count.authorized_flag\n",
    "category_2_count_max=category_2_count.groupby(level=0).idxmax()\n",
    "category_2_count_max=category_2_count_max.apply(lambda x: x[1])\n",
    "category_2_count_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before replacing nan values\n",
      " 1.0    1077518\n",
      " 3.0     289525\n",
      " 5.0     259266\n",
      " 4.0     178590\n",
      "NaN       92469\n",
      " 2.0      65663\n",
      "Name: category_2, dtype: int64\n",
      "after replacing nan values\n",
      "1.0    1129966\n",
      "3.0     304780\n",
      "5.0     270897\n",
      "4.0     185915\n",
      "2.0      71473\n",
      "Name: category_2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_new_merchant_trans.set_index('card_id',inplace=True)\n",
    "print(\"before replacing nan values\")\n",
    "print(df_new_merchant_trans.category_2.value_counts(dropna=False))\n",
    "df_new_merchant_trans.category_2=df_new_merchant_trans.category_2.fillna(category_2_count_max)\n",
    "print(\"after replacing nan values\")\n",
    "print(df_new_merchant_trans.category_2.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do it in category_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A      922244\n",
       "B      836178\n",
       "C      148687\n",
       "NaN     55922\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    922244\n",
       " 2.0    836178\n",
       " 3.0    148687\n",
       "NaN      55922\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cat3={'A':1,'B':2,'C':3}\n",
    "df_new_merchant_trans.category_3=df_new_merchant_trans.category_3.map(d_cat3)\n",
    "df_new_merchant_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cat3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This means that we don't have any card_id which have only NaN values in category_3. So we can jump to changing nan values in each card id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1    2.0\n",
       "C_ID_0001238066    2.0\n",
       "C_ID_0001506ef0    1.0\n",
       "C_ID_0001793786    1.0\n",
       "C_ID_000183fdda    2.0\n",
       "Name: authorized_flag, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.reset_index(inplace=True)\n",
    "category_3_count=df_new_merchant_trans.groupby(['card_id','category_3']).count()\n",
    "category_3_count=category_3_count.authorized_flag\n",
    "category_3_count_max=category_3_count.groupby(level=0).idxmax()\n",
    "category_3_count_max=category_3_count_max.apply(lambda x: x[1])\n",
    "category_3_count_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check again what was before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    922244\n",
       " 2.0    836178\n",
       " 3.0    148687\n",
       "NaN      55922\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.set_index('card_id',inplace=True)\n",
    "df_new_merchant_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    922575\n",
       " 2.0    883126\n",
       " 3.0    154744\n",
       "NaN       2586\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.category_3=df_new_merchant_trans.category_3.fillna(category_3_count_max)\n",
    "df_new_merchant_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are still categories which are Nan. Maybe we can get them from historical transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    15412531\n",
       "B    11833535\n",
       "C     1866295\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_hist_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/historical_transactions.csv')\n",
    "#df_hist_trans=reduce_mem_usage(df_hist_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans.category_3=df_hist_trans.category_3.map(d_cat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1    2\n",
       "C_ID_0001238066    2\n",
       "C_ID_0001506ef0    1\n",
       "C_ID_0001793786    1\n",
       "C_ID_000183fdda    2\n",
       "Name: authorized_flag, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_3_count_h=df_hist_trans.groupby(['card_id','category_3']).count()\n",
    "category_3_count_h=category_3_count_h.authorized_flag\n",
    "category_3_count_h_max=category_3_count_h.groupby(level=0).idxmax()\n",
    "category_3_count_h_max=category_3_count_h_max.apply(lambda x: x[1])\n",
    "category_3_count_h_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    922582\n",
       "2.0    884860\n",
       "3.0    155589\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.category_3=df_new_merchant_trans.category_3.fillna(category_3_count_h_max)\n",
    "df_new_merchant_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    922582\n",
       "B    884860\n",
       "C    155589\n",
       "Name: category_3, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.category_3=df_new_merchant_trans.category_3.map(d_cat3_inv)\n",
    "df_new_merchant_trans.category_3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good we are able to remove all nan values by using historic transactions for category_3\n",
    "### Now, let's work on 'merchant_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                26216\n",
       "M_ID_00a6ca8a8a    23018\n",
       "M_ID_cd2c0b07e9    19118\n",
       "M_ID_9139332ccc    14220\n",
       "M_ID_50f575c681    13778\n",
       "Name: merchant_id, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.merchant_id.value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 13)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans[df_new_merchant_trans.merchant_id.isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_new_merchant_trans[df_new_merchant_trans.merchant_id.isnull()].index.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost all of them are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1    M_ID_00a6ca8a8a\n",
       "C_ID_0001238066    M_ID_00a6ca8a8a\n",
       "C_ID_0001506ef0    M_ID_ab756f937e\n",
       "C_ID_0001793786    M_ID_0360f86430\n",
       "C_ID_000183fdda    M_ID_113378fe3b\n",
       "Name: authorized_flag, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.reset_index(inplace=True)\n",
    "merchant_id_count=df_new_merchant_trans.groupby(['card_id','merchant_id']).count()\n",
    "merchant_id_count=merchant_id_count.authorized_flag\n",
    "merchant_id_count_max=merchant_id_count.groupby(level=0).idxmax()\n",
    "merchant_id_count_max=merchant_id_count_max.apply(lambda x: x[1])\n",
    "merchant_id_count_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                26216\n",
       "M_ID_00a6ca8a8a    23018\n",
       "M_ID_cd2c0b07e9    19118\n",
       "M_ID_9139332ccc    14220\n",
       "M_ID_50f575c681    13778\n",
       "Name: merchant_id, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.merchant_id=df_new_merchant_trans.merchant_id.fillna(merchant_id_count_max)\n",
    "df_new_merchant_trans.merchant_id.value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It doesn't help at all. So, let's use data from historical transactions.\n",
    "### It seems that historic transaction doesn't help as well. Probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hist_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/historical_transactions.csv')\n",
    "#df_hist_trans=reduce_mem_usage(df_hist_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1    M_ID_9400cf2342\n",
       "C_ID_0001238066    M_ID_d17aabd756\n",
       "C_ID_0001506ef0    M_ID_b1fc88154d\n",
       "C_ID_0001793786    M_ID_923d57de8d\n",
       "C_ID_000183fdda    M_ID_f9cfe0a43b\n",
       "Name: authorized_flag, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_id_count_h=df_hist_trans.groupby(['card_id','merchant_id']).count()\n",
    "merchant_id_count_h=merchant_id_count_h.authorized_flag\n",
    "merchant_id_count_max_h=merchant_id_count_h.groupby(level=0).idxmax()\n",
    "merchant_id_count_max_h=merchant_id_count_max_h.apply(lambda x: x[1])\n",
    "merchant_id_count_max_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                26216\n",
       "M_ID_00a6ca8a8a    23018\n",
       "M_ID_cd2c0b07e9    19118\n",
       "M_ID_9139332ccc    14220\n",
       "M_ID_50f575c681    13778\n",
       "Name: merchant_id, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.merchant_id=df_new_merchant_trans.merchant_id.fillna(merchant_id_count_max_h)\n",
    "df_new_merchant_trans.merchant_id.value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems that historic transaction doesn't help as well. Probably, those card_id with nan values appear only in new transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_id_nan=df_new_merchant_trans[df_new_merchant_trans.merchant_id.isnull()].card_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M_ID_00a6ca8a8a    117564\n",
       "M_ID_e5374dabc0     38087\n",
       "M_ID_9139332ccc     26338\n",
       "M_ID_50f575c681     18789\n",
       "M_ID_5ba019a379     16390\n",
       "M_ID_fc7d7969c3     13282\n",
       "M_ID_f86439cec0     10975\n",
       "M_ID_1f4773aa76     10091\n",
       "M_ID_98b342c0e3      9857\n",
       "M_ID_d855771cd9      8569\n",
       "M_ID_cd2c0b07e9      8220\n",
       "M_ID_86be58d7e0      7555\n",
       "M_ID_b9dcf28cb9      7378\n",
       "M_ID_2637773dd2      6833\n",
       "M_ID_82a30d9203      6532\n",
       "M_ID_b98db225f5      6506\n",
       "M_ID_6f274b9340      5598\n",
       "M_ID_940fb4498f      5445\n",
       "M_ID_c03b62d83d      5376\n",
       "M_ID_57df19bf28      5061\n",
       "M_ID_48257bb851      4820\n",
       "M_ID_820c7b73c8      4691\n",
       "M_ID_445742726b      4688\n",
       "M_ID_deb43ff012      4538\n",
       "M_ID_a9d91682ad      4436\n",
       "M_ID_26d4fadb60      4220\n",
       "M_ID_1ac6bbc867      4210\n",
       "M_ID_7c5e93af2f      4137\n",
       "M_ID_b5b80addf5      4110\n",
       "M_ID_59764e8cb1      3823\n",
       "                    ...  \n",
       "M_ID_9e1b313e1d         1\n",
       "M_ID_8f71384293         1\n",
       "M_ID_9373c4c47c         1\n",
       "M_ID_5caab2936b         1\n",
       "M_ID_7878f48877         1\n",
       "M_ID_d0790827e6         1\n",
       "M_ID_fbc8ecda4b         1\n",
       "M_ID_d5c415fdf1         1\n",
       "M_ID_d4d31275f1         1\n",
       "M_ID_675f637c95         1\n",
       "M_ID_6ae8c91be3         1\n",
       "M_ID_d473963538         1\n",
       "M_ID_4eb12cc902         1\n",
       "M_ID_f6cebe42ad         1\n",
       "M_ID_69cc914733         1\n",
       "M_ID_d4b93c08df         1\n",
       "M_ID_fda176ed1f         1\n",
       "M_ID_a6debc845d         1\n",
       "M_ID_a46e4bb5df         1\n",
       "M_ID_b8b1d34e6f         1\n",
       "M_ID_fccfc16918         1\n",
       "M_ID_e47349519a         1\n",
       "M_ID_198dfa62dd         1\n",
       "M_ID_d4fc051b0c         1\n",
       "M_ID_f7c777401c         1\n",
       "M_ID_7e47124517         1\n",
       "M_ID_49a253746e         1\n",
       "M_ID_2347a35a9e         1\n",
       "M_ID_a01bccd3ca         1\n",
       "M_ID_866bc4005c         1\n",
       "Name: merchant_id, Length: 181925, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_hist_trans[df_hist_trans.index.isin(car_id_nan)].merchant_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's just change to the most frequent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M_ID_00a6ca8a8a    23018\n",
       "M_ID_cd2c0b07e9    19118\n",
       "M_ID_9139332ccc    14220\n",
       "M_ID_50f575c681    13778\n",
       "M_ID_725a60d404     7029\n",
       "Name: merchant_id, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.merchant_id.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_merchant_trans['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id                 False\n",
       "authorized_flag         False\n",
       "city_id                 False\n",
       "category_1              False\n",
       "installments            False\n",
       "category_3              False\n",
       "merchant_category_id    False\n",
       "merchant_id             False\n",
       "month_lag               False\n",
       "purchase_amount         False\n",
       "purchase_date           False\n",
       "category_2              False\n",
       "state_id                False\n",
       "subsector_id            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchant_trans.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new_merchant_trans.to_csv('C:/Users/user/Documents/Salamat/ELO/new_merchant_transactions_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hist_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/historical_transactions_new.csv')\n",
    "# df_hist_trans=reduce_mem_usage(df_hist_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag         False\n",
       "city_id                 False\n",
       "category_1              False\n",
       "installments            False\n",
       "category_3              False\n",
       "merchant_category_id    False\n",
       "merchant_id             False\n",
       "month_lag               False\n",
       "purchase_amount         False\n",
       "purchase_date           False\n",
       "category_2              False\n",
       "state_id                False\n",
       "subsector_id            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing is started here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/historical_transactions_new.csv')\n",
    "df_new_merchant_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/new_merchant_transactions_new.csv')\n",
    "df_train = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/train.csv')\n",
    "df_test = pd.read_csv('test_without_nan.csv') # nan values filled by first purchase from historic transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n",
      "Mem. usage decreased to 114.20 Mb (45.5% reduction)\n",
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_hist_trans=reduce_mem_usage(df_hist_trans)\n",
    "df_new_merchant_trans=reduce_mem_usage(df_new_merchant_trans)\n",
    "df_train=reduce_mem_usage(df_train)\n",
    "df_test=reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's work with dates . We need reference date at month_lag=0. Let's start with converting purchase_date to datime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans.purchase_date=pd.to_datetime(df_hist_trans.purchase_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_date=df_hist_trans[df_hist_trans.month_lag==0].groupby('card_id').purchase_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_month_lag_nan=df_hist_trans[df_hist_trans.card_id.isin(pur_date.index)==False].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_id_nan_unique=df_hist_trans.loc[index_month_lag_nan].card_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans.purchase_date=pd.to_datetime(df_hist_trans.purchase_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703331</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.733128</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.720386</td>\n",
       "      <td>2017-08-09 22:04:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>2017-09-02 10:06:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>Y</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.722865</td>\n",
       "      <td>2017-03-10 01:14:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id authorized_flag  city_id category_1  installments  \\\n",
       "0  C_ID_4e6213e9bc               Y       88          N             0   \n",
       "1  C_ID_4e6213e9bc               Y       88          N             0   \n",
       "2  C_ID_4e6213e9bc               Y       88          N             0   \n",
       "3  C_ID_4e6213e9bc               Y       88          N             0   \n",
       "4  C_ID_4e6213e9bc               Y       88          N             0   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          A                    80  M_ID_e020e9b302         -8   \n",
       "1          A                   367  M_ID_86ec983688         -7   \n",
       "2          A                    80  M_ID_979ed661fc         -6   \n",
       "3          A                   560  M_ID_e6d5ae8ea6         -5   \n",
       "4          A                    80  M_ID_e020e9b302        -11   \n",
       "\n",
       "   purchase_amount       purchase_date  category_2  state_id  subsector_id  \n",
       "0        -0.703331 2017-06-25 15:33:07         1.0        16            37  \n",
       "1        -0.733128 2017-07-15 12:10:45         1.0        16            16  \n",
       "2        -0.720386 2017-08-09 22:04:29         1.0        16            37  \n",
       "3        -0.735352 2017-09-02 10:06:26         1.0        16            34  \n",
       "4        -0.722865 2017-03-10 01:14:19         1.0        16            37  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1   2018-02-27 05:14:57\n",
       "C_ID_0001238066   2018-02-27 16:18:59\n",
       "C_ID_0001506ef0   2018-02-17 12:33:56\n",
       "C_ID_0001793786   2017-10-31 20:20:18\n",
       "C_ID_000183fdda   2018-02-25 20:57:08\n",
       "Name: purchase_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pur_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293172,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pur_date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325540, 13)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.groupby('card_id').count().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a lot of missing values. I have tried various ways to fillna . Starting from simplest for more in depth\n",
    "1) Just fill it with 2018 Feb\n",
    "\n",
    "2) Check max(month_lag) which is something but not [-1,-11] in hystory_transactions, than just find month_lag==0 purchase date by adding respective month_lag*30. It makes sense to do. However, error was actually higher than previous example (3.699)\n",
    "\n",
    "3) Since  at purchase_date at max(month_lag) might be in between the beggining and the end of the month we might have error of 1 month. Therefore, I tried to add max(purchase_date)+min(purchase_date)/(1+(min(abs(month_lag)+max(abs(month_lag)) (doesn't help)\n",
    "\n",
    "4) Since it doesn't help I decided to change which are in 2018 to Feb 2018\n",
    "\n",
    "### Finally, first one seems to be best solution.\n",
    "\n",
    "I will show how I did it just each of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Filling nan values with 2018 Feb\n",
    "Let's choose values which are NaN in history_transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_id_nan_unique=df_hist_trans[df_hist_trans.card_id.isin(pur_date.index)==False].card_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(card_id_nan_unique)\n",
    "df['month_lag_date']=pd.to_datetime('2008-02') # Seetting all nan values to 2018 Feb\n",
    "df.set_index(0,inplace=True)\n",
    "new_map=df.month_lag_date\n",
    "del df\n",
    "\n",
    "pur_date_1=pur_date.append(new_map)\n",
    "train_month_lag_0=df_train.card_id.map(pur_date_1)\n",
    "test_month_lag_0=df_test.card_id.map(pur_date_1)\n",
    "hist_lag_0=df_hist_trans.card_id.map( pur_date_1)\n",
    "new_mech_lag_0=df_new_merchant_trans.card_id.map(pur_date_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Filling nan values with respect to max(month_lag) in history_transacation. Simply by adding number of days with respect max(month lag) . max(purchase_date)+ abs(max(month_lag))*30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_month_lag_max=df_hist_trans.loc[index_month_lag_nan,['card_id','purchase_date','month_lag']].groupby('card_id').max()\n",
    "hist_month_lag_max_=hist_month_lag_max.copy()\n",
    "new_map=hist_month_lag_max_.purchase_date+ pd.to_timedelta(hist_month_lag_max_.month_lag.abs()*30,unit='D')\n",
    "\n",
    "train_month_lag_0=df_train.card_id.map(new_map)\n",
    "test_month_lag_0=df_test.card_id.map(new_map)\n",
    "hist_lag_0=df_hist_trans.card_id.map( new_map)\n",
    "new_mech_lag_0=df_new_merchant_trans.card_id.map(new_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_date_2=pur_date.append(new_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you just to add to purch. Incomment below lines if u wanna try method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist_month_lag_min_max=df_hist_trans.loc[index_month_lag_nan,['card_id','month_lag','purchase_date']].groupby('card_id').agg(['min','max'])\n",
    "hist_month_lag_min_max['average_month']=(hist_month_lag_min_max['purchase_date']['max']-hist_month_lag_min_max['purchase_date']['min'])\n",
    "hist_month_lag_min_max['average_month']=hist_month_lag_min_max['average_month']/(1-hist_month_lag_min_max.month_lag['min']+hist_month_lag_min_max.month_lag['max'])\n",
    "hist_month_lag_min_max['month_lag_0_date']=hist_month_lag_min_max.purchase_date['max']-hist_month_lag_min_max.month_lag['max']*hist_month_lag_min_max['average_month']\n",
    "new_map=hist_month_lag_min_max.month_lag_0_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_date_3=pur_date.append(new_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you just to add to purch. Incomment below lines if u wanna try method 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_2018=pd.to_datetime('2018-02')\n",
    "new_map=new_map.apply(lambda x: ref_2018 if x.year==2018 else x )\n",
    "pur_date_4=pur_date.append(new_map)\n",
    "# train_month_lag_0=df_train.card_id.map(pur_date_4)\n",
    "# test_month_lag_0=df_test.card_id.map(pur_date_4)\n",
    "# hist_lag_0=df_hist_trans.card_id.map( pur_date_4)\n",
    "# new_mech_lag_0=df_new_merchant_trans.card_id.map(pur_date_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, uncomment and change name of the files if you wanna save results ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_month_lag_0.to_csv('C:/Users/user/Documents/Salamat/ELO/train_month_lag_0_updated.csv',index=False,header=None)\n",
    "# test_month_lag_0.to_csv('C:/Users/user/Documents/Salamat/ELO/test_month_lag_0_updated.csv',index=False,header=None)\n",
    "# hist_lag_0.to_csv('C:/Users/user/Documents/Salamat/ELO/hist_month_lag_0_updated.csv',index=False,header=None)\n",
    "# new_mech_lag_0.to_csv('C:/Users/user/Documents/Salamat/ELO/new_mech_month_lag_0_updated.csv',index=False,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) is the best solution 4) is second best solution\n",
    "## Finally, we fill all missing values now we can do some feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload files if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/train.csv')\n",
    "# df_test = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/test.csv')\n",
    "# df_hist_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/historical_transactions_new.csv')\n",
    "# df_new_merchant_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/new_merchant_transactions_new.csv')\n",
    "\n",
    "# df_train=reduce_mem_usage(df_train)\n",
    "# df_test=reduce_mem_usage(df_test)\n",
    "# df_hist_trans=reduce_mem_usage(df_hist_trans)\n",
    "# df_new_merchant_trans=reduce_mem_usage(df_new_merchant_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_month_lag_0=pd.read_csv('C:/Users/user/Documents/Salamat/ELO/train_month_lag_0.csv',header=None,squeeze=True,parse_dates=[0])\n",
    "# test_month_lag_0=pd.read_csv('C:/Users/user/Documents/Salamat/ELO/test_month_lag_0.csv',header=None,squeeze=True,parse_dates=[0])\n",
    "# hist_lag_0=pd.read_csv('C:/Users/user/Documents/Salamat/ELO/hist_month_lag_0.csv',header=None,squeeze=True,parse_dates=[0])\n",
    "# new_mech_lag_0=pd.read_csv('C:/Users/user/Documents/Salamat/ELO/new_mech_month_lag_0.csv',header=None,squeeze=True,parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "#    df['category_2'].fillna(1.0,inplace=True)\n",
    "#    df['category_3'].fillna('A',inplace=True)\n",
    "#    df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293172,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pur_date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id\n",
       "C_ID_00007093c1   2018-02-27 05:14:57\n",
       "C_ID_0001238066   2018-02-27 16:18:59\n",
       "C_ID_0001506ef0   2018-02-17 12:33:56\n",
       "C_ID_0001793786   2017-10-31 20:20:18\n",
       "C_ID_000183fdda   2018-02-25 20:57:08\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pur_date_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325540,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pur_date_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods=[pur_date_1,pur_date_2,pur_date_3,pur_date_4]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "_uuid": "dda90662d05e22310dd713df106ea07f4b8bccfc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.60176\tvalid_1's rmse: 1.63202\n",
      "[200]\ttraining's rmse: 1.56993\tvalid_1's rmse: 1.60435\n",
      "[300]\ttraining's rmse: 1.55459\tvalid_1's rmse: 1.59345\n",
      "[400]\ttraining's rmse: 1.54471\tvalid_1's rmse: 1.58753\n",
      "[500]\ttraining's rmse: 1.53713\tvalid_1's rmse: 1.58406\n",
      "[600]\ttraining's rmse: 1.5309\tvalid_1's rmse: 1.58191\n",
      "[700]\ttraining's rmse: 1.52548\tvalid_1's rmse: 1.58048\n",
      "[800]\ttraining's rmse: 1.5207\tvalid_1's rmse: 1.5796\n",
      "[900]\ttraining's rmse: 1.51628\tvalid_1's rmse: 1.57893\n",
      "[1000]\ttraining's rmse: 1.51231\tvalid_1's rmse: 1.57851\n",
      "[1100]\ttraining's rmse: 1.50844\tvalid_1's rmse: 1.5782\n",
      "[1200]\ttraining's rmse: 1.50468\tvalid_1's rmse: 1.57801\n",
      "[1300]\ttraining's rmse: 1.50108\tvalid_1's rmse: 1.57784\n",
      "[1400]\ttraining's rmse: 1.49748\tvalid_1's rmse: 1.57768\n",
      "[1500]\ttraining's rmse: 1.49409\tvalid_1's rmse: 1.57754\n",
      "[1600]\ttraining's rmse: 1.49072\tvalid_1's rmse: 1.5775\n",
      "[1700]\ttraining's rmse: 1.48744\tvalid_1's rmse: 1.57749\n",
      "[1800]\ttraining's rmse: 1.48422\tvalid_1's rmse: 1.57737\n",
      "[1900]\ttraining's rmse: 1.481\tvalid_1's rmse: 1.57723\n",
      "[2000]\ttraining's rmse: 1.47783\tvalid_1's rmse: 1.57714\n",
      "[2100]\ttraining's rmse: 1.47473\tvalid_1's rmse: 1.57712\n",
      "[2200]\ttraining's rmse: 1.47161\tvalid_1's rmse: 1.57707\n",
      "[2300]\ttraining's rmse: 1.4686\tvalid_1's rmse: 1.57699\n",
      "[2400]\ttraining's rmse: 1.46553\tvalid_1's rmse: 1.57696\n",
      "[2500]\ttraining's rmse: 1.46252\tvalid_1's rmse: 1.57696\n",
      "Early stopping, best iteration is:\n",
      "[2456]\ttraining's rmse: 1.4638\tvalid_1's rmse: 1.5769\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.60852\tvalid_1's rmse: 1.60459\n",
      "[200]\ttraining's rmse: 1.57616\tvalid_1's rmse: 1.57766\n",
      "[300]\ttraining's rmse: 1.56079\tvalid_1's rmse: 1.56717\n",
      "[400]\ttraining's rmse: 1.55064\tvalid_1's rmse: 1.56151\n",
      "[500]\ttraining's rmse: 1.54301\tvalid_1's rmse: 1.55829\n",
      "[600]\ttraining's rmse: 1.53681\tvalid_1's rmse: 1.55624\n",
      "[700]\ttraining's rmse: 1.53141\tvalid_1's rmse: 1.555\n",
      "[800]\ttraining's rmse: 1.52653\tvalid_1's rmse: 1.55398\n",
      "[900]\ttraining's rmse: 1.52219\tvalid_1's rmse: 1.55338\n",
      "[1000]\ttraining's rmse: 1.51807\tvalid_1's rmse: 1.55296\n",
      "[1100]\ttraining's rmse: 1.51416\tvalid_1's rmse: 1.55268\n",
      "[1200]\ttraining's rmse: 1.51051\tvalid_1's rmse: 1.55249\n",
      "[1300]\ttraining's rmse: 1.50682\tvalid_1's rmse: 1.55234\n",
      "[1400]\ttraining's rmse: 1.50335\tvalid_1's rmse: 1.55216\n",
      "[1500]\ttraining's rmse: 1.49994\tvalid_1's rmse: 1.55201\n",
      "[1600]\ttraining's rmse: 1.49664\tvalid_1's rmse: 1.55191\n",
      "[1700]\ttraining's rmse: 1.49323\tvalid_1's rmse: 1.55184\n",
      "[1800]\ttraining's rmse: 1.48994\tvalid_1's rmse: 1.55183\n",
      "[1900]\ttraining's rmse: 1.48658\tvalid_1's rmse: 1.55172\n",
      "[2000]\ttraining's rmse: 1.48346\tvalid_1's rmse: 1.55161\n",
      "[2100]\ttraining's rmse: 1.48024\tvalid_1's rmse: 1.55156\n",
      "[2200]\ttraining's rmse: 1.47716\tvalid_1's rmse: 1.55156\n",
      "Early stopping, best iteration is:\n",
      "[2138]\ttraining's rmse: 1.47911\tvalid_1's rmse: 1.55153\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.60259\tvalid_1's rmse: 1.62965\n",
      "[200]\ttraining's rmse: 1.57077\tvalid_1's rmse: 1.60142\n",
      "[300]\ttraining's rmse: 1.55555\tvalid_1's rmse: 1.58981\n",
      "[400]\ttraining's rmse: 1.54569\tvalid_1's rmse: 1.58368\n",
      "[500]\ttraining's rmse: 1.53813\tvalid_1's rmse: 1.57988\n",
      "[600]\ttraining's rmse: 1.53199\tvalid_1's rmse: 1.57761\n",
      "[700]\ttraining's rmse: 1.52668\tvalid_1's rmse: 1.5762\n",
      "[800]\ttraining's rmse: 1.52189\tvalid_1's rmse: 1.57529\n",
      "[900]\ttraining's rmse: 1.51757\tvalid_1's rmse: 1.57458\n",
      "[1000]\ttraining's rmse: 1.51353\tvalid_1's rmse: 1.5741\n",
      "[1100]\ttraining's rmse: 1.50962\tvalid_1's rmse: 1.57373\n",
      "[1200]\ttraining's rmse: 1.50601\tvalid_1's rmse: 1.57342\n",
      "[1300]\ttraining's rmse: 1.5025\tvalid_1's rmse: 1.57321\n",
      "[1400]\ttraining's rmse: 1.49901\tvalid_1's rmse: 1.57292\n",
      "[1500]\ttraining's rmse: 1.49557\tvalid_1's rmse: 1.57275\n",
      "[1600]\ttraining's rmse: 1.49235\tvalid_1's rmse: 1.57257\n",
      "[1700]\ttraining's rmse: 1.48914\tvalid_1's rmse: 1.57239\n",
      "[1800]\ttraining's rmse: 1.48595\tvalid_1's rmse: 1.57231\n",
      "[1900]\ttraining's rmse: 1.48282\tvalid_1's rmse: 1.57221\n",
      "[2000]\ttraining's rmse: 1.47963\tvalid_1's rmse: 1.5721\n",
      "[2100]\ttraining's rmse: 1.47666\tvalid_1's rmse: 1.57203\n",
      "[2200]\ttraining's rmse: 1.47359\tvalid_1's rmse: 1.57188\n",
      "[2300]\ttraining's rmse: 1.47067\tvalid_1's rmse: 1.57184\n",
      "[2400]\ttraining's rmse: 1.46771\tvalid_1's rmse: 1.57176\n",
      "[2500]\ttraining's rmse: 1.46475\tvalid_1's rmse: 1.57173\n",
      "[2600]\ttraining's rmse: 1.46184\tvalid_1's rmse: 1.57163\n",
      "[2700]\ttraining's rmse: 1.45892\tvalid_1's rmse: 1.57152\n",
      "[2800]\ttraining's rmse: 1.45592\tvalid_1's rmse: 1.57149\n",
      "Early stopping, best iteration is:\n",
      "[2764]\ttraining's rmse: 1.457\tvalid_1's rmse: 1.57145\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.60702\tvalid_1's rmse: 1.61101\n",
      "[200]\ttraining's rmse: 1.57533\tvalid_1's rmse: 1.58306\n",
      "[300]\ttraining's rmse: 1.56012\tvalid_1's rmse: 1.57157\n",
      "[400]\ttraining's rmse: 1.5503\tvalid_1's rmse: 1.56533\n",
      "[500]\ttraining's rmse: 1.54281\tvalid_1's rmse: 1.56174\n",
      "[600]\ttraining's rmse: 1.53663\tvalid_1's rmse: 1.55947\n",
      "[700]\ttraining's rmse: 1.53129\tvalid_1's rmse: 1.558\n",
      "[800]\ttraining's rmse: 1.52649\tvalid_1's rmse: 1.55711\n",
      "[900]\ttraining's rmse: 1.5221\tvalid_1's rmse: 1.55651\n",
      "[1000]\ttraining's rmse: 1.51802\tvalid_1's rmse: 1.55602\n",
      "[1100]\ttraining's rmse: 1.51411\tvalid_1's rmse: 1.55568\n",
      "[1200]\ttraining's rmse: 1.51041\tvalid_1's rmse: 1.55538\n",
      "[1300]\ttraining's rmse: 1.50678\tvalid_1's rmse: 1.55509\n",
      "[1400]\ttraining's rmse: 1.50323\tvalid_1's rmse: 1.55487\n",
      "[1500]\ttraining's rmse: 1.49977\tvalid_1's rmse: 1.55469\n",
      "[1600]\ttraining's rmse: 1.49643\tvalid_1's rmse: 1.55466\n",
      "[1700]\ttraining's rmse: 1.49315\tvalid_1's rmse: 1.55458\n",
      "[1800]\ttraining's rmse: 1.48995\tvalid_1's rmse: 1.55448\n",
      "[1900]\ttraining's rmse: 1.48667\tvalid_1's rmse: 1.55439\n",
      "[2000]\ttraining's rmse: 1.48343\tvalid_1's rmse: 1.55432\n",
      "[2100]\ttraining's rmse: 1.48023\tvalid_1's rmse: 1.55431\n",
      "[2200]\ttraining's rmse: 1.47716\tvalid_1's rmse: 1.55428\n",
      "[2300]\ttraining's rmse: 1.47403\tvalid_1's rmse: 1.55418\n",
      "[2400]\ttraining's rmse: 1.4709\tvalid_1's rmse: 1.5541\n",
      "[2500]\ttraining's rmse: 1.46774\tvalid_1's rmse: 1.55402\n",
      "[2600]\ttraining's rmse: 1.46467\tvalid_1's rmse: 1.55398\n",
      "[2700]\ttraining's rmse: 1.46177\tvalid_1's rmse: 1.554\n",
      "Early stopping, best iteration is:\n",
      "[2609]\ttraining's rmse: 1.46442\tvalid_1's rmse: 1.55397\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 1.61506\tvalid_1's rmse: 1.57905\n",
      "[200]\ttraining's rmse: 1.58327\tvalid_1's rmse: 1.55103\n",
      "[300]\ttraining's rmse: 1.56791\tvalid_1's rmse: 1.53971\n",
      "[400]\ttraining's rmse: 1.55792\tvalid_1's rmse: 1.53375\n",
      "[500]\ttraining's rmse: 1.55028\tvalid_1's rmse: 1.53006\n",
      "[600]\ttraining's rmse: 1.54404\tvalid_1's rmse: 1.52786\n",
      "[700]\ttraining's rmse: 1.53865\tvalid_1's rmse: 1.52647\n",
      "[800]\ttraining's rmse: 1.53392\tvalid_1's rmse: 1.52545\n",
      "[900]\ttraining's rmse: 1.52956\tvalid_1's rmse: 1.52477\n",
      "[1000]\ttraining's rmse: 1.52549\tvalid_1's rmse: 1.52422\n",
      "[1100]\ttraining's rmse: 1.52149\tvalid_1's rmse: 1.52388\n",
      "[1200]\ttraining's rmse: 1.51774\tvalid_1's rmse: 1.52358\n",
      "[1300]\ttraining's rmse: 1.51417\tvalid_1's rmse: 1.52337\n",
      "[1400]\ttraining's rmse: 1.51059\tvalid_1's rmse: 1.52316\n",
      "[1500]\ttraining's rmse: 1.50708\tvalid_1's rmse: 1.52301\n",
      "[1600]\ttraining's rmse: 1.50375\tvalid_1's rmse: 1.52283\n",
      "[1700]\ttraining's rmse: 1.5004\tvalid_1's rmse: 1.52269\n",
      "[1800]\ttraining's rmse: 1.49706\tvalid_1's rmse: 1.52254\n",
      "[1900]\ttraining's rmse: 1.49383\tvalid_1's rmse: 1.52236\n",
      "Early stopping, best iteration is:\n",
      "[1899]\ttraining's rmse: 1.49386\tvalid_1's rmse: 1.52236\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "CV_error=[]\n",
    "#methods=[pur_date_1,pur_date_2,pur_date_3,pur_date_4]\n",
    "methods=[pur_date_4]\n",
    "for method in methods:\n",
    "    df_hist_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/historical_transactions_new.csv')\n",
    "    df_new_merchant_trans = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/new_merchant_transactions_new.csv')\n",
    "    df_train = pd.read_csv('C:/Users/user/Documents/Salamat/ELO/train.csv')\n",
    "    df_test = pd.read_csv('test_without_nan.csv') # nan values filled by first purchase from historic transactions\n",
    "    \n",
    "    train_month_lag_0=df_train.card_id.map(new_map)\n",
    "    test_month_lag_0=df_test.card_id.map(new_map)\n",
    "    hist_lag_0=df_hist_trans.card_id.map( new_map)\n",
    "    new_mech_lag_0=df_new_merchant_trans.card_id.map(new_map)\n",
    "    \n",
    "    \n",
    "    #I we can take weekofyear,day of week, weekend as extra parameter which I didn't. I am not sure if month diff is correct. Still confused about this issue\n",
    "    \n",
    "    for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "        df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "        df['year'] = df['purchase_date'].dt.year\n",
    "        df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "        df['month'] = df['purchase_date'].dt.month\n",
    "        df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "        df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n",
    "        df['hour'] = df['purchase_date'].dt.hour\n",
    "        df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "        df['category_1'] = df['category_1'].map({'Y':1, 'N':0})\n",
    "        df['month_diff'] = ((df['card_id'].map(method) - df['purchase_date']).dt.days)//30\n",
    "        df['month_diff'] += df['month_lag']\n",
    "        \n",
    "        #https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/73244\n",
    "        #df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "        #df['month_diff'] += df['month_lag']\n",
    "\n",
    "    # We will use our extracted values for reference. From month_lag at zero (max)    \n",
    "\n",
    "#     df_hist_trans['month_diff'] = ((df_hist_trans['card_id'].map(method) - df_hist_trans['purchase_date']).dt.days)//30\n",
    "#     df_hist_trans['month_diff'] += df_hist_trans['month_lag']\n",
    "\n",
    "#     df_new_merchant_trans['month_diff'] = ((df_new_merchant_trans['card_id'].map(method) - df_new_merchant_trans['purchase_date']).dt.days)//30\n",
    "#     df_new_merchant_trans['month_diff'] += df_new_merchant_trans['month_lag']\n",
    "\n",
    "\n",
    "    aggs = {}\n",
    "    for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id']:\n",
    "        aggs[col] = ['nunique']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "    aggs['installments'] = ['sum','max','min','mean','var']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var']\n",
    "    aggs['month_diff'] = ['mean']\n",
    "    aggs['authorized_flag'] = ['sum', 'mean']\n",
    "    aggs['weekend'] = ['sum', 'mean']\n",
    "    aggs['category_1'] = ['sum', 'mean']\n",
    "    aggs['card_id'] = ['size']\n",
    "\n",
    "    for col in ['category_2','category_3']:\n",
    "        df_hist_trans[col+'_mean'] = df_hist_trans.groupby([col])['purchase_amount'].transform('mean')\n",
    "        aggs[col+'_mean'] = ['mean']    \n",
    "\n",
    "    new_columns = get_new_columns('hist',aggs)\n",
    "    df_hist_trans_group = df_hist_trans.groupby('card_id').agg(aggs)\n",
    "    df_hist_trans_group.columns = new_columns\n",
    "    df_hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "    df_hist_trans_group['hist_purchase_date_diff'] = (df_hist_trans_group['hist_purchase_date_max'] - df_hist_trans_group['hist_purchase_date_min']).dt.days\n",
    "    df_hist_trans_group['hist_purchase_date_average'] = df_hist_trans_group['hist_purchase_date_diff']/df_hist_trans_group['hist_card_id_size']\n",
    "\n",
    "    #df_hist_trans_group['hist_purchase_date_uptonow'] = (datetime.datetime.today() - df_hist_trans_group['hist_purchase_date_max']).dt.days\n",
    "    #df_hist_trans_group['hist_purchase_date_uptonow'] = (hist_lag_0 - df_hist_trans_group['hist_purchase_date_max']).dt.days\n",
    "\n",
    "    df_hist_trans_group['hist_purchase_date_uptonow'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group['hist_purchase_date_max']).dt.days\n",
    "\n",
    "\n",
    "\n",
    "    df_train = df_train.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "    df_test = df_test.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "    #del df_hist_trans_group;gc.collect()\n",
    "\n",
    "    aggs = {}\n",
    "    for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id']:\n",
    "        aggs[col] = ['nunique']\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "    aggs['installments'] = ['sum','max','min','mean','var']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var']\n",
    "    aggs['month_diff'] = ['mean']\n",
    "    aggs['weekend'] = ['sum', 'mean']\n",
    "    aggs['category_1'] = ['sum', 'mean']\n",
    "    aggs['card_id'] = ['size']\n",
    "\n",
    "    for col in ['category_2','category_3']:\n",
    "        df_new_merchant_trans[col+'_mean'] = df_new_merchant_trans.groupby([col])['purchase_amount'].transform('mean')\n",
    "        aggs[col+'_mean'] = ['mean']\n",
    "\n",
    "    new_columns = get_new_columns('new_hist',aggs)\n",
    "    df_hist_trans_group = df_new_merchant_trans.groupby('card_id').agg(aggs)\n",
    "    df_hist_trans_group.columns = new_columns\n",
    "    df_hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "    df_hist_trans_group['new_hist_purchase_date_diff'] = (df_hist_trans_group['new_hist_purchase_date_max'] - df_hist_trans_group['new_hist_purchase_date_min']).dt.days\n",
    "    df_hist_trans_group['new_hist_purchase_date_average'] = df_hist_trans_group['new_hist_purchase_date_diff']/df_hist_trans_group['new_hist_card_id_size']\n",
    "\n",
    "    #df_hist_trans_group['new_hist_purchase_date_uptonow'] = (datetime.datetime.today() - df_hist_trans_group['new_hist_purchase_date_max']).dt.days\n",
    "    #df_hist_trans_group['new_hist_purchase_date_uptonow'] = (new_mech_lag_0 - df_hist_trans_group['new_hist_purchase_date_max']).dt.days\n",
    "\n",
    "\n",
    "    df_hist_trans_group['new_hist_purchase_date_uptonow'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group['new_hist_purchase_date_max']).dt.days\n",
    "\n",
    "\n",
    "\n",
    "    df_train = df_train.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "    df_test = df_test.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "    #del df_hist_trans_group;gc.collect()\n",
    "\n",
    "    df_train['outliers'] = 0\n",
    "    df_train.loc[df_train['target'] < -30, 'outliers'] = 1\n",
    "    df_train['outliers'].value_counts()\n",
    "\n",
    "\n",
    "    for df in [df_train,df_test]:\n",
    "        df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "        df['dayofweek'] = df['first_active_month'].dt.dayofweek\n",
    "        df['weekofyear'] = df['first_active_month'].dt.weekofyear\n",
    "        df['month'] = df['first_active_month'].dt.month\n",
    "\n",
    "        #df['elapsed_time'] = (datetime.datetime.today() - df['first_active_month']).dt.days\n",
    "        df['elapsed_time'] = (df['card_id'].map(method) - df['first_active_month']).dt.days\n",
    "\n",
    "        df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "        df['new_hist_first_buy'] = (df['new_hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "        for f in ['hist_purchase_date_max','hist_purchase_date_min','new_hist_purchase_date_max',\\\n",
    "                         'new_hist_purchase_date_min']:\n",
    "            df[f] = df[f].astype(np.int64) * 1e-9\n",
    "        df['card_id_total'] = df['new_hist_card_id_size']+df['hist_card_id_size']\n",
    "        df['purchase_amount_total'] = df['new_hist_purchase_amount_sum']+df['hist_purchase_amount_sum']\n",
    "\n",
    "#     for f in ['feature_1','feature_2','feature_3']:\n",
    "#         order_label = df_train.groupby([f])['outliers'].mean()\n",
    "#         df_train[f] = df_train[f].map(order_label)\n",
    "#         df_test[f] = df_test[f].map(order_label)\n",
    "\n",
    "\n",
    "    ### We will change only elapsed time\n",
    "\n",
    "    #df_train['elapsed_time'] = (df_train['card_id'].map(method) - df_train['first_active_month']).dt.days\n",
    "    #df_test['elapsed_time'] = (df_test['card_id'].map(method) - df_test['first_active_month']).dt.days  \n",
    "\n",
    "    df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','target','outliers']]\n",
    "    df_train=df_train[df_train.outliers==0]\n",
    "    target = df_train['target']\n",
    "    #del df_train['target']\n",
    "\n",
    "    param = {'num_leaves': 31,\n",
    "             'min_data_in_leaf': 30, \n",
    "             'objective':'regression',\n",
    "             'max_depth': -1,\n",
    "             'learning_rate': 0.01,\n",
    "             \"min_child_samples\": 20,\n",
    "             \"boosting\": \"gbdt\",\n",
    "             \"feature_fraction\": 0.9,\n",
    "             \"bagging_freq\": 1,\n",
    "             \"bagging_fraction\": 0.9 ,\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"verbosity\": -1,\n",
    "             \"nthread\": 4,\n",
    "             \"random_state\": 4590}\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx],categorical_feature=['feature_1','feature_2','feature_3'])#, categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][df_train_columns], label=target.iloc[val_idx],categorical_feature=['feature_1', 'feature_2','feature_3'])#, categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"Feature\"] = df_train_columns\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    CV_error.append(np.sqrt(mean_squared_error(oof, target)))\n",
    "    results.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48264799, -0.28098615, -0.39777551, ...,  1.05381595,\n",
       "       -0.74629051,  0.07038839])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_outlier=pd.read_csv(\"chau_feature_engineering_date_fixed_4.csv\")\n",
    "model_without_outlier=pd.read_csv(\"chau_pur_date_4_trained_wo_out.csv\")\n",
    "model_with_outlier.set_index('card_id',inplace=True)\n",
    "model_without_outlier.set_index('card_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_mixed=model_without_outlier.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_mixed.loc[map2.index]=model_with_outlier.loc[map2.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_mixed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_mixed.to_csv(\"chau_feature_engineering_date_fixed_4_mixed_outliers.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_high_prob=map2[map2.target>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_6ab591cf62</th>\n",
       "      <td>0.578366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_aae50409e7</th>\n",
       "      <td>0.574478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_bced41d837</th>\n",
       "      <td>0.573339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_ac114ef831</th>\n",
       "      <td>0.568470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_86ddafb51c</th>\n",
       "      <td>0.568377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_a74b12dcf8</th>\n",
       "      <td>0.544721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_65a0e440f8</th>\n",
       "      <td>0.542128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_e7f772dfc0</th>\n",
       "      <td>0.534590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_e54aeb08f7</th>\n",
       "      <td>0.515356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_833aa2f7af</th>\n",
       "      <td>0.502522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   target\n",
       "card_id                  \n",
       "C_ID_6ab591cf62  0.578366\n",
       "C_ID_aae50409e7  0.574478\n",
       "C_ID_bced41d837  0.573339\n",
       "C_ID_ac114ef831  0.568470\n",
       "C_ID_86ddafb51c  0.568377\n",
       "C_ID_a74b12dcf8  0.544721\n",
       "C_ID_65a0e440f8  0.542128\n",
       "C_ID_e7f772dfc0  0.534590\n",
       "C_ID_e54aeb08f7  0.515356\n",
       "C_ID_833aa2f7af  0.502522"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_high_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>C_ID_a74b12dcf8</td>\n",
       "      <td>-25.262202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20556</th>\n",
       "      <td>C_ID_aae50409e7</td>\n",
       "      <td>-21.672768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27982</th>\n",
       "      <td>C_ID_e7f772dfc0</td>\n",
       "      <td>-18.387164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30248</th>\n",
       "      <td>C_ID_65a0e440f8</td>\n",
       "      <td>-15.969893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32446</th>\n",
       "      <td>C_ID_ac114ef831</td>\n",
       "      <td>-21.413514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70804</th>\n",
       "      <td>C_ID_833aa2f7af</td>\n",
       "      <td>-15.424178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77945</th>\n",
       "      <td>C_ID_6ab591cf62</td>\n",
       "      <td>-20.672101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80840</th>\n",
       "      <td>C_ID_bced41d837</td>\n",
       "      <td>-15.642591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104991</th>\n",
       "      <td>C_ID_86ddafb51c</td>\n",
       "      <td>-20.197719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114106</th>\n",
       "      <td>C_ID_e54aeb08f7</td>\n",
       "      <td>-17.926073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id     target\n",
       "7750    C_ID_a74b12dcf8 -25.262202\n",
       "20556   C_ID_aae50409e7 -21.672768\n",
       "27982   C_ID_e7f772dfc0 -18.387164\n",
       "30248   C_ID_65a0e440f8 -15.969893\n",
       "32446   C_ID_ac114ef831 -21.413514\n",
       "70804   C_ID_833aa2f7af -15.424178\n",
       "77945   C_ID_6ab591cf62 -20.672101\n",
       "80840   C_ID_bced41d837 -15.642591\n",
       "104991  C_ID_86ddafb51c -20.197719\n",
       "114106  C_ID_e54aeb08f7 -17.926073"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_mixed[model_with_mixed.card_id.isin(index_high_prob.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_mixed_2=model_with_mixed.copy()\n",
    "model_with_mixed_2.set_index('card_id',inplace=True)\n",
    "model_with_mixed_2.loc[index_high_prob.index]=-33.21928095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_mixed_2.reset_index(inplace=True)\n",
    "model_with_mixed.to_csv(\"chau_feature_engineering_date_fixed_4_mixed_outliers_whighprop.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#sklearn.metrics.roc_auc_score(y_true, y_score, average=macro, sample_weight=None, max_fpr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"chau_pur_date_4_trained_wo_out.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_out=pd.read_csv(\"predicted_outliers_test.csv\",squeeze=True)\n",
    "map_out.set_index(\"card_id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1=map_out.sort_values('target',ascending=False).head(1340)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1347.4907"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(map_out)*1.09/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ration of outliers\n",
      "0.010930233709890698\n",
      " unique values of outliers\n",
      "[-33.21928095]\n"
     ]
    }
   ],
   "source": [
    "df_train_origina=pd.read_csv('train.csv')\n",
    "print(\"ration of outliers\")\n",
    "print(len(df_train_origina[df_train_origina.target<-20])/len(df_train_origina))\n",
    "print(\" unique values of outliers\")\n",
    "print(df_train_origina[df_train_origina.target<-20].target.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1=map_out.sort_values('target',ascending=False).head(1340)\n",
    "map2=map_out.sort_values('target',ascending=False).head(25000)\n",
    "\n",
    "\n",
    "\n",
    "sub_df=pd.read_csv(\"chau_pur_date_4_trained_wo_out.csv\")\n",
    "sub_df.set_index('card_id',inplace=True)\n",
    "sub_df.loc[map2.index,'target']=-33.21928095\n",
    "sub_df.reset_index(inplace=True)\n",
    "sub_df.to_csv(\"chau_pur_date_4_trained_w_out_25000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that it is same ration than outliers will be ~1340 in test set. Howver, according to their results \n",
    "https://www.kaggle.com/waitingli/combining-your-model-with-a-model-without-outlier\n",
    "they choose first 25000 to be outliers rather than 1340.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":df_train[\"card_id\"].values})\n",
    "sub_df[\"target_predicted\"] = oof\n",
    "sub_df[\"target_real\"]=target\n",
    "sub_df.to_csv(\"predicted_outliers_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_origina=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='purchase_date_'\n",
    "for i in range(1,5):\n",
    "    name_=name+str(i)\n",
    "    sub_df = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "    sub_df[\"target\"] = results[i-1]\n",
    "    sub_df.to_csv(\"chau_feature_engineering_date_fixed_\"+str(i)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"chau_feature_engineering_date_fixed_4_catfeatures.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pur_date_1,pur_date_2,pur_date_3,pur_date_4\n",
    "best seems to be still first and last\n",
    "[3.6503261351619978, 3.652261631810461, 3.6524115687225662, 3.6506695114985384]\n",
    "\n",
    "\n",
    "trying without using maping outliers: CV score \n",
    "3.649842864600676\n",
    "     for f in ['feature_1','feature_2','feature_3']:\n",
    "         order_label = df_train.groupby([f])['outliers'].mean()\n",
    "         df_train[f] = df_train[f].map(order_label)\n",
    "         df_test[f] = df_test[f].map(order_label)\n",
    "         \n",
    "         \n",
    "same as previous with categorical features for fearure_1,2,3\n",
    "3.6491202164373253\n",
    "\n",
    "Same as previous but without outliers: CV_score\n",
    "Outliers have significant effect on the score\n",
    "\n",
    "1.5559535690683506\n",
    "\n",
    "predicting outliers based on pur_date_4\n",
    "log_loss on train\n",
    "0.044014957513606616\n",
    "roc_auc\n",
    "0.903436128739\n",
    "\n",
    "with categorical feature_1,feature_2,feature_3\n",
    "0.0440283251986\n",
    "0.903455034721\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_out=pd.read_csv(\"predicted_outliers_test.csv\",index_col='card_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vfor category_3==0 in history_transactions there is only installment is equal to 0 or -1.\n",
    " 0    15411747\n",
    "-1         784\n",
    "Name: installments, dtype: int64\n",
    "\n",
    "if it is 'B' than various examples will appear: \n",
    "1    11677522\n",
    "-1      156013\n",
    "Name: installments, dtype: int64\n",
    "\n",
    "for 'C':\n",
    "2      666416\n",
    " 3      538207\n",
    " 4      179525\n",
    " 6      132634\n",
    " 10     118827\n",
    " 5      116090\n",
    " 12      55064\n",
    "-1       21362\n",
    " 8       20474\n",
    " 7       10906\n",
    " 9        5772\n",
    " 11        830\n",
    " 999       188\n",
    "Name: installments, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 fixed\n",
    "\n",
    "3.6499271201859389\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40b64481054fa71e692829c7039eccceb31b77fe"
   },
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"Feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances_feature_date_fixed_outlier_prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "355e9c24949b8e5d677fe5a2f117228c3310dab6"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"chau_feature_engineering_3_date_updated3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58c9a5445698e42dfbd9548695290487a2ce171a"
   },
   "source": [
    "**To be continued ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features.groupby('Feature').mean().sort_values('importance',ascending=False).to_csv('feature_importance2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('C:/Users/user/Documents/Salamat/ELO/train_new_lag_updated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('C:/Users/user/Documents/Salamat/ELO/test_new_lag_updated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features.groupby('Feature').mean().sort_values('importance',ascending=False).to_csv('best_features_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target[(target<=1)&(target>=-1)])/len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
