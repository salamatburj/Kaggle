{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6df55b542f152882e00385a0f73198f4e3bc4316"
   },
   "source": [
    "**FEEL FREE TO UPVOTE**  （＾ｖ＾）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "b00db406434116eaef1206208331f97fe0542872"
   },
   "outputs": [],
   "source": [
    "\n",
    "#v20提交成绩得到了3.688， cv 成绩3.6519\n",
    "#使用authorized_flag 进行特征分别处理,收到了奇效\n",
    "#使用countVectorizer 对类别变量进行编码，内存存在压力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "_uuid": "09e0aca6b56b5baa7b76ba12dce4473242d8fc8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in range(10)]\n",
    "a[0:int(10 * 0.2 + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "_uuid": "337eacd2e6e13207d06cb90f9f8cd352d300b323"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_hist_trans = pd.read_csv('../../ELO/historical_transactions.csv')\n",
    "df_new_merchant_trans = pd.read_csv('../../ELO/new_merchant_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "_uuid": "252db1c4842288dc2c4c5a116daa5674073c6daf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n",
      "Mem. usage decreased to 114.20 Mb (45.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_hist_trans = reduce_mem_usage(df_hist_trans)\n",
    "df_new_merchant_trans = reduce_mem_usage(df_new_merchant_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "_uuid": "795c83a0713bc5d21122d425c298aedb5c39dd15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326311"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans['merchant_id'].nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e944bbd9d23a99ea40ceda141d78fb03f6db0f2"
   },
   "source": [
    "**Purchasing Journeys**\n",
    "\n",
    "[An Introduction to Predictive Customer Lifetime Value Modeling](https://www.datascience.com/blog/intro-to-predictive-modeling-for-customer-lifetime-value)\n",
    "\n",
    "![](https://d2mxuefqeaa7sj.cloudfront.net/s_60ECB163AE4078E84C49514ED5D5B38C222B9C0EA718BEA3759DABF297034DEB_1488169955068_file.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "_uuid": "86e05f51244a327e8d196d39e2b04a0e94d98279"
   },
   "outputs": [],
   "source": [
    "hist_monthly_perchase_cnts = df_hist_trans.groupby('card_id').month_lag.value_counts().unstack()\n",
    "hist_monthly_perchase_cnts.fillna(0, inplace=True)\n",
    "hist_monthly_perchase_cnts.columns = [f'hist_per_cnts_month_lag{col}' for col in hist_monthly_perchase_cnts.columns]\n",
    "new_merchant_monthly_perchase_cnts = df_new_merchant_trans.groupby('card_id').month_lag.value_counts().unstack()\n",
    "new_merchant_monthly_perchase_cnts.fillna(0, inplace=True)\n",
    "new_merchant_monthly_perchase_cnts.columns = [f'new_merchant_per_cnts_month_lag{col}' for col in new_merchant_monthly_perchase_cnts.columns]\n",
    "df_train = df_train.join(hist_monthly_perchase_cnts, on='card_id')\n",
    "df_train = df_train.join(new_merchant_monthly_perchase_cnts, on='card_id')\n",
    "df_test = df_test.join(hist_monthly_perchase_cnts, on='card_id')\n",
    "df_test = df_test.join(new_merchant_monthly_perchase_cnts, on='card_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "_uuid": "c410f537770efe831cb5b0206c3224b41e1f53a2"
   },
   "outputs": [],
   "source": [
    "# 结果会从 3.675 变成 3.679 ，so sad\n",
    "# i = 0\n",
    "# aggs = {}\n",
    "# aggs['purchase_amount'] = ['mean']\n",
    "# for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "#     df['purchase_amount'] = df['purchase_amount'].astype(np.float32)\n",
    "#     df_month_purchase_cnts = df.groupby(['card_id','month_lag']).agg(aggs).unstack()\n",
    "#     df_month_purchase_cnts.fillna(0, inplace = True)\n",
    "#     df_train = df_train.join(df_month_purchase_cnts, on = 'card_id')\n",
    "#     df_test = df_test.join(df_month_purchase_cnts, on = 'card_id')\n",
    "#     if i == 0:\n",
    "#         prefix = 'hist_'\n",
    "#     else:\n",
    "#         prefix = 'new_merchant_'\n",
    "#     i += 1\n",
    "#     df_train.columns = [prefix + c[0] + c[1] + str(c[2]) if type(c) is tuple else c for c in df_train.columns ]\n",
    "#     df_test.columns = [prefix + c[0] + c[1] + str(c[2]) if type(c) is tuple else c for c in df_test.columns ]\n",
    "#     del df_month_purchase_cnts\n",
    "#     gc.collect()\n",
    "#     time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "_uuid": "45b6e47a38b5a4a6c277d383b1247b067865f6bb"
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    count = 0\n",
    "    for i in range(1,len(x)):\n",
    "        if x.iloc[i] != x.iloc[i-1]:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "_uuid": "f626b1a935e84bf48faed5d76b80cef8c17c9e82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_merchant_switch_times'], dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_merchant = df_hist_trans[['card_id','purchase_date','merchant_category_id']]\n",
    "df_hist_merchant_sorted = df_hist_merchant.sort_values(by = ['card_id','purchase_date'])\n",
    "switch_merchants = df_hist_merchant_sorted.groupby(by = 'card_id')[['merchant_category_id']].aggregate(lambda x: func(x))\n",
    "switch_merchants.columns = ['customer_merchant_switch_times']\n",
    "switch_merchants.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_merchants.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "_uuid": "774ce8669fe3ed7e23d1cb48732ed7a363b1b50a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_per_cnts_month_lag-13</th>\n",
       "      <th>hist_per_cnts_month_lag-12</th>\n",
       "      <th>hist_per_cnts_month_lag-11</th>\n",
       "      <th>hist_per_cnts_month_lag-10</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_per_cnts_month_lag-6</th>\n",
       "      <th>hist_per_cnts_month_lag-5</th>\n",
       "      <th>hist_per_cnts_month_lag-4</th>\n",
       "      <th>hist_per_cnts_month_lag-3</th>\n",
       "      <th>hist_per_cnts_month_lag-2</th>\n",
       "      <th>hist_per_cnts_month_lag-1</th>\n",
       "      <th>hist_per_cnts_month_lag0</th>\n",
       "      <th>new_merchant_per_cnts_month_lag1</th>\n",
       "      <th>new_merchant_per_cnts_month_lag2</th>\n",
       "      <th>customer_merchant_switch_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0   \n",
       "3            2017-09  C_ID_186d6a6901          4          3          0   \n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  hist_per_cnts_month_lag-13  hist_per_cnts_month_lag-12  \\\n",
       "0 -0.820283                         0.0                         0.0   \n",
       "1  0.392913                         0.0                        21.0   \n",
       "2  0.688056                         6.0                         6.0   \n",
       "3  0.142495                         0.0                         0.0   \n",
       "4 -0.159749                         0.0                         0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-11  hist_per_cnts_month_lag-10  \\\n",
       "0                         0.0                         0.0   \n",
       "1                        22.0                        13.0   \n",
       "2                         5.0                         7.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "                ...                hist_per_cnts_month_lag-6  \\\n",
       "0               ...                                     44.0   \n",
       "1               ...                                     49.0   \n",
       "2               ...                                      2.0   \n",
       "3               ...                                      0.0   \n",
       "4               ...                                      0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-5  hist_per_cnts_month_lag-4  \\\n",
       "0                       20.0                       22.0   \n",
       "1                       14.0                       24.0   \n",
       "2                        1.0                        6.0   \n",
       "3                       11.0                       31.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-3  hist_per_cnts_month_lag-2  \\\n",
       "0                       21.0                       57.0   \n",
       "1                       26.0                       16.0   \n",
       "2                        0.0                        1.0   \n",
       "3                        7.0                        6.0   \n",
       "4                       21.0                       31.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-1  hist_per_cnts_month_lag0  \\\n",
       "0                       21.0                      23.0   \n",
       "1                       47.0                      51.0   \n",
       "2                        2.0                       1.0   \n",
       "3                        6.0                      16.0   \n",
       "4                       46.0                      35.0   \n",
       "\n",
       "   new_merchant_per_cnts_month_lag1  new_merchant_per_cnts_month_lag2  \\\n",
       "0                              12.0                              11.0   \n",
       "1                               3.0                               3.0   \n",
       "2                               0.0                               1.0   \n",
       "3                               2.0                               5.0   \n",
       "4                              16.0                              20.0   \n",
       "\n",
       "   customer_merchant_switch_times  \n",
       "0                             212  \n",
       "1                             300  \n",
       "2                              14  \n",
       "3                              72  \n",
       "4                              87  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.merge(switch_merchants,on='card_id',how='left')\n",
    "df_test = df_test.merge(switch_merchants,on='card_id',how='left')\n",
    "del switch_merchants,df_hist_merchant,df_hist_merchant_sorted\n",
    "gc.collect()\n",
    "time.sleep(5)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "_uuid": "4bdcf9c97640b83ed14aca50aa012dd88471d55e"
   },
   "outputs": [],
   "source": [
    "df_hist_trans.purchase_date=pd.to_datetime(df_hist_trans.purchase_date)\n",
    "pur_date=df_hist_trans[df_hist_trans.month_lag==0].groupby('card_id').purchase_date.max()\n",
    "card_id_nan_unique=df_hist_trans[df_hist_trans.card_id.isin(pur_date.index)==False].card_id.unique()\n",
    "df=pd.DataFrame(card_id_nan_unique)\n",
    "df['month_lag_date']=pd.to_datetime('2018-02') # Seetting all nan values to 2018 Feb\n",
    "df.set_index(0,inplace=True)\n",
    "new_map=df.month_lag_date\n",
    "method=pur_date.append(new_map)\n",
    "del df,pur_date\n",
    "gc.collect()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "_uuid": "71f89a3b8a93b2f2feb2cd0a45f860cde33687be"
   },
   "outputs": [],
   "source": [
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "#     df['category_2'].fillna(1.0,inplace=True)\n",
    "#     df['category_3'].fillna('A',inplace=True)\n",
    "#     df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\n",
    "    #修改特征\n",
    "    df['category_2'].fillna(-1,inplace=True)\n",
    "    df['category_3'].fillna('other',inplace=True)\n",
    "    df['merchant_id'].fillna('other',inplace=True)\n",
    "#     df.loc[df['installments'].isin([999,-1]),'installments'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "_uuid": "dda90662d05e22310dd713df106ea07f4b8bccfc"
   },
   "outputs": [],
   "source": [
    "def get_new_columns(name,aggs):\n",
    "    #for for 写法 nice\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "_uuid": "690ba01a38f524e9345b419200f588f937bc067a"
   },
   "outputs": [],
   "source": [
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['year'] = df['purchase_date'].dt.year\n",
    "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "    df['month'] = df['purchase_date'].dt.month\n",
    "    df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "    df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n",
    "    df['hour'] = df['purchase_date'].dt.hour\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "    df['category_1'] = df['category_1'].map({'Y':1, 'N':0}) \n",
    "    #https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/73244\n",
    "    ##Think about this part!\n",
    "    ## This line of code may be missleading since there is no single ref date. \n",
    "    df['month_diff'] = ((datetime.datetime(2018,6,1) - df['purchase_date']).dt.days)//30 # original code\n",
    "    df['month_diff'] += df['month_lag']\n",
    "    \n",
    "    ## removing 'month_diff' reduces LB score to 3.682\n",
    "    ## This line of code can be also missleading since for new merchant hist it might be negative. But why we care about it.\n",
    "    #df['month_diff'] = ((df['card_id'].map(method) - df['purchase_date']).dt.days)//30 # method that I used in my code\n",
    "    \n",
    "    ##But we already have mongth lag for each purchase! So we don't really need it!\n",
    "    ### month_diff seems to be important feature think more about it\n",
    "    \n",
    "    # This makes it even more irrelevant for my case since it will be equal to zero in most of the cases.So, let's remove it for my case\n",
    "    #df['month_diff'] += df['month_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "_uuid": "52d785dd8bb1eac029fbdeeaae93ffffedc71210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.to_datetime('2018-12-30')-pd.to_datetime('2019-12-30')).days//30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "_uuid": "80aadb70cf47be8cf45b681d73214ace43fe8d1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#因为根据auth_flag 将特征分成了两部分，这里聚合一个全局的auth_flag 特征\n",
    "aggs = {}\n",
    "aggs['purchase_amount'] = ['sum']\n",
    "# aggs['installments'] = ['sum','max','min','mean','var','median']\n",
    "aggs['authorized_flag'] = ['sum', 'mean','std']\n",
    "aggs['card_id'] = ['size']\n",
    "auth_flag = df_hist_trans.groupby(['card_id']).agg(aggs)\n",
    "auth_flag.columns = get_new_columns('auth_flag',aggs)\n",
    "auth_flag.reset_index(inplace=True)\n",
    "df_train = df_train.merge(auth_flag,on='card_id',how='left')\n",
    "df_test = df_test.merge(auth_flag,on='card_id',how='left')\n",
    "del auth_flag\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "_uuid": "49db45166453de5e0509d5e43d52604344954744"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对 authorized_flag进行结果编码\n",
    "aggs = {}\n",
    "for col in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "    df_hist_trans[col+'_auth_mean'] = df_hist_trans.groupby([col])['authorized_flag'].transform('mean')\n",
    "    df_hist_trans[col+'_auth_sum'] = df_hist_trans.groupby([col])['authorized_flag'].transform('sum') \n",
    "    aggs[col+'_auth_mean'] = ['mean']\n",
    "    aggs[col+'_auth_sum'] = ['sum'] \n",
    "auth_encoder = df_hist_trans.groupby(['card_id']).agg(aggs)\n",
    "auth_encoder.columns = get_new_columns('auth_encoder',aggs)\n",
    "auth_encoder.reset_index(inplace=True)\n",
    "df_train = df_train.merge(auth_encoder,on='card_id',how='left')\n",
    "df_test = df_test.merge(auth_encoder,on='card_id',how='left')\n",
    "del auth_encoder\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "_uuid": "5b08ce613977fc59acfdac57c208ba71db6a5ea3"
   },
   "outputs": [],
   "source": [
    "def aggregate_per_month(prefix,history,agg_func):\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = [prefix + '_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = [prefix + '_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True) \n",
    "    return final_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "_uuid": "508c91c2f30371a3bb5a8e5daac36f43749c55c7"
   },
   "outputs": [],
   "source": [
    "# #对授权码 进行按月聚合\n",
    "# agg_func = {'authorized_flag': [ 'sum', 'mean','median']}\n",
    "# final_group =  aggregate_per_month('agg_per_month_total',df_hist_trans,agg_func) \n",
    "# df_train = df_train.merge(final_group,on='card_id',how='left')\n",
    "# df_test = df_test.merge(final_group,on='card_id',how='left')\n",
    "# del final_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "_uuid": "6dfd525f8227507cad2d8d3a6144bb1708f7e462"
   },
   "outputs": [],
   "source": [
    "authorized_transactions = df_hist_trans[df_hist_trans['authorized_flag'] == 1]\n",
    "df_hist_trans = df_hist_trans[df_hist_trans['authorized_flag'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "_uuid": "22f8b5af830b7591197956f40b8b575d1e75c713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2516909, 33)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "_uuid": "53204f1e1752f4e51d96e7c05360898ababc655d"
   },
   "outputs": [],
   "source": [
    "# agg_func = {'purchase_amount': [ 'sum', 'mean', 'min', 'max', 'std']}\n",
    "# final_group =  aggregate_per_month('agg_per_month_auth',authorized_transactions,agg_func) \n",
    "# df_train = df_train.merge(final_group,on='card_id',how='left')\n",
    "# df_test = df_test.merge(final_group,on='card_id',how='left')\n",
    "# del final_group\n",
    "# final_group =  aggregate_per_month('agg_per_month_hist',df_hist_trans,agg_func) \n",
    "# df_train = df_train.merge(final_group,on='card_id',how='left')\n",
    "# df_test = df_test.merge(final_group,on='card_id',how='left')\n",
    "# del final_group\n",
    "# final_group =  aggregate_per_month('agg_per_month_hist_new',df_new_merchant_trans,agg_func) \n",
    "# df_train = df_train.merge(final_group,on='card_id',how='left')\n",
    "# df_test = df_test.merge(final_group,on='card_id',how='left')\n",
    "# del final_group\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "_uuid": "6bc6f16f1dbf38bcb45a9345fd1e789b23f0efb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['outliers'] = 0\n",
    "df_train.loc[df_train['target'] < -30, 'outliers'] = 1\n",
    "df_train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "_uuid": "ddf1d5bb0ade2b22b0f072c208c1506ea64503ea"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for df in [authorized_transactions,df_hist_trans]:\n",
    "    aggs = {}\n",
    "    for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id',\n",
    "                'state_id','city_id']:\n",
    "        aggs[col] = ['nunique']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var','median']\n",
    "    aggs['installments'] = ['sum','max','min','mean','var','median']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var','median']\n",
    "    \n",
    "    ## I also remove this part since it is also irrelevant since it is equivelent to month_lag. But it makes it worser\n",
    "    aggs['month_diff'] = ['mean','median']\n",
    "#     aggs['authorized_flag'] = ['sum', 'mean','median']\n",
    "    aggs['weekend'] = ['sum', 'mean']\n",
    "    aggs['category_1'] = ['sum', 'mean']\n",
    "    aggs['card_id'] = ['size']\n",
    "    #产生交叉特征，内存有问题\n",
    "    features = ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id'\n",
    "               ,'merchant_id']\n",
    "#     for coli in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "#         for colj in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "#             df[coli + colj] = df[coli].astype(str) + df[colj].astype(str)\n",
    "#             features.append(coli + colj)\n",
    "    for col in features:\n",
    "        df[col+'_mean'] = df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        df[col+'_sum'] = df.groupby([col])['purchase_amount'].transform('sum') \n",
    "        aggs[col+'_mean'] = ['mean']\n",
    "        aggs[col+'_sum'] = ['sum'] \n",
    "#         添加特征，使用outlier进行编码\n",
    "#         outliers_mean = df.groupby([col])['outliers'].mean()\n",
    "#         outliers_sum = df.groupby([col])['outliers'].sum()\n",
    "#         df[col+'_outliers_mean'] = df[col].map(outliers_mean)\n",
    "#         df[col+'_outliers_sum'] = df[col].map(outliers_sum)\n",
    "#         aggs[col+'_outliers_mean'] = ['mean']\n",
    "#         aggs[col+'_outliers_sum'] =['sum']   \n",
    "        \n",
    "    if i == 0:\n",
    "        prefix = 'auth_hist'\n",
    "    else:\n",
    "        prefix = 'hist'\n",
    "    new_columns = get_new_columns(prefix,aggs)\n",
    "    i += 1\n",
    "    # df_hist_trans.sort_values(['card_id','purchase_date'],inplace = True)\n",
    "\n",
    "    df_hist_trans_group = df.groupby('card_id').agg(aggs)\n",
    "    df_hist_trans_group.columns = new_columns\n",
    "    df_hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "    df_hist_trans_group[prefix + '_purchase_date_diff'] = (df_hist_trans_group[prefix + '_purchase_date_max'] - df_hist_trans_group[prefix + '_purchase_date_min']).dt.days\n",
    "    df_hist_trans_group[prefix + '_purchase_date_average'] = df_hist_trans_group[prefix + '_purchase_date_diff']/df_hist_trans_group[prefix + '_card_id_size']\n",
    "    ###Think about below line of code  \n",
    "    ###up to now for history means month_lag_0 to purdate_min\n",
    "#     df_hist_trans_group[prefix + '_purchase_date_uptonow'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group[prefix + '_purchase_date_max']).dt.days\n",
    "    ### This is new feature but I change the name to the old name since it makes more sense. Total number of days from first purchase to month lag 0 (until promotion)\n",
    "    df_hist_trans_group[prefix + '_purchase_date_uptonow'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group[prefix + '_purchase_date_min']).dt.days\n",
    "    ### This is old feature but I change the name to [prefix + '_first_purchase'] from [prefix + '_purchase_date_uptonow']\n",
    "    ### since it makes more sense. Number of days for the last purchase from month_lag_0\n",
    "    df_hist_trans_group[prefix + '_first_purchase'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group[prefix + '_purchase_date_max']).dt.days\n",
    "    #下面这个特征考虑了：有的人可能购买频率较低，但是还是忠实粉丝的情况\n",
    "#     df_hist_trans_group[prefix + '_purchase_date_uptonow_ave'] =  df_hist_trans_group[prefix + '_purchase_date_uptonow']/df_hist_trans_group[prefix + '_purchase_date_average']\n",
    "    #每一个card中未授权消费次数\n",
    "#     df_hist_trans_group[prefix + '_unauthorized_number'] = df_hist_trans_group[prefix + '_card_id_size'] - df_hist_trans_group[prefix + '_authorized_flag_sum']\n",
    "    #最近活跃时间，确实是一个强特征，感觉可以再挖出来几个特征，比如最近5次消费时间，最近10次消费时间，如果值比较小，说明最近很活跃\n",
    "    #没有效果\n",
    "    # grouped =  df_hist_trans.groupby('card_id')['purchase_date']\n",
    "    # df_hist_trans_group['hist_purchase_5thdate_uptonow'] =  (datetime.datetime.today() -grouped.shift(5)).dt.days\n",
    "    # df_hist_trans_group['hist_purchase_3thdate_uptonow'] =  (datetime.datetime.today() -grouped.shift(3)).dt.days\n",
    "    # df_hist_trans_group['hist_purchase_10thdate_uptonow'] =  (datetime.datetime.today() -grouped.shift(10)).dt.days\n",
    "    df_train = df_train.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "    df_test = df_test.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "    del df_hist_trans_group\n",
    "    gc.collect()\n",
    "    time.sleep(5)\n",
    "    #内存问题，暂时先放弃\n",
    "#     for col in ['subsector_id','merchant_category_id','state_id','city_id']:\n",
    "#         df[col]=df[col].astype(str)\n",
    "#         grouped = df[['card_id',col]].groupby('card_id')[col].aggregate(lambda x: ' '.join(x))\n",
    "#         cv_fit=cv.fit_transform(grouped)\n",
    "#         cv_df = pd.DataFrame(cv_fit.toarray())\n",
    "#         print(i,col)\n",
    "#         if i == 1:\n",
    "#             cv_df.columns = ['auth' + '_' + col + \"_\" + str(c) for c in cv_df.columns]\n",
    "#         elif i == 2:\n",
    "#              cv_df.columns = ['hist' + '_' + col + \"_\" + str(c) for c in cv_df.columns]\n",
    "#         cv_df['card_id'] = grouped.index\n",
    "#         df_train = df_train.merge(cv_df,on='card_id',how='left')\n",
    "#         df_test = df_test.merge(cv_df,on='card_id',how='left')\n",
    "#         del cv_df,grouped\n",
    "#         gc.collect()\n",
    "    del df\n",
    "    gc.collect()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "_uuid": "71cd4c771352a36807b366ebdf305469ee22a485"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_per_cnts_month_lag-13</th>\n",
       "      <th>hist_per_cnts_month_lag-12</th>\n",
       "      <th>hist_per_cnts_month_lag-11</th>\n",
       "      <th>hist_per_cnts_month_lag-10</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_merchant_category_id_mean_mean</th>\n",
       "      <th>hist_merchant_category_id_sum_sum</th>\n",
       "      <th>hist_city_id_mean_mean</th>\n",
       "      <th>hist_city_id_sum_sum</th>\n",
       "      <th>hist_merchant_id_mean_mean</th>\n",
       "      <th>hist_merchant_id_sum_sum</th>\n",
       "      <th>hist_purchase_date_diff</th>\n",
       "      <th>hist_purchase_date_average</th>\n",
       "      <th>hist_purchase_date_uptonow</th>\n",
       "      <th>hist_first_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.846728</td>\n",
       "      <td>1.144478e+07</td>\n",
       "      <td>17.928541</td>\n",
       "      <td>7.615314e+07</td>\n",
       "      <td>12.858409</td>\n",
       "      <td>337518.250000</td>\n",
       "      <td>164.0</td>\n",
       "      <td>12.615385</td>\n",
       "      <td>224.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.988992</td>\n",
       "      <td>2.014900e+06</td>\n",
       "      <td>16.378971</td>\n",
       "      <td>6.238182e+07</td>\n",
       "      <td>1.745633</td>\n",
       "      <td>8938.264648</td>\n",
       "      <td>299.0</td>\n",
       "      <td>27.181818</td>\n",
       "      <td>334.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316483</td>\n",
       "      <td>1.042644e+06</td>\n",
       "      <td>7.287305</td>\n",
       "      <td>5.252981e+05</td>\n",
       "      <td>-0.559304</td>\n",
       "      <td>-1012.340759</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>368.0</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.685194</td>\n",
       "      <td>2.026175e+06</td>\n",
       "      <td>2.260627</td>\n",
       "      <td>8.374476e+05</td>\n",
       "      <td>0.144859</td>\n",
       "      <td>1023.051819</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0   \n",
       "3            2017-09  C_ID_186d6a6901          4          3          0   \n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  hist_per_cnts_month_lag-13  hist_per_cnts_month_lag-12  \\\n",
       "0 -0.820283                         0.0                         0.0   \n",
       "1  0.392913                         0.0                        21.0   \n",
       "2  0.688056                         6.0                         6.0   \n",
       "3  0.142495                         0.0                         0.0   \n",
       "4 -0.159749                         0.0                         0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-11  hist_per_cnts_month_lag-10  \\\n",
       "0                         0.0                         0.0   \n",
       "1                        22.0                        13.0   \n",
       "2                         5.0                         7.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "          ...           hist_merchant_category_id_mean_mean  \\\n",
       "0         ...                                     13.846728   \n",
       "1         ...                                      2.988992   \n",
       "2         ...                                      1.316483   \n",
       "3         ...                                           NaN   \n",
       "4         ...                                      3.685194   \n",
       "\n",
       "   hist_merchant_category_id_sum_sum  hist_city_id_mean_mean  \\\n",
       "0                       1.144478e+07               17.928541   \n",
       "1                       2.014900e+06               16.378971   \n",
       "2                       1.042644e+06                7.287305   \n",
       "3                                NaN                     NaN   \n",
       "4                       2.026175e+06                2.260627   \n",
       "\n",
       "   hist_city_id_sum_sum  hist_merchant_id_mean_mean  hist_merchant_id_sum_sum  \\\n",
       "0          7.615314e+07                   12.858409             337518.250000   \n",
       "1          6.238182e+07                    1.745633               8938.264648   \n",
       "2          5.252981e+05                   -0.559304              -1012.340759   \n",
       "3                   NaN                         NaN                       NaN   \n",
       "4          8.374476e+05                    0.144859               1023.051819   \n",
       "\n",
       "   hist_purchase_date_diff  hist_purchase_date_average  \\\n",
       "0                    164.0                   12.615385   \n",
       "1                    299.0                   27.181818   \n",
       "2                     56.0                   28.000000   \n",
       "3                      NaN                         NaN   \n",
       "4                     37.0                    7.400000   \n",
       "\n",
       "   hist_purchase_date_uptonow  hist_first_purchase  \n",
       "0                       224.0                 59.0  \n",
       "1                       334.0                 34.0  \n",
       "2                       368.0                312.0  \n",
       "3                         NaN                  NaN  \n",
       "4                        38.0                  1.0  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "_uuid": "f7f5625db40db4395374991124fb796c9decd60b"
   },
   "outputs": [],
   "source": [
    "aggs = {}\n",
    "#添加特征\n",
    "for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id',\n",
    "            'state_id','city_id']:\n",
    "    aggs[col] = ['nunique']\n",
    "    \n",
    "aggs['purchase_amount'] = ['sum','max','min','mean','var','median']\n",
    "aggs['installments'] = ['sum','max','min','mean','var','median']\n",
    "aggs['purchase_date'] = ['max','min']\n",
    "aggs['month_lag'] = ['max','min','mean','var','median']\n",
    "\n",
    "### Now we also need to remove from here since we already have month_lag\n",
    "aggs['month_diff'] = ['mean','median']\n",
    "\n",
    "\n",
    "aggs['weekend'] = ['sum', 'mean']\n",
    "aggs['authorized_flag'] = ['sum', 'mean','median']\n",
    "aggs['category_1'] = ['sum', 'mean']\n",
    "aggs['card_id'] = ['size']\n",
    "\n",
    "#添加特征   \n",
    "features = ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id'\n",
    "               ,'merchant_id']\n",
    "#产生交叉特征，内存有问题\n",
    "# for coli in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "#     for colj in ['category_2','category_3','state_id','subsector_id','merchant_category_id','city_id']:\n",
    "#         df_new_merchant_trans[coli + colj] = df_new_merchant_trans[coli].astype(str) + df_new_merchant_trans[colj].astype(str)\n",
    "#         features.append(coli + colj)\n",
    "for col in features:\n",
    "    df_new_merchant_trans[col+'_mean'] = df_new_merchant_trans.groupby([col])['purchase_amount'].transform('mean')\n",
    "    df_new_merchant_trans[col+'_sum'] = df_new_merchant_trans.groupby([col])['purchase_amount'].transform('sum')\n",
    "    aggs[col+'_mean'] = ['mean']\n",
    "    aggs[col+'_sum'] = ['sum']\n",
    "    #添加特征，使用outlier进行编码\n",
    "#     outliers_mean = df.groupby([col])['outliers'].mean()\n",
    "#     outliers_sum = df.groupby([col])['outliers'].sum()\n",
    "#     df[col+'_outliers_mean'] = df[col].map(outliers_mean)\n",
    "#     df[col+'_outliers_sum'] = df[col].map(outliers_sum)\n",
    "#     aggs[col+'_outliers_mean'] = ['mean']\n",
    "#     aggs[col+'_outliers_sum'] =['sum']   \n",
    "    \n",
    "new_columns = get_new_columns('new_hist',aggs)\n",
    "# df_new_merchant_trans.sort_values(['card_id','purchase_date'],inplace = True)\n",
    "df_hist_trans_group = df_new_merchant_trans.groupby('card_id').agg(aggs)\n",
    "df_hist_trans_group.columns = new_columns\n",
    "df_hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "df_hist_trans_group['new_hist_purchase_date_diff'] = (df_hist_trans_group['new_hist_purchase_date_max'] - df_hist_trans_group['new_hist_purchase_date_min']).dt.days\n",
    "df_hist_trans_group['new_hist_purchase_date_average'] = df_hist_trans_group['new_hist_purchase_date_diff']/df_hist_trans_group['new_hist_card_id_size']\n",
    "\n",
    "\n",
    "# it is fine for new mech transaction history. This means total number of days from month_lag_0 ti kast purchase\n",
    "df_hist_trans_group['new_hist_purchase_date_uptonow'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group['new_hist_purchase_date_max']).dt.days\n",
    "\n",
    "# new feature for the first purchase.This means total number of days from month_lag_0 to first purchase.\n",
    "df_hist_trans_group['new_hist_first_purchase'] = (df_hist_trans_group['card_id'].map(method) - df_hist_trans_group['new_hist_purchase_date_min']).dt.days\n",
    "\n",
    "#下面这个特征考虑了：有的人可能购买频率较低，但是还是忠实粉丝的情况\n",
    "# df_hist_trans_group['new_hist_purchase_date_uptonow_ave'] =  df_hist_trans_group['new_hist_purchase_date_uptonow']/df_hist_trans_group['new_hist_purchase_date_average']\n",
    "\n",
    "#每一个card中未授权消费次数\n",
    "df_hist_trans_group['new_hist_unauthorized_number'] = df_hist_trans_group['new_hist_card_id_size'] - df_hist_trans_group['new_hist_authorized_flag_sum']\n",
    "# grouped = df_new_merchant_trans.groupby('card_id')['purchase_date']\n",
    "# df_hist_trans_group['new_hist_purchase_5thdate_uptonow'] =  (datetime.datetime.today() - grouped.shift(5)).dt.days\n",
    "# df_hist_trans_group['new_hist_purchase_3thdate_uptonow'] =  (datetime.datetime.today() - grouped.shift(3)).dt.days\n",
    "# df_hist_trans_group['new_hist_purchase_10thdate_uptonow'] =  (datetime.datetime.today() - grouped.shift(10)).dt.days\n",
    "\n",
    "df_train = df_train.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "df_test = df_test.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "del df_hist_trans_group\n",
    "gc.collect()\n",
    "del df_new_merchant_trans\n",
    "gc.collect()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "_uuid": "ce2082fc1fb0e3f8f7d27fc166aa7a8351b65504"
   },
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['dayofweek'] = df['first_active_month'].dt.dayofweek\n",
    "    df['weekofyear'] = df['first_active_month'].dt.weekofyear\n",
    "    df['month'] = df['first_active_month'].dt.month\n",
    "    df['elapsed_time'] = (df['card_id'].map(method) - df['first_active_month']).dt.days\n",
    "    # 3.678，so bad\n",
    "#     # add some interaction features\n",
    "#     df['feature_1_hist_month_lag_max'] = df['hist_month_lag_max'] * df['feature_1']\n",
    "#     df['feature_2_hist_month_lag_max'] = df['hist_month_lag_max'] * df['feature_2']\n",
    "#     df['feature_3_hist_month_lag_max'] = df['hist_month_lag_max'] * df['feature_3']\n",
    "#     df['feature_1_auth_hist_month_lag_max'] = df['auth_hist_month_lag_max'] * df['feature_1']\n",
    "#     df['feature_2_auth_hist_month_lag_max'] = df['auth_hist_month_lag_max'] * df['feature_2']\n",
    "#     df['feature_3_auth_hist_month_lag_max'] = df['auth_hist_month_lag_max'] * df['feature_3']\n",
    "    \n",
    "    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['new_hist_first_buy'] = (df['new_hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    #添加特征\n",
    "    df['auth_hist_first_buy'] = (df['auth_hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    #修改特征\n",
    "    for f in ['hist_purchase_date_max','hist_purchase_date_min','new_hist_purchase_date_max',\\\n",
    "                     'new_hist_purchase_date_min','auth_hist_purchase_date_max','auth_hist_purchase_date_min']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "    for f in ['auth_encoder_category_2_auth_sum_sum','auth_encoder_category_3_auth_sum_sum',\n",
    "            'auth_encoder_state_id_auth_sum_sum','auth_encoder_subsector_id_auth_sum_sum',\n",
    "            'auth_encoder_merchant_category_id_auth_sum_sum','auth_encoder_city_id_auth_sum_sum']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "    #上面auth_flag已经聚合过了card_id_size ,purchase_amount\n",
    "#     df['card_id_total'] = df['new_hist_card_id_size']+df['hist_card_id_size']  + df['auth_hist_card_id_size']\n",
    "#     df['purchase_amount_total'] = df['new_hist_purchase_amount_sum']+df['hist_purchase_amount_sum']+df['auth_hist_purchase_amount_sum']\n",
    "#添加特征\n",
    "\n",
    "for f in ['feature_1','feature_2','feature_3','month','dayofweek']:\n",
    "    order_label1 = df_train.groupby([f])['outliers'].mean()\n",
    "    df_train[f+'_outliers_mean'] = df_train[f].map(order_label1)\n",
    "    df_test[f+'_outliers_mean'] = df_test[f].map(order_label1)\n",
    "    \n",
    "    order_label2 = df_train.groupby([f])['outliers'].sum()\n",
    "    df_train[f+'_outliers_sum'] = df_train[f].map(order_label2)\n",
    "    df_test[f+'_outliers_sum'] = df_test[f].map(order_label2)\n",
    "    \n",
    "#     order_label1 = df_train.groupby([f])['target'].mean()\n",
    "#     df_train[f+'_target_mean'] = df_train[f].map(order_label1) \n",
    "#     df_test[f+'_target_sum'] = df_test[f].map(order_label1)\n",
    "#     order_label2 = df_train.gorupby([f])['target'].sum()\n",
    "#     df_train[f+'_target_sum'] = df_train[f].map(order_label2)\n",
    "#     df_test[f+'_target_sum'] = df_test[f].map(order_label2)\n",
    " \n",
    "# get_dummies 似乎有一点点不良影响\n",
    "df_train = pd.get_dummies(df_train,columns =['feature_1','feature_2'])\n",
    "df_test = pd.get_dummies(df_test,columns =['feature_1','feature_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "_uuid": "3877e4f1418facb4da080ba31ef8ebae1724e7b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_per_cnts_month_lag-13</th>\n",
       "      <th>hist_per_cnts_month_lag-12</th>\n",
       "      <th>hist_per_cnts_month_lag-11</th>\n",
       "      <th>hist_per_cnts_month_lag-10</th>\n",
       "      <th>hist_per_cnts_month_lag-9</th>\n",
       "      <th>hist_per_cnts_month_lag-8</th>\n",
       "      <th>...</th>\n",
       "      <th>dayofweek_outliers_mean</th>\n",
       "      <th>dayofweek_outliers_sum</th>\n",
       "      <th>feature_1_1</th>\n",
       "      <th>feature_1_2</th>\n",
       "      <th>feature_1_3</th>\n",
       "      <th>feature_1_4</th>\n",
       "      <th>feature_1_5</th>\n",
       "      <th>feature_2_1</th>\n",
       "      <th>feature_2_2</th>\n",
       "      <th>feature_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015174</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_3    target  \\\n",
       "0         2017-06-01  C_ID_92a2005557          1 -0.820283   \n",
       "1         2017-01-01  C_ID_3d0044924f          0  0.392913   \n",
       "2         2016-08-01  C_ID_d639edf6cd          0  0.688056   \n",
       "3         2017-09-01  C_ID_186d6a6901          0  0.142495   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          0 -0.159749   \n",
       "\n",
       "   hist_per_cnts_month_lag-13  hist_per_cnts_month_lag-12  \\\n",
       "0                         0.0                         0.0   \n",
       "1                         0.0                        21.0   \n",
       "2                         6.0                         6.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-11  hist_per_cnts_month_lag-10  \\\n",
       "0                         0.0                         0.0   \n",
       "1                        22.0                        13.0   \n",
       "2                         5.0                         7.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-9  hist_per_cnts_month_lag-8     ...       \\\n",
       "0                        0.0                        3.0     ...        \n",
       "1                       18.0                       15.0     ...        \n",
       "2                        4.0                        0.0     ...        \n",
       "3                        0.0                        0.0     ...        \n",
       "4                        0.0                        0.0     ...        \n",
       "\n",
       "   dayofweek_outliers_mean  dayofweek_outliers_sum  feature_1_1  feature_1_2  \\\n",
       "0                 0.015174                     401            0            0   \n",
       "1                 0.009631                     289            0            0   \n",
       "2                 0.013597                     247            0            1   \n",
       "3                 0.005835                     201            0            0   \n",
       "4                 0.011268                     409            1            0   \n",
       "\n",
       "   feature_1_3  feature_1_4  feature_1_5  feature_2_1  feature_2_2  \\\n",
       "0            0            0            1            0            1   \n",
       "1            0            1            0            1            0   \n",
       "2            0            0            0            0            1   \n",
       "3            0            1            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   feature_2_3  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#首次购买的时间居然早于首次激活的时间，进行调整\n",
    "df_train.loc[df_train['auth_hist_first_buy'] < 0, 'auth_hist_first_buy'] = -1\n",
    "df_train.loc[df_train['hist_first_buy'] < 0, 'hist_first_buy'] = -1\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "_uuid": "c4f20f27679889542acfd60d1f1ac381b201ac43"
   },
   "outputs": [],
   "source": [
    "exclude_features = []\n",
    "exclude_features += ['card_id', 'first_active_month','target','outliers']\n",
    "df_train_columns = [c for c in df_train.columns if c not in exclude_features ]\n",
    "target = df_train['target']\n",
    "# del df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "_uuid": "b7ff07b98323cf30f11ec6130f5c64e6c4db0aac",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all=df_train.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 6,\n",
    "         \"random_state\": 4950}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = lgb.Dataset(df_train[df_train_columns], label=target)#, categorical_feature=categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 3.68115 + 0.0298475\n",
      "[400]\tcv_agg's rmse: 3.66086 + 0.0290447\n",
      "[600]\tcv_agg's rmse: 3.6537 + 0.0282303\n",
      "[800]\tcv_agg's rmse: 3.65097 + 0.027759\n",
      "[1000]\tcv_agg's rmse: 3.64979 + 0.0272081\n",
      "[1200]\tcv_agg's rmse: 3.64938 + 0.027373\n",
      "[1400]\tcv_agg's rmse: 3.6491 + 0.0272723\n",
      "[1600]\tcv_agg's rmse: 3.64898 + 0.0269808\n",
      "[1800]\tcv_agg's rmse: 3.64937 + 0.0268535\n",
      "[2000]\tcv_agg's rmse: 3.64983 + 0.0265247\n",
      "best cv score: 3.6489240970108425\n",
      "best boost nums: 1470\n"
     ]
    }
   ],
   "source": [
    "lgb_cv = lgb.cv(param, trn_data, 10000, stratified=False, early_stopping_rounds=600, verbose_eval=200)\n",
    "print(f'best cv score: {lgb_cv[\"rmse-mean\"][-1]}\\nbest boost nums: {len(lgb_cv[\"rmse-mean\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.57363\n",
      "[400]\ttraining's rmse: 3.4877\n",
      "[600]\ttraining's rmse: 3.43205\n",
      "[800]\ttraining's rmse: 3.3894\n",
      "[1000]\ttraining's rmse: 3.3523\n",
      "[1200]\ttraining's rmse: 3.31879\n",
      "[1400]\ttraining's rmse: 3.28802\n"
     ]
    }
   ],
   "source": [
    "trn_data = lgb.Dataset(df_train[df_train_columns], label=target)#, categorical_feature=categorical_feats)\n",
    "clf = lgb.train(param, trn_data,1470, valid_sets=(trn_data), verbose_eval=200)\n",
    "y_pred=clf.predict(df_test[df_train_columns2],clf.best_iteration)\n",
    "df=pd.DataFrame({'card_id':df_test.card_id,'target':y_pred})\n",
    "df.to_csv('single_model_without_extra_feature.csv',index=False)\n",
    "#LB:3.675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train with additional feature where first purchase was made before first active month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=df_hist_trans.groupby('card_id').purchase_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2=df_train.copy()\n",
    "df_test2=df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['first_purchase']=df_train.card_id.map(df_)\n",
    "df_test['first_purchase']=df_test.card_id.map(df_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_purchase</th>\n",
       "      <th>first_active_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-15 14:58:10</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-03 21:27:17</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-02-23 19:32:09</td>\n",
       "      <td>2016-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-20 21:49:13</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_purchase first_active_month\n",
       "0 2017-07-15 14:58:10         2017-06-01\n",
       "1 2017-03-03 21:27:17         2017-01-01\n",
       "2 2017-02-23 19:32:09         2016-08-01\n",
       "3                 NaT         2017-09-01\n",
       "4 2018-01-20 21:49:13         2017-11-01"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['first_purchase','first_active_month']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['early_purchase']=(df_train['first_active_month']-df_train['first_purchase']).dt.days\n",
    "df_test['early_purchase']=(df_test['first_active_month']-df_test['first_purchase']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columns2=df_train_columns[:]\n",
    "df_train_columns2.append('early_purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 3.68005 + 0.0295708\n",
      "[400]\tcv_agg's rmse: 3.65926 + 0.028767\n",
      "[600]\tcv_agg's rmse: 3.6523 + 0.028096\n",
      "[800]\tcv_agg's rmse: 3.64968 + 0.0276799\n",
      "[1000]\tcv_agg's rmse: 3.64854 + 0.0274654\n",
      "[1200]\tcv_agg's rmse: 3.64842 + 0.0269529\n",
      "[1400]\tcv_agg's rmse: 3.64802 + 0.0266792\n",
      "[1600]\tcv_agg's rmse: 3.64819 + 0.0265051\n",
      "[1800]\tcv_agg's rmse: 3.64843 + 0.0264347\n",
      "[2000]\tcv_agg's rmse: 3.64886 + 0.0262525\n",
      "best cv score: 3.6479357833608823\n",
      "best boost nums: 1499\n"
     ]
    }
   ],
   "source": [
    "trn_data = lgb.Dataset(df_train[df_train_columns2], label=target)#, categorical_feature=categorical_feats)\n",
    "lgb_cv = lgb.cv(param, trn_data, 10000, stratified=False, early_stopping_rounds=600, verbose_eval=200)\n",
    "print(f'best cv score: {lgb_cv[\"rmse-mean\"][-1]}\\nbest boost nums: {len(lgb_cv[\"rmse-mean\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.57441\n",
      "[400]\ttraining's rmse: 3.4887\n",
      "[600]\ttraining's rmse: 3.4336\n",
      "[800]\ttraining's rmse: 3.39122\n",
      "[1000]\ttraining's rmse: 3.35475\n",
      "[1200]\ttraining's rmse: 3.32149\n",
      "[1400]\ttraining's rmse: 3.29067\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(param, trn_data,len(lgb_cv['rmse-mean']), valid_sets=(trn_data), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(df_test[df_train_columns2],clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'card_id':df_test.card_id,'target':y_pred})\n",
    "df.to_csv('single_model_extra_feature2.csv',index=False)\n",
    "#LB:3.677"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use merchant features from Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('merchant_merge_hist_features.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_per_cnts_month_lag-13</th>\n",
       "      <th>hist_per_cnts_month_lag-12</th>\n",
       "      <th>hist_per_cnts_month_lag-11</th>\n",
       "      <th>hist_per_cnts_month_lag-10</th>\n",
       "      <th>hist_per_cnts_month_lag-9</th>\n",
       "      <th>hist_per_cnts_month_lag-8</th>\n",
       "      <th>...</th>\n",
       "      <th>merchant_merge_hist_avg_purchases_lag6_sum</th>\n",
       "      <th>merchant_merge_hist_avg_purchases_lag6_mean</th>\n",
       "      <th>merchant_merge_hist_active_months_lag6_sum</th>\n",
       "      <th>merchant_merge_hist_active_months_lag6_mean</th>\n",
       "      <th>merchant_merge_hist_avg_sales_lag12_sum</th>\n",
       "      <th>merchant_merge_hist_avg_sales_lag12_mean</th>\n",
       "      <th>merchant_merge_hist_avg_purchases_lag12_sum</th>\n",
       "      <th>merchant_merge_hist_avg_purchases_lag12_mean</th>\n",
       "      <th>merchant_merge_hist_active_months_lag12_sum</th>\n",
       "      <th>merchant_merge_hist_active_months_lag12_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5458.811530</td>\n",
       "      <td>21.076492</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2146.409912</td>\n",
       "      <td>8.287297</td>\n",
       "      <td>6016.990200</td>\n",
       "      <td>23.231622</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>11.895753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1540.508953</td>\n",
       "      <td>4.220572</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>811.349976</td>\n",
       "      <td>2.222877</td>\n",
       "      <td>1673.471042</td>\n",
       "      <td>4.584852</td>\n",
       "      <td>4329.0</td>\n",
       "      <td>11.860274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.681600</td>\n",
       "      <td>1.379127</td>\n",
       "      <td>264.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.610001</td>\n",
       "      <td>1.195682</td>\n",
       "      <td>61.731488</td>\n",
       "      <td>1.402988</td>\n",
       "      <td>523.0</td>\n",
       "      <td>11.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>223.430503</td>\n",
       "      <td>2.510455</td>\n",
       "      <td>534.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>156.160004</td>\n",
       "      <td>1.754607</td>\n",
       "      <td>226.538512</td>\n",
       "      <td>2.545377</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>11.348315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>787.523525</td>\n",
       "      <td>5.585273</td>\n",
       "      <td>846.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>385.179993</td>\n",
       "      <td>2.731773</td>\n",
       "      <td>845.721981</td>\n",
       "      <td>5.998028</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>11.652482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_3    target  \\\n",
       "0         2017-06-01  C_ID_92a2005557          1 -0.820283   \n",
       "1         2017-01-01  C_ID_3d0044924f          0  0.392913   \n",
       "2         2016-08-01  C_ID_d639edf6cd          0  0.688056   \n",
       "3         2017-09-01  C_ID_186d6a6901          0  0.142495   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          0 -0.159749   \n",
       "\n",
       "   hist_per_cnts_month_lag-13  hist_per_cnts_month_lag-12  \\\n",
       "0                         0.0                         0.0   \n",
       "1                         0.0                        21.0   \n",
       "2                         6.0                         6.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-11  hist_per_cnts_month_lag-10  \\\n",
       "0                         0.0                         0.0   \n",
       "1                        22.0                        13.0   \n",
       "2                         5.0                         7.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   hist_per_cnts_month_lag-9  hist_per_cnts_month_lag-8  \\\n",
       "0                        0.0                        3.0   \n",
       "1                       18.0                       15.0   \n",
       "2                        4.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "                       ...                       \\\n",
       "0                      ...                        \n",
       "1                      ...                        \n",
       "2                      ...                        \n",
       "3                      ...                        \n",
       "4                      ...                        \n",
       "\n",
       "   merchant_merge_hist_avg_purchases_lag6_sum  \\\n",
       "0                                 5458.811530   \n",
       "1                                 1540.508953   \n",
       "2                                   60.681600   \n",
       "3                                  223.430503   \n",
       "4                                  787.523525   \n",
       "\n",
       "   merchant_merge_hist_avg_purchases_lag6_mean  \\\n",
       "0                                    21.076492   \n",
       "1                                     4.220572   \n",
       "2                                     1.379127   \n",
       "3                                     2.510455   \n",
       "4                                     5.585273   \n",
       "\n",
       "   merchant_merge_hist_active_months_lag6_sum  \\\n",
       "0                                      1554.0   \n",
       "1                                      2190.0   \n",
       "2                                       264.0   \n",
       "3                                       534.0   \n",
       "4                                       846.0   \n",
       "\n",
       "   merchant_merge_hist_active_months_lag6_mean  \\\n",
       "0                                          6.0   \n",
       "1                                          6.0   \n",
       "2                                          6.0   \n",
       "3                                          6.0   \n",
       "4                                          6.0   \n",
       "\n",
       "   merchant_merge_hist_avg_sales_lag12_sum  \\\n",
       "0                              2146.409912   \n",
       "1                               811.349976   \n",
       "2                                52.610001   \n",
       "3                               156.160004   \n",
       "4                               385.179993   \n",
       "\n",
       "   merchant_merge_hist_avg_sales_lag12_mean  \\\n",
       "0                                  8.287297   \n",
       "1                                  2.222877   \n",
       "2                                  1.195682   \n",
       "3                                  1.754607   \n",
       "4                                  2.731773   \n",
       "\n",
       "   merchant_merge_hist_avg_purchases_lag12_sum  \\\n",
       "0                                  6016.990200   \n",
       "1                                  1673.471042   \n",
       "2                                    61.731488   \n",
       "3                                   226.538512   \n",
       "4                                   845.721981   \n",
       "\n",
       "   merchant_merge_hist_avg_purchases_lag12_mean  \\\n",
       "0                                     23.231622   \n",
       "1                                      4.584852   \n",
       "2                                      1.402988   \n",
       "3                                      2.545377   \n",
       "4                                      5.998028   \n",
       "\n",
       "   merchant_merge_hist_active_months_lag12_sum  \\\n",
       "0                                       3081.0   \n",
       "1                                       4329.0   \n",
       "2                                        523.0   \n",
       "3                                       1010.0   \n",
       "4                                       1643.0   \n",
       "\n",
       "   merchant_merge_hist_active_months_lag12_mean  \n",
       "0                                     11.895753  \n",
       "1                                     11.860274  \n",
       "2                                     11.886364  \n",
       "3                                     11.348315  \n",
       "4                                     11.652482  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train3=pd.merge(df_train,df,on='card_id')\n",
    "df_test3=pd.merge(df_test,df,on='card_id')\n",
    "df_train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_features = []\n",
    "exclude_features += ['card_id', 'first_active_month','target','outliers']\n",
    "df_train_columns3 = [c for c in df_train.columns if c not in exclude_features ]\n",
    "target3 = df_train3['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columns3.remove('first_purchase')\n",
    "df_train_columns3.remove('early_purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 232)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train3.shape[1],df_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 3.68115 + 0.0298475\n",
      "[400]\tcv_agg's rmse: 3.66086 + 0.0290447\n",
      "[600]\tcv_agg's rmse: 3.6537 + 0.0282303\n",
      "[800]\tcv_agg's rmse: 3.65097 + 0.027759\n",
      "[1000]\tcv_agg's rmse: 3.64979 + 0.0272081\n",
      "[1200]\tcv_agg's rmse: 3.64938 + 0.027373\n",
      "[1400]\tcv_agg's rmse: 3.6491 + 0.0272723\n",
      "[1600]\tcv_agg's rmse: 3.64898 + 0.0269808\n",
      "[1800]\tcv_agg's rmse: 3.64937 + 0.0268535\n",
      "[2000]\tcv_agg's rmse: 3.64983 + 0.0265247\n",
      "best cv score: 3.6489240970108425\n",
      "best boost nums: 1470\n"
     ]
    }
   ],
   "source": [
    "trn_data = lgb.Dataset(df_train3[df_train_columns3], label=target3)#, categorical_feature=categorical_feats)\n",
    "lgb_cv = lgb.cv(param, trn_data, 10000, stratified=False, early_stopping_rounds=600, verbose_eval=200)\n",
    "print(f'best cv score: {lgb_cv[\"rmse-mean\"][-1]}\\nbest boost nums: {len(lgb_cv[\"rmse-mean\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.57363\n",
      "[400]\ttraining's rmse: 3.4877\n",
      "[600]\ttraining's rmse: 3.43205\n",
      "[800]\ttraining's rmse: 3.3894\n",
      "[1000]\ttraining's rmse: 3.3523\n",
      "[1200]\ttraining's rmse: 3.31879\n",
      "[1400]\ttraining's rmse: 3.28802\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(param, trn_data,len(lgb_cv['rmse-mean']), valid_sets=(trn_data), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(df_test3[df_train_columns3],clf.best_iteration)\n",
    "df=pd.DataFrame({'card_id':df_test.card_id,'target':y_pred})\n",
    "df.to_csv('single_model_extra_feature_merchants.csv',index=False)\n",
    "#LB:3.675"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some card_id don't have purchases in historical transactions and some don't have in new transaction. When we call nunique function it gives nan values. Let's change them to 0, since it is more meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth_hist_merchant_id_nunique\n",
      "auth_hist_merchant_id_mean_mean\n",
      "auth_hist_merchant_id_sum_sum\n",
      "hist_merchant_id_nunique\n",
      "hist_merchant_id_mean_mean\n",
      "hist_merchant_id_sum_sum\n",
      "new_hist_merchant_id_nunique\n",
      "new_hist_merchant_id_mean_mean\n",
      "new_hist_merchant_id_sum_sum\n"
     ]
    }
   ],
   "source": [
    "# Setting nan values to zero since no purchases were made either in historical or new merchant transactions\n",
    "df_train_new=df_train.copy()\n",
    "df_test_new=df_test.copy()\n",
    "for i in range(len(df_train_columns)):\n",
    "    if 'merchant_id' in df_train_columns[i]:\n",
    "        print(df_train_columns[i])\n",
    "        df_train_new.loc[df_train[df_train_columns[i]].isnull(),df_train_columns[i]]=0\n",
    "        df_test_new.loc[df_test[df_train_columns[i]].isnull(),df_train_columns[i]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 3.68053 + 0.0297062\n",
      "[400]\tcv_agg's rmse: 3.66003 + 0.0285893\n",
      "[600]\tcv_agg's rmse: 3.65289 + 0.0278717\n",
      "[800]\tcv_agg's rmse: 3.64992 + 0.0276302\n",
      "[1000]\tcv_agg's rmse: 3.64886 + 0.0272983\n",
      "[1200]\tcv_agg's rmse: 3.64851 + 0.0270548\n",
      "[1400]\tcv_agg's rmse: 3.6481 + 0.0270018\n",
      "[1600]\tcv_agg's rmse: 3.64794 + 0.0266963\n",
      "[1800]\tcv_agg's rmse: 3.64815 + 0.0263886\n",
      "[2000]\tcv_agg's rmse: 3.64856 + 0.0259969\n",
      "[2200]\tcv_agg's rmse: 3.64893 + 0.0257287\n",
      "best cv score: 3.6478577211263903\n",
      "best boost nums: 1629\n"
     ]
    }
   ],
   "source": [
    "trn_data = lgb.Dataset(df_train_new[df_train_columns], label=df_train_new.target)#, categorical_feature=categorical_feats)\n",
    "lgb_cv = lgb.cv(param, trn_data, 10000, stratified=False, early_stopping_rounds=600, verbose_eval=200)\n",
    "print(f'best cv score: {lgb_cv[\"rmse-mean\"][-1]}\\nbest boost nums: {len(lgb_cv[\"rmse-mean\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.57396\n",
      "[400]\ttraining's rmse: 3.48818\n",
      "[600]\ttraining's rmse: 3.43237\n",
      "[800]\ttraining's rmse: 3.38986\n",
      "[1000]\ttraining's rmse: 3.35354\n",
      "[1200]\ttraining's rmse: 3.32107\n",
      "[1400]\ttraining's rmse: 3.28974\n",
      "[1600]\ttraining's rmse: 3.26068\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(param, trn_data,len(lgb_cv['rmse-mean']), valid_sets=(trn_data), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(df_test_new[df_train_columns], num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pd = pd.DataFrame({\n",
    "        'card_id': df_test.card_id,\n",
    "        'target': all_test\n",
    "})\n",
    "final_pd.to_csv('with_li_idea_nan_modified.csv', index=False)\n",
    "#LB:3.671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
