{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error \n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_pickle('df_train.pickle')\n",
    "# test = pd.read_pickle('df_test.pickle')\n",
    "\n",
    "train = pd.read_csv('df_train_2_extra.csv')\n",
    "test = pd.read_csv('df_test_2_extra.csv')\n",
    "#target = np.loadtxt('wang.target.txt')\n",
    "target=train['target']\n",
    "outlier=train['outliers']\n",
    "#outlier = np.zeros(len(target), dtype=np.int)\n",
    "#outlier[target < -33] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 255)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### outlier ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010930233709890698"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier.sum() / len(outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [c for c in train.columns if c not in ['card_id', 'first_active_month','target','outliers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_with_outlier = pd.DataFrame({\n",
    "    'target': target,\n",
    "    'outlier': outlier\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.379747496467408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]/(train.shape[0]+test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am going to use 20% and 10% of data as test set. Let's start with 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, y_train, y_test = train_test_split(train, target_with_outlier, test_size=0.20, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((161533, 257), (40384, 257), (161533, 2), (40384, 2))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.010932750583472107, 0.010920166402535658)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.outlier.mean(),y_test.outlier.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lb(pred_target):\n",
    "    return mean_squared_error(y_test.target, pred_target) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will use different number of features as train set\n",
    "feats1=pd.read_csv('threshold_feature_elimination10_2extra_test10.csv', squeeze=True).tolist()\n",
    "feats2=pd.read_csv('threshold_feature_elimination50_2extra_test10.csv', squeeze=True).tolist()\n",
    "feats3=pd.read_csv('threshold_feature_elimination70_2extra_test10.csv', squeeze=True).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 150, 91, 72)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats),len(feats1),len(feats2),len(feats3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed parameters for all training\n",
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 6,\n",
    "         \"random_state\": 4950}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(df_train,df_test,fold,feature):\n",
    "    results=pd.DataFrame()\n",
    "    folds = StratifiedKFold(n_splits=fold, shuffle=True, random_state=4950)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    val_error=[]\n",
    "    test_error=[]\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "\n",
    "        # cal the outlier ratio for each fold\n",
    "        cur_fold= df_train.iloc[trn_idx]\n",
    "        number_outliers = len(cur_fold[cur_fold['outliers'] == 1])\n",
    "        total = len(cur_fold)\n",
    "        print(\"fold %s %s %s\" % (fold_,number_outliers, number_outliers / total))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][feature], label=y_train.target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][feature], label=y_train.target.iloc[val_idx])\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 600)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][feature], num_iteration=clf.best_iteration)\n",
    "        oof_test=clf.predict(df_test[feature], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        val_error.append(np.sqrt(mean_squared_error(oof[val_idx], y_train.target.iloc[val_idx])))\n",
    "        test_error.append(np.sqrt(mean_squared_error(oof_test, y_test.target)))\n",
    "        \n",
    "        predictions += clf.predict(df_test[feature], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    results['cv_error']=val_error\n",
    "    results['test_error']=test_error\n",
    "    results['fold']=[i for i in range(1,fold+1,1)]\n",
    "    results['ave_cv_error']=np.sqrt(mean_squared_error(oof,  y_train.target))\n",
    "    results['ave_test_error']=np.sqrt(mean_squared_error(predictions, y_test.target))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.62935\tvalid_1's rmse: 3.71384\n",
      "[200]\ttraining's rmse: 3.52828\tvalid_1's rmse: 3.68523\n",
      "[300]\ttraining's rmse: 3.46763\tvalid_1's rmse: 3.67322\n",
      "[400]\ttraining's rmse: 3.42191\tvalid_1's rmse: 3.66686\n",
      "[500]\ttraining's rmse: 3.38514\tvalid_1's rmse: 3.6633\n",
      "[600]\ttraining's rmse: 3.35347\tvalid_1's rmse: 3.66153\n",
      "[700]\ttraining's rmse: 3.3255\tvalid_1's rmse: 3.66107\n",
      "[800]\ttraining's rmse: 3.29924\tvalid_1's rmse: 3.65998\n",
      "[900]\ttraining's rmse: 3.27402\tvalid_1's rmse: 3.66058\n",
      "[1000]\ttraining's rmse: 3.25103\tvalid_1's rmse: 3.66049\n",
      "[1100]\ttraining's rmse: 3.22944\tvalid_1's rmse: 3.66004\n",
      "[1200]\ttraining's rmse: 3.20855\tvalid_1's rmse: 3.66024\n",
      "[1300]\ttraining's rmse: 3.18737\tvalid_1's rmse: 3.66043\n",
      "[1400]\ttraining's rmse: 3.1652\tvalid_1's rmse: 3.66044\n",
      "[1500]\ttraining's rmse: 3.14578\tvalid_1's rmse: 3.66084\n",
      "[1600]\ttraining's rmse: 3.12707\tvalid_1's rmse: 3.66112\n",
      "[1700]\ttraining's rmse: 3.10918\tvalid_1's rmse: 3.66139\n",
      "[1800]\ttraining's rmse: 3.09028\tvalid_1's rmse: 3.66176\n",
      "Early stopping, best iteration is:\n",
      "[1225]\ttraining's rmse: 3.20354\tvalid_1's rmse: 3.65994\n",
      "fold 1 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63728\tvalid_1's rmse: 3.70428\n",
      "[200]\ttraining's rmse: 3.53833\tvalid_1's rmse: 3.66563\n",
      "[300]\ttraining's rmse: 3.4759\tvalid_1's rmse: 3.6519\n",
      "[400]\ttraining's rmse: 3.43118\tvalid_1's rmse: 3.6446\n",
      "[500]\ttraining's rmse: 3.3926\tvalid_1's rmse: 3.64014\n",
      "[600]\ttraining's rmse: 3.3611\tvalid_1's rmse: 3.63667\n",
      "[700]\ttraining's rmse: 3.33211\tvalid_1's rmse: 3.63498\n",
      "[800]\ttraining's rmse: 3.30599\tvalid_1's rmse: 3.63441\n",
      "[900]\ttraining's rmse: 3.2806\tvalid_1's rmse: 3.63363\n",
      "[1000]\ttraining's rmse: 3.25885\tvalid_1's rmse: 3.63347\n",
      "[1100]\ttraining's rmse: 3.23725\tvalid_1's rmse: 3.63329\n",
      "[1200]\ttraining's rmse: 3.2155\tvalid_1's rmse: 3.63369\n",
      "[1300]\ttraining's rmse: 3.19459\tvalid_1's rmse: 3.63389\n",
      "[1400]\ttraining's rmse: 3.17538\tvalid_1's rmse: 3.63397\n",
      "[1500]\ttraining's rmse: 3.15723\tvalid_1's rmse: 3.63396\n",
      "Early stopping, best iteration is:\n",
      "[965]\ttraining's rmse: 3.26612\tvalid_1's rmse: 3.63304\n",
      "fold 2 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.62808\tvalid_1's rmse: 3.71459\n",
      "[200]\ttraining's rmse: 3.52501\tvalid_1's rmse: 3.68665\n",
      "[300]\ttraining's rmse: 3.46308\tvalid_1's rmse: 3.67625\n",
      "[400]\ttraining's rmse: 3.41655\tvalid_1's rmse: 3.67053\n",
      "[500]\ttraining's rmse: 3.37918\tvalid_1's rmse: 3.66685\n",
      "[600]\ttraining's rmse: 3.34557\tvalid_1's rmse: 3.66505\n",
      "[700]\ttraining's rmse: 3.3169\tvalid_1's rmse: 3.66382\n",
      "[800]\ttraining's rmse: 3.2911\tvalid_1's rmse: 3.66396\n",
      "[900]\ttraining's rmse: 3.2664\tvalid_1's rmse: 3.66313\n",
      "[1000]\ttraining's rmse: 3.24341\tvalid_1's rmse: 3.66257\n",
      "[1100]\ttraining's rmse: 3.22019\tvalid_1's rmse: 3.66256\n",
      "[1200]\ttraining's rmse: 3.19917\tvalid_1's rmse: 3.66244\n",
      "[1300]\ttraining's rmse: 3.17876\tvalid_1's rmse: 3.66247\n",
      "[1400]\ttraining's rmse: 3.15908\tvalid_1's rmse: 3.66286\n",
      "[1500]\ttraining's rmse: 3.13767\tvalid_1's rmse: 3.66321\n",
      "[1600]\ttraining's rmse: 3.11734\tvalid_1's rmse: 3.66382\n",
      "[1700]\ttraining's rmse: 3.0978\tvalid_1's rmse: 3.66394\n",
      "[1800]\ttraining's rmse: 3.07917\tvalid_1's rmse: 3.66489\n",
      "Early stopping, best iteration is:\n",
      "[1224]\ttraining's rmse: 3.19417\tvalid_1's rmse: 3.66232\n",
      "fold 3 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63405\tvalid_1's rmse: 3.70709\n",
      "[200]\ttraining's rmse: 3.53473\tvalid_1's rmse: 3.66814\n",
      "[300]\ttraining's rmse: 3.47439\tvalid_1's rmse: 3.65199\n",
      "[400]\ttraining's rmse: 3.42628\tvalid_1's rmse: 3.64375\n",
      "[500]\ttraining's rmse: 3.38938\tvalid_1's rmse: 3.63809\n",
      "[600]\ttraining's rmse: 3.35627\tvalid_1's rmse: 3.63422\n",
      "[700]\ttraining's rmse: 3.32662\tvalid_1's rmse: 3.63239\n",
      "[800]\ttraining's rmse: 3.29971\tvalid_1's rmse: 3.63047\n",
      "[900]\ttraining's rmse: 3.27553\tvalid_1's rmse: 3.63003\n",
      "[1000]\ttraining's rmse: 3.25249\tvalid_1's rmse: 3.62914\n",
      "[1100]\ttraining's rmse: 3.22981\tvalid_1's rmse: 3.62963\n",
      "[1200]\ttraining's rmse: 3.20783\tvalid_1's rmse: 3.62953\n",
      "[1300]\ttraining's rmse: 3.18599\tvalid_1's rmse: 3.62957\n",
      "[1400]\ttraining's rmse: 3.16682\tvalid_1's rmse: 3.62941\n",
      "[1500]\ttraining's rmse: 3.14713\tvalid_1's rmse: 3.62909\n",
      "[1600]\ttraining's rmse: 3.12684\tvalid_1's rmse: 3.62894\n",
      "[1700]\ttraining's rmse: 3.10684\tvalid_1's rmse: 3.62881\n",
      "[1800]\ttraining's rmse: 3.08845\tvalid_1's rmse: 3.62904\n",
      "[1900]\ttraining's rmse: 3.07013\tvalid_1's rmse: 3.62902\n",
      "[2000]\ttraining's rmse: 3.05148\tvalid_1's rmse: 3.62922\n",
      "[2100]\ttraining's rmse: 3.03378\tvalid_1's rmse: 3.62938\n",
      "[2200]\ttraining's rmse: 3.0168\tvalid_1's rmse: 3.62966\n",
      "Early stopping, best iteration is:\n",
      "[1642]\ttraining's rmse: 3.11885\tvalid_1's rmse: 3.6286\n",
      "fold 4 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.62299\tvalid_1's rmse: 3.72611\n",
      "[200]\ttraining's rmse: 3.51837\tvalid_1's rmse: 3.70385\n",
      "[300]\ttraining's rmse: 3.45674\tvalid_1's rmse: 3.69578\n",
      "[400]\ttraining's rmse: 3.4099\tvalid_1's rmse: 3.69129\n",
      "[500]\ttraining's rmse: 3.37135\tvalid_1's rmse: 3.68858\n",
      "[600]\ttraining's rmse: 3.33981\tvalid_1's rmse: 3.68724\n",
      "[700]\ttraining's rmse: 3.30995\tvalid_1's rmse: 3.68641\n",
      "[800]\ttraining's rmse: 3.28183\tvalid_1's rmse: 3.68598\n",
      "[900]\ttraining's rmse: 3.25639\tvalid_1's rmse: 3.686\n",
      "[1000]\ttraining's rmse: 3.23368\tvalid_1's rmse: 3.68611\n",
      "[1100]\ttraining's rmse: 3.21147\tvalid_1's rmse: 3.68672\n",
      "[1200]\ttraining's rmse: 3.18919\tvalid_1's rmse: 3.68771\n",
      "[1300]\ttraining's rmse: 3.16849\tvalid_1's rmse: 3.68771\n",
      "Early stopping, best iteration is:\n",
      "[779]\ttraining's rmse: 3.28809\tvalid_1's rmse: 3.68564\n",
      "fold 0 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63626\tvalid_1's rmse: 3.71346\n",
      "[200]\ttraining's rmse: 3.5394\tvalid_1's rmse: 3.68372\n",
      "[300]\ttraining's rmse: 3.48188\tvalid_1's rmse: 3.67283\n",
      "[400]\ttraining's rmse: 3.43872\tvalid_1's rmse: 3.66778\n",
      "[500]\ttraining's rmse: 3.40324\tvalid_1's rmse: 3.66428\n",
      "[600]\ttraining's rmse: 3.37397\tvalid_1's rmse: 3.66215\n",
      "[700]\ttraining's rmse: 3.34832\tvalid_1's rmse: 3.66077\n",
      "[800]\ttraining's rmse: 3.32344\tvalid_1's rmse: 3.65905\n",
      "[900]\ttraining's rmse: 3.29968\tvalid_1's rmse: 3.65894\n",
      "[1000]\ttraining's rmse: 3.27779\tvalid_1's rmse: 3.65907\n",
      "[1100]\ttraining's rmse: 3.25758\tvalid_1's rmse: 3.65867\n",
      "[1200]\ttraining's rmse: 3.23761\tvalid_1's rmse: 3.65966\n",
      "[1300]\ttraining's rmse: 3.21809\tvalid_1's rmse: 3.65998\n",
      "[1400]\ttraining's rmse: 3.19865\tvalid_1's rmse: 3.66041\n",
      "[1500]\ttraining's rmse: 3.17982\tvalid_1's rmse: 3.66056\n",
      "Early stopping, best iteration is:\n",
      "[971]\ttraining's rmse: 3.28406\tvalid_1's rmse: 3.65861\n",
      "fold 1 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64175\tvalid_1's rmse: 3.70402\n",
      "[200]\ttraining's rmse: 3.54813\tvalid_1's rmse: 3.66493\n",
      "[300]\ttraining's rmse: 3.48879\tvalid_1's rmse: 3.65108\n",
      "[400]\ttraining's rmse: 3.44605\tvalid_1's rmse: 3.64297\n",
      "[500]\ttraining's rmse: 3.41231\tvalid_1's rmse: 3.63884\n",
      "[600]\ttraining's rmse: 3.38209\tvalid_1's rmse: 3.63616\n",
      "[700]\ttraining's rmse: 3.3557\tvalid_1's rmse: 3.63455\n",
      "[800]\ttraining's rmse: 3.33052\tvalid_1's rmse: 3.6332\n",
      "[900]\ttraining's rmse: 3.30785\tvalid_1's rmse: 3.63234\n",
      "[1000]\ttraining's rmse: 3.28595\tvalid_1's rmse: 3.63167\n",
      "[1100]\ttraining's rmse: 3.26519\tvalid_1's rmse: 3.63107\n",
      "[1200]\ttraining's rmse: 3.24477\tvalid_1's rmse: 3.63159\n",
      "[1300]\ttraining's rmse: 3.22545\tvalid_1's rmse: 3.63142\n",
      "[1400]\ttraining's rmse: 3.20836\tvalid_1's rmse: 3.63116\n",
      "[1500]\ttraining's rmse: 3.1897\tvalid_1's rmse: 3.6315\n",
      "[1600]\ttraining's rmse: 3.17117\tvalid_1's rmse: 3.63188\n",
      "Early stopping, best iteration is:\n",
      "[1089]\ttraining's rmse: 3.26721\tvalid_1's rmse: 3.631\n",
      "fold 2 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63339\tvalid_1's rmse: 3.71569\n",
      "[200]\ttraining's rmse: 3.53539\tvalid_1's rmse: 3.68642\n",
      "[300]\ttraining's rmse: 3.47577\tvalid_1's rmse: 3.67691\n",
      "[400]\ttraining's rmse: 3.43208\tvalid_1's rmse: 3.67195\n",
      "[500]\ttraining's rmse: 3.39696\tvalid_1's rmse: 3.66895\n",
      "[600]\ttraining's rmse: 3.3652\tvalid_1's rmse: 3.6678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttraining's rmse: 3.33801\tvalid_1's rmse: 3.66641\n",
      "[800]\ttraining's rmse: 3.31369\tvalid_1's rmse: 3.66543\n",
      "[900]\ttraining's rmse: 3.29032\tvalid_1's rmse: 3.66477\n",
      "[1000]\ttraining's rmse: 3.26807\tvalid_1's rmse: 3.66506\n",
      "[1100]\ttraining's rmse: 3.24712\tvalid_1's rmse: 3.6651\n",
      "[1200]\ttraining's rmse: 3.22671\tvalid_1's rmse: 3.66515\n",
      "[1300]\ttraining's rmse: 3.20642\tvalid_1's rmse: 3.66575\n",
      "[1400]\ttraining's rmse: 3.18707\tvalid_1's rmse: 3.66597\n",
      "[1500]\ttraining's rmse: 3.16854\tvalid_1's rmse: 3.66682\n",
      "Early stopping, best iteration is:\n",
      "[903]\ttraining's rmse: 3.28971\tvalid_1's rmse: 3.66471\n",
      "fold 3 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64044\tvalid_1's rmse: 3.7063\n",
      "[200]\ttraining's rmse: 3.54512\tvalid_1's rmse: 3.6649\n",
      "[300]\ttraining's rmse: 3.48746\tvalid_1's rmse: 3.64915\n",
      "[400]\ttraining's rmse: 3.44415\tvalid_1's rmse: 3.64022\n",
      "[500]\ttraining's rmse: 3.40759\tvalid_1's rmse: 3.63527\n",
      "[600]\ttraining's rmse: 3.37668\tvalid_1's rmse: 3.63174\n",
      "[700]\ttraining's rmse: 3.34835\tvalid_1's rmse: 3.62982\n",
      "[800]\ttraining's rmse: 3.32314\tvalid_1's rmse: 3.62909\n",
      "[900]\ttraining's rmse: 3.2993\tvalid_1's rmse: 3.62876\n",
      "[1000]\ttraining's rmse: 3.27639\tvalid_1's rmse: 3.62804\n",
      "[1100]\ttraining's rmse: 3.25522\tvalid_1's rmse: 3.62808\n",
      "[1200]\ttraining's rmse: 3.23384\tvalid_1's rmse: 3.62727\n",
      "[1300]\ttraining's rmse: 3.21312\tvalid_1's rmse: 3.62779\n",
      "[1400]\ttraining's rmse: 3.19511\tvalid_1's rmse: 3.62727\n",
      "[1500]\ttraining's rmse: 3.17665\tvalid_1's rmse: 3.62709\n",
      "[1600]\ttraining's rmse: 3.15758\tvalid_1's rmse: 3.62783\n",
      "[1700]\ttraining's rmse: 3.13959\tvalid_1's rmse: 3.62758\n",
      "[1800]\ttraining's rmse: 3.1234\tvalid_1's rmse: 3.62728\n",
      "[1900]\ttraining's rmse: 3.10663\tvalid_1's rmse: 3.62739\n",
      "[2000]\ttraining's rmse: 3.09006\tvalid_1's rmse: 3.62743\n",
      "Early stopping, best iteration is:\n",
      "[1458]\ttraining's rmse: 3.18409\tvalid_1's rmse: 3.62694\n",
      "fold 4 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.62857\tvalid_1's rmse: 3.72468\n",
      "[200]\ttraining's rmse: 3.52791\tvalid_1's rmse: 3.70144\n",
      "[300]\ttraining's rmse: 3.47017\tvalid_1's rmse: 3.69161\n",
      "[400]\ttraining's rmse: 3.42717\tvalid_1's rmse: 3.6868\n",
      "[500]\ttraining's rmse: 3.39179\tvalid_1's rmse: 3.68394\n",
      "[600]\ttraining's rmse: 3.36041\tvalid_1's rmse: 3.68285\n",
      "[700]\ttraining's rmse: 3.33328\tvalid_1's rmse: 3.68132\n",
      "[800]\ttraining's rmse: 3.30759\tvalid_1's rmse: 3.68101\n",
      "[900]\ttraining's rmse: 3.28512\tvalid_1's rmse: 3.68096\n",
      "[1000]\ttraining's rmse: 3.26272\tvalid_1's rmse: 3.68065\n",
      "[1100]\ttraining's rmse: 3.24195\tvalid_1's rmse: 3.68106\n",
      "[1200]\ttraining's rmse: 3.22338\tvalid_1's rmse: 3.68065\n",
      "[1300]\ttraining's rmse: 3.20341\tvalid_1's rmse: 3.68045\n",
      "[1400]\ttraining's rmse: 3.18467\tvalid_1's rmse: 3.68063\n",
      "[1500]\ttraining's rmse: 3.16633\tvalid_1's rmse: 3.68032\n",
      "[1600]\ttraining's rmse: 3.14936\tvalid_1's rmse: 3.68041\n",
      "[1700]\ttraining's rmse: 3.13178\tvalid_1's rmse: 3.6805\n",
      "[1800]\ttraining's rmse: 3.11501\tvalid_1's rmse: 3.68096\n",
      "Early stopping, best iteration is:\n",
      "[1264]\ttraining's rmse: 3.21066\tvalid_1's rmse: 3.68005\n",
      "fold 0 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64209\tvalid_1's rmse: 3.71061\n",
      "[200]\ttraining's rmse: 3.54984\tvalid_1's rmse: 3.68075\n",
      "[300]\ttraining's rmse: 3.49651\tvalid_1's rmse: 3.66946\n",
      "[400]\ttraining's rmse: 3.45517\tvalid_1's rmse: 3.66402\n",
      "[500]\ttraining's rmse: 3.4227\tvalid_1's rmse: 3.6611\n",
      "[600]\ttraining's rmse: 3.39476\tvalid_1's rmse: 3.65907\n",
      "[700]\ttraining's rmse: 3.37164\tvalid_1's rmse: 3.6579\n",
      "[800]\ttraining's rmse: 3.34903\tvalid_1's rmse: 3.65708\n",
      "[900]\ttraining's rmse: 3.32707\tvalid_1's rmse: 3.65698\n",
      "[1000]\ttraining's rmse: 3.30685\tvalid_1's rmse: 3.65644\n",
      "[1100]\ttraining's rmse: 3.28753\tvalid_1's rmse: 3.6562\n",
      "[1200]\ttraining's rmse: 3.26949\tvalid_1's rmse: 3.65694\n",
      "[1300]\ttraining's rmse: 3.2516\tvalid_1's rmse: 3.65656\n",
      "[1400]\ttraining's rmse: 3.23421\tvalid_1's rmse: 3.65622\n",
      "[1500]\ttraining's rmse: 3.21722\tvalid_1's rmse: 3.65642\n",
      "[1600]\ttraining's rmse: 3.20092\tvalid_1's rmse: 3.65705\n",
      "[1700]\ttraining's rmse: 3.18541\tvalid_1's rmse: 3.65718\n",
      "[1800]\ttraining's rmse: 3.16948\tvalid_1's rmse: 3.65731\n",
      "[1900]\ttraining's rmse: 3.15419\tvalid_1's rmse: 3.65788\n",
      "[2000]\ttraining's rmse: 3.139\tvalid_1's rmse: 3.6582\n",
      "Early stopping, best iteration is:\n",
      "[1434]\ttraining's rmse: 3.22895\tvalid_1's rmse: 3.6559\n",
      "fold 1 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64598\tvalid_1's rmse: 3.70139\n",
      "[200]\ttraining's rmse: 3.55625\tvalid_1's rmse: 3.66051\n",
      "[300]\ttraining's rmse: 3.50148\tvalid_1's rmse: 3.64648\n",
      "[400]\ttraining's rmse: 3.46009\tvalid_1's rmse: 3.63998\n",
      "[500]\ttraining's rmse: 3.42667\tvalid_1's rmse: 3.63529\n",
      "[600]\ttraining's rmse: 3.39908\tvalid_1's rmse: 3.6328\n",
      "[700]\ttraining's rmse: 3.37497\tvalid_1's rmse: 3.63088\n",
      "[800]\ttraining's rmse: 3.35278\tvalid_1's rmse: 3.62964\n",
      "[900]\ttraining's rmse: 3.33122\tvalid_1's rmse: 3.62944\n",
      "[1000]\ttraining's rmse: 3.31101\tvalid_1's rmse: 3.62938\n",
      "[1100]\ttraining's rmse: 3.29236\tvalid_1's rmse: 3.62896\n",
      "[1200]\ttraining's rmse: 3.27484\tvalid_1's rmse: 3.62882\n",
      "[1300]\ttraining's rmse: 3.25688\tvalid_1's rmse: 3.62902\n",
      "[1400]\ttraining's rmse: 3.24136\tvalid_1's rmse: 3.62981\n",
      "[1500]\ttraining's rmse: 3.22282\tvalid_1's rmse: 3.62998\n",
      "[1600]\ttraining's rmse: 3.20481\tvalid_1's rmse: 3.63005\n",
      "[1700]\ttraining's rmse: 3.18793\tvalid_1's rmse: 3.63068\n",
      "[1800]\ttraining's rmse: 3.17116\tvalid_1's rmse: 3.63135\n",
      "Early stopping, best iteration is:\n",
      "[1227]\ttraining's rmse: 3.26933\tvalid_1's rmse: 3.62862\n",
      "fold 2 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63817\tvalid_1's rmse: 3.71046\n",
      "[200]\ttraining's rmse: 3.54525\tvalid_1's rmse: 3.68045\n",
      "[300]\ttraining's rmse: 3.48987\tvalid_1's rmse: 3.66901\n",
      "[400]\ttraining's rmse: 3.44979\tvalid_1's rmse: 3.66395\n",
      "[500]\ttraining's rmse: 3.41643\tvalid_1's rmse: 3.66142\n",
      "[600]\ttraining's rmse: 3.3883\tvalid_1's rmse: 3.65987\n",
      "[700]\ttraining's rmse: 3.36306\tvalid_1's rmse: 3.659\n",
      "[800]\ttraining's rmse: 3.33988\tvalid_1's rmse: 3.65865\n",
      "[900]\ttraining's rmse: 3.31854\tvalid_1's rmse: 3.65864\n",
      "[1000]\ttraining's rmse: 3.29797\tvalid_1's rmse: 3.6591\n",
      "[1100]\ttraining's rmse: 3.27852\tvalid_1's rmse: 3.65933\n",
      "[1200]\ttraining's rmse: 3.25997\tvalid_1's rmse: 3.65983\n",
      "[1300]\ttraining's rmse: 3.24232\tvalid_1's rmse: 3.66047\n",
      "[1400]\ttraining's rmse: 3.22612\tvalid_1's rmse: 3.66081\n",
      "Early stopping, best iteration is:\n",
      "[876]\ttraining's rmse: 3.32315\tvalid_1's rmse: 3.65849\n",
      "fold 3 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64638\tvalid_1's rmse: 3.7011\n",
      "[200]\ttraining's rmse: 3.55622\tvalid_1's rmse: 3.66244\n",
      "[300]\ttraining's rmse: 3.50211\tvalid_1's rmse: 3.6474\n",
      "[400]\ttraining's rmse: 3.46275\tvalid_1's rmse: 3.63945\n",
      "[500]\ttraining's rmse: 3.42923\tvalid_1's rmse: 3.63479\n",
      "[600]\ttraining's rmse: 3.39997\tvalid_1's rmse: 3.63296\n",
      "[700]\ttraining's rmse: 3.37536\tvalid_1's rmse: 3.63077\n",
      "[800]\ttraining's rmse: 3.35141\tvalid_1's rmse: 3.62977\n",
      "[900]\ttraining's rmse: 3.33071\tvalid_1's rmse: 3.62885\n",
      "[1000]\ttraining's rmse: 3.30936\tvalid_1's rmse: 3.62886\n",
      "[1100]\ttraining's rmse: 3.28955\tvalid_1's rmse: 3.62842\n",
      "[1200]\ttraining's rmse: 3.26952\tvalid_1's rmse: 3.62835\n",
      "[1300]\ttraining's rmse: 3.2513\tvalid_1's rmse: 3.62826\n",
      "[1400]\ttraining's rmse: 3.23319\tvalid_1's rmse: 3.62843\n",
      "[1500]\ttraining's rmse: 3.21623\tvalid_1's rmse: 3.62856\n",
      "[1600]\ttraining's rmse: 3.19926\tvalid_1's rmse: 3.62937\n",
      "[1700]\ttraining's rmse: 3.18229\tvalid_1's rmse: 3.62984\n",
      "Early stopping, best iteration is:\n",
      "[1161]\ttraining's rmse: 3.27692\tvalid_1's rmse: 3.62791\n",
      "fold 4 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63277\tvalid_1's rmse: 3.72411\n",
      "[200]\ttraining's rmse: 3.53758\tvalid_1's rmse: 3.70064\n",
      "[300]\ttraining's rmse: 3.4838\tvalid_1's rmse: 3.69289\n",
      "[400]\ttraining's rmse: 3.44261\tvalid_1's rmse: 3.68806\n",
      "[500]\ttraining's rmse: 3.40891\tvalid_1's rmse: 3.68545\n",
      "[600]\ttraining's rmse: 3.38078\tvalid_1's rmse: 3.68377\n",
      "[700]\ttraining's rmse: 3.35588\tvalid_1's rmse: 3.68331\n",
      "[800]\ttraining's rmse: 3.33294\tvalid_1's rmse: 3.68268\n",
      "[900]\ttraining's rmse: 3.31137\tvalid_1's rmse: 3.68304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.29094\tvalid_1's rmse: 3.68246\n",
      "[1100]\ttraining's rmse: 3.27143\tvalid_1's rmse: 3.68264\n",
      "[1200]\ttraining's rmse: 3.25285\tvalid_1's rmse: 3.68262\n",
      "[1300]\ttraining's rmse: 3.23409\tvalid_1's rmse: 3.68277\n",
      "[1400]\ttraining's rmse: 3.21702\tvalid_1's rmse: 3.6831\n",
      "[1500]\ttraining's rmse: 3.20026\tvalid_1's rmse: 3.68287\n",
      "[1600]\ttraining's rmse: 3.18478\tvalid_1's rmse: 3.68334\n",
      "Early stopping, best iteration is:\n",
      "[1009]\ttraining's rmse: 3.28909\tvalid_1's rmse: 3.68238\n",
      "fold 0 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64517\tvalid_1's rmse: 3.70989\n",
      "[200]\ttraining's rmse: 3.55521\tvalid_1's rmse: 3.67776\n",
      "[300]\ttraining's rmse: 3.50313\tvalid_1's rmse: 3.66758\n",
      "[400]\ttraining's rmse: 3.46281\tvalid_1's rmse: 3.66244\n",
      "[500]\ttraining's rmse: 3.4319\tvalid_1's rmse: 3.65951\n",
      "[600]\ttraining's rmse: 3.40508\tvalid_1's rmse: 3.6577\n",
      "[700]\ttraining's rmse: 3.38121\tvalid_1's rmse: 3.65648\n",
      "[800]\ttraining's rmse: 3.35916\tvalid_1's rmse: 3.65613\n",
      "[900]\ttraining's rmse: 3.33755\tvalid_1's rmse: 3.65589\n",
      "[1000]\ttraining's rmse: 3.31864\tvalid_1's rmse: 3.65607\n",
      "[1100]\ttraining's rmse: 3.29959\tvalid_1's rmse: 3.65683\n",
      "[1200]\ttraining's rmse: 3.28135\tvalid_1's rmse: 3.65704\n",
      "[1300]\ttraining's rmse: 3.26312\tvalid_1's rmse: 3.65741\n",
      "[1400]\ttraining's rmse: 3.24561\tvalid_1's rmse: 3.6578\n",
      "[1500]\ttraining's rmse: 3.22901\tvalid_1's rmse: 3.65843\n",
      "Early stopping, best iteration is:\n",
      "[919]\ttraining's rmse: 3.33374\tvalid_1's rmse: 3.65574\n",
      "fold 1 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65012\tvalid_1's rmse: 3.70074\n",
      "[200]\ttraining's rmse: 3.56243\tvalid_1's rmse: 3.6617\n",
      "[300]\ttraining's rmse: 3.50806\tvalid_1's rmse: 3.64765\n",
      "[400]\ttraining's rmse: 3.46895\tvalid_1's rmse: 3.64076\n",
      "[500]\ttraining's rmse: 3.43607\tvalid_1's rmse: 3.63708\n",
      "[600]\ttraining's rmse: 3.40943\tvalid_1's rmse: 3.63426\n",
      "[700]\ttraining's rmse: 3.38493\tvalid_1's rmse: 3.63241\n",
      "[800]\ttraining's rmse: 3.3626\tvalid_1's rmse: 3.63165\n",
      "[900]\ttraining's rmse: 3.34173\tvalid_1's rmse: 3.63095\n",
      "[1000]\ttraining's rmse: 3.32175\tvalid_1's rmse: 3.6303\n",
      "[1100]\ttraining's rmse: 3.30266\tvalid_1's rmse: 3.62971\n",
      "[1200]\ttraining's rmse: 3.28453\tvalid_1's rmse: 3.63046\n",
      "[1300]\ttraining's rmse: 3.26765\tvalid_1's rmse: 3.63084\n",
      "[1400]\ttraining's rmse: 3.2514\tvalid_1's rmse: 3.63087\n",
      "[1500]\ttraining's rmse: 3.23459\tvalid_1's rmse: 3.63124\n",
      "[1600]\ttraining's rmse: 3.21878\tvalid_1's rmse: 3.63087\n",
      "Early stopping, best iteration is:\n",
      "[1074]\ttraining's rmse: 3.30688\tvalid_1's rmse: 3.62957\n",
      "fold 2 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64212\tvalid_1's rmse: 3.71086\n",
      "[200]\ttraining's rmse: 3.55188\tvalid_1's rmse: 3.6804\n",
      "[300]\ttraining's rmse: 3.49776\tvalid_1's rmse: 3.66926\n",
      "[400]\ttraining's rmse: 3.45905\tvalid_1's rmse: 3.66382\n",
      "[500]\ttraining's rmse: 3.4272\tvalid_1's rmse: 3.66092\n",
      "[600]\ttraining's rmse: 3.39855\tvalid_1's rmse: 3.65851\n",
      "[700]\ttraining's rmse: 3.3734\tvalid_1's rmse: 3.65785\n",
      "[800]\ttraining's rmse: 3.35066\tvalid_1's rmse: 3.65772\n",
      "[900]\ttraining's rmse: 3.32985\tvalid_1's rmse: 3.65747\n",
      "[1000]\ttraining's rmse: 3.30999\tvalid_1's rmse: 3.65773\n",
      "[1100]\ttraining's rmse: 3.29185\tvalid_1's rmse: 3.65805\n",
      "[1200]\ttraining's rmse: 3.2741\tvalid_1's rmse: 3.65879\n",
      "[1300]\ttraining's rmse: 3.2562\tvalid_1's rmse: 3.65982\n",
      "[1400]\ttraining's rmse: 3.23949\tvalid_1's rmse: 3.66014\n",
      "[1500]\ttraining's rmse: 3.22345\tvalid_1's rmse: 3.66068\n",
      "Early stopping, best iteration is:\n",
      "[914]\ttraining's rmse: 3.32685\tvalid_1's rmse: 3.65725\n",
      "fold 3 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64848\tvalid_1's rmse: 3.70292\n",
      "[200]\ttraining's rmse: 3.56208\tvalid_1's rmse: 3.66234\n",
      "[300]\ttraining's rmse: 3.50941\tvalid_1's rmse: 3.64829\n",
      "[400]\ttraining's rmse: 3.47039\tvalid_1's rmse: 3.64028\n",
      "[500]\ttraining's rmse: 3.43807\tvalid_1's rmse: 3.63455\n",
      "[600]\ttraining's rmse: 3.41\tvalid_1's rmse: 3.63165\n",
      "[700]\ttraining's rmse: 3.385\tvalid_1's rmse: 3.62919\n",
      "[800]\ttraining's rmse: 3.36228\tvalid_1's rmse: 3.62818\n",
      "[900]\ttraining's rmse: 3.34146\tvalid_1's rmse: 3.62705\n",
      "[1000]\ttraining's rmse: 3.32069\tvalid_1's rmse: 3.62662\n",
      "[1100]\ttraining's rmse: 3.30099\tvalid_1's rmse: 3.62693\n",
      "[1200]\ttraining's rmse: 3.28202\tvalid_1's rmse: 3.62679\n",
      "[1300]\ttraining's rmse: 3.26527\tvalid_1's rmse: 3.62724\n",
      "[1400]\ttraining's rmse: 3.24806\tvalid_1's rmse: 3.6274\n",
      "[1500]\ttraining's rmse: 3.23028\tvalid_1's rmse: 3.62815\n",
      "Early stopping, best iteration is:\n",
      "[953]\ttraining's rmse: 3.33035\tvalid_1's rmse: 3.62643\n",
      "fold 4 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63605\tvalid_1's rmse: 3.72313\n",
      "[200]\ttraining's rmse: 3.54475\tvalid_1's rmse: 3.6989\n",
      "[300]\ttraining's rmse: 3.49063\tvalid_1's rmse: 3.69029\n",
      "[400]\ttraining's rmse: 3.4512\tvalid_1's rmse: 3.68524\n",
      "[500]\ttraining's rmse: 3.41898\tvalid_1's rmse: 3.68286\n",
      "[600]\ttraining's rmse: 3.3918\tvalid_1's rmse: 3.68171\n",
      "[700]\ttraining's rmse: 3.36708\tvalid_1's rmse: 3.68094\n",
      "[800]\ttraining's rmse: 3.34321\tvalid_1's rmse: 3.68019\n",
      "[900]\ttraining's rmse: 3.32217\tvalid_1's rmse: 3.6796\n",
      "[1000]\ttraining's rmse: 3.30231\tvalid_1's rmse: 3.67918\n",
      "[1100]\ttraining's rmse: 3.28338\tvalid_1's rmse: 3.67791\n",
      "[1200]\ttraining's rmse: 3.26538\tvalid_1's rmse: 3.67814\n",
      "[1300]\ttraining's rmse: 3.24735\tvalid_1's rmse: 3.67811\n",
      "[1400]\ttraining's rmse: 3.22923\tvalid_1's rmse: 3.67822\n",
      "[1500]\ttraining's rmse: 3.21216\tvalid_1's rmse: 3.67797\n",
      "[1600]\ttraining's rmse: 3.19477\tvalid_1's rmse: 3.67855\n",
      "[1700]\ttraining's rmse: 3.17918\tvalid_1's rmse: 3.67873\n",
      "[1800]\ttraining's rmse: 3.16249\tvalid_1's rmse: 3.67918\n",
      "Early stopping, best iteration is:\n",
      "[1252]\ttraining's rmse: 3.2558\tvalid_1's rmse: 3.67779\n",
      "fold 0 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63505\tvalid_1's rmse: 3.70449\n",
      "[200]\ttraining's rmse: 3.53676\tvalid_1's rmse: 3.67182\n",
      "[300]\ttraining's rmse: 3.47829\tvalid_1's rmse: 3.65802\n",
      "[400]\ttraining's rmse: 3.43352\tvalid_1's rmse: 3.65158\n",
      "[500]\ttraining's rmse: 3.39838\tvalid_1's rmse: 3.64744\n",
      "[600]\ttraining's rmse: 3.36721\tvalid_1's rmse: 3.64586\n",
      "[700]\ttraining's rmse: 3.33906\tvalid_1's rmse: 3.645\n",
      "[800]\ttraining's rmse: 3.31297\tvalid_1's rmse: 3.64471\n",
      "[900]\ttraining's rmse: 3.2899\tvalid_1's rmse: 3.64373\n",
      "[1000]\ttraining's rmse: 3.26804\tvalid_1's rmse: 3.64402\n",
      "[1100]\ttraining's rmse: 3.24561\tvalid_1's rmse: 3.64373\n",
      "[1200]\ttraining's rmse: 3.2243\tvalid_1's rmse: 3.6438\n",
      "[1300]\ttraining's rmse: 3.20336\tvalid_1's rmse: 3.64354\n",
      "[1400]\ttraining's rmse: 3.18476\tvalid_1's rmse: 3.6438\n",
      "[1500]\ttraining's rmse: 3.16583\tvalid_1's rmse: 3.64437\n",
      "[1600]\ttraining's rmse: 3.14742\tvalid_1's rmse: 3.64426\n",
      "[1700]\ttraining's rmse: 3.12873\tvalid_1's rmse: 3.64411\n",
      "[1800]\ttraining's rmse: 3.11069\tvalid_1's rmse: 3.64411\n",
      "[1900]\ttraining's rmse: 3.09279\tvalid_1's rmse: 3.64425\n",
      "Early stopping, best iteration is:\n",
      "[1328]\ttraining's rmse: 3.19752\tvalid_1's rmse: 3.64337\n",
      "fold 1 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63159\tvalid_1's rmse: 3.72362\n",
      "[200]\ttraining's rmse: 3.53057\tvalid_1's rmse: 3.69111\n",
      "[300]\ttraining's rmse: 3.47013\tvalid_1's rmse: 3.68109\n",
      "[400]\ttraining's rmse: 3.42538\tvalid_1's rmse: 3.67319\n",
      "[500]\ttraining's rmse: 3.38847\tvalid_1's rmse: 3.66904\n",
      "[600]\ttraining's rmse: 3.35704\tvalid_1's rmse: 3.66685\n",
      "[700]\ttraining's rmse: 3.32771\tvalid_1's rmse: 3.66559\n",
      "[800]\ttraining's rmse: 3.30208\tvalid_1's rmse: 3.66492\n",
      "[900]\ttraining's rmse: 3.27817\tvalid_1's rmse: 3.66447\n",
      "[1000]\ttraining's rmse: 3.25623\tvalid_1's rmse: 3.66413\n",
      "[1100]\ttraining's rmse: 3.23501\tvalid_1's rmse: 3.664\n",
      "[1200]\ttraining's rmse: 3.21463\tvalid_1's rmse: 3.66386\n",
      "[1300]\ttraining's rmse: 3.19455\tvalid_1's rmse: 3.66388\n",
      "[1400]\ttraining's rmse: 3.17485\tvalid_1's rmse: 3.66406\n",
      "[1500]\ttraining's rmse: 3.15578\tvalid_1's rmse: 3.66413\n",
      "[1600]\ttraining's rmse: 3.1377\tvalid_1's rmse: 3.66471\n",
      "[1700]\ttraining's rmse: 3.11947\tvalid_1's rmse: 3.66468\n",
      "[1800]\ttraining's rmse: 3.10128\tvalid_1's rmse: 3.66434\n",
      "Early stopping, best iteration is:\n",
      "[1236]\ttraining's rmse: 3.20763\tvalid_1's rmse: 3.66372\n",
      "fold 2 1472 0.010935213318376656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63853\tvalid_1's rmse: 3.69663\n",
      "[200]\ttraining's rmse: 3.54206\tvalid_1's rmse: 3.65832\n",
      "[300]\ttraining's rmse: 3.48262\tvalid_1's rmse: 3.64366\n",
      "[400]\ttraining's rmse: 3.43872\tvalid_1's rmse: 3.63589\n",
      "[500]\ttraining's rmse: 3.40254\tvalid_1's rmse: 3.63125\n",
      "[600]\ttraining's rmse: 3.37107\tvalid_1's rmse: 3.62724\n",
      "[700]\ttraining's rmse: 3.34405\tvalid_1's rmse: 3.62576\n",
      "[800]\ttraining's rmse: 3.31848\tvalid_1's rmse: 3.6246\n",
      "[900]\ttraining's rmse: 3.29314\tvalid_1's rmse: 3.62408\n",
      "[1000]\ttraining's rmse: 3.2696\tvalid_1's rmse: 3.62324\n",
      "[1100]\ttraining's rmse: 3.2463\tvalid_1's rmse: 3.62327\n",
      "[1200]\ttraining's rmse: 3.22554\tvalid_1's rmse: 3.62373\n",
      "[1300]\ttraining's rmse: 3.20503\tvalid_1's rmse: 3.62379\n",
      "[1400]\ttraining's rmse: 3.18477\tvalid_1's rmse: 3.62392\n",
      "[1500]\ttraining's rmse: 3.16562\tvalid_1's rmse: 3.6248\n",
      "[1600]\ttraining's rmse: 3.14774\tvalid_1's rmse: 3.62523\n",
      "Early stopping, best iteration is:\n",
      "[1072]\ttraining's rmse: 3.25269\tvalid_1's rmse: 3.62281\n",
      "fold 3 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63222\tvalid_1's rmse: 3.70746\n",
      "[200]\ttraining's rmse: 3.53075\tvalid_1's rmse: 3.67521\n",
      "[300]\ttraining's rmse: 3.46935\tvalid_1's rmse: 3.66225\n",
      "[400]\ttraining's rmse: 3.42348\tvalid_1's rmse: 3.65647\n",
      "[500]\ttraining's rmse: 3.38623\tvalid_1's rmse: 3.65223\n",
      "[600]\ttraining's rmse: 3.35442\tvalid_1's rmse: 3.64955\n",
      "[700]\ttraining's rmse: 3.3253\tvalid_1's rmse: 3.64806\n",
      "[800]\ttraining's rmse: 3.2979\tvalid_1's rmse: 3.64807\n",
      "[900]\ttraining's rmse: 3.27363\tvalid_1's rmse: 3.64782\n",
      "[1000]\ttraining's rmse: 3.25027\tvalid_1's rmse: 3.64794\n",
      "[1100]\ttraining's rmse: 3.22879\tvalid_1's rmse: 3.64827\n",
      "[1200]\ttraining's rmse: 3.20748\tvalid_1's rmse: 3.64816\n",
      "[1300]\ttraining's rmse: 3.18762\tvalid_1's rmse: 3.64802\n",
      "[1400]\ttraining's rmse: 3.16709\tvalid_1's rmse: 3.64861\n",
      "Early stopping, best iteration is:\n",
      "[885]\ttraining's rmse: 3.27668\tvalid_1's rmse: 3.64756\n",
      "fold 4 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63344\tvalid_1's rmse: 3.71521\n",
      "[200]\ttraining's rmse: 3.53486\tvalid_1's rmse: 3.67724\n",
      "[300]\ttraining's rmse: 3.47295\tvalid_1's rmse: 3.66229\n",
      "[400]\ttraining's rmse: 3.42864\tvalid_1's rmse: 3.65381\n",
      "[500]\ttraining's rmse: 3.39159\tvalid_1's rmse: 3.64741\n",
      "[600]\ttraining's rmse: 3.35855\tvalid_1's rmse: 3.64324\n",
      "[700]\ttraining's rmse: 3.3299\tvalid_1's rmse: 3.63973\n",
      "[800]\ttraining's rmse: 3.30419\tvalid_1's rmse: 3.63761\n",
      "[900]\ttraining's rmse: 3.27903\tvalid_1's rmse: 3.63565\n",
      "[1000]\ttraining's rmse: 3.25578\tvalid_1's rmse: 3.63466\n",
      "[1100]\ttraining's rmse: 3.23387\tvalid_1's rmse: 3.63443\n",
      "[1200]\ttraining's rmse: 3.21228\tvalid_1's rmse: 3.63384\n",
      "[1300]\ttraining's rmse: 3.19163\tvalid_1's rmse: 3.63328\n",
      "[1400]\ttraining's rmse: 3.17158\tvalid_1's rmse: 3.63318\n",
      "[1500]\ttraining's rmse: 3.15183\tvalid_1's rmse: 3.63267\n",
      "[1600]\ttraining's rmse: 3.13281\tvalid_1's rmse: 3.63244\n",
      "[1700]\ttraining's rmse: 3.11379\tvalid_1's rmse: 3.632\n",
      "[1800]\ttraining's rmse: 3.09583\tvalid_1's rmse: 3.63248\n",
      "[1900]\ttraining's rmse: 3.07798\tvalid_1's rmse: 3.63251\n",
      "[2000]\ttraining's rmse: 3.06063\tvalid_1's rmse: 3.63215\n",
      "[2100]\ttraining's rmse: 3.04264\tvalid_1's rmse: 3.63206\n",
      "[2200]\ttraining's rmse: 3.02607\tvalid_1's rmse: 3.63157\n",
      "[2300]\ttraining's rmse: 3.00835\tvalid_1's rmse: 3.63174\n",
      "[2400]\ttraining's rmse: 2.9916\tvalid_1's rmse: 3.63161\n",
      "[2500]\ttraining's rmse: 2.97628\tvalid_1's rmse: 3.63162\n",
      "[2600]\ttraining's rmse: 2.96078\tvalid_1's rmse: 3.63203\n",
      "[2700]\ttraining's rmse: 2.94519\tvalid_1's rmse: 3.63237\n",
      "[2800]\ttraining's rmse: 2.92912\tvalid_1's rmse: 3.63193\n",
      "[2900]\ttraining's rmse: 2.91331\tvalid_1's rmse: 3.63236\n",
      "[3000]\ttraining's rmse: 2.89853\tvalid_1's rmse: 3.63233\n",
      "Early stopping, best iteration is:\n",
      "[2420]\ttraining's rmse: 2.98835\tvalid_1's rmse: 3.63131\n",
      "fold 5 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.62855\tvalid_1's rmse: 3.72431\n",
      "[200]\ttraining's rmse: 3.52599\tvalid_1's rmse: 3.70285\n",
      "[300]\ttraining's rmse: 3.46542\tvalid_1's rmse: 3.69401\n",
      "[400]\ttraining's rmse: 3.41925\tvalid_1's rmse: 3.68996\n",
      "[500]\ttraining's rmse: 3.38254\tvalid_1's rmse: 3.6873\n",
      "[600]\ttraining's rmse: 3.35156\tvalid_1's rmse: 3.68637\n",
      "[700]\ttraining's rmse: 3.32261\tvalid_1's rmse: 3.68543\n",
      "[800]\ttraining's rmse: 3.29686\tvalid_1's rmse: 3.68405\n",
      "[900]\ttraining's rmse: 3.27119\tvalid_1's rmse: 3.68434\n",
      "[1000]\ttraining's rmse: 3.24826\tvalid_1's rmse: 3.68457\n",
      "[1100]\ttraining's rmse: 3.22673\tvalid_1's rmse: 3.68393\n",
      "[1200]\ttraining's rmse: 3.20622\tvalid_1's rmse: 3.68384\n",
      "[1300]\ttraining's rmse: 3.18679\tvalid_1's rmse: 3.6835\n",
      "[1400]\ttraining's rmse: 3.16576\tvalid_1's rmse: 3.68412\n",
      "[1500]\ttraining's rmse: 3.14651\tvalid_1's rmse: 3.68417\n",
      "[1600]\ttraining's rmse: 3.1278\tvalid_1's rmse: 3.68419\n",
      "[1700]\ttraining's rmse: 3.10925\tvalid_1's rmse: 3.68468\n",
      "[1800]\ttraining's rmse: 3.09145\tvalid_1's rmse: 3.68464\n",
      "[1900]\ttraining's rmse: 3.07515\tvalid_1's rmse: 3.68476\n",
      "Early stopping, best iteration is:\n",
      "[1314]\ttraining's rmse: 3.184\tvalid_1's rmse: 3.68345\n",
      "fold 0 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64121\tvalid_1's rmse: 3.70098\n",
      "[200]\ttraining's rmse: 3.54647\tvalid_1's rmse: 3.66775\n",
      "[300]\ttraining's rmse: 3.49191\tvalid_1's rmse: 3.65494\n",
      "[400]\ttraining's rmse: 3.44861\tvalid_1's rmse: 3.64846\n",
      "[500]\ttraining's rmse: 3.4143\tvalid_1's rmse: 3.64484\n",
      "[600]\ttraining's rmse: 3.38523\tvalid_1's rmse: 3.64307\n",
      "[700]\ttraining's rmse: 3.35799\tvalid_1's rmse: 3.6419\n",
      "[800]\ttraining's rmse: 3.33363\tvalid_1's rmse: 3.64143\n",
      "[900]\ttraining's rmse: 3.31159\tvalid_1's rmse: 3.64129\n",
      "[1000]\ttraining's rmse: 3.29094\tvalid_1's rmse: 3.64153\n",
      "[1100]\ttraining's rmse: 3.27097\tvalid_1's rmse: 3.64128\n",
      "[1200]\ttraining's rmse: 3.25134\tvalid_1's rmse: 3.64062\n",
      "[1300]\ttraining's rmse: 3.2325\tvalid_1's rmse: 3.64046\n",
      "[1400]\ttraining's rmse: 3.21378\tvalid_1's rmse: 3.64029\n",
      "[1500]\ttraining's rmse: 3.19539\tvalid_1's rmse: 3.64059\n",
      "[1600]\ttraining's rmse: 3.17898\tvalid_1's rmse: 3.6406\n",
      "[1700]\ttraining's rmse: 3.16174\tvalid_1's rmse: 3.64034\n",
      "[1800]\ttraining's rmse: 3.14561\tvalid_1's rmse: 3.64004\n",
      "[1900]\ttraining's rmse: 3.12902\tvalid_1's rmse: 3.64053\n",
      "[2000]\ttraining's rmse: 3.11264\tvalid_1's rmse: 3.64102\n",
      "[2100]\ttraining's rmse: 3.09629\tvalid_1's rmse: 3.64106\n",
      "[2200]\ttraining's rmse: 3.08013\tvalid_1's rmse: 3.64148\n",
      "[2300]\ttraining's rmse: 3.06506\tvalid_1's rmse: 3.64205\n",
      "[2400]\ttraining's rmse: 3.05019\tvalid_1's rmse: 3.64206\n",
      "Early stopping, best iteration is:\n",
      "[1803]\ttraining's rmse: 3.14493\tvalid_1's rmse: 3.63995\n",
      "fold 1 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63691\tvalid_1's rmse: 3.72373\n",
      "[200]\ttraining's rmse: 3.5411\tvalid_1's rmse: 3.68976\n",
      "[300]\ttraining's rmse: 3.48265\tvalid_1's rmse: 3.67933\n",
      "[400]\ttraining's rmse: 3.43968\tvalid_1's rmse: 3.6727\n",
      "[500]\ttraining's rmse: 3.40496\tvalid_1's rmse: 3.66972\n",
      "[600]\ttraining's rmse: 3.37575\tvalid_1's rmse: 3.66651\n",
      "[700]\ttraining's rmse: 3.34905\tvalid_1's rmse: 3.66497\n",
      "[800]\ttraining's rmse: 3.32477\tvalid_1's rmse: 3.66436\n",
      "[900]\ttraining's rmse: 3.30252\tvalid_1's rmse: 3.66333\n",
      "[1000]\ttraining's rmse: 3.28028\tvalid_1's rmse: 3.66241\n",
      "[1100]\ttraining's rmse: 3.26064\tvalid_1's rmse: 3.66213\n",
      "[1200]\ttraining's rmse: 3.24086\tvalid_1's rmse: 3.66237\n",
      "[1300]\ttraining's rmse: 3.22203\tvalid_1's rmse: 3.66287\n",
      "[1400]\ttraining's rmse: 3.20405\tvalid_1's rmse: 3.66288\n",
      "[1500]\ttraining's rmse: 3.18606\tvalid_1's rmse: 3.66322\n",
      "[1600]\ttraining's rmse: 3.16866\tvalid_1's rmse: 3.66339\n",
      "Early stopping, best iteration is:\n",
      "[1040]\ttraining's rmse: 3.27225\tvalid_1's rmse: 3.66196\n",
      "fold 2 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64428\tvalid_1's rmse: 3.69512\n",
      "[200]\ttraining's rmse: 3.55224\tvalid_1's rmse: 3.65538\n",
      "[300]\ttraining's rmse: 3.49421\tvalid_1's rmse: 3.64006\n",
      "[400]\ttraining's rmse: 3.45255\tvalid_1's rmse: 3.63291\n",
      "[500]\ttraining's rmse: 3.4186\tvalid_1's rmse: 3.62824\n",
      "[600]\ttraining's rmse: 3.38917\tvalid_1's rmse: 3.62464\n",
      "[700]\ttraining's rmse: 3.36207\tvalid_1's rmse: 3.6232\n",
      "[800]\ttraining's rmse: 3.33672\tvalid_1's rmse: 3.62244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttraining's rmse: 3.31383\tvalid_1's rmse: 3.62243\n",
      "[1000]\ttraining's rmse: 3.29229\tvalid_1's rmse: 3.62227\n",
      "[1100]\ttraining's rmse: 3.27173\tvalid_1's rmse: 3.62308\n",
      "[1200]\ttraining's rmse: 3.2517\tvalid_1's rmse: 3.62408\n",
      "[1300]\ttraining's rmse: 3.23194\tvalid_1's rmse: 3.62451\n",
      "[1400]\ttraining's rmse: 3.21354\tvalid_1's rmse: 3.62482\n",
      "[1500]\ttraining's rmse: 3.1955\tvalid_1's rmse: 3.625\n",
      "Early stopping, best iteration is:\n",
      "[989]\ttraining's rmse: 3.29457\tvalid_1's rmse: 3.6221\n",
      "fold 3 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63817\tvalid_1's rmse: 3.70639\n",
      "[200]\ttraining's rmse: 3.54062\tvalid_1's rmse: 3.67531\n",
      "[300]\ttraining's rmse: 3.48234\tvalid_1's rmse: 3.66304\n",
      "[400]\ttraining's rmse: 3.4393\tvalid_1's rmse: 3.65665\n",
      "[500]\ttraining's rmse: 3.40393\tvalid_1's rmse: 3.65386\n",
      "[600]\ttraining's rmse: 3.37336\tvalid_1's rmse: 3.65222\n",
      "[700]\ttraining's rmse: 3.34581\tvalid_1's rmse: 3.65121\n",
      "[800]\ttraining's rmse: 3.32075\tvalid_1's rmse: 3.6507\n",
      "[900]\ttraining's rmse: 3.29708\tvalid_1's rmse: 3.65073\n",
      "[1000]\ttraining's rmse: 3.27604\tvalid_1's rmse: 3.65038\n",
      "[1100]\ttraining's rmse: 3.25523\tvalid_1's rmse: 3.65081\n",
      "[1200]\ttraining's rmse: 3.2349\tvalid_1's rmse: 3.65087\n",
      "[1300]\ttraining's rmse: 3.21501\tvalid_1's rmse: 3.65114\n",
      "[1400]\ttraining's rmse: 3.19635\tvalid_1's rmse: 3.65155\n",
      "[1500]\ttraining's rmse: 3.1773\tvalid_1's rmse: 3.65123\n",
      "Early stopping, best iteration is:\n",
      "[975]\ttraining's rmse: 3.28106\tvalid_1's rmse: 3.65022\n",
      "fold 4 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63908\tvalid_1's rmse: 3.71454\n",
      "[200]\ttraining's rmse: 3.5442\tvalid_1's rmse: 3.67361\n",
      "[300]\ttraining's rmse: 3.48689\tvalid_1's rmse: 3.65908\n",
      "[400]\ttraining's rmse: 3.44477\tvalid_1's rmse: 3.6506\n",
      "[500]\ttraining's rmse: 3.41128\tvalid_1's rmse: 3.64515\n",
      "[600]\ttraining's rmse: 3.38086\tvalid_1's rmse: 3.64155\n",
      "[700]\ttraining's rmse: 3.35383\tvalid_1's rmse: 3.63882\n",
      "[800]\ttraining's rmse: 3.32898\tvalid_1's rmse: 3.63722\n",
      "[900]\ttraining's rmse: 3.3056\tvalid_1's rmse: 3.63553\n",
      "[1000]\ttraining's rmse: 3.28486\tvalid_1's rmse: 3.63481\n",
      "[1100]\ttraining's rmse: 3.26372\tvalid_1's rmse: 3.63394\n",
      "[1200]\ttraining's rmse: 3.24273\tvalid_1's rmse: 3.63403\n",
      "[1300]\ttraining's rmse: 3.22448\tvalid_1's rmse: 3.63379\n",
      "[1400]\ttraining's rmse: 3.2059\tvalid_1's rmse: 3.63392\n",
      "[1500]\ttraining's rmse: 3.18686\tvalid_1's rmse: 3.6342\n",
      "[1600]\ttraining's rmse: 3.16962\tvalid_1's rmse: 3.6337\n",
      "[1700]\ttraining's rmse: 3.15185\tvalid_1's rmse: 3.63359\n",
      "[1800]\ttraining's rmse: 3.1352\tvalid_1's rmse: 3.63414\n",
      "[1900]\ttraining's rmse: 3.11855\tvalid_1's rmse: 3.63471\n",
      "[2000]\ttraining's rmse: 3.10233\tvalid_1's rmse: 3.6343\n",
      "[2100]\ttraining's rmse: 3.08585\tvalid_1's rmse: 3.63451\n",
      "[2200]\ttraining's rmse: 3.06946\tvalid_1's rmse: 3.63387\n",
      "Early stopping, best iteration is:\n",
      "[1674]\ttraining's rmse: 3.15653\tvalid_1's rmse: 3.63326\n",
      "fold 5 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63283\tvalid_1's rmse: 3.72353\n",
      "[200]\ttraining's rmse: 3.53518\tvalid_1's rmse: 3.69995\n",
      "[300]\ttraining's rmse: 3.47705\tvalid_1's rmse: 3.69092\n",
      "[400]\ttraining's rmse: 3.43363\tvalid_1's rmse: 3.68725\n",
      "[500]\ttraining's rmse: 3.39954\tvalid_1's rmse: 3.68449\n",
      "[600]\ttraining's rmse: 3.36838\tvalid_1's rmse: 3.6821\n",
      "[700]\ttraining's rmse: 3.34116\tvalid_1's rmse: 3.68121\n",
      "[800]\ttraining's rmse: 3.31738\tvalid_1's rmse: 3.68066\n",
      "[900]\ttraining's rmse: 3.29438\tvalid_1's rmse: 3.68033\n",
      "[1000]\ttraining's rmse: 3.27258\tvalid_1's rmse: 3.68031\n",
      "[1100]\ttraining's rmse: 3.25283\tvalid_1's rmse: 3.68004\n",
      "[1200]\ttraining's rmse: 3.2344\tvalid_1's rmse: 3.67992\n",
      "[1300]\ttraining's rmse: 3.21525\tvalid_1's rmse: 3.68025\n",
      "[1400]\ttraining's rmse: 3.19711\tvalid_1's rmse: 3.68006\n",
      "[1500]\ttraining's rmse: 3.17955\tvalid_1's rmse: 3.68053\n",
      "[1600]\ttraining's rmse: 3.16253\tvalid_1's rmse: 3.68099\n",
      "[1700]\ttraining's rmse: 3.14562\tvalid_1's rmse: 3.68137\n",
      "[1800]\ttraining's rmse: 3.12881\tvalid_1's rmse: 3.68218\n",
      "Early stopping, best iteration is:\n",
      "[1207]\ttraining's rmse: 3.23301\tvalid_1's rmse: 3.67985\n",
      "fold 0 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64569\tvalid_1's rmse: 3.69727\n",
      "[200]\ttraining's rmse: 3.55596\tvalid_1's rmse: 3.66454\n",
      "[300]\ttraining's rmse: 3.50465\tvalid_1's rmse: 3.65192\n",
      "[400]\ttraining's rmse: 3.46515\tvalid_1's rmse: 3.64582\n",
      "[500]\ttraining's rmse: 3.43295\tvalid_1's rmse: 3.64327\n",
      "[600]\ttraining's rmse: 3.40578\tvalid_1's rmse: 3.64139\n",
      "[700]\ttraining's rmse: 3.38031\tvalid_1's rmse: 3.64013\n",
      "[800]\ttraining's rmse: 3.35753\tvalid_1's rmse: 3.63854\n",
      "[900]\ttraining's rmse: 3.33699\tvalid_1's rmse: 3.63852\n",
      "[1000]\ttraining's rmse: 3.31795\tvalid_1's rmse: 3.63801\n",
      "[1100]\ttraining's rmse: 3.2985\tvalid_1's rmse: 3.63809\n",
      "[1200]\ttraining's rmse: 3.27991\tvalid_1's rmse: 3.63849\n",
      "[1300]\ttraining's rmse: 3.26173\tvalid_1's rmse: 3.63815\n",
      "[1400]\ttraining's rmse: 3.24542\tvalid_1's rmse: 3.63855\n",
      "[1500]\ttraining's rmse: 3.22869\tvalid_1's rmse: 3.63825\n",
      "Early stopping, best iteration is:\n",
      "[981]\ttraining's rmse: 3.32163\tvalid_1's rmse: 3.63776\n",
      "fold 1 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6426\tvalid_1's rmse: 3.72013\n",
      "[200]\ttraining's rmse: 3.55086\tvalid_1's rmse: 3.68824\n",
      "[300]\ttraining's rmse: 3.49714\tvalid_1's rmse: 3.67838\n",
      "[400]\ttraining's rmse: 3.45708\tvalid_1's rmse: 3.67238\n",
      "[500]\ttraining's rmse: 3.42335\tvalid_1's rmse: 3.66845\n",
      "[600]\ttraining's rmse: 3.39582\tvalid_1's rmse: 3.66661\n",
      "[700]\ttraining's rmse: 3.37245\tvalid_1's rmse: 3.66561\n",
      "[800]\ttraining's rmse: 3.35041\tvalid_1's rmse: 3.6653\n",
      "[900]\ttraining's rmse: 3.32966\tvalid_1's rmse: 3.66511\n",
      "[1000]\ttraining's rmse: 3.30942\tvalid_1's rmse: 3.66505\n",
      "[1100]\ttraining's rmse: 3.29073\tvalid_1's rmse: 3.66514\n",
      "[1200]\ttraining's rmse: 3.27163\tvalid_1's rmse: 3.66502\n",
      "[1300]\ttraining's rmse: 3.2534\tvalid_1's rmse: 3.66527\n",
      "[1400]\ttraining's rmse: 3.23667\tvalid_1's rmse: 3.66541\n",
      "[1500]\ttraining's rmse: 3.22012\tvalid_1's rmse: 3.66552\n",
      "[1600]\ttraining's rmse: 3.20456\tvalid_1's rmse: 3.66605\n",
      "[1700]\ttraining's rmse: 3.18772\tvalid_1's rmse: 3.66617\n",
      "Early stopping, best iteration is:\n",
      "[1182]\ttraining's rmse: 3.27519\tvalid_1's rmse: 3.66474\n",
      "fold 2 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64807\tvalid_1's rmse: 3.69132\n",
      "[200]\ttraining's rmse: 3.55999\tvalid_1's rmse: 3.65224\n",
      "[300]\ttraining's rmse: 3.50796\tvalid_1's rmse: 3.63964\n",
      "[400]\ttraining's rmse: 3.46801\tvalid_1's rmse: 3.63343\n",
      "[500]\ttraining's rmse: 3.4366\tvalid_1's rmse: 3.62901\n",
      "[600]\ttraining's rmse: 3.40928\tvalid_1's rmse: 3.62647\n",
      "[700]\ttraining's rmse: 3.38524\tvalid_1's rmse: 3.62444\n",
      "[800]\ttraining's rmse: 3.3629\tvalid_1's rmse: 3.62391\n",
      "[900]\ttraining's rmse: 3.34209\tvalid_1's rmse: 3.62414\n",
      "[1000]\ttraining's rmse: 3.32232\tvalid_1's rmse: 3.62465\n",
      "[1100]\ttraining's rmse: 3.30339\tvalid_1's rmse: 3.62547\n",
      "[1200]\ttraining's rmse: 3.28439\tvalid_1's rmse: 3.62586\n",
      "[1300]\ttraining's rmse: 3.26595\tvalid_1's rmse: 3.6259\n",
      "[1400]\ttraining's rmse: 3.24961\tvalid_1's rmse: 3.62672\n",
      "Early stopping, best iteration is:\n",
      "[845]\ttraining's rmse: 3.35378\tvalid_1's rmse: 3.62356\n",
      "fold 3 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64381\tvalid_1's rmse: 3.70601\n",
      "[200]\ttraining's rmse: 3.55166\tvalid_1's rmse: 3.67446\n",
      "[300]\ttraining's rmse: 3.49804\tvalid_1's rmse: 3.66227\n",
      "[400]\ttraining's rmse: 3.45765\tvalid_1's rmse: 3.65618\n",
      "[500]\ttraining's rmse: 3.42383\tvalid_1's rmse: 3.65286\n",
      "[600]\ttraining's rmse: 3.39652\tvalid_1's rmse: 3.65148\n",
      "[700]\ttraining's rmse: 3.37105\tvalid_1's rmse: 3.6505\n",
      "[800]\ttraining's rmse: 3.34819\tvalid_1's rmse: 3.64997\n",
      "[900]\ttraining's rmse: 3.32653\tvalid_1's rmse: 3.65011\n",
      "[1000]\ttraining's rmse: 3.30729\tvalid_1's rmse: 3.65036\n",
      "[1100]\ttraining's rmse: 3.2876\tvalid_1's rmse: 3.65029\n",
      "[1200]\ttraining's rmse: 3.26847\tvalid_1's rmse: 3.65017\n",
      "[1300]\ttraining's rmse: 3.25205\tvalid_1's rmse: 3.65033\n",
      "[1400]\ttraining's rmse: 3.23507\tvalid_1's rmse: 3.65058\n",
      "Early stopping, best iteration is:\n",
      "[821]\ttraining's rmse: 3.34351\tvalid_1's rmse: 3.64958\n",
      "fold 4 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 3.64405\tvalid_1's rmse: 3.70908\n",
      "[200]\ttraining's rmse: 3.55529\tvalid_1's rmse: 3.6692\n",
      "[300]\ttraining's rmse: 3.50213\tvalid_1's rmse: 3.65481\n",
      "[400]\ttraining's rmse: 3.46271\tvalid_1's rmse: 3.64535\n",
      "[500]\ttraining's rmse: 3.42981\tvalid_1's rmse: 3.64013\n",
      "[600]\ttraining's rmse: 3.40061\tvalid_1's rmse: 3.63589\n",
      "[700]\ttraining's rmse: 3.37715\tvalid_1's rmse: 3.63324\n",
      "[800]\ttraining's rmse: 3.35485\tvalid_1's rmse: 3.6315\n",
      "[900]\ttraining's rmse: 3.33375\tvalid_1's rmse: 3.63012\n",
      "[1000]\ttraining's rmse: 3.31507\tvalid_1's rmse: 3.62973\n",
      "[1100]\ttraining's rmse: 3.2961\tvalid_1's rmse: 3.62901\n",
      "[1200]\ttraining's rmse: 3.27898\tvalid_1's rmse: 3.62841\n",
      "[1300]\ttraining's rmse: 3.26147\tvalid_1's rmse: 3.62857\n",
      "[1400]\ttraining's rmse: 3.24401\tvalid_1's rmse: 3.62845\n",
      "[1500]\ttraining's rmse: 3.22668\tvalid_1's rmse: 3.62802\n",
      "[1600]\ttraining's rmse: 3.21036\tvalid_1's rmse: 3.62857\n",
      "[1700]\ttraining's rmse: 3.19426\tvalid_1's rmse: 3.62869\n",
      "[1800]\ttraining's rmse: 3.17813\tvalid_1's rmse: 3.62922\n",
      "[1900]\ttraining's rmse: 3.16289\tvalid_1's rmse: 3.62944\n",
      "[2000]\ttraining's rmse: 3.14739\tvalid_1's rmse: 3.62964\n",
      "[2100]\ttraining's rmse: 3.13202\tvalid_1's rmse: 3.62976\n",
      "Early stopping, best iteration is:\n",
      "[1520]\ttraining's rmse: 3.22376\tvalid_1's rmse: 3.62778\n",
      "fold 5 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63858\tvalid_1's rmse: 3.72128\n",
      "[200]\ttraining's rmse: 3.54689\tvalid_1's rmse: 3.69608\n",
      "[300]\ttraining's rmse: 3.49312\tvalid_1's rmse: 3.6872\n",
      "[400]\ttraining's rmse: 3.45241\tvalid_1's rmse: 3.68434\n",
      "[500]\ttraining's rmse: 3.41809\tvalid_1's rmse: 3.68194\n",
      "[600]\ttraining's rmse: 3.39058\tvalid_1's rmse: 3.68174\n",
      "[700]\ttraining's rmse: 3.36562\tvalid_1's rmse: 3.68167\n",
      "[800]\ttraining's rmse: 3.34291\tvalid_1's rmse: 3.68102\n",
      "[900]\ttraining's rmse: 3.32085\tvalid_1's rmse: 3.68056\n",
      "[1000]\ttraining's rmse: 3.30199\tvalid_1's rmse: 3.68021\n",
      "[1100]\ttraining's rmse: 3.28363\tvalid_1's rmse: 3.68045\n",
      "[1200]\ttraining's rmse: 3.26542\tvalid_1's rmse: 3.68035\n",
      "[1300]\ttraining's rmse: 3.24721\tvalid_1's rmse: 3.68089\n",
      "[1400]\ttraining's rmse: 3.23001\tvalid_1's rmse: 3.68163\n",
      "[1500]\ttraining's rmse: 3.21382\tvalid_1's rmse: 3.68167\n",
      "[1600]\ttraining's rmse: 3.19748\tvalid_1's rmse: 3.68164\n",
      "Early stopping, best iteration is:\n",
      "[1033]\ttraining's rmse: 3.29569\tvalid_1's rmse: 3.67973\n",
      "fold 0 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64817\tvalid_1's rmse: 3.69958\n",
      "[200]\ttraining's rmse: 3.56136\tvalid_1's rmse: 3.66644\n",
      "[300]\ttraining's rmse: 3.51062\tvalid_1's rmse: 3.65351\n",
      "[400]\ttraining's rmse: 3.47124\tvalid_1's rmse: 3.64774\n",
      "[500]\ttraining's rmse: 3.44071\tvalid_1's rmse: 3.64383\n",
      "[600]\ttraining's rmse: 3.41406\tvalid_1's rmse: 3.64214\n",
      "[700]\ttraining's rmse: 3.38983\tvalid_1's rmse: 3.64104\n",
      "[800]\ttraining's rmse: 3.36772\tvalid_1's rmse: 3.63994\n",
      "[900]\ttraining's rmse: 3.34714\tvalid_1's rmse: 3.63958\n",
      "[1000]\ttraining's rmse: 3.3282\tvalid_1's rmse: 3.6401\n",
      "[1100]\ttraining's rmse: 3.30904\tvalid_1's rmse: 3.64028\n",
      "[1200]\ttraining's rmse: 3.29098\tvalid_1's rmse: 3.64042\n",
      "[1300]\ttraining's rmse: 3.2731\tvalid_1's rmse: 3.64086\n",
      "[1400]\ttraining's rmse: 3.25591\tvalid_1's rmse: 3.64143\n",
      "Early stopping, best iteration is:\n",
      "[874]\ttraining's rmse: 3.35281\tvalid_1's rmse: 3.63909\n",
      "fold 1 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64542\tvalid_1's rmse: 3.7212\n",
      "[200]\ttraining's rmse: 3.55634\tvalid_1's rmse: 3.68899\n",
      "[300]\ttraining's rmse: 3.5036\tvalid_1's rmse: 3.67967\n",
      "[400]\ttraining's rmse: 3.4641\tvalid_1's rmse: 3.67418\n",
      "[500]\ttraining's rmse: 3.43195\tvalid_1's rmse: 3.6709\n",
      "[600]\ttraining's rmse: 3.40446\tvalid_1's rmse: 3.66885\n",
      "[700]\ttraining's rmse: 3.38094\tvalid_1's rmse: 3.66718\n",
      "[800]\ttraining's rmse: 3.35966\tvalid_1's rmse: 3.6668\n",
      "[900]\ttraining's rmse: 3.33912\tvalid_1's rmse: 3.66638\n",
      "[1000]\ttraining's rmse: 3.31847\tvalid_1's rmse: 3.66593\n",
      "[1100]\ttraining's rmse: 3.30045\tvalid_1's rmse: 3.66591\n",
      "[1200]\ttraining's rmse: 3.28221\tvalid_1's rmse: 3.66632\n",
      "[1300]\ttraining's rmse: 3.26461\tvalid_1's rmse: 3.66664\n",
      "[1400]\ttraining's rmse: 3.24808\tvalid_1's rmse: 3.66621\n",
      "[1500]\ttraining's rmse: 3.2326\tvalid_1's rmse: 3.66689\n",
      "[1600]\ttraining's rmse: 3.21686\tvalid_1's rmse: 3.66732\n",
      "Early stopping, best iteration is:\n",
      "[1048]\ttraining's rmse: 3.30983\tvalid_1's rmse: 3.66573\n",
      "fold 2 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65164\tvalid_1's rmse: 3.69085\n",
      "[200]\ttraining's rmse: 3.56679\tvalid_1's rmse: 3.64932\n",
      "[300]\ttraining's rmse: 3.51545\tvalid_1's rmse: 3.63495\n",
      "[400]\ttraining's rmse: 3.47684\tvalid_1's rmse: 3.62795\n",
      "[500]\ttraining's rmse: 3.44632\tvalid_1's rmse: 3.62279\n",
      "[600]\ttraining's rmse: 3.41996\tvalid_1's rmse: 3.61912\n",
      "[700]\ttraining's rmse: 3.39734\tvalid_1's rmse: 3.6177\n",
      "[800]\ttraining's rmse: 3.3758\tvalid_1's rmse: 3.61729\n",
      "[900]\ttraining's rmse: 3.35556\tvalid_1's rmse: 3.6177\n",
      "[1000]\ttraining's rmse: 3.33654\tvalid_1's rmse: 3.61822\n",
      "[1100]\ttraining's rmse: 3.31736\tvalid_1's rmse: 3.61809\n",
      "[1200]\ttraining's rmse: 3.2996\tvalid_1's rmse: 3.61814\n",
      "[1300]\ttraining's rmse: 3.28147\tvalid_1's rmse: 3.61841\n",
      "[1400]\ttraining's rmse: 3.26524\tvalid_1's rmse: 3.61832\n",
      "Early stopping, best iteration is:\n",
      "[807]\ttraining's rmse: 3.37425\tvalid_1's rmse: 3.61699\n",
      "fold 3 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64659\tvalid_1's rmse: 3.70681\n",
      "[200]\ttraining's rmse: 3.55813\tvalid_1's rmse: 3.67564\n",
      "[300]\ttraining's rmse: 3.50544\tvalid_1's rmse: 3.66559\n",
      "[400]\ttraining's rmse: 3.46655\tvalid_1's rmse: 3.65967\n",
      "[500]\ttraining's rmse: 3.43333\tvalid_1's rmse: 3.65624\n",
      "[600]\ttraining's rmse: 3.40509\tvalid_1's rmse: 3.65457\n",
      "[700]\ttraining's rmse: 3.37939\tvalid_1's rmse: 3.65369\n",
      "[800]\ttraining's rmse: 3.35658\tvalid_1's rmse: 3.65377\n",
      "[900]\ttraining's rmse: 3.33552\tvalid_1's rmse: 3.65467\n",
      "[1000]\ttraining's rmse: 3.31488\tvalid_1's rmse: 3.65445\n",
      "[1100]\ttraining's rmse: 3.29698\tvalid_1's rmse: 3.65469\n",
      "[1200]\ttraining's rmse: 3.27878\tvalid_1's rmse: 3.65475\n",
      "[1300]\ttraining's rmse: 3.26193\tvalid_1's rmse: 3.65491\n",
      "Early stopping, best iteration is:\n",
      "[710]\ttraining's rmse: 3.37719\tvalid_1's rmse: 3.65368\n",
      "fold 4 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64699\tvalid_1's rmse: 3.71111\n",
      "[200]\ttraining's rmse: 3.56028\tvalid_1's rmse: 3.66974\n",
      "[300]\ttraining's rmse: 3.50942\tvalid_1's rmse: 3.65343\n",
      "[400]\ttraining's rmse: 3.47035\tvalid_1's rmse: 3.64398\n",
      "[500]\ttraining's rmse: 3.43904\tvalid_1's rmse: 3.63809\n",
      "[600]\ttraining's rmse: 3.41223\tvalid_1's rmse: 3.63348\n",
      "[700]\ttraining's rmse: 3.38936\tvalid_1's rmse: 3.63017\n",
      "[800]\ttraining's rmse: 3.36759\tvalid_1's rmse: 3.62887\n",
      "[900]\ttraining's rmse: 3.34743\tvalid_1's rmse: 3.62759\n",
      "[1000]\ttraining's rmse: 3.32859\tvalid_1's rmse: 3.62658\n",
      "[1100]\ttraining's rmse: 3.31019\tvalid_1's rmse: 3.62563\n",
      "[1200]\ttraining's rmse: 3.29253\tvalid_1's rmse: 3.62539\n",
      "[1300]\ttraining's rmse: 3.27512\tvalid_1's rmse: 3.62555\n",
      "[1400]\ttraining's rmse: 3.25777\tvalid_1's rmse: 3.62607\n",
      "[1500]\ttraining's rmse: 3.24131\tvalid_1's rmse: 3.62604\n",
      "[1600]\ttraining's rmse: 3.22492\tvalid_1's rmse: 3.62687\n",
      "[1700]\ttraining's rmse: 3.20966\tvalid_1's rmse: 3.62727\n",
      "Early stopping, best iteration is:\n",
      "[1165]\ttraining's rmse: 3.29874\tvalid_1's rmse: 3.62519\n",
      "fold 5 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64023\tvalid_1's rmse: 3.71998\n",
      "[200]\ttraining's rmse: 3.55008\tvalid_1's rmse: 3.69649\n",
      "[300]\ttraining's rmse: 3.49741\tvalid_1's rmse: 3.68782\n",
      "[400]\ttraining's rmse: 3.4582\tvalid_1's rmse: 3.68481\n",
      "[500]\ttraining's rmse: 3.42494\tvalid_1's rmse: 3.68281\n",
      "[600]\ttraining's rmse: 3.39811\tvalid_1's rmse: 3.68185\n",
      "[700]\ttraining's rmse: 3.37303\tvalid_1's rmse: 3.68189\n",
      "[800]\ttraining's rmse: 3.35107\tvalid_1's rmse: 3.68144\n",
      "[900]\ttraining's rmse: 3.32976\tvalid_1's rmse: 3.68142\n",
      "[1000]\ttraining's rmse: 3.31038\tvalid_1's rmse: 3.68096\n",
      "[1100]\ttraining's rmse: 3.29186\tvalid_1's rmse: 3.68123\n",
      "[1200]\ttraining's rmse: 3.27535\tvalid_1's rmse: 3.68137\n",
      "[1300]\ttraining's rmse: 3.25848\tvalid_1's rmse: 3.68174\n",
      "[1400]\ttraining's rmse: 3.24111\tvalid_1's rmse: 3.68242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's rmse: 3.22434\tvalid_1's rmse: 3.68232\n",
      "[1600]\ttraining's rmse: 3.20845\tvalid_1's rmse: 3.68234\n",
      "Early stopping, best iteration is:\n",
      "[1039]\ttraining's rmse: 3.30286\tvalid_1's rmse: 3.68079\n",
      "fold 0 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6347\tvalid_1's rmse: 3.71231\n",
      "[200]\ttraining's rmse: 3.5372\tvalid_1's rmse: 3.68356\n",
      "[300]\ttraining's rmse: 3.47884\tvalid_1's rmse: 3.67303\n",
      "[400]\ttraining's rmse: 3.4342\tvalid_1's rmse: 3.6661\n",
      "[500]\ttraining's rmse: 3.3993\tvalid_1's rmse: 3.66289\n",
      "[600]\ttraining's rmse: 3.36883\tvalid_1's rmse: 3.66016\n",
      "[700]\ttraining's rmse: 3.33989\tvalid_1's rmse: 3.65926\n",
      "[800]\ttraining's rmse: 3.31465\tvalid_1's rmse: 3.65809\n",
      "[900]\ttraining's rmse: 3.28981\tvalid_1's rmse: 3.65777\n",
      "[1000]\ttraining's rmse: 3.2678\tvalid_1's rmse: 3.6577\n",
      "[1100]\ttraining's rmse: 3.24629\tvalid_1's rmse: 3.65799\n",
      "[1200]\ttraining's rmse: 3.22542\tvalid_1's rmse: 3.65784\n",
      "[1300]\ttraining's rmse: 3.20597\tvalid_1's rmse: 3.65798\n",
      "[1400]\ttraining's rmse: 3.18714\tvalid_1's rmse: 3.65777\n",
      "[1500]\ttraining's rmse: 3.16855\tvalid_1's rmse: 3.65782\n",
      "Early stopping, best iteration is:\n",
      "[991]\ttraining's rmse: 3.26969\tvalid_1's rmse: 3.65754\n",
      "fold 1 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63416\tvalid_1's rmse: 3.72149\n",
      "[200]\ttraining's rmse: 3.5352\tvalid_1's rmse: 3.68711\n",
      "[300]\ttraining's rmse: 3.47461\tvalid_1's rmse: 3.67555\n",
      "[400]\ttraining's rmse: 3.43017\tvalid_1's rmse: 3.66911\n",
      "[500]\ttraining's rmse: 3.39466\tvalid_1's rmse: 3.66445\n",
      "[600]\ttraining's rmse: 3.36371\tvalid_1's rmse: 3.66222\n",
      "[700]\ttraining's rmse: 3.33579\tvalid_1's rmse: 3.66072\n",
      "[800]\ttraining's rmse: 3.31011\tvalid_1's rmse: 3.66148\n",
      "[900]\ttraining's rmse: 3.28667\tvalid_1's rmse: 3.66112\n",
      "[1000]\ttraining's rmse: 3.26457\tvalid_1's rmse: 3.66076\n",
      "[1100]\ttraining's rmse: 3.24349\tvalid_1's rmse: 3.6608\n",
      "[1200]\ttraining's rmse: 3.22312\tvalid_1's rmse: 3.66025\n",
      "[1300]\ttraining's rmse: 3.20446\tvalid_1's rmse: 3.66096\n",
      "[1400]\ttraining's rmse: 3.18557\tvalid_1's rmse: 3.66087\n",
      "[1500]\ttraining's rmse: 3.16616\tvalid_1's rmse: 3.66162\n",
      "[1600]\ttraining's rmse: 3.14787\tvalid_1's rmse: 3.6619\n",
      "[1700]\ttraining's rmse: 3.13017\tvalid_1's rmse: 3.66252\n",
      "Early stopping, best iteration is:\n",
      "[1168]\ttraining's rmse: 3.22951\tvalid_1's rmse: 3.66019\n",
      "fold 2 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6409\tvalid_1's rmse: 3.69676\n",
      "[200]\ttraining's rmse: 3.54618\tvalid_1's rmse: 3.65499\n",
      "[300]\ttraining's rmse: 3.48653\tvalid_1's rmse: 3.64066\n",
      "[400]\ttraining's rmse: 3.44267\tvalid_1's rmse: 3.63388\n",
      "[500]\ttraining's rmse: 3.40581\tvalid_1's rmse: 3.62844\n",
      "[600]\ttraining's rmse: 3.37584\tvalid_1's rmse: 3.62525\n",
      "[700]\ttraining's rmse: 3.34881\tvalid_1's rmse: 3.62145\n",
      "[800]\ttraining's rmse: 3.32359\tvalid_1's rmse: 3.62037\n",
      "[900]\ttraining's rmse: 3.29959\tvalid_1's rmse: 3.6199\n",
      "[1000]\ttraining's rmse: 3.27597\tvalid_1's rmse: 3.61867\n",
      "[1100]\ttraining's rmse: 3.25409\tvalid_1's rmse: 3.61774\n",
      "[1200]\ttraining's rmse: 3.2332\tvalid_1's rmse: 3.61744\n",
      "[1300]\ttraining's rmse: 3.21353\tvalid_1's rmse: 3.61726\n",
      "[1400]\ttraining's rmse: 3.19452\tvalid_1's rmse: 3.61735\n",
      "[1500]\ttraining's rmse: 3.17401\tvalid_1's rmse: 3.61786\n",
      "[1600]\ttraining's rmse: 3.15543\tvalid_1's rmse: 3.6178\n",
      "[1700]\ttraining's rmse: 3.13764\tvalid_1's rmse: 3.61748\n",
      "Early stopping, best iteration is:\n",
      "[1143]\ttraining's rmse: 3.24502\tvalid_1's rmse: 3.61689\n",
      "fold 3 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63265\tvalid_1's rmse: 3.71199\n",
      "[200]\ttraining's rmse: 3.53297\tvalid_1's rmse: 3.68098\n",
      "[300]\ttraining's rmse: 3.47333\tvalid_1's rmse: 3.66921\n",
      "[400]\ttraining's rmse: 3.42897\tvalid_1's rmse: 3.66484\n",
      "[500]\ttraining's rmse: 3.39273\tvalid_1's rmse: 3.66213\n",
      "[600]\ttraining's rmse: 3.36128\tvalid_1's rmse: 3.66006\n",
      "[700]\ttraining's rmse: 3.33306\tvalid_1's rmse: 3.6592\n",
      "[800]\ttraining's rmse: 3.30942\tvalid_1's rmse: 3.65875\n",
      "[900]\ttraining's rmse: 3.28593\tvalid_1's rmse: 3.65877\n",
      "[1000]\ttraining's rmse: 3.26303\tvalid_1's rmse: 3.65892\n",
      "[1100]\ttraining's rmse: 3.24141\tvalid_1's rmse: 3.65914\n",
      "[1200]\ttraining's rmse: 3.22068\tvalid_1's rmse: 3.65976\n",
      "[1300]\ttraining's rmse: 3.20078\tvalid_1's rmse: 3.66076\n",
      "[1400]\ttraining's rmse: 3.18016\tvalid_1's rmse: 3.66071\n",
      "Early stopping, best iteration is:\n",
      "[878]\ttraining's rmse: 3.29077\tvalid_1's rmse: 3.6584\n",
      "fold 4 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63525\tvalid_1's rmse: 3.70823\n",
      "[200]\ttraining's rmse: 3.53738\tvalid_1's rmse: 3.67318\n",
      "[300]\ttraining's rmse: 3.47724\tvalid_1's rmse: 3.65561\n",
      "[400]\ttraining's rmse: 3.43062\tvalid_1's rmse: 3.64806\n",
      "[500]\ttraining's rmse: 3.39334\tvalid_1's rmse: 3.64324\n",
      "[600]\ttraining's rmse: 3.36115\tvalid_1's rmse: 3.64014\n",
      "[700]\ttraining's rmse: 3.33318\tvalid_1's rmse: 3.63734\n",
      "[800]\ttraining's rmse: 3.30622\tvalid_1's rmse: 3.63621\n",
      "[900]\ttraining's rmse: 3.28042\tvalid_1's rmse: 3.63559\n",
      "[1000]\ttraining's rmse: 3.25791\tvalid_1's rmse: 3.63478\n",
      "[1100]\ttraining's rmse: 3.23488\tvalid_1's rmse: 3.63436\n",
      "[1200]\ttraining's rmse: 3.21276\tvalid_1's rmse: 3.63381\n",
      "[1300]\ttraining's rmse: 3.19224\tvalid_1's rmse: 3.63388\n",
      "[1400]\ttraining's rmse: 3.17263\tvalid_1's rmse: 3.63406\n",
      "[1500]\ttraining's rmse: 3.15211\tvalid_1's rmse: 3.63459\n",
      "[1600]\ttraining's rmse: 3.13376\tvalid_1's rmse: 3.63467\n",
      "[1700]\ttraining's rmse: 3.11637\tvalid_1's rmse: 3.6353\n",
      "[1800]\ttraining's rmse: 3.09658\tvalid_1's rmse: 3.63528\n",
      "Early stopping, best iteration is:\n",
      "[1247]\ttraining's rmse: 3.20322\tvalid_1's rmse: 3.63359\n",
      "fold 5 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63439\tvalid_1's rmse: 3.7215\n",
      "[200]\ttraining's rmse: 3.53636\tvalid_1's rmse: 3.68598\n",
      "[300]\ttraining's rmse: 3.47781\tvalid_1's rmse: 3.67145\n",
      "[400]\ttraining's rmse: 3.43284\tvalid_1's rmse: 3.66342\n",
      "[500]\ttraining's rmse: 3.39595\tvalid_1's rmse: 3.65752\n",
      "[600]\ttraining's rmse: 3.36383\tvalid_1's rmse: 3.65343\n",
      "[700]\ttraining's rmse: 3.3352\tvalid_1's rmse: 3.65119\n",
      "[800]\ttraining's rmse: 3.30994\tvalid_1's rmse: 3.64938\n",
      "[900]\ttraining's rmse: 3.28654\tvalid_1's rmse: 3.64787\n",
      "[1000]\ttraining's rmse: 3.26523\tvalid_1's rmse: 3.6468\n",
      "[1100]\ttraining's rmse: 3.24418\tvalid_1's rmse: 3.6463\n",
      "[1200]\ttraining's rmse: 3.22478\tvalid_1's rmse: 3.64577\n",
      "[1300]\ttraining's rmse: 3.20484\tvalid_1's rmse: 3.64544\n",
      "[1400]\ttraining's rmse: 3.18525\tvalid_1's rmse: 3.64494\n",
      "[1500]\ttraining's rmse: 3.16561\tvalid_1's rmse: 3.64448\n",
      "[1600]\ttraining's rmse: 3.14713\tvalid_1's rmse: 3.64402\n",
      "[1700]\ttraining's rmse: 3.128\tvalid_1's rmse: 3.64413\n",
      "[1800]\ttraining's rmse: 3.11009\tvalid_1's rmse: 3.64366\n",
      "[1900]\ttraining's rmse: 3.0933\tvalid_1's rmse: 3.6433\n",
      "[2000]\ttraining's rmse: 3.07551\tvalid_1's rmse: 3.64353\n",
      "[2100]\ttraining's rmse: 3.05935\tvalid_1's rmse: 3.64401\n",
      "[2200]\ttraining's rmse: 3.04235\tvalid_1's rmse: 3.64399\n",
      "[2300]\ttraining's rmse: 3.02555\tvalid_1's rmse: 3.64374\n",
      "[2400]\ttraining's rmse: 3.0093\tvalid_1's rmse: 3.64383\n",
      "[2500]\ttraining's rmse: 2.99379\tvalid_1's rmse: 3.64421\n",
      "Early stopping, best iteration is:\n",
      "[1914]\ttraining's rmse: 3.09105\tvalid_1's rmse: 3.64319\n",
      "fold 6 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63081\tvalid_1's rmse: 3.72274\n",
      "[200]\ttraining's rmse: 3.52959\tvalid_1's rmse: 3.70072\n",
      "[300]\ttraining's rmse: 3.47011\tvalid_1's rmse: 3.69305\n",
      "[400]\ttraining's rmse: 3.42528\tvalid_1's rmse: 3.68894\n",
      "[500]\ttraining's rmse: 3.38826\tvalid_1's rmse: 3.68674\n",
      "[600]\ttraining's rmse: 3.35642\tvalid_1's rmse: 3.68509\n",
      "[700]\ttraining's rmse: 3.32777\tvalid_1's rmse: 3.68477\n",
      "[800]\ttraining's rmse: 3.30216\tvalid_1's rmse: 3.6845\n",
      "[900]\ttraining's rmse: 3.27803\tvalid_1's rmse: 3.68417\n",
      "[1000]\ttraining's rmse: 3.25528\tvalid_1's rmse: 3.68481\n",
      "[1100]\ttraining's rmse: 3.23349\tvalid_1's rmse: 3.68536\n",
      "[1200]\ttraining's rmse: 3.21371\tvalid_1's rmse: 3.68491\n",
      "[1300]\ttraining's rmse: 3.19323\tvalid_1's rmse: 3.68513\n",
      "[1400]\ttraining's rmse: 3.17486\tvalid_1's rmse: 3.68538\n",
      "Early stopping, best iteration is:\n",
      "[869]\ttraining's rmse: 3.28545\tvalid_1's rmse: 3.684\n",
      "fold 0 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 3.64008\tvalid_1's rmse: 3.71199\n",
      "[200]\ttraining's rmse: 3.54642\tvalid_1's rmse: 3.68292\n",
      "[300]\ttraining's rmse: 3.49123\tvalid_1's rmse: 3.67083\n",
      "[400]\ttraining's rmse: 3.44858\tvalid_1's rmse: 3.66505\n",
      "[500]\ttraining's rmse: 3.41406\tvalid_1's rmse: 3.66068\n",
      "[600]\ttraining's rmse: 3.38388\tvalid_1's rmse: 3.65818\n",
      "[700]\ttraining's rmse: 3.35781\tvalid_1's rmse: 3.65648\n",
      "[800]\ttraining's rmse: 3.33348\tvalid_1's rmse: 3.6551\n",
      "[900]\ttraining's rmse: 3.31077\tvalid_1's rmse: 3.65472\n",
      "[1000]\ttraining's rmse: 3.29045\tvalid_1's rmse: 3.65466\n",
      "[1100]\ttraining's rmse: 3.27\tvalid_1's rmse: 3.65457\n",
      "[1200]\ttraining's rmse: 3.25136\tvalid_1's rmse: 3.65375\n",
      "[1300]\ttraining's rmse: 3.2331\tvalid_1's rmse: 3.65362\n",
      "[1400]\ttraining's rmse: 3.2158\tvalid_1's rmse: 3.65354\n",
      "[1500]\ttraining's rmse: 3.19989\tvalid_1's rmse: 3.65334\n",
      "[1600]\ttraining's rmse: 3.18207\tvalid_1's rmse: 3.65384\n",
      "[1700]\ttraining's rmse: 3.16541\tvalid_1's rmse: 3.65391\n",
      "[1800]\ttraining's rmse: 3.14984\tvalid_1's rmse: 3.6542\n",
      "[1900]\ttraining's rmse: 3.1327\tvalid_1's rmse: 3.65405\n",
      "[2000]\ttraining's rmse: 3.11627\tvalid_1's rmse: 3.65391\n",
      "Early stopping, best iteration is:\n",
      "[1488]\ttraining's rmse: 3.20202\tvalid_1's rmse: 3.65318\n",
      "fold 1 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63925\tvalid_1's rmse: 3.71583\n",
      "[200]\ttraining's rmse: 3.5449\tvalid_1's rmse: 3.68184\n",
      "[300]\ttraining's rmse: 3.48654\tvalid_1's rmse: 3.66964\n",
      "[400]\ttraining's rmse: 3.44421\tvalid_1's rmse: 3.66413\n",
      "[500]\ttraining's rmse: 3.41023\tvalid_1's rmse: 3.66053\n",
      "[600]\ttraining's rmse: 3.38084\tvalid_1's rmse: 3.65769\n",
      "[700]\ttraining's rmse: 3.35535\tvalid_1's rmse: 3.65672\n",
      "[800]\ttraining's rmse: 3.33132\tvalid_1's rmse: 3.65573\n",
      "[900]\ttraining's rmse: 3.30872\tvalid_1's rmse: 3.65439\n",
      "[1000]\ttraining's rmse: 3.28795\tvalid_1's rmse: 3.65404\n",
      "[1100]\ttraining's rmse: 3.26863\tvalid_1's rmse: 3.65393\n",
      "[1200]\ttraining's rmse: 3.24966\tvalid_1's rmse: 3.65444\n",
      "[1300]\ttraining's rmse: 3.23118\tvalid_1's rmse: 3.65514\n",
      "[1400]\ttraining's rmse: 3.21476\tvalid_1's rmse: 3.65528\n",
      "[1500]\ttraining's rmse: 3.19775\tvalid_1's rmse: 3.65604\n",
      "[1600]\ttraining's rmse: 3.17963\tvalid_1's rmse: 3.65651\n",
      "Early stopping, best iteration is:\n",
      "[1049]\ttraining's rmse: 3.27862\tvalid_1's rmse: 3.65343\n",
      "fold 2 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64637\tvalid_1's rmse: 3.69533\n",
      "[200]\ttraining's rmse: 3.55586\tvalid_1's rmse: 3.65037\n",
      "[300]\ttraining's rmse: 3.49984\tvalid_1's rmse: 3.63602\n",
      "[400]\ttraining's rmse: 3.45773\tvalid_1's rmse: 3.6281\n",
      "[500]\ttraining's rmse: 3.42395\tvalid_1's rmse: 3.62319\n",
      "[600]\ttraining's rmse: 3.39304\tvalid_1's rmse: 3.61991\n",
      "[700]\ttraining's rmse: 3.3672\tvalid_1's rmse: 3.61819\n",
      "[800]\ttraining's rmse: 3.34273\tvalid_1's rmse: 3.6173\n",
      "[900]\ttraining's rmse: 3.32016\tvalid_1's rmse: 3.61679\n",
      "[1000]\ttraining's rmse: 3.29763\tvalid_1's rmse: 3.61609\n",
      "[1100]\ttraining's rmse: 3.27676\tvalid_1's rmse: 3.61593\n",
      "[1200]\ttraining's rmse: 3.2571\tvalid_1's rmse: 3.61637\n",
      "[1300]\ttraining's rmse: 3.23651\tvalid_1's rmse: 3.6162\n",
      "[1400]\ttraining's rmse: 3.21796\tvalid_1's rmse: 3.61641\n",
      "[1500]\ttraining's rmse: 3.19909\tvalid_1's rmse: 3.61611\n",
      "[1600]\ttraining's rmse: 3.1816\tvalid_1's rmse: 3.61616\n",
      "[1700]\ttraining's rmse: 3.16469\tvalid_1's rmse: 3.61627\n",
      "[1800]\ttraining's rmse: 3.14844\tvalid_1's rmse: 3.61629\n",
      "[1900]\ttraining's rmse: 3.13261\tvalid_1's rmse: 3.61669\n",
      "[2000]\ttraining's rmse: 3.11664\tvalid_1's rmse: 3.61677\n",
      "[2100]\ttraining's rmse: 3.10101\tvalid_1's rmse: 3.61689\n",
      "Early stopping, best iteration is:\n",
      "[1534]\ttraining's rmse: 3.19339\tvalid_1's rmse: 3.61583\n",
      "fold 3 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63774\tvalid_1's rmse: 3.71038\n",
      "[200]\ttraining's rmse: 3.54191\tvalid_1's rmse: 3.68208\n",
      "[300]\ttraining's rmse: 3.48492\tvalid_1's rmse: 3.67166\n",
      "[400]\ttraining's rmse: 3.44329\tvalid_1's rmse: 3.66673\n",
      "[500]\ttraining's rmse: 3.40872\tvalid_1's rmse: 3.66405\n",
      "[600]\ttraining's rmse: 3.37944\tvalid_1's rmse: 3.6633\n",
      "[700]\ttraining's rmse: 3.35275\tvalid_1's rmse: 3.66348\n",
      "[800]\ttraining's rmse: 3.32948\tvalid_1's rmse: 3.6631\n",
      "[900]\ttraining's rmse: 3.30699\tvalid_1's rmse: 3.66369\n",
      "[1000]\ttraining's rmse: 3.28603\tvalid_1's rmse: 3.66405\n",
      "[1100]\ttraining's rmse: 3.26497\tvalid_1's rmse: 3.66478\n",
      "[1200]\ttraining's rmse: 3.24424\tvalid_1's rmse: 3.66611\n",
      "[1300]\ttraining's rmse: 3.22499\tvalid_1's rmse: 3.6664\n",
      "[1400]\ttraining's rmse: 3.20701\tvalid_1's rmse: 3.66787\n",
      "Early stopping, best iteration is:\n",
      "[841]\ttraining's rmse: 3.3194\tvalid_1's rmse: 3.66298\n",
      "fold 4 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63954\tvalid_1's rmse: 3.70869\n",
      "[200]\ttraining's rmse: 3.54574\tvalid_1's rmse: 3.67181\n",
      "[300]\ttraining's rmse: 3.48924\tvalid_1's rmse: 3.65577\n",
      "[400]\ttraining's rmse: 3.44561\tvalid_1's rmse: 3.64695\n",
      "[500]\ttraining's rmse: 3.40987\tvalid_1's rmse: 3.6415\n",
      "[600]\ttraining's rmse: 3.37963\tvalid_1's rmse: 3.63807\n",
      "[700]\ttraining's rmse: 3.35276\tvalid_1's rmse: 3.63526\n",
      "[800]\ttraining's rmse: 3.3283\tvalid_1's rmse: 3.63413\n",
      "[900]\ttraining's rmse: 3.30444\tvalid_1's rmse: 3.63296\n",
      "[1000]\ttraining's rmse: 3.28297\tvalid_1's rmse: 3.63277\n",
      "[1100]\ttraining's rmse: 3.26188\tvalid_1's rmse: 3.63278\n",
      "[1200]\ttraining's rmse: 3.24177\tvalid_1's rmse: 3.63306\n",
      "[1300]\ttraining's rmse: 3.22346\tvalid_1's rmse: 3.63345\n",
      "[1400]\ttraining's rmse: 3.20537\tvalid_1's rmse: 3.63321\n",
      "[1500]\ttraining's rmse: 3.1865\tvalid_1's rmse: 3.63393\n",
      "[1600]\ttraining's rmse: 3.169\tvalid_1's rmse: 3.63446\n",
      "Early stopping, best iteration is:\n",
      "[1025]\ttraining's rmse: 3.27769\tvalid_1's rmse: 3.6325\n",
      "fold 5 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63822\tvalid_1's rmse: 3.72014\n",
      "[200]\ttraining's rmse: 3.54521\tvalid_1's rmse: 3.68425\n",
      "[300]\ttraining's rmse: 3.48883\tvalid_1's rmse: 3.6699\n",
      "[400]\ttraining's rmse: 3.44827\tvalid_1's rmse: 3.66147\n",
      "[500]\ttraining's rmse: 3.41233\tvalid_1's rmse: 3.65613\n",
      "[600]\ttraining's rmse: 3.38302\tvalid_1's rmse: 3.65361\n",
      "[700]\ttraining's rmse: 3.35632\tvalid_1's rmse: 3.65114\n",
      "[800]\ttraining's rmse: 3.33275\tvalid_1's rmse: 3.64905\n",
      "[900]\ttraining's rmse: 3.31004\tvalid_1's rmse: 3.64778\n",
      "[1000]\ttraining's rmse: 3.28962\tvalid_1's rmse: 3.64721\n",
      "[1100]\ttraining's rmse: 3.26905\tvalid_1's rmse: 3.64623\n",
      "[1200]\ttraining's rmse: 3.24908\tvalid_1's rmse: 3.64605\n",
      "[1300]\ttraining's rmse: 3.22927\tvalid_1's rmse: 3.64537\n",
      "[1400]\ttraining's rmse: 3.20986\tvalid_1's rmse: 3.64535\n",
      "[1500]\ttraining's rmse: 3.19133\tvalid_1's rmse: 3.64557\n",
      "[1600]\ttraining's rmse: 3.17382\tvalid_1's rmse: 3.64536\n",
      "[1700]\ttraining's rmse: 3.15658\tvalid_1's rmse: 3.64549\n",
      "[1800]\ttraining's rmse: 3.13974\tvalid_1's rmse: 3.64588\n",
      "[1900]\ttraining's rmse: 3.123\tvalid_1's rmse: 3.64613\n",
      "[2000]\ttraining's rmse: 3.10732\tvalid_1's rmse: 3.64621\n",
      "[2100]\ttraining's rmse: 3.09175\tvalid_1's rmse: 3.64645\n",
      "Early stopping, best iteration is:\n",
      "[1547]\ttraining's rmse: 3.18313\tvalid_1's rmse: 3.64508\n",
      "fold 6 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63511\tvalid_1's rmse: 3.72187\n",
      "[200]\ttraining's rmse: 3.53923\tvalid_1's rmse: 3.69898\n",
      "[300]\ttraining's rmse: 3.48292\tvalid_1's rmse: 3.69197\n",
      "[400]\ttraining's rmse: 3.44158\tvalid_1's rmse: 3.68742\n",
      "[500]\ttraining's rmse: 3.40617\tvalid_1's rmse: 3.68535\n",
      "[600]\ttraining's rmse: 3.37631\tvalid_1's rmse: 3.68373\n",
      "[700]\ttraining's rmse: 3.34952\tvalid_1's rmse: 3.68293\n",
      "[800]\ttraining's rmse: 3.32468\tvalid_1's rmse: 3.6838\n",
      "[900]\ttraining's rmse: 3.30253\tvalid_1's rmse: 3.68402\n",
      "[1000]\ttraining's rmse: 3.28136\tvalid_1's rmse: 3.68388\n",
      "[1100]\ttraining's rmse: 3.26108\tvalid_1's rmse: 3.6839\n",
      "[1200]\ttraining's rmse: 3.24313\tvalid_1's rmse: 3.68459\n",
      "Early stopping, best iteration is:\n",
      "[689]\ttraining's rmse: 3.35274\tvalid_1's rmse: 3.68265\n",
      "fold 0 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64517\tvalid_1's rmse: 3.70628\n",
      "[200]\ttraining's rmse: 3.55645\tvalid_1's rmse: 3.6765\n",
      "[300]\ttraining's rmse: 3.50324\tvalid_1's rmse: 3.66408\n",
      "[400]\ttraining's rmse: 3.46432\tvalid_1's rmse: 3.65842\n",
      "[500]\ttraining's rmse: 3.43166\tvalid_1's rmse: 3.65393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's rmse: 3.40475\tvalid_1's rmse: 3.65097\n",
      "[700]\ttraining's rmse: 3.38008\tvalid_1's rmse: 3.65004\n",
      "[800]\ttraining's rmse: 3.35846\tvalid_1's rmse: 3.64903\n",
      "[900]\ttraining's rmse: 3.3364\tvalid_1's rmse: 3.64882\n",
      "[1000]\ttraining's rmse: 3.31667\tvalid_1's rmse: 3.64864\n",
      "[1100]\ttraining's rmse: 3.29717\tvalid_1's rmse: 3.64816\n",
      "[1200]\ttraining's rmse: 3.27966\tvalid_1's rmse: 3.64769\n",
      "[1300]\ttraining's rmse: 3.26237\tvalid_1's rmse: 3.64818\n",
      "[1400]\ttraining's rmse: 3.24599\tvalid_1's rmse: 3.64804\n",
      "[1500]\ttraining's rmse: 3.22933\tvalid_1's rmse: 3.6477\n",
      "[1600]\ttraining's rmse: 3.21333\tvalid_1's rmse: 3.6485\n",
      "[1700]\ttraining's rmse: 3.19784\tvalid_1's rmse: 3.64906\n",
      "Early stopping, best iteration is:\n",
      "[1163]\ttraining's rmse: 3.28676\tvalid_1's rmse: 3.64756\n",
      "fold 1 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64507\tvalid_1's rmse: 3.71668\n",
      "[200]\ttraining's rmse: 3.55582\tvalid_1's rmse: 3.68159\n",
      "[300]\ttraining's rmse: 3.50162\tvalid_1's rmse: 3.66999\n",
      "[400]\ttraining's rmse: 3.46176\tvalid_1's rmse: 3.6649\n",
      "[500]\ttraining's rmse: 3.43055\tvalid_1's rmse: 3.66166\n",
      "[600]\ttraining's rmse: 3.40336\tvalid_1's rmse: 3.65973\n",
      "[700]\ttraining's rmse: 3.37959\tvalid_1's rmse: 3.6588\n",
      "[800]\ttraining's rmse: 3.35836\tvalid_1's rmse: 3.65817\n",
      "[900]\ttraining's rmse: 3.33789\tvalid_1's rmse: 3.65802\n",
      "[1000]\ttraining's rmse: 3.31962\tvalid_1's rmse: 3.65834\n",
      "[1100]\ttraining's rmse: 3.30149\tvalid_1's rmse: 3.65882\n",
      "[1200]\ttraining's rmse: 3.28286\tvalid_1's rmse: 3.6582\n",
      "[1300]\ttraining's rmse: 3.26539\tvalid_1's rmse: 3.65798\n",
      "[1400]\ttraining's rmse: 3.24986\tvalid_1's rmse: 3.65861\n",
      "[1500]\ttraining's rmse: 3.23375\tvalid_1's rmse: 3.65864\n",
      "[1600]\ttraining's rmse: 3.217\tvalid_1's rmse: 3.65862\n",
      "[1700]\ttraining's rmse: 3.20184\tvalid_1's rmse: 3.65846\n",
      "[1800]\ttraining's rmse: 3.18668\tvalid_1's rmse: 3.65923\n",
      "Early stopping, best iteration is:\n",
      "[1253]\ttraining's rmse: 3.27296\tvalid_1's rmse: 3.6574\n",
      "fold 2 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65035\tvalid_1's rmse: 3.6922\n",
      "[200]\ttraining's rmse: 3.56422\tvalid_1's rmse: 3.64795\n",
      "[300]\ttraining's rmse: 3.5109\tvalid_1's rmse: 3.63333\n",
      "[400]\ttraining's rmse: 3.47273\tvalid_1's rmse: 3.62664\n",
      "[500]\ttraining's rmse: 3.4411\tvalid_1's rmse: 3.6222\n",
      "[600]\ttraining's rmse: 3.4148\tvalid_1's rmse: 3.61915\n",
      "[700]\ttraining's rmse: 3.39099\tvalid_1's rmse: 3.61811\n",
      "[800]\ttraining's rmse: 3.36857\tvalid_1's rmse: 3.61745\n",
      "[900]\ttraining's rmse: 3.34702\tvalid_1's rmse: 3.61649\n",
      "[1000]\ttraining's rmse: 3.32748\tvalid_1's rmse: 3.61601\n",
      "[1100]\ttraining's rmse: 3.3082\tvalid_1's rmse: 3.61498\n",
      "[1200]\ttraining's rmse: 3.29058\tvalid_1's rmse: 3.61474\n",
      "[1300]\ttraining's rmse: 3.27328\tvalid_1's rmse: 3.61436\n",
      "[1400]\ttraining's rmse: 3.25616\tvalid_1's rmse: 3.6143\n",
      "[1500]\ttraining's rmse: 3.23896\tvalid_1's rmse: 3.61462\n",
      "[1600]\ttraining's rmse: 3.22226\tvalid_1's rmse: 3.6144\n",
      "[1700]\ttraining's rmse: 3.20586\tvalid_1's rmse: 3.61405\n",
      "[1800]\ttraining's rmse: 3.18963\tvalid_1's rmse: 3.61391\n",
      "[1900]\ttraining's rmse: 3.17456\tvalid_1's rmse: 3.61448\n",
      "[2000]\ttraining's rmse: 3.15813\tvalid_1's rmse: 3.61431\n",
      "[2100]\ttraining's rmse: 3.1434\tvalid_1's rmse: 3.61507\n",
      "[2200]\ttraining's rmse: 3.12874\tvalid_1's rmse: 3.61493\n",
      "[2300]\ttraining's rmse: 3.11487\tvalid_1's rmse: 3.6158\n",
      "Early stopping, best iteration is:\n",
      "[1760]\ttraining's rmse: 3.19595\tvalid_1's rmse: 3.61351\n",
      "fold 3 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64307\tvalid_1's rmse: 3.70732\n",
      "[200]\ttraining's rmse: 3.55402\tvalid_1's rmse: 3.67406\n",
      "[300]\ttraining's rmse: 3.50066\tvalid_1's rmse: 3.66438\n",
      "[400]\ttraining's rmse: 3.46242\tvalid_1's rmse: 3.66\n",
      "[500]\ttraining's rmse: 3.43128\tvalid_1's rmse: 3.65727\n",
      "[600]\ttraining's rmse: 3.40387\tvalid_1's rmse: 3.65589\n",
      "[700]\ttraining's rmse: 3.37939\tvalid_1's rmse: 3.65531\n",
      "[800]\ttraining's rmse: 3.35797\tvalid_1's rmse: 3.65556\n",
      "[900]\ttraining's rmse: 3.3363\tvalid_1's rmse: 3.65651\n",
      "[1000]\ttraining's rmse: 3.31663\tvalid_1's rmse: 3.65615\n",
      "[1100]\ttraining's rmse: 3.29755\tvalid_1's rmse: 3.65639\n",
      "[1200]\ttraining's rmse: 3.27919\tvalid_1's rmse: 3.65678\n",
      "[1300]\ttraining's rmse: 3.26093\tvalid_1's rmse: 3.65725\n",
      "Early stopping, best iteration is:\n",
      "[796]\ttraining's rmse: 3.35894\tvalid_1's rmse: 3.65523\n",
      "fold 4 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64477\tvalid_1's rmse: 3.70537\n",
      "[200]\ttraining's rmse: 3.55636\tvalid_1's rmse: 3.66923\n",
      "[300]\ttraining's rmse: 3.50345\tvalid_1's rmse: 3.65322\n",
      "[400]\ttraining's rmse: 3.46351\tvalid_1's rmse: 3.64544\n",
      "[500]\ttraining's rmse: 3.43133\tvalid_1's rmse: 3.64024\n",
      "[600]\ttraining's rmse: 3.40281\tvalid_1's rmse: 3.63812\n",
      "[700]\ttraining's rmse: 3.37785\tvalid_1's rmse: 3.63751\n",
      "[800]\ttraining's rmse: 3.35381\tvalid_1's rmse: 3.63724\n",
      "[900]\ttraining's rmse: 3.33233\tvalid_1's rmse: 3.6381\n",
      "[1000]\ttraining's rmse: 3.31195\tvalid_1's rmse: 3.63836\n",
      "[1100]\ttraining's rmse: 3.29203\tvalid_1's rmse: 3.63892\n",
      "[1200]\ttraining's rmse: 3.27387\tvalid_1's rmse: 3.63898\n",
      "[1300]\ttraining's rmse: 3.25652\tvalid_1's rmse: 3.63946\n",
      "Early stopping, best iteration is:\n",
      "[787]\ttraining's rmse: 3.35706\tvalid_1's rmse: 3.63698\n",
      "fold 5 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64449\tvalid_1's rmse: 3.71757\n",
      "[200]\ttraining's rmse: 3.55588\tvalid_1's rmse: 3.68347\n",
      "[300]\ttraining's rmse: 3.50378\tvalid_1's rmse: 3.66753\n",
      "[400]\ttraining's rmse: 3.46592\tvalid_1's rmse: 3.65908\n",
      "[500]\ttraining's rmse: 3.43381\tvalid_1's rmse: 3.65345\n",
      "[600]\ttraining's rmse: 3.40764\tvalid_1's rmse: 3.65009\n",
      "[700]\ttraining's rmse: 3.38402\tvalid_1's rmse: 3.6473\n",
      "[800]\ttraining's rmse: 3.36298\tvalid_1's rmse: 3.6453\n",
      "[900]\ttraining's rmse: 3.34248\tvalid_1's rmse: 3.64422\n",
      "[1000]\ttraining's rmse: 3.323\tvalid_1's rmse: 3.64308\n",
      "[1100]\ttraining's rmse: 3.30389\tvalid_1's rmse: 3.64297\n",
      "[1200]\ttraining's rmse: 3.28672\tvalid_1's rmse: 3.64217\n",
      "[1300]\ttraining's rmse: 3.27039\tvalid_1's rmse: 3.64146\n",
      "[1400]\ttraining's rmse: 3.2533\tvalid_1's rmse: 3.64071\n",
      "[1500]\ttraining's rmse: 3.236\tvalid_1's rmse: 3.64063\n",
      "[1600]\ttraining's rmse: 3.21966\tvalid_1's rmse: 3.64081\n",
      "[1700]\ttraining's rmse: 3.20431\tvalid_1's rmse: 3.64095\n",
      "[1800]\ttraining's rmse: 3.18996\tvalid_1's rmse: 3.64086\n",
      "[1900]\ttraining's rmse: 3.17475\tvalid_1's rmse: 3.64112\n",
      "[2000]\ttraining's rmse: 3.15874\tvalid_1's rmse: 3.64105\n",
      "[2100]\ttraining's rmse: 3.14461\tvalid_1's rmse: 3.64162\n",
      "Early stopping, best iteration is:\n",
      "[1523]\ttraining's rmse: 3.23241\tvalid_1's rmse: 3.64027\n",
      "fold 6 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64052\tvalid_1's rmse: 3.71689\n",
      "[200]\ttraining's rmse: 3.54982\tvalid_1's rmse: 3.69207\n",
      "[300]\ttraining's rmse: 3.49626\tvalid_1's rmse: 3.6845\n",
      "[400]\ttraining's rmse: 3.45618\tvalid_1's rmse: 3.68184\n",
      "[500]\ttraining's rmse: 3.42433\tvalid_1's rmse: 3.67984\n",
      "[600]\ttraining's rmse: 3.39601\tvalid_1's rmse: 3.67893\n",
      "[700]\ttraining's rmse: 3.37171\tvalid_1's rmse: 3.67873\n",
      "[800]\ttraining's rmse: 3.34917\tvalid_1's rmse: 3.6785\n",
      "[900]\ttraining's rmse: 3.3289\tvalid_1's rmse: 3.67818\n",
      "[1000]\ttraining's rmse: 3.30996\tvalid_1's rmse: 3.6794\n",
      "[1100]\ttraining's rmse: 3.29119\tvalid_1's rmse: 3.67935\n",
      "[1200]\ttraining's rmse: 3.27366\tvalid_1's rmse: 3.67959\n",
      "[1300]\ttraining's rmse: 3.25672\tvalid_1's rmse: 3.67993\n",
      "[1400]\ttraining's rmse: 3.24022\tvalid_1's rmse: 3.67991\n",
      "Early stopping, best iteration is:\n",
      "[834]\ttraining's rmse: 3.34201\tvalid_1's rmse: 3.67802\n",
      "fold 0 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64814\tvalid_1's rmse: 3.70599\n",
      "[200]\ttraining's rmse: 3.56248\tvalid_1's rmse: 3.67558\n",
      "[300]\ttraining's rmse: 3.51037\tvalid_1's rmse: 3.66455\n",
      "[400]\ttraining's rmse: 3.47187\tvalid_1's rmse: 3.65929\n",
      "[500]\ttraining's rmse: 3.44159\tvalid_1's rmse: 3.6559\n",
      "[600]\ttraining's rmse: 3.41448\tvalid_1's rmse: 3.65272\n",
      "[700]\ttraining's rmse: 3.3907\tvalid_1's rmse: 3.6516\n",
      "[800]\ttraining's rmse: 3.36895\tvalid_1's rmse: 3.65117\n",
      "[900]\ttraining's rmse: 3.34781\tvalid_1's rmse: 3.65125\n",
      "[1000]\ttraining's rmse: 3.32801\tvalid_1's rmse: 3.65118\n",
      "[1100]\ttraining's rmse: 3.30853\tvalid_1's rmse: 3.65064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 3.29146\tvalid_1's rmse: 3.65091\n",
      "[1300]\ttraining's rmse: 3.27507\tvalid_1's rmse: 3.65097\n",
      "[1400]\ttraining's rmse: 3.25808\tvalid_1's rmse: 3.65079\n",
      "[1500]\ttraining's rmse: 3.24129\tvalid_1's rmse: 3.65032\n",
      "[1600]\ttraining's rmse: 3.22507\tvalid_1's rmse: 3.65134\n",
      "[1700]\ttraining's rmse: 3.20936\tvalid_1's rmse: 3.65162\n",
      "[1800]\ttraining's rmse: 3.19429\tvalid_1's rmse: 3.65176\n",
      "[1900]\ttraining's rmse: 3.17956\tvalid_1's rmse: 3.65242\n",
      "[2000]\ttraining's rmse: 3.1649\tvalid_1's rmse: 3.65264\n",
      "[2100]\ttraining's rmse: 3.15\tvalid_1's rmse: 3.65268\n",
      "Early stopping, best iteration is:\n",
      "[1503]\ttraining's rmse: 3.24073\tvalid_1's rmse: 3.65025\n",
      "fold 1 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64694\tvalid_1's rmse: 3.71583\n",
      "[200]\ttraining's rmse: 3.55991\tvalid_1's rmse: 3.68166\n",
      "[300]\ttraining's rmse: 3.50752\tvalid_1's rmse: 3.67\n",
      "[400]\ttraining's rmse: 3.46906\tvalid_1's rmse: 3.66421\n",
      "[500]\ttraining's rmse: 3.4389\tvalid_1's rmse: 3.66194\n",
      "[600]\ttraining's rmse: 3.41219\tvalid_1's rmse: 3.66\n",
      "[700]\ttraining's rmse: 3.38993\tvalid_1's rmse: 3.6592\n",
      "[800]\ttraining's rmse: 3.36864\tvalid_1's rmse: 3.65952\n",
      "[900]\ttraining's rmse: 3.34896\tvalid_1's rmse: 3.65914\n",
      "[1000]\ttraining's rmse: 3.32945\tvalid_1's rmse: 3.65957\n",
      "[1100]\ttraining's rmse: 3.31079\tvalid_1's rmse: 3.65981\n",
      "[1200]\ttraining's rmse: 3.293\tvalid_1's rmse: 3.65974\n",
      "[1300]\ttraining's rmse: 3.27675\tvalid_1's rmse: 3.65968\n",
      "[1400]\ttraining's rmse: 3.26051\tvalid_1's rmse: 3.66035\n",
      "[1500]\ttraining's rmse: 3.24496\tvalid_1's rmse: 3.66056\n",
      "Early stopping, best iteration is:\n",
      "[950]\ttraining's rmse: 3.33928\tvalid_1's rmse: 3.65867\n",
      "fold 2 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65316\tvalid_1's rmse: 3.6902\n",
      "[200]\ttraining's rmse: 3.57009\tvalid_1's rmse: 3.64705\n",
      "[300]\ttraining's rmse: 3.5182\tvalid_1's rmse: 3.63292\n",
      "[400]\ttraining's rmse: 3.48132\tvalid_1's rmse: 3.62483\n",
      "[500]\ttraining's rmse: 3.44958\tvalid_1's rmse: 3.62076\n",
      "[600]\ttraining's rmse: 3.42346\tvalid_1's rmse: 3.61785\n",
      "[700]\ttraining's rmse: 3.40035\tvalid_1's rmse: 3.61532\n",
      "[800]\ttraining's rmse: 3.37829\tvalid_1's rmse: 3.61539\n",
      "[900]\ttraining's rmse: 3.35753\tvalid_1's rmse: 3.61532\n",
      "[1000]\ttraining's rmse: 3.3384\tvalid_1's rmse: 3.61503\n",
      "[1100]\ttraining's rmse: 3.3199\tvalid_1's rmse: 3.61419\n",
      "[1200]\ttraining's rmse: 3.30271\tvalid_1's rmse: 3.61407\n",
      "[1300]\ttraining's rmse: 3.28524\tvalid_1's rmse: 3.614\n",
      "[1400]\ttraining's rmse: 3.26932\tvalid_1's rmse: 3.61417\n",
      "[1500]\ttraining's rmse: 3.25327\tvalid_1's rmse: 3.6142\n",
      "[1600]\ttraining's rmse: 3.23719\tvalid_1's rmse: 3.61473\n",
      "[1700]\ttraining's rmse: 3.22066\tvalid_1's rmse: 3.6153\n",
      "[1800]\ttraining's rmse: 3.20538\tvalid_1's rmse: 3.6154\n",
      "[1900]\ttraining's rmse: 3.18946\tvalid_1's rmse: 3.61543\n",
      "Early stopping, best iteration is:\n",
      "[1338]\ttraining's rmse: 3.27888\tvalid_1's rmse: 3.61388\n",
      "fold 3 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64481\tvalid_1's rmse: 3.70417\n",
      "[200]\ttraining's rmse: 3.55766\tvalid_1's rmse: 3.67212\n",
      "[300]\ttraining's rmse: 3.50626\tvalid_1's rmse: 3.66248\n",
      "[400]\ttraining's rmse: 3.46864\tvalid_1's rmse: 3.65751\n",
      "[500]\ttraining's rmse: 3.43734\tvalid_1's rmse: 3.65446\n",
      "[600]\ttraining's rmse: 3.40982\tvalid_1's rmse: 3.65358\n",
      "[700]\ttraining's rmse: 3.38639\tvalid_1's rmse: 3.65306\n",
      "[800]\ttraining's rmse: 3.36471\tvalid_1's rmse: 3.65317\n",
      "[900]\ttraining's rmse: 3.34464\tvalid_1's rmse: 3.65381\n",
      "[1000]\ttraining's rmse: 3.32524\tvalid_1's rmse: 3.65394\n",
      "[1100]\ttraining's rmse: 3.30601\tvalid_1's rmse: 3.65471\n",
      "[1200]\ttraining's rmse: 3.28875\tvalid_1's rmse: 3.6553\n",
      "[1300]\ttraining's rmse: 3.27155\tvalid_1's rmse: 3.6559\n",
      "Early stopping, best iteration is:\n",
      "[774]\ttraining's rmse: 3.37024\tvalid_1's rmse: 3.65285\n",
      "fold 4 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64813\tvalid_1's rmse: 3.70413\n",
      "[200]\ttraining's rmse: 3.56191\tvalid_1's rmse: 3.66709\n",
      "[300]\ttraining's rmse: 3.50978\tvalid_1's rmse: 3.6524\n",
      "[400]\ttraining's rmse: 3.47147\tvalid_1's rmse: 3.64533\n",
      "[500]\ttraining's rmse: 3.43924\tvalid_1's rmse: 3.64047\n",
      "[600]\ttraining's rmse: 3.41104\tvalid_1's rmse: 3.63724\n",
      "[700]\ttraining's rmse: 3.38576\tvalid_1's rmse: 3.63646\n",
      "[800]\ttraining's rmse: 3.36338\tvalid_1's rmse: 3.63617\n",
      "[900]\ttraining's rmse: 3.34326\tvalid_1's rmse: 3.63642\n",
      "[1000]\ttraining's rmse: 3.32308\tvalid_1's rmse: 3.63622\n",
      "[1100]\ttraining's rmse: 3.30367\tvalid_1's rmse: 3.63652\n",
      "[1200]\ttraining's rmse: 3.28558\tvalid_1's rmse: 3.63733\n",
      "[1300]\ttraining's rmse: 3.26846\tvalid_1's rmse: 3.63722\n",
      "[1400]\ttraining's rmse: 3.25272\tvalid_1's rmse: 3.63738\n",
      "Early stopping, best iteration is:\n",
      "[853]\ttraining's rmse: 3.35262\tvalid_1's rmse: 3.63569\n",
      "fold 5 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64687\tvalid_1's rmse: 3.71752\n",
      "[200]\ttraining's rmse: 3.56125\tvalid_1's rmse: 3.68026\n",
      "[300]\ttraining's rmse: 3.51075\tvalid_1's rmse: 3.6662\n",
      "[400]\ttraining's rmse: 3.47424\tvalid_1's rmse: 3.65786\n",
      "[500]\ttraining's rmse: 3.44249\tvalid_1's rmse: 3.65205\n",
      "[600]\ttraining's rmse: 3.41661\tvalid_1's rmse: 3.64861\n",
      "[700]\ttraining's rmse: 3.39361\tvalid_1's rmse: 3.64698\n",
      "[800]\ttraining's rmse: 3.37171\tvalid_1's rmse: 3.64438\n",
      "[900]\ttraining's rmse: 3.35174\tvalid_1's rmse: 3.64349\n",
      "[1000]\ttraining's rmse: 3.33313\tvalid_1's rmse: 3.64237\n",
      "[1100]\ttraining's rmse: 3.3146\tvalid_1's rmse: 3.6419\n",
      "[1200]\ttraining's rmse: 3.29741\tvalid_1's rmse: 3.64136\n",
      "[1300]\ttraining's rmse: 3.28093\tvalid_1's rmse: 3.64074\n",
      "[1400]\ttraining's rmse: 3.26424\tvalid_1's rmse: 3.6408\n",
      "[1500]\ttraining's rmse: 3.24793\tvalid_1's rmse: 3.64089\n",
      "[1600]\ttraining's rmse: 3.23281\tvalid_1's rmse: 3.64097\n",
      "[1700]\ttraining's rmse: 3.21709\tvalid_1's rmse: 3.64153\n",
      "[1800]\ttraining's rmse: 3.20134\tvalid_1's rmse: 3.64152\n",
      "[1900]\ttraining's rmse: 3.1868\tvalid_1's rmse: 3.64161\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's rmse: 3.27644\tvalid_1's rmse: 3.64053\n",
      "fold 6 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64344\tvalid_1's rmse: 3.71807\n",
      "[200]\ttraining's rmse: 3.55557\tvalid_1's rmse: 3.69359\n",
      "[300]\ttraining's rmse: 3.50311\tvalid_1's rmse: 3.68692\n",
      "[400]\ttraining's rmse: 3.46484\tvalid_1's rmse: 3.68418\n",
      "[500]\ttraining's rmse: 3.4333\tvalid_1's rmse: 3.68288\n",
      "[600]\ttraining's rmse: 3.40563\tvalid_1's rmse: 3.68185\n",
      "[700]\ttraining's rmse: 3.38171\tvalid_1's rmse: 3.6826\n",
      "[800]\ttraining's rmse: 3.3586\tvalid_1's rmse: 3.68277\n",
      "[900]\ttraining's rmse: 3.33823\tvalid_1's rmse: 3.68283\n",
      "[1000]\ttraining's rmse: 3.31931\tvalid_1's rmse: 3.68388\n",
      "[1100]\ttraining's rmse: 3.30065\tvalid_1's rmse: 3.68397\n",
      "Early stopping, best iteration is:\n",
      "[590]\ttraining's rmse: 3.40805\tvalid_1's rmse: 3.68182\n",
      "fold 0 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63688\tvalid_1's rmse: 3.70565\n",
      "[200]\ttraining's rmse: 3.54081\tvalid_1's rmse: 3.67562\n",
      "[300]\ttraining's rmse: 3.48299\tvalid_1's rmse: 3.66445\n",
      "[400]\ttraining's rmse: 3.44028\tvalid_1's rmse: 3.65786\n",
      "[500]\ttraining's rmse: 3.40455\tvalid_1's rmse: 3.65453\n",
      "[600]\ttraining's rmse: 3.37499\tvalid_1's rmse: 3.65175\n",
      "[700]\ttraining's rmse: 3.34679\tvalid_1's rmse: 3.65047\n",
      "[800]\ttraining's rmse: 3.3208\tvalid_1's rmse: 3.64947\n",
      "[900]\ttraining's rmse: 3.29697\tvalid_1's rmse: 3.64928\n",
      "[1000]\ttraining's rmse: 3.27422\tvalid_1's rmse: 3.6474\n",
      "[1100]\ttraining's rmse: 3.25305\tvalid_1's rmse: 3.64637\n",
      "[1200]\ttraining's rmse: 3.23136\tvalid_1's rmse: 3.64641\n",
      "[1300]\ttraining's rmse: 3.21245\tvalid_1's rmse: 3.64597\n",
      "[1400]\ttraining's rmse: 3.1935\tvalid_1's rmse: 3.6461\n",
      "[1500]\ttraining's rmse: 3.17547\tvalid_1's rmse: 3.6461\n",
      "[1600]\ttraining's rmse: 3.15759\tvalid_1's rmse: 3.64574\n",
      "[1700]\ttraining's rmse: 3.14009\tvalid_1's rmse: 3.64602\n",
      "[1800]\ttraining's rmse: 3.12258\tvalid_1's rmse: 3.64591\n",
      "[1900]\ttraining's rmse: 3.10496\tvalid_1's rmse: 3.64629\n",
      "[2000]\ttraining's rmse: 3.08775\tvalid_1's rmse: 3.64648\n",
      "[2100]\ttraining's rmse: 3.07127\tvalid_1's rmse: 3.64671\n",
      "[2200]\ttraining's rmse: 3.05535\tvalid_1's rmse: 3.64716\n",
      "Early stopping, best iteration is:\n",
      "[1615]\ttraining's rmse: 3.15489\tvalid_1's rmse: 3.64542\n",
      "fold 1 1545 0.010931010817809412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63587\tvalid_1's rmse: 3.71447\n",
      "[200]\ttraining's rmse: 3.53806\tvalid_1's rmse: 3.68419\n",
      "[300]\ttraining's rmse: 3.48067\tvalid_1's rmse: 3.67462\n",
      "[400]\ttraining's rmse: 3.43669\tvalid_1's rmse: 3.66922\n",
      "[500]\ttraining's rmse: 3.40092\tvalid_1's rmse: 3.66616\n",
      "[600]\ttraining's rmse: 3.37025\tvalid_1's rmse: 3.66426\n",
      "[700]\ttraining's rmse: 3.34326\tvalid_1's rmse: 3.66222\n",
      "[800]\ttraining's rmse: 3.3182\tvalid_1's rmse: 3.66168\n",
      "[900]\ttraining's rmse: 3.29499\tvalid_1's rmse: 3.66077\n",
      "[1000]\ttraining's rmse: 3.27431\tvalid_1's rmse: 3.65998\n",
      "[1100]\ttraining's rmse: 3.25403\tvalid_1's rmse: 3.66005\n",
      "[1200]\ttraining's rmse: 3.23411\tvalid_1's rmse: 3.65968\n",
      "[1300]\ttraining's rmse: 3.21323\tvalid_1's rmse: 3.65942\n",
      "[1400]\ttraining's rmse: 3.1928\tvalid_1's rmse: 3.65921\n",
      "[1500]\ttraining's rmse: 3.17415\tvalid_1's rmse: 3.65963\n",
      "[1600]\ttraining's rmse: 3.156\tvalid_1's rmse: 3.65958\n",
      "[1700]\ttraining's rmse: 3.13722\tvalid_1's rmse: 3.66033\n",
      "[1800]\ttraining's rmse: 3.11941\tvalid_1's rmse: 3.66039\n",
      "[1900]\ttraining's rmse: 3.10288\tvalid_1's rmse: 3.66091\n",
      "Early stopping, best iteration is:\n",
      "[1370]\ttraining's rmse: 3.19885\tvalid_1's rmse: 3.65887\n",
      "fold 2 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63991\tvalid_1's rmse: 3.70616\n",
      "[200]\ttraining's rmse: 3.54373\tvalid_1's rmse: 3.66533\n",
      "[300]\ttraining's rmse: 3.4857\tvalid_1's rmse: 3.64927\n",
      "[400]\ttraining's rmse: 3.44274\tvalid_1's rmse: 3.63939\n",
      "[500]\ttraining's rmse: 3.40673\tvalid_1's rmse: 3.6336\n",
      "[600]\ttraining's rmse: 3.3757\tvalid_1's rmse: 3.62888\n",
      "[700]\ttraining's rmse: 3.3489\tvalid_1's rmse: 3.62691\n",
      "[800]\ttraining's rmse: 3.32279\tvalid_1's rmse: 3.62479\n",
      "[900]\ttraining's rmse: 3.29889\tvalid_1's rmse: 3.62367\n",
      "[1000]\ttraining's rmse: 3.27776\tvalid_1's rmse: 3.62291\n",
      "[1100]\ttraining's rmse: 3.25694\tvalid_1's rmse: 3.62261\n",
      "[1200]\ttraining's rmse: 3.23766\tvalid_1's rmse: 3.62183\n",
      "[1300]\ttraining's rmse: 3.21844\tvalid_1's rmse: 3.62242\n",
      "[1400]\ttraining's rmse: 3.19883\tvalid_1's rmse: 3.62246\n",
      "[1500]\ttraining's rmse: 3.18048\tvalid_1's rmse: 3.62255\n",
      "[1600]\ttraining's rmse: 3.16181\tvalid_1's rmse: 3.62268\n",
      "[1700]\ttraining's rmse: 3.14219\tvalid_1's rmse: 3.62271\n",
      "Early stopping, best iteration is:\n",
      "[1197]\ttraining's rmse: 3.23825\tvalid_1's rmse: 3.62181\n",
      "fold 3 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63706\tvalid_1's rmse: 3.71144\n",
      "[200]\ttraining's rmse: 3.54066\tvalid_1's rmse: 3.6767\n",
      "[300]\ttraining's rmse: 3.48165\tvalid_1's rmse: 3.66302\n",
      "[400]\ttraining's rmse: 3.43761\tvalid_1's rmse: 3.65675\n",
      "[500]\ttraining's rmse: 3.40182\tvalid_1's rmse: 3.65295\n",
      "[600]\ttraining's rmse: 3.37129\tvalid_1's rmse: 3.6504\n",
      "[700]\ttraining's rmse: 3.34385\tvalid_1's rmse: 3.64837\n",
      "[800]\ttraining's rmse: 3.31981\tvalid_1's rmse: 3.64668\n",
      "[900]\ttraining's rmse: 3.29603\tvalid_1's rmse: 3.64718\n",
      "[1000]\ttraining's rmse: 3.27331\tvalid_1's rmse: 3.64759\n",
      "[1100]\ttraining's rmse: 3.25137\tvalid_1's rmse: 3.64762\n",
      "[1200]\ttraining's rmse: 3.23033\tvalid_1's rmse: 3.64856\n",
      "[1300]\ttraining's rmse: 3.2104\tvalid_1's rmse: 3.64877\n",
      "[1400]\ttraining's rmse: 3.19059\tvalid_1's rmse: 3.64903\n",
      "Early stopping, best iteration is:\n",
      "[834]\ttraining's rmse: 3.31125\tvalid_1's rmse: 3.64649\n",
      "fold 4 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6361\tvalid_1's rmse: 3.70951\n",
      "[200]\ttraining's rmse: 3.53599\tvalid_1's rmse: 3.67979\n",
      "[300]\ttraining's rmse: 3.47608\tvalid_1's rmse: 3.66849\n",
      "[400]\ttraining's rmse: 3.43075\tvalid_1's rmse: 3.66135\n",
      "[500]\ttraining's rmse: 3.39405\tvalid_1's rmse: 3.6571\n",
      "[600]\ttraining's rmse: 3.36347\tvalid_1's rmse: 3.65508\n",
      "[700]\ttraining's rmse: 3.33757\tvalid_1's rmse: 3.65406\n",
      "[800]\ttraining's rmse: 3.31208\tvalid_1's rmse: 3.65349\n",
      "[900]\ttraining's rmse: 3.28769\tvalid_1's rmse: 3.65283\n",
      "[1000]\ttraining's rmse: 3.26563\tvalid_1's rmse: 3.65329\n",
      "[1100]\ttraining's rmse: 3.24416\tvalid_1's rmse: 3.65279\n",
      "[1200]\ttraining's rmse: 3.22323\tvalid_1's rmse: 3.65295\n",
      "[1300]\ttraining's rmse: 3.20311\tvalid_1's rmse: 3.65335\n",
      "[1400]\ttraining's rmse: 3.18394\tvalid_1's rmse: 3.65376\n",
      "[1500]\ttraining's rmse: 3.16591\tvalid_1's rmse: 3.65399\n",
      "Early stopping, best iteration is:\n",
      "[928]\ttraining's rmse: 3.28132\tvalid_1's rmse: 3.65257\n",
      "fold 5 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63898\tvalid_1's rmse: 3.70255\n",
      "[200]\ttraining's rmse: 3.54312\tvalid_1's rmse: 3.66085\n",
      "[300]\ttraining's rmse: 3.48372\tvalid_1's rmse: 3.644\n",
      "[400]\ttraining's rmse: 3.43928\tvalid_1's rmse: 3.63514\n",
      "[500]\ttraining's rmse: 3.40311\tvalid_1's rmse: 3.62998\n",
      "[600]\ttraining's rmse: 3.37068\tvalid_1's rmse: 3.62605\n",
      "[700]\ttraining's rmse: 3.3426\tvalid_1's rmse: 3.62379\n",
      "[800]\ttraining's rmse: 3.31641\tvalid_1's rmse: 3.62261\n",
      "[900]\ttraining's rmse: 3.29221\tvalid_1's rmse: 3.62126\n",
      "[1000]\ttraining's rmse: 3.26839\tvalid_1's rmse: 3.62088\n",
      "[1100]\ttraining's rmse: 3.24772\tvalid_1's rmse: 3.62019\n",
      "[1200]\ttraining's rmse: 3.22607\tvalid_1's rmse: 3.62073\n",
      "[1300]\ttraining's rmse: 3.20587\tvalid_1's rmse: 3.62082\n",
      "[1400]\ttraining's rmse: 3.187\tvalid_1's rmse: 3.62076\n",
      "[1500]\ttraining's rmse: 3.16765\tvalid_1's rmse: 3.62111\n",
      "[1600]\ttraining's rmse: 3.14884\tvalid_1's rmse: 3.62034\n",
      "[1700]\ttraining's rmse: 3.13103\tvalid_1's rmse: 3.62009\n",
      "[1800]\ttraining's rmse: 3.11271\tvalid_1's rmse: 3.62035\n",
      "[1900]\ttraining's rmse: 3.09486\tvalid_1's rmse: 3.62084\n",
      "[2000]\ttraining's rmse: 3.07677\tvalid_1's rmse: 3.62113\n",
      "[2100]\ttraining's rmse: 3.05976\tvalid_1's rmse: 3.62184\n",
      "[2200]\ttraining's rmse: 3.04391\tvalid_1's rmse: 3.62261\n",
      "Early stopping, best iteration is:\n",
      "[1698]\ttraining's rmse: 3.13141\tvalid_1's rmse: 3.61999\n",
      "fold 6 1546 0.010938008518345574\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63124\tvalid_1's rmse: 3.73326\n",
      "[200]\ttraining's rmse: 3.53329\tvalid_1's rmse: 3.70598\n",
      "[300]\ttraining's rmse: 3.47474\tvalid_1's rmse: 3.69278\n",
      "[400]\ttraining's rmse: 3.42901\tvalid_1's rmse: 3.68653\n",
      "[500]\ttraining's rmse: 3.39262\tvalid_1's rmse: 3.68222\n",
      "[600]\ttraining's rmse: 3.36138\tvalid_1's rmse: 3.67804\n",
      "[700]\ttraining's rmse: 3.33289\tvalid_1's rmse: 3.67592\n",
      "[800]\ttraining's rmse: 3.30753\tvalid_1's rmse: 3.67467\n",
      "[900]\ttraining's rmse: 3.28433\tvalid_1's rmse: 3.67327\n",
      "[1000]\ttraining's rmse: 3.263\tvalid_1's rmse: 3.67224\n",
      "[1100]\ttraining's rmse: 3.2423\tvalid_1's rmse: 3.67159\n",
      "[1200]\ttraining's rmse: 3.22184\tvalid_1's rmse: 3.67075\n",
      "[1300]\ttraining's rmse: 3.20294\tvalid_1's rmse: 3.67081\n",
      "[1400]\ttraining's rmse: 3.18369\tvalid_1's rmse: 3.67122\n",
      "[1500]\ttraining's rmse: 3.1649\tvalid_1's rmse: 3.67074\n",
      "[1600]\ttraining's rmse: 3.14631\tvalid_1's rmse: 3.67094\n",
      "[1700]\ttraining's rmse: 3.1282\tvalid_1's rmse: 3.67105\n",
      "[1800]\ttraining's rmse: 3.1106\tvalid_1's rmse: 3.6706\n",
      "[1900]\ttraining's rmse: 3.09304\tvalid_1's rmse: 3.6705\n",
      "[2000]\ttraining's rmse: 3.07629\tvalid_1's rmse: 3.67067\n",
      "[2100]\ttraining's rmse: 3.0593\tvalid_1's rmse: 3.67066\n",
      "[2200]\ttraining's rmse: 3.04331\tvalid_1's rmse: 3.6709\n",
      "[2300]\ttraining's rmse: 3.02733\tvalid_1's rmse: 3.6713\n",
      "Early stopping, best iteration is:\n",
      "[1753]\ttraining's rmse: 3.11882\tvalid_1's rmse: 3.67007\n",
      "fold 7 1546 0.010937931132068797\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63225\tvalid_1's rmse: 3.72101\n",
      "[200]\ttraining's rmse: 3.533\tvalid_1's rmse: 3.70035\n",
      "[300]\ttraining's rmse: 3.47322\tvalid_1's rmse: 3.6937\n",
      "[400]\ttraining's rmse: 3.42937\tvalid_1's rmse: 3.69191\n",
      "[500]\ttraining's rmse: 3.39175\tvalid_1's rmse: 3.69087\n",
      "[600]\ttraining's rmse: 3.35956\tvalid_1's rmse: 3.69072\n",
      "[700]\ttraining's rmse: 3.33274\tvalid_1's rmse: 3.69105\n",
      "[800]\ttraining's rmse: 3.307\tvalid_1's rmse: 3.69089\n",
      "[900]\ttraining's rmse: 3.2834\tvalid_1's rmse: 3.69169\n",
      "[1000]\ttraining's rmse: 3.26167\tvalid_1's rmse: 3.69218\n",
      "[1100]\ttraining's rmse: 3.24009\tvalid_1's rmse: 3.69232\n",
      "Early stopping, best iteration is:\n",
      "[532]\ttraining's rmse: 3.38131\tvalid_1's rmse: 3.69059\n",
      "fold 0 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64129\tvalid_1's rmse: 3.70276\n",
      "[200]\ttraining's rmse: 3.54854\tvalid_1's rmse: 3.67208\n",
      "[300]\ttraining's rmse: 3.49383\tvalid_1's rmse: 3.6599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 3.45396\tvalid_1's rmse: 3.6521\n",
      "[500]\ttraining's rmse: 3.41961\tvalid_1's rmse: 3.64843\n",
      "[600]\ttraining's rmse: 3.39033\tvalid_1's rmse: 3.64658\n",
      "[700]\ttraining's rmse: 3.36251\tvalid_1's rmse: 3.64548\n",
      "[800]\ttraining's rmse: 3.33783\tvalid_1's rmse: 3.6438\n",
      "[900]\ttraining's rmse: 3.31516\tvalid_1's rmse: 3.6423\n",
      "[1000]\ttraining's rmse: 3.29408\tvalid_1's rmse: 3.64079\n",
      "[1100]\ttraining's rmse: 3.27451\tvalid_1's rmse: 3.64059\n",
      "[1200]\ttraining's rmse: 3.25467\tvalid_1's rmse: 3.63939\n",
      "[1300]\ttraining's rmse: 3.23708\tvalid_1's rmse: 3.63909\n",
      "[1400]\ttraining's rmse: 3.22035\tvalid_1's rmse: 3.63889\n",
      "[1500]\ttraining's rmse: 3.20396\tvalid_1's rmse: 3.63921\n",
      "[1600]\ttraining's rmse: 3.18749\tvalid_1's rmse: 3.639\n",
      "[1700]\ttraining's rmse: 3.17112\tvalid_1's rmse: 3.63917\n",
      "[1800]\ttraining's rmse: 3.15553\tvalid_1's rmse: 3.6396\n",
      "[1900]\ttraining's rmse: 3.1399\tvalid_1's rmse: 3.63948\n",
      "Early stopping, best iteration is:\n",
      "[1317]\ttraining's rmse: 3.23447\tvalid_1's rmse: 3.6388\n",
      "fold 1 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64116\tvalid_1's rmse: 3.71164\n",
      "[200]\ttraining's rmse: 3.54685\tvalid_1's rmse: 3.68128\n",
      "[300]\ttraining's rmse: 3.49022\tvalid_1's rmse: 3.66915\n",
      "[400]\ttraining's rmse: 3.44789\tvalid_1's rmse: 3.66473\n",
      "[500]\ttraining's rmse: 3.41347\tvalid_1's rmse: 3.66117\n",
      "[600]\ttraining's rmse: 3.38374\tvalid_1's rmse: 3.659\n",
      "[700]\ttraining's rmse: 3.35714\tvalid_1's rmse: 3.65716\n",
      "[800]\ttraining's rmse: 3.33415\tvalid_1's rmse: 3.656\n",
      "[900]\ttraining's rmse: 3.31244\tvalid_1's rmse: 3.65527\n",
      "[1000]\ttraining's rmse: 3.29233\tvalid_1's rmse: 3.65457\n",
      "[1100]\ttraining's rmse: 3.27291\tvalid_1's rmse: 3.65395\n",
      "[1200]\ttraining's rmse: 3.25475\tvalid_1's rmse: 3.65411\n",
      "[1300]\ttraining's rmse: 3.23572\tvalid_1's rmse: 3.65402\n",
      "[1400]\ttraining's rmse: 3.21719\tvalid_1's rmse: 3.65418\n",
      "[1500]\ttraining's rmse: 3.19962\tvalid_1's rmse: 3.65368\n",
      "[1600]\ttraining's rmse: 3.18252\tvalid_1's rmse: 3.65384\n",
      "[1700]\ttraining's rmse: 3.16622\tvalid_1's rmse: 3.65419\n",
      "[1800]\ttraining's rmse: 3.1499\tvalid_1's rmse: 3.65433\n",
      "[1900]\ttraining's rmse: 3.13278\tvalid_1's rmse: 3.65493\n",
      "[2000]\ttraining's rmse: 3.11714\tvalid_1's rmse: 3.65538\n",
      "[2100]\ttraining's rmse: 3.10209\tvalid_1's rmse: 3.65614\n",
      "Early stopping, best iteration is:\n",
      "[1557]\ttraining's rmse: 3.18965\tvalid_1's rmse: 3.65321\n",
      "fold 2 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64366\tvalid_1's rmse: 3.70691\n",
      "[200]\ttraining's rmse: 3.55259\tvalid_1's rmse: 3.66456\n",
      "[300]\ttraining's rmse: 3.49676\tvalid_1's rmse: 3.6503\n",
      "[400]\ttraining's rmse: 3.45599\tvalid_1's rmse: 3.64204\n",
      "[500]\ttraining's rmse: 3.42273\tvalid_1's rmse: 3.63676\n",
      "[600]\ttraining's rmse: 3.39382\tvalid_1's rmse: 3.63336\n",
      "[700]\ttraining's rmse: 3.36785\tvalid_1's rmse: 3.63137\n",
      "[800]\ttraining's rmse: 3.34286\tvalid_1's rmse: 3.63058\n",
      "[900]\ttraining's rmse: 3.31973\tvalid_1's rmse: 3.62951\n",
      "[1000]\ttraining's rmse: 3.29941\tvalid_1's rmse: 3.62917\n",
      "[1100]\ttraining's rmse: 3.27941\tvalid_1's rmse: 3.62864\n",
      "[1200]\ttraining's rmse: 3.26085\tvalid_1's rmse: 3.6283\n",
      "[1300]\ttraining's rmse: 3.24292\tvalid_1's rmse: 3.62819\n",
      "[1400]\ttraining's rmse: 3.22539\tvalid_1's rmse: 3.62762\n",
      "[1500]\ttraining's rmse: 3.20762\tvalid_1's rmse: 3.62775\n",
      "[1600]\ttraining's rmse: 3.19034\tvalid_1's rmse: 3.62744\n",
      "[1700]\ttraining's rmse: 3.17202\tvalid_1's rmse: 3.62719\n",
      "[1800]\ttraining's rmse: 3.15461\tvalid_1's rmse: 3.62729\n",
      "[1900]\ttraining's rmse: 3.13961\tvalid_1's rmse: 3.62637\n",
      "[2000]\ttraining's rmse: 3.12419\tvalid_1's rmse: 3.62666\n",
      "[2100]\ttraining's rmse: 3.10864\tvalid_1's rmse: 3.62765\n",
      "[2200]\ttraining's rmse: 3.09292\tvalid_1's rmse: 3.62791\n",
      "[2300]\ttraining's rmse: 3.07772\tvalid_1's rmse: 3.62837\n",
      "[2400]\ttraining's rmse: 3.06354\tvalid_1's rmse: 3.62923\n",
      "Early stopping, best iteration is:\n",
      "[1896]\ttraining's rmse: 3.14001\tvalid_1's rmse: 3.62635\n",
      "fold 3 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64257\tvalid_1's rmse: 3.70915\n",
      "[200]\ttraining's rmse: 3.55059\tvalid_1's rmse: 3.67424\n",
      "[300]\ttraining's rmse: 3.49467\tvalid_1's rmse: 3.66065\n",
      "[400]\ttraining's rmse: 3.45222\tvalid_1's rmse: 3.65421\n",
      "[500]\ttraining's rmse: 3.4181\tvalid_1's rmse: 3.65089\n",
      "[600]\ttraining's rmse: 3.38872\tvalid_1's rmse: 3.6485\n",
      "[700]\ttraining's rmse: 3.36202\tvalid_1's rmse: 3.64697\n",
      "[800]\ttraining's rmse: 3.33797\tvalid_1's rmse: 3.64677\n",
      "[900]\ttraining's rmse: 3.3161\tvalid_1's rmse: 3.6479\n",
      "[1000]\ttraining's rmse: 3.29484\tvalid_1's rmse: 3.64872\n",
      "[1100]\ttraining's rmse: 3.2738\tvalid_1's rmse: 3.64913\n",
      "[1200]\ttraining's rmse: 3.25414\tvalid_1's rmse: 3.6499\n",
      "[1300]\ttraining's rmse: 3.23483\tvalid_1's rmse: 3.6511\n",
      "Early stopping, best iteration is:\n",
      "[755]\ttraining's rmse: 3.34902\tvalid_1's rmse: 3.64645\n",
      "fold 4 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63975\tvalid_1's rmse: 3.71231\n",
      "[200]\ttraining's rmse: 3.54508\tvalid_1's rmse: 3.67975\n",
      "[300]\ttraining's rmse: 3.48888\tvalid_1's rmse: 3.66899\n",
      "[400]\ttraining's rmse: 3.44526\tvalid_1's rmse: 3.66268\n",
      "[500]\ttraining's rmse: 3.41006\tvalid_1's rmse: 3.65897\n",
      "[600]\ttraining's rmse: 3.38174\tvalid_1's rmse: 3.65642\n",
      "[700]\ttraining's rmse: 3.35624\tvalid_1's rmse: 3.65503\n",
      "[800]\ttraining's rmse: 3.33138\tvalid_1's rmse: 3.65448\n",
      "[900]\ttraining's rmse: 3.3088\tvalid_1's rmse: 3.65455\n",
      "[1000]\ttraining's rmse: 3.28946\tvalid_1's rmse: 3.65419\n",
      "[1100]\ttraining's rmse: 3.26994\tvalid_1's rmse: 3.65374\n",
      "[1200]\ttraining's rmse: 3.24983\tvalid_1's rmse: 3.65369\n",
      "[1300]\ttraining's rmse: 3.23182\tvalid_1's rmse: 3.65354\n",
      "[1400]\ttraining's rmse: 3.21374\tvalid_1's rmse: 3.65315\n",
      "[1500]\ttraining's rmse: 3.19698\tvalid_1's rmse: 3.65313\n",
      "[1600]\ttraining's rmse: 3.18022\tvalid_1's rmse: 3.65368\n",
      "[1700]\ttraining's rmse: 3.1629\tvalid_1's rmse: 3.65351\n",
      "[1800]\ttraining's rmse: 3.14656\tvalid_1's rmse: 3.65382\n",
      "[1900]\ttraining's rmse: 3.13104\tvalid_1's rmse: 3.65482\n",
      "[2000]\ttraining's rmse: 3.11575\tvalid_1's rmse: 3.65555\n",
      "Early stopping, best iteration is:\n",
      "[1470]\ttraining's rmse: 3.20236\tvalid_1's rmse: 3.65266\n",
      "fold 5 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64408\tvalid_1's rmse: 3.70304\n",
      "[200]\ttraining's rmse: 3.55291\tvalid_1's rmse: 3.65841\n",
      "[300]\ttraining's rmse: 3.49717\tvalid_1's rmse: 3.64015\n",
      "[400]\ttraining's rmse: 3.4553\tvalid_1's rmse: 3.63149\n",
      "[500]\ttraining's rmse: 3.42139\tvalid_1's rmse: 3.62596\n",
      "[600]\ttraining's rmse: 3.39069\tvalid_1's rmse: 3.6221\n",
      "[700]\ttraining's rmse: 3.36329\tvalid_1's rmse: 3.61921\n",
      "[800]\ttraining's rmse: 3.33818\tvalid_1's rmse: 3.61786\n",
      "[900]\ttraining's rmse: 3.3155\tvalid_1's rmse: 3.61705\n",
      "[1000]\ttraining's rmse: 3.29363\tvalid_1's rmse: 3.61736\n",
      "[1100]\ttraining's rmse: 3.27356\tvalid_1's rmse: 3.61688\n",
      "[1200]\ttraining's rmse: 3.2529\tvalid_1's rmse: 3.61777\n",
      "[1300]\ttraining's rmse: 3.2346\tvalid_1's rmse: 3.61785\n",
      "[1400]\ttraining's rmse: 3.21671\tvalid_1's rmse: 3.61793\n",
      "[1500]\ttraining's rmse: 3.19903\tvalid_1's rmse: 3.61847\n",
      "[1600]\ttraining's rmse: 3.18307\tvalid_1's rmse: 3.61862\n",
      "Early stopping, best iteration is:\n",
      "[1061]\ttraining's rmse: 3.2811\tvalid_1's rmse: 3.61654\n",
      "fold 6 1546 0.010938008518345574\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63654\tvalid_1's rmse: 3.73404\n",
      "[200]\ttraining's rmse: 3.54257\tvalid_1's rmse: 3.70611\n",
      "[300]\ttraining's rmse: 3.48697\tvalid_1's rmse: 3.69411\n",
      "[400]\ttraining's rmse: 3.44534\tvalid_1's rmse: 3.6879\n",
      "[500]\ttraining's rmse: 3.41132\tvalid_1's rmse: 3.68371\n",
      "[600]\ttraining's rmse: 3.38159\tvalid_1's rmse: 3.68002\n",
      "[700]\ttraining's rmse: 3.35517\tvalid_1's rmse: 3.67807\n",
      "[800]\ttraining's rmse: 3.33113\tvalid_1's rmse: 3.67609\n",
      "[900]\ttraining's rmse: 3.30872\tvalid_1's rmse: 3.67433\n",
      "[1000]\ttraining's rmse: 3.28715\tvalid_1's rmse: 3.67361\n",
      "[1100]\ttraining's rmse: 3.26668\tvalid_1's rmse: 3.67299\n",
      "[1200]\ttraining's rmse: 3.24684\tvalid_1's rmse: 3.67179\n",
      "[1300]\ttraining's rmse: 3.22726\tvalid_1's rmse: 3.67102\n",
      "[1400]\ttraining's rmse: 3.2097\tvalid_1's rmse: 3.67107\n",
      "[1500]\ttraining's rmse: 3.19224\tvalid_1's rmse: 3.67109\n",
      "[1600]\ttraining's rmse: 3.17546\tvalid_1's rmse: 3.67108\n",
      "[1700]\ttraining's rmse: 3.15707\tvalid_1's rmse: 3.67043\n",
      "[1800]\ttraining's rmse: 3.14131\tvalid_1's rmse: 3.67085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\ttraining's rmse: 3.12609\tvalid_1's rmse: 3.6709\n",
      "[2000]\ttraining's rmse: 3.11043\tvalid_1's rmse: 3.67175\n",
      "[2100]\ttraining's rmse: 3.09481\tvalid_1's rmse: 3.6719\n",
      "[2200]\ttraining's rmse: 3.07942\tvalid_1's rmse: 3.67157\n",
      "Early stopping, best iteration is:\n",
      "[1673]\ttraining's rmse: 3.16161\tvalid_1's rmse: 3.67033\n",
      "fold 7 1546 0.010937931132068797\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63627\tvalid_1's rmse: 3.71885\n",
      "[200]\ttraining's rmse: 3.54116\tvalid_1's rmse: 3.69729\n",
      "[300]\ttraining's rmse: 3.48506\tvalid_1's rmse: 3.68925\n",
      "[400]\ttraining's rmse: 3.44427\tvalid_1's rmse: 3.68584\n",
      "[500]\ttraining's rmse: 3.40846\tvalid_1's rmse: 3.68395\n",
      "[600]\ttraining's rmse: 3.37854\tvalid_1's rmse: 3.68233\n",
      "[700]\ttraining's rmse: 3.35217\tvalid_1's rmse: 3.68193\n",
      "[800]\ttraining's rmse: 3.32822\tvalid_1's rmse: 3.68199\n",
      "[900]\ttraining's rmse: 3.30596\tvalid_1's rmse: 3.68205\n",
      "[1000]\ttraining's rmse: 3.28527\tvalid_1's rmse: 3.68133\n",
      "[1100]\ttraining's rmse: 3.2647\tvalid_1's rmse: 3.68118\n",
      "[1200]\ttraining's rmse: 3.24647\tvalid_1's rmse: 3.68179\n",
      "[1300]\ttraining's rmse: 3.22752\tvalid_1's rmse: 3.68247\n",
      "[1400]\ttraining's rmse: 3.21135\tvalid_1's rmse: 3.68262\n",
      "[1500]\ttraining's rmse: 3.19428\tvalid_1's rmse: 3.68219\n",
      "[1600]\ttraining's rmse: 3.1761\tvalid_1's rmse: 3.68211\n",
      "Early stopping, best iteration is:\n",
      "[1057]\ttraining's rmse: 3.27298\tvalid_1's rmse: 3.68084\n",
      "fold 0 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64653\tvalid_1's rmse: 3.69947\n",
      "[200]\ttraining's rmse: 3.55837\tvalid_1's rmse: 3.67002\n",
      "[300]\ttraining's rmse: 3.50735\tvalid_1's rmse: 3.65816\n",
      "[400]\ttraining's rmse: 3.47018\tvalid_1's rmse: 3.65209\n",
      "[500]\ttraining's rmse: 3.43788\tvalid_1's rmse: 3.64942\n",
      "[600]\ttraining's rmse: 3.41109\tvalid_1's rmse: 3.64715\n",
      "[700]\ttraining's rmse: 3.38747\tvalid_1's rmse: 3.64625\n",
      "[800]\ttraining's rmse: 3.36594\tvalid_1's rmse: 3.64466\n",
      "[900]\ttraining's rmse: 3.34567\tvalid_1's rmse: 3.64418\n",
      "[1000]\ttraining's rmse: 3.32659\tvalid_1's rmse: 3.64331\n",
      "[1100]\ttraining's rmse: 3.30776\tvalid_1's rmse: 3.64254\n",
      "[1200]\ttraining's rmse: 3.29004\tvalid_1's rmse: 3.64202\n",
      "[1300]\ttraining's rmse: 3.27324\tvalid_1's rmse: 3.64196\n",
      "[1400]\ttraining's rmse: 3.25682\tvalid_1's rmse: 3.64147\n",
      "[1500]\ttraining's rmse: 3.24093\tvalid_1's rmse: 3.64132\n",
      "[1600]\ttraining's rmse: 3.2247\tvalid_1's rmse: 3.64182\n",
      "[1700]\ttraining's rmse: 3.21007\tvalid_1's rmse: 3.64226\n",
      "[1800]\ttraining's rmse: 3.19479\tvalid_1's rmse: 3.64238\n",
      "Early stopping, best iteration is:\n",
      "[1248]\ttraining's rmse: 3.28173\tvalid_1's rmse: 3.64113\n",
      "fold 1 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64655\tvalid_1's rmse: 3.70681\n",
      "[200]\ttraining's rmse: 3.55709\tvalid_1's rmse: 3.67548\n",
      "[300]\ttraining's rmse: 3.50457\tvalid_1's rmse: 3.66403\n",
      "[400]\ttraining's rmse: 3.46477\tvalid_1's rmse: 3.65985\n",
      "[500]\ttraining's rmse: 3.43322\tvalid_1's rmse: 3.65751\n",
      "[600]\ttraining's rmse: 3.40627\tvalid_1's rmse: 3.65597\n",
      "[700]\ttraining's rmse: 3.38211\tvalid_1's rmse: 3.65544\n",
      "[800]\ttraining's rmse: 3.36034\tvalid_1's rmse: 3.65345\n",
      "[900]\ttraining's rmse: 3.33928\tvalid_1's rmse: 3.6535\n",
      "[1000]\ttraining's rmse: 3.32004\tvalid_1's rmse: 3.65317\n",
      "[1100]\ttraining's rmse: 3.30211\tvalid_1's rmse: 3.65302\n",
      "[1200]\ttraining's rmse: 3.28499\tvalid_1's rmse: 3.6527\n",
      "[1300]\ttraining's rmse: 3.26742\tvalid_1's rmse: 3.65368\n",
      "[1400]\ttraining's rmse: 3.25035\tvalid_1's rmse: 3.65466\n",
      "[1500]\ttraining's rmse: 3.23393\tvalid_1's rmse: 3.65435\n",
      "[1600]\ttraining's rmse: 3.21848\tvalid_1's rmse: 3.65439\n",
      "[1700]\ttraining's rmse: 3.20251\tvalid_1's rmse: 3.65506\n",
      "Early stopping, best iteration is:\n",
      "[1163]\ttraining's rmse: 3.2912\tvalid_1's rmse: 3.65238\n",
      "fold 2 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6482\tvalid_1's rmse: 3.70194\n",
      "[200]\ttraining's rmse: 3.56187\tvalid_1's rmse: 3.66416\n",
      "[300]\ttraining's rmse: 3.50882\tvalid_1's rmse: 3.65151\n",
      "[400]\ttraining's rmse: 3.4701\tvalid_1's rmse: 3.64418\n",
      "[500]\ttraining's rmse: 3.43865\tvalid_1's rmse: 3.63945\n",
      "[600]\ttraining's rmse: 3.41162\tvalid_1's rmse: 3.63735\n",
      "[700]\ttraining's rmse: 3.38823\tvalid_1's rmse: 3.63548\n",
      "[800]\ttraining's rmse: 3.36647\tvalid_1's rmse: 3.6345\n",
      "[900]\ttraining's rmse: 3.34612\tvalid_1's rmse: 3.63388\n",
      "[1000]\ttraining's rmse: 3.32679\tvalid_1's rmse: 3.63273\n",
      "[1100]\ttraining's rmse: 3.30788\tvalid_1's rmse: 3.63236\n",
      "[1200]\ttraining's rmse: 3.2916\tvalid_1's rmse: 3.63147\n",
      "[1300]\ttraining's rmse: 3.27528\tvalid_1's rmse: 3.63147\n",
      "[1400]\ttraining's rmse: 3.25905\tvalid_1's rmse: 3.63157\n",
      "[1500]\ttraining's rmse: 3.24291\tvalid_1's rmse: 3.63154\n",
      "[1600]\ttraining's rmse: 3.22689\tvalid_1's rmse: 3.63131\n",
      "[1700]\ttraining's rmse: 3.2108\tvalid_1's rmse: 3.63141\n",
      "[1800]\ttraining's rmse: 3.19597\tvalid_1's rmse: 3.63224\n",
      "[1900]\ttraining's rmse: 3.18092\tvalid_1's rmse: 3.63293\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's rmse: 3.27053\tvalid_1's rmse: 3.63101\n",
      "fold 3 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64656\tvalid_1's rmse: 3.70648\n",
      "[200]\ttraining's rmse: 3.55913\tvalid_1's rmse: 3.67248\n",
      "[300]\ttraining's rmse: 3.5072\tvalid_1's rmse: 3.65921\n",
      "[400]\ttraining's rmse: 3.4685\tvalid_1's rmse: 3.65272\n",
      "[500]\ttraining's rmse: 3.43698\tvalid_1's rmse: 3.64989\n",
      "[600]\ttraining's rmse: 3.41008\tvalid_1's rmse: 3.64874\n",
      "[700]\ttraining's rmse: 3.3872\tvalid_1's rmse: 3.64797\n",
      "[800]\ttraining's rmse: 3.36588\tvalid_1's rmse: 3.64735\n",
      "[900]\ttraining's rmse: 3.34526\tvalid_1's rmse: 3.64848\n",
      "[1000]\ttraining's rmse: 3.32603\tvalid_1's rmse: 3.64934\n",
      "[1100]\ttraining's rmse: 3.30676\tvalid_1's rmse: 3.64969\n",
      "[1200]\ttraining's rmse: 3.28865\tvalid_1's rmse: 3.65098\n",
      "[1300]\ttraining's rmse: 3.27125\tvalid_1's rmse: 3.65171\n",
      "[1400]\ttraining's rmse: 3.2548\tvalid_1's rmse: 3.65153\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's rmse: 3.36552\tvalid_1's rmse: 3.64732\n",
      "fold 4 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64548\tvalid_1's rmse: 3.7094\n",
      "[200]\ttraining's rmse: 3.55574\tvalid_1's rmse: 3.67691\n",
      "[300]\ttraining's rmse: 3.50314\tvalid_1's rmse: 3.66724\n",
      "[400]\ttraining's rmse: 3.46303\tvalid_1's rmse: 3.66163\n",
      "[500]\ttraining's rmse: 3.43077\tvalid_1's rmse: 3.65829\n",
      "[600]\ttraining's rmse: 3.40303\tvalid_1's rmse: 3.65652\n",
      "[700]\ttraining's rmse: 3.37991\tvalid_1's rmse: 3.6558\n",
      "[800]\ttraining's rmse: 3.35794\tvalid_1's rmse: 3.65581\n",
      "[900]\ttraining's rmse: 3.3386\tvalid_1's rmse: 3.6552\n",
      "[1000]\ttraining's rmse: 3.31885\tvalid_1's rmse: 3.65593\n",
      "[1100]\ttraining's rmse: 3.30015\tvalid_1's rmse: 3.65584\n",
      "[1200]\ttraining's rmse: 3.28217\tvalid_1's rmse: 3.65546\n",
      "[1300]\ttraining's rmse: 3.26646\tvalid_1's rmse: 3.65527\n",
      "[1400]\ttraining's rmse: 3.24974\tvalid_1's rmse: 3.65569\n",
      "[1500]\ttraining's rmse: 3.23477\tvalid_1's rmse: 3.65585\n",
      "[1600]\ttraining's rmse: 3.21972\tvalid_1's rmse: 3.65644\n",
      "[1700]\ttraining's rmse: 3.20344\tvalid_1's rmse: 3.65646\n",
      "[1800]\ttraining's rmse: 3.18775\tvalid_1's rmse: 3.65679\n",
      "Early stopping, best iteration is:\n",
      "[1285]\ttraining's rmse: 3.26869\tvalid_1's rmse: 3.65502\n",
      "fold 5 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65019\tvalid_1's rmse: 3.69819\n",
      "[200]\ttraining's rmse: 3.56361\tvalid_1's rmse: 3.65493\n",
      "[300]\ttraining's rmse: 3.51223\tvalid_1's rmse: 3.6384\n",
      "[400]\ttraining's rmse: 3.47356\tvalid_1's rmse: 3.62842\n",
      "[500]\ttraining's rmse: 3.44071\tvalid_1's rmse: 3.62215\n",
      "[600]\ttraining's rmse: 3.41308\tvalid_1's rmse: 3.61793\n",
      "[700]\ttraining's rmse: 3.38859\tvalid_1's rmse: 3.61575\n",
      "[800]\ttraining's rmse: 3.36668\tvalid_1's rmse: 3.61548\n",
      "[900]\ttraining's rmse: 3.3468\tvalid_1's rmse: 3.61558\n",
      "[1000]\ttraining's rmse: 3.32633\tvalid_1's rmse: 3.61606\n",
      "[1100]\ttraining's rmse: 3.30782\tvalid_1's rmse: 3.6163\n",
      "[1200]\ttraining's rmse: 3.28894\tvalid_1's rmse: 3.61566\n",
      "[1300]\ttraining's rmse: 3.27084\tvalid_1's rmse: 3.61623\n",
      "Early stopping, best iteration is:\n",
      "[737]\ttraining's rmse: 3.37993\tvalid_1's rmse: 3.6153\n",
      "fold 6 1546 0.010938008518345574\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64083\tvalid_1's rmse: 3.73347\n",
      "[200]\ttraining's rmse: 3.55238\tvalid_1's rmse: 3.70515\n",
      "[300]\ttraining's rmse: 3.50081\tvalid_1's rmse: 3.69381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 3.46282\tvalid_1's rmse: 3.68744\n",
      "[500]\ttraining's rmse: 3.42985\tvalid_1's rmse: 3.68117\n",
      "[600]\ttraining's rmse: 3.40265\tvalid_1's rmse: 3.67773\n",
      "[700]\ttraining's rmse: 3.37762\tvalid_1's rmse: 3.67655\n",
      "[800]\ttraining's rmse: 3.35631\tvalid_1's rmse: 3.67491\n",
      "[900]\ttraining's rmse: 3.33646\tvalid_1's rmse: 3.67316\n",
      "[1000]\ttraining's rmse: 3.31804\tvalid_1's rmse: 3.67215\n",
      "[1100]\ttraining's rmse: 3.29993\tvalid_1's rmse: 3.67158\n",
      "[1200]\ttraining's rmse: 3.28317\tvalid_1's rmse: 3.67071\n",
      "[1300]\ttraining's rmse: 3.26561\tvalid_1's rmse: 3.67043\n",
      "[1400]\ttraining's rmse: 3.24893\tvalid_1's rmse: 3.67061\n",
      "[1500]\ttraining's rmse: 3.23327\tvalid_1's rmse: 3.67072\n",
      "[1600]\ttraining's rmse: 3.2178\tvalid_1's rmse: 3.67045\n",
      "[1700]\ttraining's rmse: 3.20029\tvalid_1's rmse: 3.67055\n",
      "[1800]\ttraining's rmse: 3.18637\tvalid_1's rmse: 3.66995\n",
      "[1900]\ttraining's rmse: 3.17177\tvalid_1's rmse: 3.67043\n",
      "[2000]\ttraining's rmse: 3.15705\tvalid_1's rmse: 3.6698\n",
      "[2100]\ttraining's rmse: 3.14114\tvalid_1's rmse: 3.67009\n",
      "[2200]\ttraining's rmse: 3.12589\tvalid_1's rmse: 3.67041\n",
      "[2300]\ttraining's rmse: 3.11187\tvalid_1's rmse: 3.67048\n",
      "[2400]\ttraining's rmse: 3.09769\tvalid_1's rmse: 3.67085\n",
      "Early stopping, best iteration is:\n",
      "[1825]\ttraining's rmse: 3.18254\tvalid_1's rmse: 3.66973\n",
      "fold 7 1546 0.010937931132068797\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64281\tvalid_1's rmse: 3.71662\n",
      "[200]\ttraining's rmse: 3.55288\tvalid_1's rmse: 3.69347\n",
      "[300]\ttraining's rmse: 3.50014\tvalid_1's rmse: 3.68673\n",
      "[400]\ttraining's rmse: 3.46065\tvalid_1's rmse: 3.68451\n",
      "[500]\ttraining's rmse: 3.42744\tvalid_1's rmse: 3.68357\n",
      "[600]\ttraining's rmse: 3.39991\tvalid_1's rmse: 3.68337\n",
      "[700]\ttraining's rmse: 3.37656\tvalid_1's rmse: 3.68347\n",
      "[800]\ttraining's rmse: 3.35375\tvalid_1's rmse: 3.68433\n",
      "[900]\ttraining's rmse: 3.3331\tvalid_1's rmse: 3.68436\n",
      "[1000]\ttraining's rmse: 3.31402\tvalid_1's rmse: 3.68444\n",
      "[1100]\ttraining's rmse: 3.29602\tvalid_1's rmse: 3.68469\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's rmse: 3.41281\tvalid_1's rmse: 3.68291\n",
      "fold 0 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64864\tvalid_1's rmse: 3.70116\n",
      "[200]\ttraining's rmse: 3.56406\tvalid_1's rmse: 3.66973\n",
      "[300]\ttraining's rmse: 3.5128\tvalid_1's rmse: 3.65711\n",
      "[400]\ttraining's rmse: 3.47626\tvalid_1's rmse: 3.65101\n",
      "[500]\ttraining's rmse: 3.44599\tvalid_1's rmse: 3.64809\n",
      "[600]\ttraining's rmse: 3.42005\tvalid_1's rmse: 3.64518\n",
      "[700]\ttraining's rmse: 3.39747\tvalid_1's rmse: 3.64355\n",
      "[800]\ttraining's rmse: 3.37507\tvalid_1's rmse: 3.64297\n",
      "[900]\ttraining's rmse: 3.35532\tvalid_1's rmse: 3.6419\n",
      "[1000]\ttraining's rmse: 3.33656\tvalid_1's rmse: 3.64185\n",
      "[1100]\ttraining's rmse: 3.31756\tvalid_1's rmse: 3.6415\n",
      "[1200]\ttraining's rmse: 3.29928\tvalid_1's rmse: 3.64179\n",
      "[1300]\ttraining's rmse: 3.2827\tvalid_1's rmse: 3.64127\n",
      "[1400]\ttraining's rmse: 3.26525\tvalid_1's rmse: 3.64086\n",
      "[1500]\ttraining's rmse: 3.24921\tvalid_1's rmse: 3.64107\n",
      "[1600]\ttraining's rmse: 3.23374\tvalid_1's rmse: 3.64135\n",
      "[1700]\ttraining's rmse: 3.21913\tvalid_1's rmse: 3.6413\n",
      "[1800]\ttraining's rmse: 3.20368\tvalid_1's rmse: 3.64201\n",
      "[1900]\ttraining's rmse: 3.18953\tvalid_1's rmse: 3.6413\n",
      "Early stopping, best iteration is:\n",
      "[1379]\ttraining's rmse: 3.26914\tvalid_1's rmse: 3.64062\n",
      "fold 1 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6491\tvalid_1's rmse: 3.70648\n",
      "[200]\ttraining's rmse: 3.5626\tvalid_1's rmse: 3.67553\n",
      "[300]\ttraining's rmse: 3.51168\tvalid_1's rmse: 3.66584\n",
      "[400]\ttraining's rmse: 3.47317\tvalid_1's rmse: 3.66105\n",
      "[500]\ttraining's rmse: 3.44189\tvalid_1's rmse: 3.65813\n",
      "[600]\ttraining's rmse: 3.41498\tvalid_1's rmse: 3.65743\n",
      "[700]\ttraining's rmse: 3.39076\tvalid_1's rmse: 3.65582\n",
      "[800]\ttraining's rmse: 3.36919\tvalid_1's rmse: 3.65411\n",
      "[900]\ttraining's rmse: 3.349\tvalid_1's rmse: 3.6543\n",
      "[1000]\ttraining's rmse: 3.3303\tvalid_1's rmse: 3.654\n",
      "[1100]\ttraining's rmse: 3.3129\tvalid_1's rmse: 3.65348\n",
      "[1200]\ttraining's rmse: 3.2946\tvalid_1's rmse: 3.65406\n",
      "[1300]\ttraining's rmse: 3.27787\tvalid_1's rmse: 3.65489\n",
      "[1400]\ttraining's rmse: 3.26106\tvalid_1's rmse: 3.65517\n",
      "[1500]\ttraining's rmse: 3.24455\tvalid_1's rmse: 3.65576\n",
      "[1600]\ttraining's rmse: 3.22908\tvalid_1's rmse: 3.65617\n",
      "Early stopping, best iteration is:\n",
      "[1060]\ttraining's rmse: 3.31959\tvalid_1's rmse: 3.65319\n",
      "fold 2 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65198\tvalid_1's rmse: 3.70029\n",
      "[200]\ttraining's rmse: 3.56842\tvalid_1's rmse: 3.65959\n",
      "[300]\ttraining's rmse: 3.5178\tvalid_1's rmse: 3.64531\n",
      "[400]\ttraining's rmse: 3.48029\tvalid_1's rmse: 3.63667\n",
      "[500]\ttraining's rmse: 3.44988\tvalid_1's rmse: 3.63151\n",
      "[600]\ttraining's rmse: 3.42331\tvalid_1's rmse: 3.62814\n",
      "[700]\ttraining's rmse: 3.40051\tvalid_1's rmse: 3.62614\n",
      "[800]\ttraining's rmse: 3.37919\tvalid_1's rmse: 3.62482\n",
      "[900]\ttraining's rmse: 3.35925\tvalid_1's rmse: 3.62378\n",
      "[1000]\ttraining's rmse: 3.34114\tvalid_1's rmse: 3.62251\n",
      "[1100]\ttraining's rmse: 3.32273\tvalid_1's rmse: 3.62219\n",
      "[1200]\ttraining's rmse: 3.30594\tvalid_1's rmse: 3.62232\n",
      "[1300]\ttraining's rmse: 3.29045\tvalid_1's rmse: 3.62274\n",
      "[1400]\ttraining's rmse: 3.27484\tvalid_1's rmse: 3.62331\n",
      "[1500]\ttraining's rmse: 3.25982\tvalid_1's rmse: 3.62258\n",
      "[1600]\ttraining's rmse: 3.24431\tvalid_1's rmse: 3.62288\n",
      "[1700]\ttraining's rmse: 3.22883\tvalid_1's rmse: 3.62259\n",
      "Early stopping, best iteration is:\n",
      "[1166]\ttraining's rmse: 3.3115\tvalid_1's rmse: 3.6219\n",
      "fold 3 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64857\tvalid_1's rmse: 3.70623\n",
      "[200]\ttraining's rmse: 3.56318\tvalid_1's rmse: 3.67121\n",
      "[300]\ttraining's rmse: 3.51256\tvalid_1's rmse: 3.65921\n",
      "[400]\ttraining's rmse: 3.47344\tvalid_1's rmse: 3.65139\n",
      "[500]\ttraining's rmse: 3.44297\tvalid_1's rmse: 3.64889\n",
      "[600]\ttraining's rmse: 3.41727\tvalid_1's rmse: 3.64685\n",
      "[700]\ttraining's rmse: 3.39384\tvalid_1's rmse: 3.64492\n",
      "[800]\ttraining's rmse: 3.37293\tvalid_1's rmse: 3.64471\n",
      "[900]\ttraining's rmse: 3.35311\tvalid_1's rmse: 3.64589\n",
      "[1000]\ttraining's rmse: 3.33416\tvalid_1's rmse: 3.64599\n",
      "[1100]\ttraining's rmse: 3.31575\tvalid_1's rmse: 3.64703\n",
      "[1200]\ttraining's rmse: 3.29847\tvalid_1's rmse: 3.64748\n",
      "[1300]\ttraining's rmse: 3.28157\tvalid_1's rmse: 3.6481\n",
      "[1400]\ttraining's rmse: 3.26588\tvalid_1's rmse: 3.64835\n",
      "Early stopping, best iteration is:\n",
      "[811]\ttraining's rmse: 3.37028\tvalid_1's rmse: 3.64424\n",
      "fold 4 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64791\tvalid_1's rmse: 3.70828\n",
      "[200]\ttraining's rmse: 3.56066\tvalid_1's rmse: 3.67469\n",
      "[300]\ttraining's rmse: 3.50878\tvalid_1's rmse: 3.6637\n",
      "[400]\ttraining's rmse: 3.47\tvalid_1's rmse: 3.65771\n",
      "[500]\ttraining's rmse: 3.43866\tvalid_1's rmse: 3.65378\n",
      "[600]\ttraining's rmse: 3.41148\tvalid_1's rmse: 3.65138\n",
      "[700]\ttraining's rmse: 3.38875\tvalid_1's rmse: 3.65126\n",
      "[800]\ttraining's rmse: 3.36822\tvalid_1's rmse: 3.65129\n",
      "[900]\ttraining's rmse: 3.34858\tvalid_1's rmse: 3.6505\n",
      "[1000]\ttraining's rmse: 3.32957\tvalid_1's rmse: 3.65011\n",
      "[1100]\ttraining's rmse: 3.31158\tvalid_1's rmse: 3.64979\n",
      "[1200]\ttraining's rmse: 3.2932\tvalid_1's rmse: 3.65016\n",
      "[1300]\ttraining's rmse: 3.27665\tvalid_1's rmse: 3.65012\n",
      "[1400]\ttraining's rmse: 3.25959\tvalid_1's rmse: 3.65056\n",
      "[1500]\ttraining's rmse: 3.24488\tvalid_1's rmse: 3.65065\n",
      "[1600]\ttraining's rmse: 3.22991\tvalid_1's rmse: 3.65049\n",
      "[1700]\ttraining's rmse: 3.21521\tvalid_1's rmse: 3.65025\n",
      "Early stopping, best iteration is:\n",
      "[1165]\ttraining's rmse: 3.30026\tvalid_1's rmse: 3.64958\n",
      "fold 5 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65202\tvalid_1's rmse: 3.69678\n",
      "[200]\ttraining's rmse: 3.56751\tvalid_1's rmse: 3.65582\n",
      "[300]\ttraining's rmse: 3.51659\tvalid_1's rmse: 3.63816\n",
      "[400]\ttraining's rmse: 3.47801\tvalid_1's rmse: 3.62967\n",
      "[500]\ttraining's rmse: 3.4457\tvalid_1's rmse: 3.62343\n",
      "[600]\ttraining's rmse: 3.41825\tvalid_1's rmse: 3.61977\n",
      "[700]\ttraining's rmse: 3.39473\tvalid_1's rmse: 3.61801\n",
      "[800]\ttraining's rmse: 3.37393\tvalid_1's rmse: 3.61779\n",
      "[900]\ttraining's rmse: 3.35346\tvalid_1's rmse: 3.61796\n",
      "[1000]\ttraining's rmse: 3.33391\tvalid_1's rmse: 3.61722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\ttraining's rmse: 3.31541\tvalid_1's rmse: 3.61746\n",
      "[1200]\ttraining's rmse: 3.29781\tvalid_1's rmse: 3.61786\n",
      "[1300]\ttraining's rmse: 3.28012\tvalid_1's rmse: 3.61786\n",
      "[1400]\ttraining's rmse: 3.26343\tvalid_1's rmse: 3.61785\n",
      "[1500]\ttraining's rmse: 3.24728\tvalid_1's rmse: 3.61853\n",
      "Early stopping, best iteration is:\n",
      "[984]\ttraining's rmse: 3.33671\tvalid_1's rmse: 3.61698\n",
      "fold 6 1546 0.010938008518345574\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64376\tvalid_1's rmse: 3.73262\n",
      "[200]\ttraining's rmse: 3.55771\tvalid_1's rmse: 3.70389\n",
      "[300]\ttraining's rmse: 3.50673\tvalid_1's rmse: 3.69221\n",
      "[400]\ttraining's rmse: 3.46927\tvalid_1's rmse: 3.68614\n",
      "[500]\ttraining's rmse: 3.43878\tvalid_1's rmse: 3.68169\n",
      "[600]\ttraining's rmse: 3.41234\tvalid_1's rmse: 3.67802\n",
      "[700]\ttraining's rmse: 3.38873\tvalid_1's rmse: 3.67577\n",
      "[800]\ttraining's rmse: 3.36694\tvalid_1's rmse: 3.67359\n",
      "[900]\ttraining's rmse: 3.3464\tvalid_1's rmse: 3.67217\n",
      "[1000]\ttraining's rmse: 3.3273\tvalid_1's rmse: 3.67072\n",
      "[1100]\ttraining's rmse: 3.31003\tvalid_1's rmse: 3.66975\n",
      "[1200]\ttraining's rmse: 3.29342\tvalid_1's rmse: 3.66905\n",
      "[1300]\ttraining's rmse: 3.27635\tvalid_1's rmse: 3.66931\n",
      "[1400]\ttraining's rmse: 3.26016\tvalid_1's rmse: 3.66976\n",
      "[1500]\ttraining's rmse: 3.24489\tvalid_1's rmse: 3.66912\n",
      "[1600]\ttraining's rmse: 3.22873\tvalid_1's rmse: 3.66937\n",
      "[1700]\ttraining's rmse: 3.21206\tvalid_1's rmse: 3.66928\n",
      "[1800]\ttraining's rmse: 3.19693\tvalid_1's rmse: 3.66954\n",
      "[1900]\ttraining's rmse: 3.18114\tvalid_1's rmse: 3.6688\n",
      "[2000]\ttraining's rmse: 3.16656\tvalid_1's rmse: 3.66865\n",
      "[2100]\ttraining's rmse: 3.15243\tvalid_1's rmse: 3.66817\n",
      "[2200]\ttraining's rmse: 3.13922\tvalid_1's rmse: 3.6683\n",
      "[2300]\ttraining's rmse: 3.12524\tvalid_1's rmse: 3.66878\n",
      "[2400]\ttraining's rmse: 3.11171\tvalid_1's rmse: 3.66918\n",
      "[2500]\ttraining's rmse: 3.0984\tvalid_1's rmse: 3.66929\n",
      "[2600]\ttraining's rmse: 3.08573\tvalid_1's rmse: 3.6699\n",
      "Early stopping, best iteration is:\n",
      "[2080]\ttraining's rmse: 3.15531\tvalid_1's rmse: 3.66793\n",
      "fold 7 1546 0.010937931132068797\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6448\tvalid_1's rmse: 3.71542\n",
      "[200]\ttraining's rmse: 3.55768\tvalid_1's rmse: 3.69172\n",
      "[300]\ttraining's rmse: 3.50566\tvalid_1's rmse: 3.68542\n",
      "[400]\ttraining's rmse: 3.46813\tvalid_1's rmse: 3.68344\n",
      "[500]\ttraining's rmse: 3.43648\tvalid_1's rmse: 3.68259\n",
      "[600]\ttraining's rmse: 3.40927\tvalid_1's rmse: 3.68241\n",
      "[700]\ttraining's rmse: 3.38471\tvalid_1's rmse: 3.68296\n",
      "[800]\ttraining's rmse: 3.36306\tvalid_1's rmse: 3.68412\n",
      "[900]\ttraining's rmse: 3.34311\tvalid_1's rmse: 3.68457\n",
      "[1000]\ttraining's rmse: 3.32502\tvalid_1's rmse: 3.68441\n",
      "[1100]\ttraining's rmse: 3.30673\tvalid_1's rmse: 3.6847\n",
      "Early stopping, best iteration is:\n",
      "[538]\ttraining's rmse: 3.42563\tvalid_1's rmse: 3.68214\n",
      "fold 0 1569 0.010927401381769557\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6378\tvalid_1's rmse: 3.71339\n",
      "[200]\ttraining's rmse: 3.54111\tvalid_1's rmse: 3.68753\n",
      "[300]\ttraining's rmse: 3.48313\tvalid_1's rmse: 3.67641\n",
      "[400]\ttraining's rmse: 3.43869\tvalid_1's rmse: 3.67122\n",
      "[500]\ttraining's rmse: 3.40398\tvalid_1's rmse: 3.66766\n",
      "[600]\ttraining's rmse: 3.37332\tvalid_1's rmse: 3.66579\n",
      "[700]\ttraining's rmse: 3.34603\tvalid_1's rmse: 3.66396\n",
      "[800]\ttraining's rmse: 3.32067\tvalid_1's rmse: 3.66277\n",
      "[900]\ttraining's rmse: 3.29618\tvalid_1's rmse: 3.66162\n",
      "[1000]\ttraining's rmse: 3.27519\tvalid_1's rmse: 3.6606\n",
      "[1100]\ttraining's rmse: 3.25454\tvalid_1's rmse: 3.65964\n",
      "[1200]\ttraining's rmse: 3.23502\tvalid_1's rmse: 3.65962\n",
      "[1300]\ttraining's rmse: 3.2164\tvalid_1's rmse: 3.65941\n",
      "[1400]\ttraining's rmse: 3.19802\tvalid_1's rmse: 3.65893\n",
      "[1500]\ttraining's rmse: 3.17892\tvalid_1's rmse: 3.65899\n",
      "[1600]\ttraining's rmse: 3.16162\tvalid_1's rmse: 3.65921\n",
      "[1700]\ttraining's rmse: 3.14469\tvalid_1's rmse: 3.65937\n",
      "[1800]\ttraining's rmse: 3.12728\tvalid_1's rmse: 3.65956\n",
      "[1900]\ttraining's rmse: 3.11144\tvalid_1's rmse: 3.65957\n",
      "Early stopping, best iteration is:\n",
      "[1390]\ttraining's rmse: 3.20005\tvalid_1's rmse: 3.65877\n",
      "fold 1 1569 0.010927401381769557\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63716\tvalid_1's rmse: 3.71564\n",
      "[200]\ttraining's rmse: 3.53926\tvalid_1's rmse: 3.68189\n",
      "[300]\ttraining's rmse: 3.48339\tvalid_1's rmse: 3.66939\n",
      "[400]\ttraining's rmse: 3.44027\tvalid_1's rmse: 3.66162\n",
      "[500]\ttraining's rmse: 3.40461\tvalid_1's rmse: 3.65789\n",
      "[600]\ttraining's rmse: 3.37383\tvalid_1's rmse: 3.65562\n",
      "[700]\ttraining's rmse: 3.34647\tvalid_1's rmse: 3.65494\n",
      "[800]\ttraining's rmse: 3.3214\tvalid_1's rmse: 3.65432\n",
      "[900]\ttraining's rmse: 3.29899\tvalid_1's rmse: 3.65326\n",
      "[1000]\ttraining's rmse: 3.27703\tvalid_1's rmse: 3.65289\n",
      "[1100]\ttraining's rmse: 3.25663\tvalid_1's rmse: 3.65293\n",
      "[1200]\ttraining's rmse: 3.23645\tvalid_1's rmse: 3.65371\n",
      "[1300]\ttraining's rmse: 3.21801\tvalid_1's rmse: 3.65402\n",
      "[1400]\ttraining's rmse: 3.19883\tvalid_1's rmse: 3.65434\n",
      "[1500]\ttraining's rmse: 3.18124\tvalid_1's rmse: 3.65501\n",
      "[1600]\ttraining's rmse: 3.16216\tvalid_1's rmse: 3.65539\n",
      "Early stopping, best iteration is:\n",
      "[1011]\ttraining's rmse: 3.27462\tvalid_1's rmse: 3.65257\n",
      "fold 2 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63618\tvalid_1's rmse: 3.7165\n",
      "[200]\ttraining's rmse: 3.53984\tvalid_1's rmse: 3.68454\n",
      "[300]\ttraining's rmse: 3.48102\tvalid_1's rmse: 3.67367\n",
      "[400]\ttraining's rmse: 3.43741\tvalid_1's rmse: 3.66813\n",
      "[500]\ttraining's rmse: 3.40207\tvalid_1's rmse: 3.66376\n",
      "[600]\ttraining's rmse: 3.37276\tvalid_1's rmse: 3.66113\n",
      "[700]\ttraining's rmse: 3.3448\tvalid_1's rmse: 3.65993\n",
      "[800]\ttraining's rmse: 3.31782\tvalid_1's rmse: 3.65972\n",
      "[900]\ttraining's rmse: 3.29456\tvalid_1's rmse: 3.65905\n",
      "[1000]\ttraining's rmse: 3.27274\tvalid_1's rmse: 3.65901\n",
      "[1100]\ttraining's rmse: 3.25279\tvalid_1's rmse: 3.65899\n",
      "[1200]\ttraining's rmse: 3.2329\tvalid_1's rmse: 3.6587\n",
      "[1300]\ttraining's rmse: 3.2141\tvalid_1's rmse: 3.65961\n",
      "[1400]\ttraining's rmse: 3.1954\tvalid_1's rmse: 3.65902\n",
      "[1500]\ttraining's rmse: 3.177\tvalid_1's rmse: 3.65962\n",
      "[1600]\ttraining's rmse: 3.15922\tvalid_1's rmse: 3.65997\n",
      "[1700]\ttraining's rmse: 3.14161\tvalid_1's rmse: 3.65972\n",
      "Early stopping, best iteration is:\n",
      "[1181]\ttraining's rmse: 3.23676\tvalid_1's rmse: 3.65854\n",
      "fold 3 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64335\tvalid_1's rmse: 3.68478\n",
      "[200]\ttraining's rmse: 3.54939\tvalid_1's rmse: 3.64145\n",
      "[300]\ttraining's rmse: 3.49219\tvalid_1's rmse: 3.62569\n",
      "[400]\ttraining's rmse: 3.44825\tvalid_1's rmse: 3.61752\n",
      "[500]\ttraining's rmse: 3.41284\tvalid_1's rmse: 3.6112\n",
      "[600]\ttraining's rmse: 3.38337\tvalid_1's rmse: 3.60709\n",
      "[700]\ttraining's rmse: 3.35657\tvalid_1's rmse: 3.60423\n",
      "[800]\ttraining's rmse: 3.33047\tvalid_1's rmse: 3.60358\n",
      "[900]\ttraining's rmse: 3.30819\tvalid_1's rmse: 3.60241\n",
      "[1000]\ttraining's rmse: 3.28569\tvalid_1's rmse: 3.60263\n",
      "[1100]\ttraining's rmse: 3.2644\tvalid_1's rmse: 3.6031\n",
      "[1200]\ttraining's rmse: 3.24292\tvalid_1's rmse: 3.60398\n",
      "[1300]\ttraining's rmse: 3.22323\tvalid_1's rmse: 3.60389\n",
      "[1400]\ttraining's rmse: 3.20514\tvalid_1's rmse: 3.60402\n",
      "[1500]\ttraining's rmse: 3.18663\tvalid_1's rmse: 3.60423\n",
      "Early stopping, best iteration is:\n",
      "[928]\ttraining's rmse: 3.3021\tvalid_1's rmse: 3.60223\n",
      "fold 4 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63648\tvalid_1's rmse: 3.70764\n",
      "[200]\ttraining's rmse: 3.53991\tvalid_1's rmse: 3.67694\n",
      "[300]\ttraining's rmse: 3.48159\tvalid_1's rmse: 3.66611\n",
      "[400]\ttraining's rmse: 3.43761\tvalid_1's rmse: 3.65954\n",
      "[500]\ttraining's rmse: 3.40247\tvalid_1's rmse: 3.65621\n",
      "[600]\ttraining's rmse: 3.37271\tvalid_1's rmse: 3.65449\n",
      "[700]\ttraining's rmse: 3.34587\tvalid_1's rmse: 3.65341\n",
      "[800]\ttraining's rmse: 3.31978\tvalid_1's rmse: 3.65361\n",
      "[900]\ttraining's rmse: 3.29672\tvalid_1's rmse: 3.65338\n",
      "[1000]\ttraining's rmse: 3.27344\tvalid_1's rmse: 3.65321\n",
      "[1100]\ttraining's rmse: 3.25122\tvalid_1's rmse: 3.65378\n",
      "[1200]\ttraining's rmse: 3.23094\tvalid_1's rmse: 3.65386\n",
      "[1300]\ttraining's rmse: 3.21217\tvalid_1's rmse: 3.65402\n",
      "Early stopping, best iteration is:\n",
      "[719]\ttraining's rmse: 3.34021\tvalid_1's rmse: 3.65307\n",
      "fold 5 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 3.63579\tvalid_1's rmse: 3.72087\n",
      "[200]\ttraining's rmse: 3.53681\tvalid_1's rmse: 3.69314\n",
      "[300]\ttraining's rmse: 3.47842\tvalid_1's rmse: 3.68146\n",
      "[400]\ttraining's rmse: 3.43332\tvalid_1's rmse: 3.6742\n",
      "[500]\ttraining's rmse: 3.39661\tvalid_1's rmse: 3.67076\n",
      "[600]\ttraining's rmse: 3.36485\tvalid_1's rmse: 3.66847\n",
      "[700]\ttraining's rmse: 3.33751\tvalid_1's rmse: 3.66721\n",
      "[800]\ttraining's rmse: 3.31155\tvalid_1's rmse: 3.6671\n",
      "[900]\ttraining's rmse: 3.2881\tvalid_1's rmse: 3.6676\n",
      "[1000]\ttraining's rmse: 3.26604\tvalid_1's rmse: 3.66748\n",
      "[1100]\ttraining's rmse: 3.24554\tvalid_1's rmse: 3.66703\n",
      "[1200]\ttraining's rmse: 3.22353\tvalid_1's rmse: 3.66683\n",
      "[1300]\ttraining's rmse: 3.20367\tvalid_1's rmse: 3.66557\n",
      "[1400]\ttraining's rmse: 3.18412\tvalid_1's rmse: 3.66519\n",
      "[1500]\ttraining's rmse: 3.16487\tvalid_1's rmse: 3.66477\n",
      "[1600]\ttraining's rmse: 3.14659\tvalid_1's rmse: 3.6658\n",
      "[1700]\ttraining's rmse: 3.12777\tvalid_1's rmse: 3.66579\n",
      "[1800]\ttraining's rmse: 3.11005\tvalid_1's rmse: 3.66601\n",
      "[1900]\ttraining's rmse: 3.09225\tvalid_1's rmse: 3.6662\n",
      "[2000]\ttraining's rmse: 3.07548\tvalid_1's rmse: 3.66734\n",
      "Early stopping, best iteration is:\n",
      "[1496]\ttraining's rmse: 3.16555\tvalid_1's rmse: 3.66464\n",
      "fold 6 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63832\tvalid_1's rmse: 3.71549\n",
      "[200]\ttraining's rmse: 3.5427\tvalid_1's rmse: 3.67227\n",
      "[300]\ttraining's rmse: 3.48363\tvalid_1's rmse: 3.65454\n",
      "[400]\ttraining's rmse: 3.43837\tvalid_1's rmse: 3.64589\n",
      "[500]\ttraining's rmse: 3.40201\tvalid_1's rmse: 3.63977\n",
      "[600]\ttraining's rmse: 3.3715\tvalid_1's rmse: 3.63598\n",
      "[700]\ttraining's rmse: 3.34457\tvalid_1's rmse: 3.63258\n",
      "[800]\ttraining's rmse: 3.31825\tvalid_1's rmse: 3.62959\n",
      "[900]\ttraining's rmse: 3.29525\tvalid_1's rmse: 3.62742\n",
      "[1000]\ttraining's rmse: 3.27379\tvalid_1's rmse: 3.62657\n",
      "[1100]\ttraining's rmse: 3.25209\tvalid_1's rmse: 3.62518\n",
      "[1200]\ttraining's rmse: 3.23258\tvalid_1's rmse: 3.6244\n",
      "[1300]\ttraining's rmse: 3.21246\tvalid_1's rmse: 3.62375\n",
      "[1400]\ttraining's rmse: 3.1927\tvalid_1's rmse: 3.62322\n",
      "[1500]\ttraining's rmse: 3.17383\tvalid_1's rmse: 3.62279\n",
      "[1600]\ttraining's rmse: 3.15669\tvalid_1's rmse: 3.62315\n",
      "[1700]\ttraining's rmse: 3.13822\tvalid_1's rmse: 3.62303\n",
      "[1800]\ttraining's rmse: 3.12015\tvalid_1's rmse: 3.62326\n",
      "[1900]\ttraining's rmse: 3.10302\tvalid_1's rmse: 3.62319\n",
      "[2000]\ttraining's rmse: 3.08515\tvalid_1's rmse: 3.62267\n",
      "[2100]\ttraining's rmse: 3.06911\tvalid_1's rmse: 3.62225\n",
      "[2200]\ttraining's rmse: 3.05233\tvalid_1's rmse: 3.62257\n",
      "[2300]\ttraining's rmse: 3.03642\tvalid_1's rmse: 3.62263\n",
      "[2400]\ttraining's rmse: 3.01956\tvalid_1's rmse: 3.62323\n",
      "[2500]\ttraining's rmse: 3.00471\tvalid_1's rmse: 3.62297\n",
      "[2600]\ttraining's rmse: 2.98965\tvalid_1's rmse: 3.62311\n",
      "Early stopping, best iteration is:\n",
      "[2059]\ttraining's rmse: 3.07544\tvalid_1's rmse: 3.62196\n",
      "fold 7 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63255\tvalid_1's rmse: 3.7352\n",
      "[200]\ttraining's rmse: 3.53483\tvalid_1's rmse: 3.70574\n",
      "[300]\ttraining's rmse: 3.4774\tvalid_1's rmse: 3.6941\n",
      "[400]\ttraining's rmse: 3.43434\tvalid_1's rmse: 3.68698\n",
      "[500]\ttraining's rmse: 3.39928\tvalid_1's rmse: 3.68241\n",
      "[600]\ttraining's rmse: 3.3676\tvalid_1's rmse: 3.67853\n",
      "[700]\ttraining's rmse: 3.33889\tvalid_1's rmse: 3.67554\n",
      "[800]\ttraining's rmse: 3.31452\tvalid_1's rmse: 3.67484\n",
      "[900]\ttraining's rmse: 3.29218\tvalid_1's rmse: 3.67402\n",
      "[1000]\ttraining's rmse: 3.27086\tvalid_1's rmse: 3.6732\n",
      "[1100]\ttraining's rmse: 3.24975\tvalid_1's rmse: 3.67302\n",
      "[1200]\ttraining's rmse: 3.23017\tvalid_1's rmse: 3.67244\n",
      "[1300]\ttraining's rmse: 3.21034\tvalid_1's rmse: 3.671\n",
      "[1400]\ttraining's rmse: 3.19052\tvalid_1's rmse: 3.67072\n",
      "[1500]\ttraining's rmse: 3.17249\tvalid_1's rmse: 3.66984\n",
      "[1600]\ttraining's rmse: 3.15483\tvalid_1's rmse: 3.66982\n",
      "[1700]\ttraining's rmse: 3.13676\tvalid_1's rmse: 3.66956\n",
      "[1800]\ttraining's rmse: 3.11892\tvalid_1's rmse: 3.67004\n",
      "[1900]\ttraining's rmse: 3.1013\tvalid_1's rmse: 3.67051\n",
      "[2000]\ttraining's rmse: 3.08403\tvalid_1's rmse: 3.66987\n",
      "[2100]\ttraining's rmse: 3.0679\tvalid_1's rmse: 3.67037\n",
      "[2200]\ttraining's rmse: 3.05094\tvalid_1's rmse: 3.6707\n",
      "Early stopping, best iteration is:\n",
      "[1651]\ttraining's rmse: 3.14564\tvalid_1's rmse: 3.6693\n",
      "fold 8 1570 0.010934213641998524\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63312\tvalid_1's rmse: 3.72022\n",
      "[200]\ttraining's rmse: 3.53557\tvalid_1's rmse: 3.70075\n",
      "[300]\ttraining's rmse: 3.47628\tvalid_1's rmse: 3.69762\n",
      "[400]\ttraining's rmse: 3.43036\tvalid_1's rmse: 3.69536\n",
      "[500]\ttraining's rmse: 3.39414\tvalid_1's rmse: 3.69359\n",
      "[600]\ttraining's rmse: 3.36172\tvalid_1's rmse: 3.69315\n",
      "[700]\ttraining's rmse: 3.33304\tvalid_1's rmse: 3.69328\n",
      "[800]\ttraining's rmse: 3.30668\tvalid_1's rmse: 3.69312\n",
      "[900]\ttraining's rmse: 3.28314\tvalid_1's rmse: 3.69371\n",
      "[1000]\ttraining's rmse: 3.26116\tvalid_1's rmse: 3.69325\n",
      "[1100]\ttraining's rmse: 3.24068\tvalid_1's rmse: 3.69298\n",
      "[1200]\ttraining's rmse: 3.22225\tvalid_1's rmse: 3.69291\n",
      "[1300]\ttraining's rmse: 3.20424\tvalid_1's rmse: 3.69365\n",
      "Early stopping, best iteration is:\n",
      "[755]\ttraining's rmse: 3.31881\tvalid_1's rmse: 3.69254\n",
      "fold 0 1569 0.010927401381769557\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64284\tvalid_1's rmse: 3.7096\n",
      "[200]\ttraining's rmse: 3.55077\tvalid_1's rmse: 3.68117\n",
      "[300]\ttraining's rmse: 3.4961\tvalid_1's rmse: 3.66936\n",
      "[400]\ttraining's rmse: 3.45471\tvalid_1's rmse: 3.6632\n",
      "[500]\ttraining's rmse: 3.42112\tvalid_1's rmse: 3.65928\n",
      "[600]\ttraining's rmse: 3.39223\tvalid_1's rmse: 3.65691\n",
      "[700]\ttraining's rmse: 3.36594\tvalid_1's rmse: 3.65526\n",
      "[800]\ttraining's rmse: 3.34154\tvalid_1's rmse: 3.65304\n",
      "[900]\ttraining's rmse: 3.31897\tvalid_1's rmse: 3.65095\n",
      "[1000]\ttraining's rmse: 3.2996\tvalid_1's rmse: 3.64978\n",
      "[1100]\ttraining's rmse: 3.27891\tvalid_1's rmse: 3.6496\n",
      "[1200]\ttraining's rmse: 3.26032\tvalid_1's rmse: 3.64898\n",
      "[1300]\ttraining's rmse: 3.24181\tvalid_1's rmse: 3.64839\n",
      "[1400]\ttraining's rmse: 3.22492\tvalid_1's rmse: 3.64819\n",
      "[1500]\ttraining's rmse: 3.20783\tvalid_1's rmse: 3.64827\n",
      "[1600]\ttraining's rmse: 3.19099\tvalid_1's rmse: 3.6489\n",
      "[1700]\ttraining's rmse: 3.17417\tvalid_1's rmse: 3.64857\n",
      "[1800]\ttraining's rmse: 3.15874\tvalid_1's rmse: 3.64775\n",
      "[1900]\ttraining's rmse: 3.14237\tvalid_1's rmse: 3.64853\n",
      "[2000]\ttraining's rmse: 3.12649\tvalid_1's rmse: 3.64921\n",
      "[2100]\ttraining's rmse: 3.11127\tvalid_1's rmse: 3.64939\n",
      "[2200]\ttraining's rmse: 3.09648\tvalid_1's rmse: 3.64924\n",
      "[2300]\ttraining's rmse: 3.08206\tvalid_1's rmse: 3.64966\n",
      "Early stopping, best iteration is:\n",
      "[1747]\ttraining's rmse: 3.16675\tvalid_1's rmse: 3.64752\n",
      "fold 1 1569 0.010927401381769557\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64307\tvalid_1's rmse: 3.7088\n",
      "[200]\ttraining's rmse: 3.5506\tvalid_1's rmse: 3.67477\n",
      "[300]\ttraining's rmse: 3.4951\tvalid_1's rmse: 3.66046\n",
      "[400]\ttraining's rmse: 3.4536\tvalid_1's rmse: 3.65355\n",
      "[500]\ttraining's rmse: 3.4179\tvalid_1's rmse: 3.64931\n",
      "[600]\ttraining's rmse: 3.38859\tvalid_1's rmse: 3.64696\n",
      "[700]\ttraining's rmse: 3.36425\tvalid_1's rmse: 3.64624\n",
      "[800]\ttraining's rmse: 3.3417\tvalid_1's rmse: 3.64485\n",
      "[900]\ttraining's rmse: 3.32039\tvalid_1's rmse: 3.64387\n",
      "[1000]\ttraining's rmse: 3.29978\tvalid_1's rmse: 3.64363\n",
      "[1100]\ttraining's rmse: 3.28048\tvalid_1's rmse: 3.64344\n",
      "[1200]\ttraining's rmse: 3.26107\tvalid_1's rmse: 3.6441\n",
      "[1300]\ttraining's rmse: 3.24282\tvalid_1's rmse: 3.64387\n",
      "[1400]\ttraining's rmse: 3.22497\tvalid_1's rmse: 3.64376\n",
      "[1500]\ttraining's rmse: 3.20718\tvalid_1's rmse: 3.6436\n",
      "[1600]\ttraining's rmse: 3.18992\tvalid_1's rmse: 3.64437\n",
      "Early stopping, best iteration is:\n",
      "[1022]\ttraining's rmse: 3.29538\tvalid_1's rmse: 3.64301\n",
      "fold 2 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64041\tvalid_1's rmse: 3.71675\n",
      "[200]\ttraining's rmse: 3.54782\tvalid_1's rmse: 3.68129\n",
      "[300]\ttraining's rmse: 3.49188\tvalid_1's rmse: 3.66906\n",
      "[400]\ttraining's rmse: 3.45158\tvalid_1's rmse: 3.6627\n",
      "[500]\ttraining's rmse: 3.41878\tvalid_1's rmse: 3.65844\n",
      "[600]\ttraining's rmse: 3.38988\tvalid_1's rmse: 3.65571\n",
      "[700]\ttraining's rmse: 3.3657\tvalid_1's rmse: 3.65499\n",
      "[800]\ttraining's rmse: 3.34163\tvalid_1's rmse: 3.65361\n",
      "[900]\ttraining's rmse: 3.32044\tvalid_1's rmse: 3.6529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.3007\tvalid_1's rmse: 3.6524\n",
      "[1100]\ttraining's rmse: 3.28114\tvalid_1's rmse: 3.65198\n",
      "[1200]\ttraining's rmse: 3.26183\tvalid_1's rmse: 3.65177\n",
      "[1300]\ttraining's rmse: 3.24449\tvalid_1's rmse: 3.65201\n",
      "[1400]\ttraining's rmse: 3.22661\tvalid_1's rmse: 3.65186\n",
      "[1500]\ttraining's rmse: 3.20974\tvalid_1's rmse: 3.65167\n",
      "[1600]\ttraining's rmse: 3.19247\tvalid_1's rmse: 3.65163\n",
      "[1700]\ttraining's rmse: 3.17524\tvalid_1's rmse: 3.65151\n",
      "[1800]\ttraining's rmse: 3.15892\tvalid_1's rmse: 3.65101\n",
      "[1900]\ttraining's rmse: 3.14249\tvalid_1's rmse: 3.65073\n",
      "[2000]\ttraining's rmse: 3.12701\tvalid_1's rmse: 3.6509\n",
      "[2100]\ttraining's rmse: 3.10967\tvalid_1's rmse: 3.651\n",
      "[2200]\ttraining's rmse: 3.09379\tvalid_1's rmse: 3.65126\n",
      "[2300]\ttraining's rmse: 3.07862\tvalid_1's rmse: 3.65153\n",
      "[2400]\ttraining's rmse: 3.06475\tvalid_1's rmse: 3.65154\n",
      "[2500]\ttraining's rmse: 3.05082\tvalid_1's rmse: 3.65198\n",
      "[2600]\ttraining's rmse: 3.0362\tvalid_1's rmse: 3.65201\n",
      "Early stopping, best iteration is:\n",
      "[2015]\ttraining's rmse: 3.12408\tvalid_1's rmse: 3.65059\n",
      "fold 3 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64894\tvalid_1's rmse: 3.68278\n",
      "[200]\ttraining's rmse: 3.55865\tvalid_1's rmse: 3.63744\n",
      "[300]\ttraining's rmse: 3.50373\tvalid_1's rmse: 3.62175\n",
      "[400]\ttraining's rmse: 3.46209\tvalid_1's rmse: 3.61047\n",
      "[500]\ttraining's rmse: 3.42963\tvalid_1's rmse: 3.60538\n",
      "[600]\ttraining's rmse: 3.40091\tvalid_1's rmse: 3.60161\n",
      "[700]\ttraining's rmse: 3.37474\tvalid_1's rmse: 3.59904\n",
      "[800]\ttraining's rmse: 3.35127\tvalid_1's rmse: 3.5982\n",
      "[900]\ttraining's rmse: 3.32827\tvalid_1's rmse: 3.59757\n",
      "[1000]\ttraining's rmse: 3.30664\tvalid_1's rmse: 3.59705\n",
      "[1100]\ttraining's rmse: 3.28629\tvalid_1's rmse: 3.59704\n",
      "[1200]\ttraining's rmse: 3.26677\tvalid_1's rmse: 3.59729\n",
      "[1300]\ttraining's rmse: 3.24762\tvalid_1's rmse: 3.59743\n",
      "[1400]\ttraining's rmse: 3.23055\tvalid_1's rmse: 3.59737\n",
      "[1500]\ttraining's rmse: 3.2138\tvalid_1's rmse: 3.59678\n",
      "[1600]\ttraining's rmse: 3.19589\tvalid_1's rmse: 3.59715\n",
      "Early stopping, best iteration is:\n",
      "[1054]\ttraining's rmse: 3.29557\tvalid_1's rmse: 3.59662\n",
      "fold 4 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64069\tvalid_1's rmse: 3.7043\n",
      "[200]\ttraining's rmse: 3.54778\tvalid_1's rmse: 3.67429\n",
      "[300]\ttraining's rmse: 3.49287\tvalid_1's rmse: 3.6634\n",
      "[400]\ttraining's rmse: 3.45095\tvalid_1's rmse: 3.65934\n",
      "[500]\ttraining's rmse: 3.41751\tvalid_1's rmse: 3.65694\n",
      "[600]\ttraining's rmse: 3.3884\tvalid_1's rmse: 3.65474\n",
      "[700]\ttraining's rmse: 3.36327\tvalid_1's rmse: 3.65469\n",
      "[800]\ttraining's rmse: 3.34005\tvalid_1's rmse: 3.65463\n",
      "[900]\ttraining's rmse: 3.3183\tvalid_1's rmse: 3.65499\n",
      "[1000]\ttraining's rmse: 3.29625\tvalid_1's rmse: 3.65552\n",
      "[1100]\ttraining's rmse: 3.27584\tvalid_1's rmse: 3.65542\n",
      "[1200]\ttraining's rmse: 3.25709\tvalid_1's rmse: 3.6553\n",
      "[1300]\ttraining's rmse: 3.23961\tvalid_1's rmse: 3.65556\n",
      "Early stopping, best iteration is:\n",
      "[784]\ttraining's rmse: 3.34403\tvalid_1's rmse: 3.65427\n",
      "fold 5 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63968\tvalid_1's rmse: 3.7182\n",
      "[200]\ttraining's rmse: 3.54651\tvalid_1's rmse: 3.68807\n",
      "[300]\ttraining's rmse: 3.49111\tvalid_1's rmse: 3.67554\n",
      "[400]\ttraining's rmse: 3.44956\tvalid_1's rmse: 3.66924\n",
      "[500]\ttraining's rmse: 3.41577\tvalid_1's rmse: 3.66537\n",
      "[600]\ttraining's rmse: 3.38568\tvalid_1's rmse: 3.6634\n",
      "[700]\ttraining's rmse: 3.35982\tvalid_1's rmse: 3.66196\n",
      "[800]\ttraining's rmse: 3.33517\tvalid_1's rmse: 3.6604\n",
      "[900]\ttraining's rmse: 3.3122\tvalid_1's rmse: 3.66088\n",
      "[1000]\ttraining's rmse: 3.29124\tvalid_1's rmse: 3.6609\n",
      "[1100]\ttraining's rmse: 3.27143\tvalid_1's rmse: 3.66061\n",
      "[1200]\ttraining's rmse: 3.25201\tvalid_1's rmse: 3.6604\n",
      "[1300]\ttraining's rmse: 3.23273\tvalid_1's rmse: 3.65969\n",
      "[1400]\ttraining's rmse: 3.21532\tvalid_1's rmse: 3.65974\n",
      "[1500]\ttraining's rmse: 3.19739\tvalid_1's rmse: 3.65963\n",
      "[1600]\ttraining's rmse: 3.18056\tvalid_1's rmse: 3.65862\n",
      "[1700]\ttraining's rmse: 3.16416\tvalid_1's rmse: 3.65796\n",
      "[1800]\ttraining's rmse: 3.1477\tvalid_1's rmse: 3.65886\n",
      "[1900]\ttraining's rmse: 3.13222\tvalid_1's rmse: 3.65945\n",
      "[2000]\ttraining's rmse: 3.11685\tvalid_1's rmse: 3.65993\n",
      "[2100]\ttraining's rmse: 3.10199\tvalid_1's rmse: 3.65967\n",
      "[2200]\ttraining's rmse: 3.0884\tvalid_1's rmse: 3.65981\n",
      "Early stopping, best iteration is:\n",
      "[1690]\ttraining's rmse: 3.16582\tvalid_1's rmse: 3.65781\n",
      "fold 6 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64331\tvalid_1's rmse: 3.71215\n",
      "[200]\ttraining's rmse: 3.55212\tvalid_1's rmse: 3.6683\n",
      "[300]\ttraining's rmse: 3.49539\tvalid_1's rmse: 3.65185\n",
      "[400]\ttraining's rmse: 3.45296\tvalid_1's rmse: 3.64166\n",
      "[500]\ttraining's rmse: 3.41995\tvalid_1's rmse: 3.63608\n",
      "[600]\ttraining's rmse: 3.39026\tvalid_1's rmse: 3.63296\n",
      "[700]\ttraining's rmse: 3.36372\tvalid_1's rmse: 3.6309\n",
      "[800]\ttraining's rmse: 3.33961\tvalid_1's rmse: 3.62982\n",
      "[900]\ttraining's rmse: 3.31794\tvalid_1's rmse: 3.62871\n",
      "[1000]\ttraining's rmse: 3.29755\tvalid_1's rmse: 3.6281\n",
      "[1100]\ttraining's rmse: 3.27722\tvalid_1's rmse: 3.6267\n",
      "[1200]\ttraining's rmse: 3.25847\tvalid_1's rmse: 3.62584\n",
      "[1300]\ttraining's rmse: 3.2387\tvalid_1's rmse: 3.62558\n",
      "[1400]\ttraining's rmse: 3.22033\tvalid_1's rmse: 3.62575\n",
      "[1500]\ttraining's rmse: 3.20243\tvalid_1's rmse: 3.62505\n",
      "[1600]\ttraining's rmse: 3.18561\tvalid_1's rmse: 3.62566\n",
      "[1700]\ttraining's rmse: 3.16997\tvalid_1's rmse: 3.62558\n",
      "[1800]\ttraining's rmse: 3.15245\tvalid_1's rmse: 3.62588\n",
      "[1900]\ttraining's rmse: 3.1358\tvalid_1's rmse: 3.62689\n",
      "[2000]\ttraining's rmse: 3.11903\tvalid_1's rmse: 3.62688\n",
      "[2100]\ttraining's rmse: 3.10362\tvalid_1's rmse: 3.62679\n",
      "Early stopping, best iteration is:\n",
      "[1500]\ttraining's rmse: 3.20243\tvalid_1's rmse: 3.62505\n",
      "fold 7 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63734\tvalid_1's rmse: 3.73335\n",
      "[200]\ttraining's rmse: 3.54389\tvalid_1's rmse: 3.70316\n",
      "[300]\ttraining's rmse: 3.49006\tvalid_1's rmse: 3.69202\n",
      "[400]\ttraining's rmse: 3.44837\tvalid_1's rmse: 3.68375\n",
      "[500]\ttraining's rmse: 3.41536\tvalid_1's rmse: 3.67943\n",
      "[600]\ttraining's rmse: 3.38554\tvalid_1's rmse: 3.67571\n",
      "[700]\ttraining's rmse: 3.35953\tvalid_1's rmse: 3.67336\n",
      "[800]\ttraining's rmse: 3.33564\tvalid_1's rmse: 3.67193\n",
      "[900]\ttraining's rmse: 3.31325\tvalid_1's rmse: 3.67051\n",
      "[1000]\ttraining's rmse: 3.2921\tvalid_1's rmse: 3.66803\n",
      "[1100]\ttraining's rmse: 3.27232\tvalid_1's rmse: 3.66747\n",
      "[1200]\ttraining's rmse: 3.25257\tvalid_1's rmse: 3.66708\n",
      "[1300]\ttraining's rmse: 3.23439\tvalid_1's rmse: 3.66631\n",
      "[1400]\ttraining's rmse: 3.21616\tvalid_1's rmse: 3.66687\n",
      "[1500]\ttraining's rmse: 3.19869\tvalid_1's rmse: 3.66558\n",
      "[1600]\ttraining's rmse: 3.18258\tvalid_1's rmse: 3.66538\n",
      "[1700]\ttraining's rmse: 3.16582\tvalid_1's rmse: 3.66473\n",
      "[1800]\ttraining's rmse: 3.14904\tvalid_1's rmse: 3.66451\n",
      "[1900]\ttraining's rmse: 3.13207\tvalid_1's rmse: 3.66437\n",
      "[2000]\ttraining's rmse: 3.11651\tvalid_1's rmse: 3.66445\n",
      "[2100]\ttraining's rmse: 3.10126\tvalid_1's rmse: 3.66428\n",
      "[2200]\ttraining's rmse: 3.08639\tvalid_1's rmse: 3.66488\n",
      "[2300]\ttraining's rmse: 3.07027\tvalid_1's rmse: 3.66563\n",
      "[2400]\ttraining's rmse: 3.05594\tvalid_1's rmse: 3.66608\n",
      "[2500]\ttraining's rmse: 3.04055\tvalid_1's rmse: 3.6672\n",
      "Early stopping, best iteration is:\n",
      "[1924]\ttraining's rmse: 3.12842\tvalid_1's rmse: 3.66409\n",
      "fold 8 1570 0.010934213641998524\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63845\tvalid_1's rmse: 3.72139\n",
      "[200]\ttraining's rmse: 3.54504\tvalid_1's rmse: 3.70048\n",
      "[300]\ttraining's rmse: 3.48742\tvalid_1's rmse: 3.69597\n",
      "[400]\ttraining's rmse: 3.44513\tvalid_1's rmse: 3.69413\n",
      "[500]\ttraining's rmse: 3.41084\tvalid_1's rmse: 3.69212\n",
      "[600]\ttraining's rmse: 3.38175\tvalid_1's rmse: 3.69086\n",
      "[700]\ttraining's rmse: 3.35631\tvalid_1's rmse: 3.69104\n",
      "[800]\ttraining's rmse: 3.33207\tvalid_1's rmse: 3.69084\n",
      "[900]\ttraining's rmse: 3.30995\tvalid_1's rmse: 3.69125\n",
      "[1000]\ttraining's rmse: 3.28967\tvalid_1's rmse: 3.69118\n",
      "[1100]\ttraining's rmse: 3.27073\tvalid_1's rmse: 3.69115\n",
      "[1200]\ttraining's rmse: 3.2513\tvalid_1's rmse: 3.69193\n",
      "[1300]\ttraining's rmse: 3.23371\tvalid_1's rmse: 3.69186\n",
      "Early stopping, best iteration is:\n",
      "[773]\ttraining's rmse: 3.3387\tvalid_1's rmse: 3.69031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 1569 0.010927401381769557\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64743\tvalid_1's rmse: 3.70941\n",
      "[200]\ttraining's rmse: 3.55914\tvalid_1's rmse: 3.6811\n",
      "[300]\ttraining's rmse: 3.507\tvalid_1's rmse: 3.67051\n",
      "[400]\ttraining's rmse: 3.46988\tvalid_1's rmse: 3.6659\n",
      "[500]\ttraining's rmse: 3.43932\tvalid_1's rmse: 3.66285\n",
      "[600]\ttraining's rmse: 3.41275\tvalid_1's rmse: 3.66103\n",
      "[700]\ttraining's rmse: 3.38894\tvalid_1's rmse: 3.65895\n",
      "[800]\ttraining's rmse: 3.36772\tvalid_1's rmse: 3.65772\n",
      "[900]\ttraining's rmse: 3.34717\tvalid_1's rmse: 3.65649\n",
      "[1000]\ttraining's rmse: 3.32792\tvalid_1's rmse: 3.65598\n",
      "[1100]\ttraining's rmse: 3.30889\tvalid_1's rmse: 3.65622\n",
      "[1200]\ttraining's rmse: 3.29292\tvalid_1's rmse: 3.65628\n",
      "[1300]\ttraining's rmse: 3.27503\tvalid_1's rmse: 3.65617\n",
      "[1400]\ttraining's rmse: 3.25864\tvalid_1's rmse: 3.65621\n",
      "[1500]\ttraining's rmse: 3.24268\tvalid_1's rmse: 3.65507\n",
      "[1600]\ttraining's rmse: 3.22773\tvalid_1's rmse: 3.65461\n",
      "[1700]\ttraining's rmse: 3.21323\tvalid_1's rmse: 3.65498\n",
      "[1800]\ttraining's rmse: 3.19753\tvalid_1's rmse: 3.65531\n",
      "[1900]\ttraining's rmse: 3.18236\tvalid_1's rmse: 3.6556\n",
      "[2000]\ttraining's rmse: 3.16787\tvalid_1's rmse: 3.65518\n",
      "[2100]\ttraining's rmse: 3.15287\tvalid_1's rmse: 3.65509\n",
      "Early stopping, best iteration is:\n",
      "[1559]\ttraining's rmse: 3.23347\tvalid_1's rmse: 3.65428\n",
      "fold 1 1569 0.010927401381769557\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64795\tvalid_1's rmse: 3.70885\n",
      "[200]\ttraining's rmse: 3.55969\tvalid_1's rmse: 3.67287\n",
      "[300]\ttraining's rmse: 3.50753\tvalid_1's rmse: 3.65925\n",
      "[400]\ttraining's rmse: 3.46919\tvalid_1's rmse: 3.65463\n",
      "[500]\ttraining's rmse: 3.43769\tvalid_1's rmse: 3.65033\n",
      "[600]\ttraining's rmse: 3.41098\tvalid_1's rmse: 3.64765\n",
      "[700]\ttraining's rmse: 3.38777\tvalid_1's rmse: 3.64552\n",
      "[800]\ttraining's rmse: 3.36688\tvalid_1's rmse: 3.64456\n",
      "[900]\ttraining's rmse: 3.34706\tvalid_1's rmse: 3.6438\n",
      "[1000]\ttraining's rmse: 3.32803\tvalid_1's rmse: 3.64341\n",
      "[1100]\ttraining's rmse: 3.30929\tvalid_1's rmse: 3.64286\n",
      "[1200]\ttraining's rmse: 3.29209\tvalid_1's rmse: 3.64316\n",
      "[1300]\ttraining's rmse: 3.27527\tvalid_1's rmse: 3.64247\n",
      "[1400]\ttraining's rmse: 3.25874\tvalid_1's rmse: 3.64192\n",
      "[1500]\ttraining's rmse: 3.2425\tvalid_1's rmse: 3.64189\n",
      "[1600]\ttraining's rmse: 3.22608\tvalid_1's rmse: 3.64163\n",
      "[1700]\ttraining's rmse: 3.21048\tvalid_1's rmse: 3.64204\n",
      "[1800]\ttraining's rmse: 3.19484\tvalid_1's rmse: 3.64212\n",
      "[1900]\ttraining's rmse: 3.1808\tvalid_1's rmse: 3.64244\n",
      "[2000]\ttraining's rmse: 3.16527\tvalid_1's rmse: 3.64223\n",
      "[2100]\ttraining's rmse: 3.15058\tvalid_1's rmse: 3.64308\n",
      "Early stopping, best iteration is:\n",
      "[1590]\ttraining's rmse: 3.22785\tvalid_1's rmse: 3.6414\n",
      "fold 2 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64604\tvalid_1's rmse: 3.71599\n",
      "[200]\ttraining's rmse: 3.55868\tvalid_1's rmse: 3.68146\n",
      "[300]\ttraining's rmse: 3.50505\tvalid_1's rmse: 3.67012\n",
      "[400]\ttraining's rmse: 3.46648\tvalid_1's rmse: 3.6655\n",
      "[500]\ttraining's rmse: 3.43506\tvalid_1's rmse: 3.66273\n",
      "[600]\ttraining's rmse: 3.40849\tvalid_1's rmse: 3.66084\n",
      "[700]\ttraining's rmse: 3.3852\tvalid_1's rmse: 3.65964\n",
      "[800]\ttraining's rmse: 3.36429\tvalid_1's rmse: 3.65941\n",
      "[900]\ttraining's rmse: 3.34394\tvalid_1's rmse: 3.65879\n",
      "[1000]\ttraining's rmse: 3.32423\tvalid_1's rmse: 3.65875\n",
      "[1100]\ttraining's rmse: 3.30642\tvalid_1's rmse: 3.65909\n",
      "[1200]\ttraining's rmse: 3.28902\tvalid_1's rmse: 3.66016\n",
      "[1300]\ttraining's rmse: 3.27218\tvalid_1's rmse: 3.66018\n",
      "[1400]\ttraining's rmse: 3.25561\tvalid_1's rmse: 3.66057\n",
      "[1500]\ttraining's rmse: 3.23966\tvalid_1's rmse: 3.66089\n",
      "Early stopping, best iteration is:\n",
      "[968]\ttraining's rmse: 3.3304\tvalid_1's rmse: 3.65838\n",
      "fold 3 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65219\tvalid_1's rmse: 3.67718\n",
      "[200]\ttraining's rmse: 3.56617\tvalid_1's rmse: 3.63142\n",
      "[300]\ttraining's rmse: 3.5153\tvalid_1's rmse: 3.61677\n",
      "[400]\ttraining's rmse: 3.47669\tvalid_1's rmse: 3.60837\n",
      "[500]\ttraining's rmse: 3.44564\tvalid_1's rmse: 3.60442\n",
      "[600]\ttraining's rmse: 3.41961\tvalid_1's rmse: 3.60153\n",
      "[700]\ttraining's rmse: 3.39625\tvalid_1's rmse: 3.60017\n",
      "[800]\ttraining's rmse: 3.37531\tvalid_1's rmse: 3.5994\n",
      "[900]\ttraining's rmse: 3.35487\tvalid_1's rmse: 3.59885\n",
      "[1000]\ttraining's rmse: 3.33556\tvalid_1's rmse: 3.5991\n",
      "[1100]\ttraining's rmse: 3.31655\tvalid_1's rmse: 3.59903\n",
      "[1200]\ttraining's rmse: 3.29867\tvalid_1's rmse: 3.59941\n",
      "[1300]\ttraining's rmse: 3.28038\tvalid_1's rmse: 3.59979\n",
      "[1400]\ttraining's rmse: 3.2646\tvalid_1's rmse: 3.59995\n",
      "[1500]\ttraining's rmse: 3.24913\tvalid_1's rmse: 3.60035\n",
      "[1600]\ttraining's rmse: 3.23196\tvalid_1's rmse: 3.60072\n",
      "Early stopping, best iteration is:\n",
      "[1030]\ttraining's rmse: 3.3295\tvalid_1's rmse: 3.59861\n",
      "fold 4 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64644\tvalid_1's rmse: 3.70444\n",
      "[200]\ttraining's rmse: 3.55969\tvalid_1's rmse: 3.67111\n",
      "[300]\ttraining's rmse: 3.50794\tvalid_1's rmse: 3.66119\n",
      "[400]\ttraining's rmse: 3.46874\tvalid_1's rmse: 3.65559\n",
      "[500]\ttraining's rmse: 3.43737\tvalid_1's rmse: 3.65363\n",
      "[600]\ttraining's rmse: 3.41103\tvalid_1's rmse: 3.65091\n",
      "[700]\ttraining's rmse: 3.38679\tvalid_1's rmse: 3.64979\n",
      "[800]\ttraining's rmse: 3.3657\tvalid_1's rmse: 3.64939\n",
      "[900]\ttraining's rmse: 3.34518\tvalid_1's rmse: 3.64974\n",
      "[1000]\ttraining's rmse: 3.32668\tvalid_1's rmse: 3.65089\n",
      "[1100]\ttraining's rmse: 3.30775\tvalid_1's rmse: 3.6523\n",
      "[1200]\ttraining's rmse: 3.29088\tvalid_1's rmse: 3.65251\n",
      "[1300]\ttraining's rmse: 3.27411\tvalid_1's rmse: 3.65308\n",
      "Early stopping, best iteration is:\n",
      "[787]\ttraining's rmse: 3.36843\tvalid_1's rmse: 3.64909\n",
      "fold 5 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64528\tvalid_1's rmse: 3.71798\n",
      "[200]\ttraining's rmse: 3.55621\tvalid_1's rmse: 3.68892\n",
      "[300]\ttraining's rmse: 3.50431\tvalid_1's rmse: 3.67743\n",
      "[400]\ttraining's rmse: 3.46536\tvalid_1's rmse: 3.67058\n",
      "[500]\ttraining's rmse: 3.43388\tvalid_1's rmse: 3.66751\n",
      "[600]\ttraining's rmse: 3.40741\tvalid_1's rmse: 3.66592\n",
      "[700]\ttraining's rmse: 3.3836\tvalid_1's rmse: 3.66421\n",
      "[800]\ttraining's rmse: 3.36229\tvalid_1's rmse: 3.66327\n",
      "[900]\ttraining's rmse: 3.34169\tvalid_1's rmse: 3.66286\n",
      "[1000]\ttraining's rmse: 3.32203\tvalid_1's rmse: 3.66244\n",
      "[1100]\ttraining's rmse: 3.30349\tvalid_1's rmse: 3.66216\n",
      "[1200]\ttraining's rmse: 3.28572\tvalid_1's rmse: 3.66247\n",
      "[1300]\ttraining's rmse: 3.26781\tvalid_1's rmse: 3.66266\n",
      "[1400]\ttraining's rmse: 3.25123\tvalid_1's rmse: 3.66272\n",
      "[1500]\ttraining's rmse: 3.2358\tvalid_1's rmse: 3.6623\n",
      "[1600]\ttraining's rmse: 3.22013\tvalid_1's rmse: 3.66268\n",
      "[1700]\ttraining's rmse: 3.20362\tvalid_1's rmse: 3.66296\n",
      "Early stopping, best iteration is:\n",
      "[1129]\ttraining's rmse: 3.29833\tvalid_1's rmse: 3.66206\n",
      "fold 6 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64895\tvalid_1's rmse: 3.70669\n",
      "[200]\ttraining's rmse: 3.56203\tvalid_1's rmse: 3.66282\n",
      "[300]\ttraining's rmse: 3.50991\tvalid_1's rmse: 3.64442\n",
      "[400]\ttraining's rmse: 3.4707\tvalid_1's rmse: 3.63416\n",
      "[500]\ttraining's rmse: 3.43993\tvalid_1's rmse: 3.62832\n",
      "[600]\ttraining's rmse: 3.41399\tvalid_1's rmse: 3.62397\n",
      "[700]\ttraining's rmse: 3.38925\tvalid_1's rmse: 3.62178\n",
      "[800]\ttraining's rmse: 3.36773\tvalid_1's rmse: 3.62125\n",
      "[900]\ttraining's rmse: 3.34667\tvalid_1's rmse: 3.62055\n",
      "[1000]\ttraining's rmse: 3.32796\tvalid_1's rmse: 3.61926\n",
      "[1100]\ttraining's rmse: 3.30921\tvalid_1's rmse: 3.61866\n",
      "[1200]\ttraining's rmse: 3.29227\tvalid_1's rmse: 3.61799\n",
      "[1300]\ttraining's rmse: 3.27481\tvalid_1's rmse: 3.61803\n",
      "[1400]\ttraining's rmse: 3.25746\tvalid_1's rmse: 3.61739\n",
      "[1500]\ttraining's rmse: 3.24021\tvalid_1's rmse: 3.61769\n",
      "[1600]\ttraining's rmse: 3.22482\tvalid_1's rmse: 3.61812\n",
      "[1700]\ttraining's rmse: 3.20929\tvalid_1's rmse: 3.61806\n",
      "[1800]\ttraining's rmse: 3.19357\tvalid_1's rmse: 3.61848\n",
      "[1900]\ttraining's rmse: 3.17872\tvalid_1's rmse: 3.61958\n",
      "Early stopping, best iteration is:\n",
      "[1358]\ttraining's rmse: 3.2646\tvalid_1's rmse: 3.61733\n",
      "fold 7 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64217\tvalid_1's rmse: 3.73234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.55435\tvalid_1's rmse: 3.70176\n",
      "[300]\ttraining's rmse: 3.50409\tvalid_1's rmse: 3.69005\n",
      "[400]\ttraining's rmse: 3.46581\tvalid_1's rmse: 3.68224\n",
      "[500]\ttraining's rmse: 3.43402\tvalid_1's rmse: 3.67587\n",
      "[600]\ttraining's rmse: 3.40691\tvalid_1's rmse: 3.67175\n",
      "[700]\ttraining's rmse: 3.38235\tvalid_1's rmse: 3.66921\n",
      "[800]\ttraining's rmse: 3.35887\tvalid_1's rmse: 3.6681\n",
      "[900]\ttraining's rmse: 3.33826\tvalid_1's rmse: 3.66769\n",
      "[1000]\ttraining's rmse: 3.31902\tvalid_1's rmse: 3.66658\n",
      "[1100]\ttraining's rmse: 3.30007\tvalid_1's rmse: 3.66526\n",
      "[1200]\ttraining's rmse: 3.28197\tvalid_1's rmse: 3.66451\n",
      "[1300]\ttraining's rmse: 3.26498\tvalid_1's rmse: 3.66385\n",
      "[1400]\ttraining's rmse: 3.24919\tvalid_1's rmse: 3.66399\n",
      "[1500]\ttraining's rmse: 3.23309\tvalid_1's rmse: 3.66379\n",
      "[1600]\ttraining's rmse: 3.21783\tvalid_1's rmse: 3.66414\n",
      "[1700]\ttraining's rmse: 3.20162\tvalid_1's rmse: 3.66438\n",
      "[1800]\ttraining's rmse: 3.18604\tvalid_1's rmse: 3.66531\n",
      "[1900]\ttraining's rmse: 3.17007\tvalid_1's rmse: 3.66534\n",
      "Early stopping, best iteration is:\n",
      "[1313]\ttraining's rmse: 3.26295\tvalid_1's rmse: 3.66353\n",
      "fold 8 1570 0.010934213641998524\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64291\tvalid_1's rmse: 3.71761\n",
      "[200]\ttraining's rmse: 3.55477\tvalid_1's rmse: 3.69715\n",
      "[300]\ttraining's rmse: 3.50229\tvalid_1's rmse: 3.69264\n",
      "[400]\ttraining's rmse: 3.46268\tvalid_1's rmse: 3.69187\n",
      "[500]\ttraining's rmse: 3.43142\tvalid_1's rmse: 3.69195\n",
      "[600]\ttraining's rmse: 3.40454\tvalid_1's rmse: 3.6913\n",
      "[700]\ttraining's rmse: 3.38032\tvalid_1's rmse: 3.69217\n",
      "[800]\ttraining's rmse: 3.35811\tvalid_1's rmse: 3.69273\n",
      "[900]\ttraining's rmse: 3.33792\tvalid_1's rmse: 3.69311\n",
      "[1000]\ttraining's rmse: 3.31857\tvalid_1's rmse: 3.69348\n",
      "[1100]\ttraining's rmse: 3.29986\tvalid_1's rmse: 3.6937\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's rmse: 3.40809\tvalid_1's rmse: 3.69082\n",
      "fold 0 1569 0.010927401381769557\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64875\tvalid_1's rmse: 3.70651\n",
      "[200]\ttraining's rmse: 3.56363\tvalid_1's rmse: 3.67684\n",
      "[300]\ttraining's rmse: 3.51293\tvalid_1's rmse: 3.66471\n",
      "[400]\ttraining's rmse: 3.47574\tvalid_1's rmse: 3.66028\n",
      "[500]\ttraining's rmse: 3.44563\tvalid_1's rmse: 3.6578\n",
      "[600]\ttraining's rmse: 3.41958\tvalid_1's rmse: 3.65519\n",
      "[700]\ttraining's rmse: 3.39645\tvalid_1's rmse: 3.65406\n",
      "[800]\ttraining's rmse: 3.37469\tvalid_1's rmse: 3.65164\n",
      "[900]\ttraining's rmse: 3.35477\tvalid_1's rmse: 3.6512\n",
      "[1000]\ttraining's rmse: 3.33681\tvalid_1's rmse: 3.65073\n",
      "[1100]\ttraining's rmse: 3.31823\tvalid_1's rmse: 3.65001\n",
      "[1200]\ttraining's rmse: 3.30096\tvalid_1's rmse: 3.64958\n",
      "[1300]\ttraining's rmse: 3.28376\tvalid_1's rmse: 3.65005\n",
      "[1400]\ttraining's rmse: 3.26716\tvalid_1's rmse: 3.65025\n",
      "[1500]\ttraining's rmse: 3.25089\tvalid_1's rmse: 3.64996\n",
      "[1600]\ttraining's rmse: 3.23596\tvalid_1's rmse: 3.64985\n",
      "[1700]\ttraining's rmse: 3.22018\tvalid_1's rmse: 3.64892\n",
      "[1800]\ttraining's rmse: 3.20572\tvalid_1's rmse: 3.64882\n",
      "[1900]\ttraining's rmse: 3.19094\tvalid_1's rmse: 3.64827\n",
      "[2000]\ttraining's rmse: 3.17735\tvalid_1's rmse: 3.64902\n",
      "[2100]\ttraining's rmse: 3.16278\tvalid_1's rmse: 3.64895\n",
      "[2200]\ttraining's rmse: 3.14783\tvalid_1's rmse: 3.64974\n",
      "[2300]\ttraining's rmse: 3.13415\tvalid_1's rmse: 3.64978\n",
      "[2400]\ttraining's rmse: 3.12174\tvalid_1's rmse: 3.6494\n",
      "[2500]\ttraining's rmse: 3.10835\tvalid_1's rmse: 3.64981\n",
      "Early stopping, best iteration is:\n",
      "[1901]\ttraining's rmse: 3.19084\tvalid_1's rmse: 3.64822\n",
      "fold 1 1569 0.010927401381769557\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64923\tvalid_1's rmse: 3.70762\n",
      "[200]\ttraining's rmse: 3.56366\tvalid_1's rmse: 3.67392\n",
      "[300]\ttraining's rmse: 3.51324\tvalid_1's rmse: 3.6614\n",
      "[400]\ttraining's rmse: 3.47589\tvalid_1's rmse: 3.65671\n",
      "[500]\ttraining's rmse: 3.44572\tvalid_1's rmse: 3.65282\n",
      "[600]\ttraining's rmse: 3.41911\tvalid_1's rmse: 3.65021\n",
      "[700]\ttraining's rmse: 3.39659\tvalid_1's rmse: 3.64852\n",
      "[800]\ttraining's rmse: 3.37652\tvalid_1's rmse: 3.64904\n",
      "[900]\ttraining's rmse: 3.35697\tvalid_1's rmse: 3.64884\n",
      "[1000]\ttraining's rmse: 3.33749\tvalid_1's rmse: 3.64866\n",
      "[1100]\ttraining's rmse: 3.31886\tvalid_1's rmse: 3.64877\n",
      "[1200]\ttraining's rmse: 3.30151\tvalid_1's rmse: 3.64955\n",
      "Early stopping, best iteration is:\n",
      "[689]\ttraining's rmse: 3.39885\tvalid_1's rmse: 3.64843\n",
      "fold 2 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64792\tvalid_1's rmse: 3.71268\n",
      "[200]\ttraining's rmse: 3.56171\tvalid_1's rmse: 3.67795\n",
      "[300]\ttraining's rmse: 3.51045\tvalid_1's rmse: 3.66804\n",
      "[400]\ttraining's rmse: 3.47264\tvalid_1's rmse: 3.66279\n",
      "[500]\ttraining's rmse: 3.44302\tvalid_1's rmse: 3.66084\n",
      "[600]\ttraining's rmse: 3.41664\tvalid_1's rmse: 3.65978\n",
      "[700]\ttraining's rmse: 3.39317\tvalid_1's rmse: 3.65877\n",
      "[800]\ttraining's rmse: 3.37225\tvalid_1's rmse: 3.65736\n",
      "[900]\ttraining's rmse: 3.35252\tvalid_1's rmse: 3.65662\n",
      "[1000]\ttraining's rmse: 3.33418\tvalid_1's rmse: 3.65592\n",
      "[1100]\ttraining's rmse: 3.31777\tvalid_1's rmse: 3.65403\n",
      "[1200]\ttraining's rmse: 3.30036\tvalid_1's rmse: 3.65423\n",
      "[1300]\ttraining's rmse: 3.28366\tvalid_1's rmse: 3.65447\n",
      "[1400]\ttraining's rmse: 3.26695\tvalid_1's rmse: 3.65475\n",
      "[1500]\ttraining's rmse: 3.25129\tvalid_1's rmse: 3.65426\n",
      "[1600]\ttraining's rmse: 3.23588\tvalid_1's rmse: 3.65503\n",
      "[1700]\ttraining's rmse: 3.22077\tvalid_1's rmse: 3.65548\n",
      "Early stopping, best iteration is:\n",
      "[1132]\ttraining's rmse: 3.31198\tvalid_1's rmse: 3.65386\n",
      "fold 3 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65548\tvalid_1's rmse: 3.6794\n",
      "[200]\ttraining's rmse: 3.57292\tvalid_1's rmse: 3.63322\n",
      "[300]\ttraining's rmse: 3.52277\tvalid_1's rmse: 3.61755\n",
      "[400]\ttraining's rmse: 3.48443\tvalid_1's rmse: 3.60866\n",
      "[500]\ttraining's rmse: 3.4538\tvalid_1's rmse: 3.6032\n",
      "[600]\ttraining's rmse: 3.42793\tvalid_1's rmse: 3.59861\n",
      "[700]\ttraining's rmse: 3.40586\tvalid_1's rmse: 3.59739\n",
      "[800]\ttraining's rmse: 3.38466\tvalid_1's rmse: 3.59764\n",
      "[900]\ttraining's rmse: 3.36513\tvalid_1's rmse: 3.59721\n",
      "[1000]\ttraining's rmse: 3.34656\tvalid_1's rmse: 3.59639\n",
      "[1100]\ttraining's rmse: 3.32892\tvalid_1's rmse: 3.59568\n",
      "[1200]\ttraining's rmse: 3.31189\tvalid_1's rmse: 3.59559\n",
      "[1300]\ttraining's rmse: 3.29507\tvalid_1's rmse: 3.59579\n",
      "[1400]\ttraining's rmse: 3.28079\tvalid_1's rmse: 3.59665\n",
      "[1500]\ttraining's rmse: 3.26492\tvalid_1's rmse: 3.59682\n",
      "[1600]\ttraining's rmse: 3.24913\tvalid_1's rmse: 3.59766\n",
      "[1700]\ttraining's rmse: 3.2341\tvalid_1's rmse: 3.59808\n",
      "[1800]\ttraining's rmse: 3.21906\tvalid_1's rmse: 3.59802\n",
      "Early stopping, best iteration is:\n",
      "[1237]\ttraining's rmse: 3.30576\tvalid_1's rmse: 3.59533\n",
      "fold 4 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64803\tvalid_1's rmse: 3.70078\n",
      "[200]\ttraining's rmse: 3.56306\tvalid_1's rmse: 3.66735\n",
      "[300]\ttraining's rmse: 3.51247\tvalid_1's rmse: 3.65615\n",
      "[400]\ttraining's rmse: 3.47479\tvalid_1's rmse: 3.65078\n",
      "[500]\ttraining's rmse: 3.44479\tvalid_1's rmse: 3.64936\n",
      "[600]\ttraining's rmse: 3.41865\tvalid_1's rmse: 3.64751\n",
      "[700]\ttraining's rmse: 3.39593\tvalid_1's rmse: 3.64598\n",
      "[800]\ttraining's rmse: 3.37403\tvalid_1's rmse: 3.64584\n",
      "[900]\ttraining's rmse: 3.35424\tvalid_1's rmse: 3.6465\n",
      "[1000]\ttraining's rmse: 3.33454\tvalid_1's rmse: 3.64581\n",
      "[1100]\ttraining's rmse: 3.31632\tvalid_1's rmse: 3.64624\n",
      "[1200]\ttraining's rmse: 3.29928\tvalid_1's rmse: 3.64664\n",
      "[1300]\ttraining's rmse: 3.28228\tvalid_1's rmse: 3.64661\n",
      "Early stopping, best iteration is:\n",
      "[767]\ttraining's rmse: 3.38119\tvalid_1's rmse: 3.64531\n",
      "fold 5 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64758\tvalid_1's rmse: 3.71622\n",
      "[200]\ttraining's rmse: 3.56127\tvalid_1's rmse: 3.68647\n",
      "[300]\ttraining's rmse: 3.51088\tvalid_1's rmse: 3.67404\n",
      "[400]\ttraining's rmse: 3.4733\tvalid_1's rmse: 3.66768\n",
      "[500]\ttraining's rmse: 3.4421\tvalid_1's rmse: 3.66415\n",
      "[600]\ttraining's rmse: 3.41626\tvalid_1's rmse: 3.66348\n",
      "[700]\ttraining's rmse: 3.39201\tvalid_1's rmse: 3.66139\n",
      "[800]\ttraining's rmse: 3.37137\tvalid_1's rmse: 3.6592\n",
      "[900]\ttraining's rmse: 3.35197\tvalid_1's rmse: 3.65864\n",
      "[1000]\ttraining's rmse: 3.33293\tvalid_1's rmse: 3.65768\n",
      "[1100]\ttraining's rmse: 3.31479\tvalid_1's rmse: 3.65687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 3.29746\tvalid_1's rmse: 3.65755\n",
      "[1300]\ttraining's rmse: 3.28013\tvalid_1's rmse: 3.65782\n",
      "[1400]\ttraining's rmse: 3.264\tvalid_1's rmse: 3.65765\n",
      "[1500]\ttraining's rmse: 3.24859\tvalid_1's rmse: 3.65675\n",
      "[1600]\ttraining's rmse: 3.23359\tvalid_1's rmse: 3.65701\n",
      "[1700]\ttraining's rmse: 3.21774\tvalid_1's rmse: 3.65746\n",
      "[1800]\ttraining's rmse: 3.20178\tvalid_1's rmse: 3.65767\n",
      "[1900]\ttraining's rmse: 3.18665\tvalid_1's rmse: 3.65719\n",
      "[2000]\ttraining's rmse: 3.17275\tvalid_1's rmse: 3.65751\n",
      "[2100]\ttraining's rmse: 3.15894\tvalid_1's rmse: 3.65763\n",
      "Early stopping, best iteration is:\n",
      "[1514]\ttraining's rmse: 3.2465\tvalid_1's rmse: 3.65647\n",
      "fold 6 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65106\tvalid_1's rmse: 3.70616\n",
      "[200]\ttraining's rmse: 3.56718\tvalid_1's rmse: 3.66312\n",
      "[300]\ttraining's rmse: 3.51596\tvalid_1's rmse: 3.6474\n",
      "[400]\ttraining's rmse: 3.47786\tvalid_1's rmse: 3.63861\n",
      "[500]\ttraining's rmse: 3.44731\tvalid_1's rmse: 3.63173\n",
      "[600]\ttraining's rmse: 3.42153\tvalid_1's rmse: 3.6274\n",
      "[700]\ttraining's rmse: 3.39789\tvalid_1's rmse: 3.62535\n",
      "[800]\ttraining's rmse: 3.37691\tvalid_1's rmse: 3.62346\n",
      "[900]\ttraining's rmse: 3.35636\tvalid_1's rmse: 3.62327\n",
      "[1000]\ttraining's rmse: 3.33813\tvalid_1's rmse: 3.62323\n",
      "[1100]\ttraining's rmse: 3.31977\tvalid_1's rmse: 3.62264\n",
      "[1200]\ttraining's rmse: 3.3025\tvalid_1's rmse: 3.62221\n",
      "[1300]\ttraining's rmse: 3.28456\tvalid_1's rmse: 3.62332\n",
      "[1400]\ttraining's rmse: 3.26759\tvalid_1's rmse: 3.62398\n",
      "[1500]\ttraining's rmse: 3.25194\tvalid_1's rmse: 3.62471\n",
      "[1600]\ttraining's rmse: 3.23616\tvalid_1's rmse: 3.62472\n",
      "[1700]\ttraining's rmse: 3.22123\tvalid_1's rmse: 3.62527\n",
      "[1800]\ttraining's rmse: 3.20506\tvalid_1's rmse: 3.62632\n",
      "Early stopping, best iteration is:\n",
      "[1201]\ttraining's rmse: 3.30229\tvalid_1's rmse: 3.62214\n",
      "fold 7 1570 0.010934289793502108\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64383\tvalid_1's rmse: 3.7325\n",
      "[200]\ttraining's rmse: 3.55892\tvalid_1's rmse: 3.70064\n",
      "[300]\ttraining's rmse: 3.50958\tvalid_1's rmse: 3.69041\n",
      "[400]\ttraining's rmse: 3.47268\tvalid_1's rmse: 3.68427\n",
      "[500]\ttraining's rmse: 3.44258\tvalid_1's rmse: 3.67926\n",
      "[600]\ttraining's rmse: 3.41658\tvalid_1's rmse: 3.67554\n",
      "[700]\ttraining's rmse: 3.3931\tvalid_1's rmse: 3.67351\n",
      "[800]\ttraining's rmse: 3.37039\tvalid_1's rmse: 3.67137\n",
      "[900]\ttraining's rmse: 3.34997\tvalid_1's rmse: 3.6703\n",
      "[1000]\ttraining's rmse: 3.33156\tvalid_1's rmse: 3.6686\n",
      "[1100]\ttraining's rmse: 3.31333\tvalid_1's rmse: 3.66727\n",
      "[1200]\ttraining's rmse: 3.29662\tvalid_1's rmse: 3.66638\n",
      "[1300]\ttraining's rmse: 3.27976\tvalid_1's rmse: 3.6665\n",
      "[1400]\ttraining's rmse: 3.26349\tvalid_1's rmse: 3.66637\n",
      "[1500]\ttraining's rmse: 3.2478\tvalid_1's rmse: 3.66548\n",
      "[1600]\ttraining's rmse: 3.23187\tvalid_1's rmse: 3.66659\n",
      "[1700]\ttraining's rmse: 3.21739\tvalid_1's rmse: 3.66613\n",
      "[1800]\ttraining's rmse: 3.20245\tvalid_1's rmse: 3.66601\n",
      "[1900]\ttraining's rmse: 3.18697\tvalid_1's rmse: 3.66628\n",
      "[2000]\ttraining's rmse: 3.17251\tvalid_1's rmse: 3.66633\n",
      "Early stopping, best iteration is:\n",
      "[1495]\ttraining's rmse: 3.24859\tvalid_1's rmse: 3.66545\n",
      "fold 8 1570 0.010934213641998524\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64544\tvalid_1's rmse: 3.71631\n",
      "[200]\ttraining's rmse: 3.55907\tvalid_1's rmse: 3.69567\n",
      "[300]\ttraining's rmse: 3.5075\tvalid_1's rmse: 3.69162\n",
      "[400]\ttraining's rmse: 3.46933\tvalid_1's rmse: 3.69112\n",
      "[500]\ttraining's rmse: 3.43803\tvalid_1's rmse: 3.69066\n",
      "[600]\ttraining's rmse: 3.4119\tvalid_1's rmse: 3.69142\n",
      "[700]\ttraining's rmse: 3.38844\tvalid_1's rmse: 3.69152\n",
      "[800]\ttraining's rmse: 3.36722\tvalid_1's rmse: 3.69189\n",
      "[900]\ttraining's rmse: 3.34714\tvalid_1's rmse: 3.6929\n",
      "[1000]\ttraining's rmse: 3.32901\tvalid_1's rmse: 3.69312\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's rmse: 3.43976\tvalid_1's rmse: 3.6903\n",
      "fold 0 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63813\tvalid_1's rmse: 3.7147\n",
      "[200]\ttraining's rmse: 3.54161\tvalid_1's rmse: 3.68847\n",
      "[300]\ttraining's rmse: 3.48464\tvalid_1's rmse: 3.67657\n",
      "[400]\ttraining's rmse: 3.44131\tvalid_1's rmse: 3.67147\n",
      "[500]\ttraining's rmse: 3.40409\tvalid_1's rmse: 3.66705\n",
      "[600]\ttraining's rmse: 3.3745\tvalid_1's rmse: 3.66534\n",
      "[700]\ttraining's rmse: 3.34698\tvalid_1's rmse: 3.66375\n",
      "[800]\ttraining's rmse: 3.32267\tvalid_1's rmse: 3.66206\n",
      "[900]\ttraining's rmse: 3.29969\tvalid_1's rmse: 3.66142\n",
      "[1000]\ttraining's rmse: 3.2777\tvalid_1's rmse: 3.6612\n",
      "[1100]\ttraining's rmse: 3.25747\tvalid_1's rmse: 3.66065\n",
      "[1200]\ttraining's rmse: 3.23754\tvalid_1's rmse: 3.65999\n",
      "[1300]\ttraining's rmse: 3.21854\tvalid_1's rmse: 3.65963\n",
      "[1400]\ttraining's rmse: 3.19845\tvalid_1's rmse: 3.65964\n",
      "[1500]\ttraining's rmse: 3.18099\tvalid_1's rmse: 3.65906\n",
      "[1600]\ttraining's rmse: 3.1625\tvalid_1's rmse: 3.65899\n",
      "[1700]\ttraining's rmse: 3.14485\tvalid_1's rmse: 3.65864\n",
      "[1800]\ttraining's rmse: 3.12725\tvalid_1's rmse: 3.6588\n",
      "[1900]\ttraining's rmse: 3.11087\tvalid_1's rmse: 3.65863\n",
      "[2000]\ttraining's rmse: 3.09493\tvalid_1's rmse: 3.65847\n",
      "[2100]\ttraining's rmse: 3.07875\tvalid_1's rmse: 3.65933\n",
      "[2200]\ttraining's rmse: 3.06205\tvalid_1's rmse: 3.65911\n",
      "[2300]\ttraining's rmse: 3.04648\tvalid_1's rmse: 3.65941\n",
      "[2400]\ttraining's rmse: 3.03056\tvalid_1's rmse: 3.66045\n",
      "Early stopping, best iteration is:\n",
      "[1867]\ttraining's rmse: 3.11665\tvalid_1's rmse: 3.65829\n",
      "fold 1 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63758\tvalid_1's rmse: 3.7132\n",
      "[200]\ttraining's rmse: 3.54122\tvalid_1's rmse: 3.67735\n",
      "[300]\ttraining's rmse: 3.48344\tvalid_1's rmse: 3.66509\n",
      "[400]\ttraining's rmse: 3.43931\tvalid_1's rmse: 3.65827\n",
      "[500]\ttraining's rmse: 3.40373\tvalid_1's rmse: 3.65414\n",
      "[600]\ttraining's rmse: 3.37355\tvalid_1's rmse: 3.65245\n",
      "[700]\ttraining's rmse: 3.3469\tvalid_1's rmse: 3.6514\n",
      "[800]\ttraining's rmse: 3.32284\tvalid_1's rmse: 3.65075\n",
      "[900]\ttraining's rmse: 3.30019\tvalid_1's rmse: 3.6508\n",
      "[1000]\ttraining's rmse: 3.27978\tvalid_1's rmse: 3.65107\n",
      "[1100]\ttraining's rmse: 3.25814\tvalid_1's rmse: 3.65141\n",
      "[1200]\ttraining's rmse: 3.23831\tvalid_1's rmse: 3.65132\n",
      "[1300]\ttraining's rmse: 3.21971\tvalid_1's rmse: 3.65225\n",
      "[1400]\ttraining's rmse: 3.20045\tvalid_1's rmse: 3.65338\n",
      "Early stopping, best iteration is:\n",
      "[839]\ttraining's rmse: 3.31369\tvalid_1's rmse: 3.65053\n",
      "fold 2 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63811\tvalid_1's rmse: 3.71373\n",
      "[200]\ttraining's rmse: 3.5428\tvalid_1's rmse: 3.67755\n",
      "[300]\ttraining's rmse: 3.48526\tvalid_1's rmse: 3.66509\n",
      "[400]\ttraining's rmse: 3.44167\tvalid_1's rmse: 3.6592\n",
      "[500]\ttraining's rmse: 3.40614\tvalid_1's rmse: 3.65517\n",
      "[600]\ttraining's rmse: 3.37632\tvalid_1's rmse: 3.65328\n",
      "[700]\ttraining's rmse: 3.35054\tvalid_1's rmse: 3.65138\n",
      "[800]\ttraining's rmse: 3.32687\tvalid_1's rmse: 3.6514\n",
      "[900]\ttraining's rmse: 3.30457\tvalid_1's rmse: 3.65198\n",
      "[1000]\ttraining's rmse: 3.28316\tvalid_1's rmse: 3.6521\n",
      "[1100]\ttraining's rmse: 3.26144\tvalid_1's rmse: 3.65207\n",
      "[1200]\ttraining's rmse: 3.24097\tvalid_1's rmse: 3.65259\n",
      "[1300]\ttraining's rmse: 3.22262\tvalid_1's rmse: 3.65168\n",
      "Early stopping, best iteration is:\n",
      "[720]\ttraining's rmse: 3.34538\tvalid_1's rmse: 3.65085\n",
      "fold 3 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6417\tvalid_1's rmse: 3.69972\n",
      "[200]\ttraining's rmse: 3.5494\tvalid_1's rmse: 3.65173\n",
      "[300]\ttraining's rmse: 3.49064\tvalid_1's rmse: 3.63576\n",
      "[400]\ttraining's rmse: 3.44798\tvalid_1's rmse: 3.62551\n",
      "[500]\ttraining's rmse: 3.41321\tvalid_1's rmse: 3.61935\n",
      "[600]\ttraining's rmse: 3.38307\tvalid_1's rmse: 3.61562\n",
      "[700]\ttraining's rmse: 3.35616\tvalid_1's rmse: 3.6128\n",
      "[800]\ttraining's rmse: 3.33066\tvalid_1's rmse: 3.61176\n",
      "[900]\ttraining's rmse: 3.30774\tvalid_1's rmse: 3.61073\n",
      "[1000]\ttraining's rmse: 3.28585\tvalid_1's rmse: 3.60967\n",
      "[1100]\ttraining's rmse: 3.26451\tvalid_1's rmse: 3.60895\n",
      "[1200]\ttraining's rmse: 3.24486\tvalid_1's rmse: 3.60827\n",
      "[1300]\ttraining's rmse: 3.22602\tvalid_1's rmse: 3.60785\n",
      "[1400]\ttraining's rmse: 3.20674\tvalid_1's rmse: 3.60761\n",
      "[1500]\ttraining's rmse: 3.18909\tvalid_1's rmse: 3.60724\n",
      "[1600]\ttraining's rmse: 3.1732\tvalid_1's rmse: 3.60762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\ttraining's rmse: 3.15534\tvalid_1's rmse: 3.60759\n",
      "[1800]\ttraining's rmse: 3.13771\tvalid_1's rmse: 3.60835\n",
      "[1900]\ttraining's rmse: 3.12126\tvalid_1's rmse: 3.6092\n",
      "[2000]\ttraining's rmse: 3.10461\tvalid_1's rmse: 3.60937\n",
      "[2100]\ttraining's rmse: 3.08817\tvalid_1's rmse: 3.60936\n",
      "Early stopping, best iteration is:\n",
      "[1504]\ttraining's rmse: 3.18838\tvalid_1's rmse: 3.60712\n",
      "fold 4 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63686\tvalid_1's rmse: 3.71526\n",
      "[200]\ttraining's rmse: 3.54123\tvalid_1's rmse: 3.68308\n",
      "[300]\ttraining's rmse: 3.48312\tvalid_1's rmse: 3.66981\n",
      "[400]\ttraining's rmse: 3.43945\tvalid_1's rmse: 3.66177\n",
      "[500]\ttraining's rmse: 3.40393\tvalid_1's rmse: 3.65596\n",
      "[600]\ttraining's rmse: 3.37347\tvalid_1's rmse: 3.65346\n",
      "[700]\ttraining's rmse: 3.34573\tvalid_1's rmse: 3.65198\n",
      "[800]\ttraining's rmse: 3.32102\tvalid_1's rmse: 3.65159\n",
      "[900]\ttraining's rmse: 3.29745\tvalid_1's rmse: 3.65189\n",
      "[1000]\ttraining's rmse: 3.27582\tvalid_1's rmse: 3.6521\n",
      "[1100]\ttraining's rmse: 3.25435\tvalid_1's rmse: 3.65256\n",
      "[1200]\ttraining's rmse: 3.2337\tvalid_1's rmse: 3.6528\n",
      "[1300]\ttraining's rmse: 3.21415\tvalid_1's rmse: 3.6533\n",
      "[1400]\ttraining's rmse: 3.19374\tvalid_1's rmse: 3.65261\n",
      "Early stopping, best iteration is:\n",
      "[830]\ttraining's rmse: 3.31408\tvalid_1's rmse: 3.65115\n",
      "fold 5 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63493\tvalid_1's rmse: 3.72558\n",
      "[200]\ttraining's rmse: 3.5368\tvalid_1's rmse: 3.69948\n",
      "[300]\ttraining's rmse: 3.47735\tvalid_1's rmse: 3.68935\n",
      "[400]\ttraining's rmse: 3.43439\tvalid_1's rmse: 3.68353\n",
      "[500]\ttraining's rmse: 3.39906\tvalid_1's rmse: 3.67964\n",
      "[600]\ttraining's rmse: 3.36818\tvalid_1's rmse: 3.67759\n",
      "[700]\ttraining's rmse: 3.34105\tvalid_1's rmse: 3.67732\n",
      "[800]\ttraining's rmse: 3.31654\tvalid_1's rmse: 3.67683\n",
      "[900]\ttraining's rmse: 3.29248\tvalid_1's rmse: 3.6758\n",
      "[1000]\ttraining's rmse: 3.27128\tvalid_1's rmse: 3.67605\n",
      "[1100]\ttraining's rmse: 3.25003\tvalid_1's rmse: 3.67587\n",
      "[1200]\ttraining's rmse: 3.23049\tvalid_1's rmse: 3.67605\n",
      "[1300]\ttraining's rmse: 3.21175\tvalid_1's rmse: 3.67632\n",
      "[1400]\ttraining's rmse: 3.19201\tvalid_1's rmse: 3.67596\n",
      "[1500]\ttraining's rmse: 3.17446\tvalid_1's rmse: 3.67568\n",
      "[1600]\ttraining's rmse: 3.15607\tvalid_1's rmse: 3.67632\n",
      "Early stopping, best iteration is:\n",
      "[1080]\ttraining's rmse: 3.25413\tvalid_1's rmse: 3.67551\n",
      "fold 6 1590 0.010936855138258357\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63945\tvalid_1's rmse: 3.69476\n",
      "[200]\ttraining's rmse: 3.5439\tvalid_1's rmse: 3.65078\n",
      "[300]\ttraining's rmse: 3.485\tvalid_1's rmse: 3.63443\n",
      "[400]\ttraining's rmse: 3.44095\tvalid_1's rmse: 3.62311\n",
      "[500]\ttraining's rmse: 3.40452\tvalid_1's rmse: 3.61761\n",
      "[600]\ttraining's rmse: 3.37251\tvalid_1's rmse: 3.6142\n",
      "[700]\ttraining's rmse: 3.34493\tvalid_1's rmse: 3.61196\n",
      "[800]\ttraining's rmse: 3.32073\tvalid_1's rmse: 3.60995\n",
      "[900]\ttraining's rmse: 3.29643\tvalid_1's rmse: 3.61017\n",
      "[1000]\ttraining's rmse: 3.27429\tvalid_1's rmse: 3.60946\n",
      "[1100]\ttraining's rmse: 3.25284\tvalid_1's rmse: 3.6087\n",
      "[1200]\ttraining's rmse: 3.23247\tvalid_1's rmse: 3.60801\n",
      "[1300]\ttraining's rmse: 3.21178\tvalid_1's rmse: 3.60783\n",
      "[1400]\ttraining's rmse: 3.19342\tvalid_1's rmse: 3.60735\n",
      "[1500]\ttraining's rmse: 3.17381\tvalid_1's rmse: 3.60786\n",
      "[1600]\ttraining's rmse: 3.15558\tvalid_1's rmse: 3.60717\n",
      "[1700]\ttraining's rmse: 3.1366\tvalid_1's rmse: 3.60714\n",
      "[1800]\ttraining's rmse: 3.11933\tvalid_1's rmse: 3.60735\n",
      "[1900]\ttraining's rmse: 3.10304\tvalid_1's rmse: 3.60717\n",
      "[2000]\ttraining's rmse: 3.08651\tvalid_1's rmse: 3.60679\n",
      "[2100]\ttraining's rmse: 3.06972\tvalid_1's rmse: 3.60775\n",
      "[2200]\ttraining's rmse: 3.05397\tvalid_1's rmse: 3.60711\n",
      "[2300]\ttraining's rmse: 3.03938\tvalid_1's rmse: 3.60827\n",
      "[2400]\ttraining's rmse: 3.02322\tvalid_1's rmse: 3.60865\n",
      "[2500]\ttraining's rmse: 3.00807\tvalid_1's rmse: 3.60904\n",
      "Early stopping, best iteration is:\n",
      "[1944]\ttraining's rmse: 3.096\tvalid_1's rmse: 3.60647\n",
      "fold 7 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64068\tvalid_1's rmse: 3.70662\n",
      "[200]\ttraining's rmse: 3.54673\tvalid_1's rmse: 3.66555\n",
      "[300]\ttraining's rmse: 3.48925\tvalid_1's rmse: 3.65024\n",
      "[400]\ttraining's rmse: 3.44549\tvalid_1's rmse: 3.64046\n",
      "[500]\ttraining's rmse: 3.40751\tvalid_1's rmse: 3.636\n",
      "[600]\ttraining's rmse: 3.37804\tvalid_1's rmse: 3.63237\n",
      "[700]\ttraining's rmse: 3.35125\tvalid_1's rmse: 3.63058\n",
      "[800]\ttraining's rmse: 3.32584\tvalid_1's rmse: 3.62875\n",
      "[900]\ttraining's rmse: 3.30234\tvalid_1's rmse: 3.62909\n",
      "[1000]\ttraining's rmse: 3.28037\tvalid_1's rmse: 3.62882\n",
      "[1100]\ttraining's rmse: 3.26029\tvalid_1's rmse: 3.62752\n",
      "[1200]\ttraining's rmse: 3.2397\tvalid_1's rmse: 3.62671\n",
      "[1300]\ttraining's rmse: 3.22018\tvalid_1's rmse: 3.6265\n",
      "[1400]\ttraining's rmse: 3.20144\tvalid_1's rmse: 3.62519\n",
      "[1500]\ttraining's rmse: 3.18307\tvalid_1's rmse: 3.62492\n",
      "[1600]\ttraining's rmse: 3.16477\tvalid_1's rmse: 3.62492\n",
      "[1700]\ttraining's rmse: 3.14717\tvalid_1's rmse: 3.62496\n",
      "[1800]\ttraining's rmse: 3.1299\tvalid_1's rmse: 3.62506\n",
      "[1900]\ttraining's rmse: 3.11362\tvalid_1's rmse: 3.62524\n",
      "[2000]\ttraining's rmse: 3.0969\tvalid_1's rmse: 3.62456\n",
      "[2100]\ttraining's rmse: 3.07987\tvalid_1's rmse: 3.62414\n",
      "[2200]\ttraining's rmse: 3.06342\tvalid_1's rmse: 3.62356\n",
      "[2300]\ttraining's rmse: 3.04764\tvalid_1's rmse: 3.62343\n",
      "[2400]\ttraining's rmse: 3.03225\tvalid_1's rmse: 3.6236\n",
      "[2500]\ttraining's rmse: 3.01628\tvalid_1's rmse: 3.62413\n",
      "[2600]\ttraining's rmse: 3.00117\tvalid_1's rmse: 3.62406\n",
      "[2700]\ttraining's rmse: 2.9869\tvalid_1's rmse: 3.6244\n",
      "[2800]\ttraining's rmse: 2.97297\tvalid_1's rmse: 3.62462\n",
      "Early stopping, best iteration is:\n",
      "[2244]\ttraining's rmse: 3.05649\tvalid_1's rmse: 3.62312\n",
      "fold 8 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63346\tvalid_1's rmse: 3.73838\n",
      "[200]\ttraining's rmse: 3.53447\tvalid_1's rmse: 3.71227\n",
      "[300]\ttraining's rmse: 3.47685\tvalid_1's rmse: 3.70265\n",
      "[400]\ttraining's rmse: 3.43496\tvalid_1's rmse: 3.69673\n",
      "[500]\ttraining's rmse: 3.39995\tvalid_1's rmse: 3.69261\n",
      "[600]\ttraining's rmse: 3.368\tvalid_1's rmse: 3.68981\n",
      "[700]\ttraining's rmse: 3.33919\tvalid_1's rmse: 3.68856\n",
      "[800]\ttraining's rmse: 3.31468\tvalid_1's rmse: 3.68757\n",
      "[900]\ttraining's rmse: 3.29242\tvalid_1's rmse: 3.68656\n",
      "[1000]\ttraining's rmse: 3.26996\tvalid_1's rmse: 3.68667\n",
      "[1100]\ttraining's rmse: 3.24838\tvalid_1's rmse: 3.68563\n",
      "[1200]\ttraining's rmse: 3.22874\tvalid_1's rmse: 3.68507\n",
      "[1300]\ttraining's rmse: 3.21021\tvalid_1's rmse: 3.68481\n",
      "[1400]\ttraining's rmse: 3.19137\tvalid_1's rmse: 3.68449\n",
      "[1500]\ttraining's rmse: 3.17319\tvalid_1's rmse: 3.68415\n",
      "[1600]\ttraining's rmse: 3.15502\tvalid_1's rmse: 3.68423\n",
      "[1700]\ttraining's rmse: 3.13884\tvalid_1's rmse: 3.68465\n",
      "[1800]\ttraining's rmse: 3.12222\tvalid_1's rmse: 3.68394\n",
      "[1900]\ttraining's rmse: 3.10521\tvalid_1's rmse: 3.68393\n",
      "[2000]\ttraining's rmse: 3.08826\tvalid_1's rmse: 3.68409\n",
      "[2100]\ttraining's rmse: 3.07115\tvalid_1's rmse: 3.68363\n",
      "[2200]\ttraining's rmse: 3.05454\tvalid_1's rmse: 3.6839\n",
      "[2300]\ttraining's rmse: 3.03812\tvalid_1's rmse: 3.68428\n",
      "[2400]\ttraining's rmse: 3.02252\tvalid_1's rmse: 3.68468\n",
      "[2500]\ttraining's rmse: 3.00686\tvalid_1's rmse: 3.68503\n",
      "[2600]\ttraining's rmse: 2.99158\tvalid_1's rmse: 3.68551\n",
      "Early stopping, best iteration is:\n",
      "[2077]\ttraining's rmse: 3.07528\tvalid_1's rmse: 3.68356\n",
      "fold 9 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63568\tvalid_1's rmse: 3.71005\n",
      "[200]\ttraining's rmse: 3.53772\tvalid_1's rmse: 3.68962\n",
      "[300]\ttraining's rmse: 3.48005\tvalid_1's rmse: 3.68526\n",
      "[400]\ttraining's rmse: 3.43665\tvalid_1's rmse: 3.68314\n",
      "[500]\ttraining's rmse: 3.40177\tvalid_1's rmse: 3.68267\n",
      "[600]\ttraining's rmse: 3.36995\tvalid_1's rmse: 3.68161\n",
      "[700]\ttraining's rmse: 3.34226\tvalid_1's rmse: 3.68165\n",
      "[800]\ttraining's rmse: 3.31618\tvalid_1's rmse: 3.68114\n",
      "[900]\ttraining's rmse: 3.29215\tvalid_1's rmse: 3.68126\n",
      "[1000]\ttraining's rmse: 3.27111\tvalid_1's rmse: 3.68124\n",
      "[1100]\ttraining's rmse: 3.25088\tvalid_1's rmse: 3.68097\n",
      "[1200]\ttraining's rmse: 3.23227\tvalid_1's rmse: 3.68177\n",
      "[1300]\ttraining's rmse: 3.21299\tvalid_1's rmse: 3.68237\n",
      "[1400]\ttraining's rmse: 3.19419\tvalid_1's rmse: 3.68231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's rmse: 3.17548\tvalid_1's rmse: 3.68243\n",
      "[1600]\ttraining's rmse: 3.15827\tvalid_1's rmse: 3.68218\n",
      "[1700]\ttraining's rmse: 3.14065\tvalid_1's rmse: 3.68279\n",
      "Early stopping, best iteration is:\n",
      "[1102]\ttraining's rmse: 3.25052\tvalid_1's rmse: 3.68091\n",
      "fold 0 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64227\tvalid_1's rmse: 3.71465\n",
      "[200]\ttraining's rmse: 3.55045\tvalid_1's rmse: 3.68496\n",
      "[300]\ttraining's rmse: 3.49609\tvalid_1's rmse: 3.67298\n",
      "[400]\ttraining's rmse: 3.45359\tvalid_1's rmse: 3.66684\n",
      "[500]\ttraining's rmse: 3.41936\tvalid_1's rmse: 3.66343\n",
      "[600]\ttraining's rmse: 3.391\tvalid_1's rmse: 3.66101\n",
      "[700]\ttraining's rmse: 3.36452\tvalid_1's rmse: 3.65996\n",
      "[800]\ttraining's rmse: 3.341\tvalid_1's rmse: 3.6581\n",
      "[900]\ttraining's rmse: 3.31834\tvalid_1's rmse: 3.6569\n",
      "[1000]\ttraining's rmse: 3.29783\tvalid_1's rmse: 3.65553\n",
      "[1100]\ttraining's rmse: 3.27843\tvalid_1's rmse: 3.65466\n",
      "[1200]\ttraining's rmse: 3.25999\tvalid_1's rmse: 3.65431\n",
      "[1300]\ttraining's rmse: 3.24174\tvalid_1's rmse: 3.65346\n",
      "[1400]\ttraining's rmse: 3.22271\tvalid_1's rmse: 3.65338\n",
      "[1500]\ttraining's rmse: 3.20592\tvalid_1's rmse: 3.65276\n",
      "[1600]\ttraining's rmse: 3.18906\tvalid_1's rmse: 3.65273\n",
      "[1700]\ttraining's rmse: 3.17263\tvalid_1's rmse: 3.65256\n",
      "[1800]\ttraining's rmse: 3.15605\tvalid_1's rmse: 3.65259\n",
      "[1900]\ttraining's rmse: 3.14041\tvalid_1's rmse: 3.6522\n",
      "[2000]\ttraining's rmse: 3.1247\tvalid_1's rmse: 3.65235\n",
      "[2100]\ttraining's rmse: 3.10913\tvalid_1's rmse: 3.65209\n",
      "[2200]\ttraining's rmse: 3.0945\tvalid_1's rmse: 3.65252\n",
      "[2300]\ttraining's rmse: 3.0786\tvalid_1's rmse: 3.65203\n",
      "[2400]\ttraining's rmse: 3.0653\tvalid_1's rmse: 3.65266\n",
      "[2500]\ttraining's rmse: 3.05071\tvalid_1's rmse: 3.65268\n",
      "[2600]\ttraining's rmse: 3.03681\tvalid_1's rmse: 3.65274\n",
      "[2700]\ttraining's rmse: 3.02376\tvalid_1's rmse: 3.65306\n",
      "[2800]\ttraining's rmse: 3.00966\tvalid_1's rmse: 3.65343\n",
      "Early stopping, best iteration is:\n",
      "[2280]\ttraining's rmse: 3.08156\tvalid_1's rmse: 3.65194\n",
      "fold 1 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64301\tvalid_1's rmse: 3.70839\n",
      "[200]\ttraining's rmse: 3.5511\tvalid_1's rmse: 3.67468\n",
      "[300]\ttraining's rmse: 3.49542\tvalid_1's rmse: 3.66209\n",
      "[400]\ttraining's rmse: 3.45405\tvalid_1's rmse: 3.65482\n",
      "[500]\ttraining's rmse: 3.41997\tvalid_1's rmse: 3.6503\n",
      "[600]\ttraining's rmse: 3.39268\tvalid_1's rmse: 3.64834\n",
      "[700]\ttraining's rmse: 3.36706\tvalid_1's rmse: 3.64694\n",
      "[800]\ttraining's rmse: 3.34434\tvalid_1's rmse: 3.64567\n",
      "[900]\ttraining's rmse: 3.32228\tvalid_1's rmse: 3.64598\n",
      "[1000]\ttraining's rmse: 3.30295\tvalid_1's rmse: 3.64558\n",
      "[1100]\ttraining's rmse: 3.28399\tvalid_1's rmse: 3.6462\n",
      "[1200]\ttraining's rmse: 3.26453\tvalid_1's rmse: 3.64584\n",
      "[1300]\ttraining's rmse: 3.24609\tvalid_1's rmse: 3.64612\n",
      "[1400]\ttraining's rmse: 3.22848\tvalid_1's rmse: 3.64684\n",
      "[1500]\ttraining's rmse: 3.21054\tvalid_1's rmse: 3.64637\n",
      "Early stopping, best iteration is:\n",
      "[972]\ttraining's rmse: 3.30836\tvalid_1's rmse: 3.64487\n",
      "fold 2 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64257\tvalid_1's rmse: 3.70945\n",
      "[200]\ttraining's rmse: 3.55143\tvalid_1's rmse: 3.67412\n",
      "[300]\ttraining's rmse: 3.49475\tvalid_1's rmse: 3.66312\n",
      "[400]\ttraining's rmse: 3.45368\tvalid_1's rmse: 3.65717\n",
      "[500]\ttraining's rmse: 3.42001\tvalid_1's rmse: 3.65389\n",
      "[600]\ttraining's rmse: 3.39176\tvalid_1's rmse: 3.65198\n",
      "[700]\ttraining's rmse: 3.36668\tvalid_1's rmse: 3.6513\n",
      "[800]\ttraining's rmse: 3.3423\tvalid_1's rmse: 3.65154\n",
      "[900]\ttraining's rmse: 3.31957\tvalid_1's rmse: 3.6512\n",
      "[1000]\ttraining's rmse: 3.29998\tvalid_1's rmse: 3.65207\n",
      "[1100]\ttraining's rmse: 3.28043\tvalid_1's rmse: 3.6514\n",
      "[1200]\ttraining's rmse: 3.2611\tvalid_1's rmse: 3.6511\n",
      "[1300]\ttraining's rmse: 3.24318\tvalid_1's rmse: 3.65144\n",
      "[1400]\ttraining's rmse: 3.22562\tvalid_1's rmse: 3.65123\n",
      "[1500]\ttraining's rmse: 3.20826\tvalid_1's rmse: 3.65159\n",
      "[1600]\ttraining's rmse: 3.19207\tvalid_1's rmse: 3.65158\n",
      "[1700]\ttraining's rmse: 3.17597\tvalid_1's rmse: 3.65187\n",
      "Early stopping, best iteration is:\n",
      "[1192]\ttraining's rmse: 3.26273\tvalid_1's rmse: 3.65093\n",
      "fold 3 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64654\tvalid_1's rmse: 3.69635\n",
      "[200]\ttraining's rmse: 3.55796\tvalid_1's rmse: 3.65221\n",
      "[300]\ttraining's rmse: 3.50169\tvalid_1's rmse: 3.63541\n",
      "[400]\ttraining's rmse: 3.46051\tvalid_1's rmse: 3.62716\n",
      "[500]\ttraining's rmse: 3.42805\tvalid_1's rmse: 3.62101\n",
      "[600]\ttraining's rmse: 3.39903\tvalid_1's rmse: 3.61537\n",
      "[700]\ttraining's rmse: 3.37367\tvalid_1's rmse: 3.61283\n",
      "[800]\ttraining's rmse: 3.35011\tvalid_1's rmse: 3.61069\n",
      "[900]\ttraining's rmse: 3.32782\tvalid_1's rmse: 3.60918\n",
      "[1000]\ttraining's rmse: 3.30764\tvalid_1's rmse: 3.60857\n",
      "[1100]\ttraining's rmse: 3.28759\tvalid_1's rmse: 3.60793\n",
      "[1200]\ttraining's rmse: 3.26955\tvalid_1's rmse: 3.60717\n",
      "[1300]\ttraining's rmse: 3.25036\tvalid_1's rmse: 3.60692\n",
      "[1400]\ttraining's rmse: 3.23213\tvalid_1's rmse: 3.60619\n",
      "[1500]\ttraining's rmse: 3.21598\tvalid_1's rmse: 3.60584\n",
      "[1600]\ttraining's rmse: 3.20046\tvalid_1's rmse: 3.60603\n",
      "[1700]\ttraining's rmse: 3.18421\tvalid_1's rmse: 3.60565\n",
      "[1800]\ttraining's rmse: 3.16798\tvalid_1's rmse: 3.60603\n",
      "[1900]\ttraining's rmse: 3.15196\tvalid_1's rmse: 3.60633\n",
      "[2000]\ttraining's rmse: 3.13593\tvalid_1's rmse: 3.60597\n",
      "[2100]\ttraining's rmse: 3.12002\tvalid_1's rmse: 3.60609\n",
      "[2200]\ttraining's rmse: 3.10413\tvalid_1's rmse: 3.60548\n",
      "[2300]\ttraining's rmse: 3.08937\tvalid_1's rmse: 3.60566\n",
      "[2400]\ttraining's rmse: 3.07499\tvalid_1's rmse: 3.60581\n",
      "[2500]\ttraining's rmse: 3.06051\tvalid_1's rmse: 3.60544\n",
      "[2600]\ttraining's rmse: 3.04636\tvalid_1's rmse: 3.60529\n",
      "[2700]\ttraining's rmse: 3.03197\tvalid_1's rmse: 3.60542\n",
      "[2800]\ttraining's rmse: 3.01932\tvalid_1's rmse: 3.60552\n",
      "[2900]\ttraining's rmse: 3.00532\tvalid_1's rmse: 3.60566\n",
      "[3000]\ttraining's rmse: 2.99284\tvalid_1's rmse: 3.60629\n",
      "[3100]\ttraining's rmse: 2.9794\tvalid_1's rmse: 3.60679\n",
      "[3200]\ttraining's rmse: 2.96725\tvalid_1's rmse: 3.60711\n",
      "Early stopping, best iteration is:\n",
      "[2614]\ttraining's rmse: 3.04458\tvalid_1's rmse: 3.6049\n",
      "fold 4 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64258\tvalid_1's rmse: 3.71612\n",
      "[200]\ttraining's rmse: 3.55101\tvalid_1's rmse: 3.68227\n",
      "[300]\ttraining's rmse: 3.49579\tvalid_1's rmse: 3.66957\n",
      "[400]\ttraining's rmse: 3.45345\tvalid_1's rmse: 3.66325\n",
      "[500]\ttraining's rmse: 3.41818\tvalid_1's rmse: 3.6596\n",
      "[600]\ttraining's rmse: 3.3898\tvalid_1's rmse: 3.65668\n",
      "[700]\ttraining's rmse: 3.36441\tvalid_1's rmse: 3.6559\n",
      "[800]\ttraining's rmse: 3.3404\tvalid_1's rmse: 3.65605\n",
      "[900]\ttraining's rmse: 3.3185\tvalid_1's rmse: 3.65625\n",
      "[1000]\ttraining's rmse: 3.29809\tvalid_1's rmse: 3.65646\n",
      "[1100]\ttraining's rmse: 3.27711\tvalid_1's rmse: 3.65725\n",
      "[1200]\ttraining's rmse: 3.25826\tvalid_1's rmse: 3.65807\n",
      "[1300]\ttraining's rmse: 3.24017\tvalid_1's rmse: 3.65878\n",
      "Early stopping, best iteration is:\n",
      "[717]\ttraining's rmse: 3.36036\tvalid_1's rmse: 3.65537\n",
      "fold 5 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.63963\tvalid_1's rmse: 3.72506\n",
      "[200]\ttraining's rmse: 3.54658\tvalid_1's rmse: 3.69884\n",
      "[300]\ttraining's rmse: 3.48891\tvalid_1's rmse: 3.68806\n",
      "[400]\ttraining's rmse: 3.44705\tvalid_1's rmse: 3.68286\n",
      "[500]\ttraining's rmse: 3.4145\tvalid_1's rmse: 3.67948\n",
      "[600]\ttraining's rmse: 3.38612\tvalid_1's rmse: 3.67792\n",
      "[700]\ttraining's rmse: 3.36113\tvalid_1's rmse: 3.67701\n",
      "[800]\ttraining's rmse: 3.33741\tvalid_1's rmse: 3.67523\n",
      "[900]\ttraining's rmse: 3.3144\tvalid_1's rmse: 3.67462\n",
      "[1000]\ttraining's rmse: 3.29296\tvalid_1's rmse: 3.6748\n",
      "[1100]\ttraining's rmse: 3.27246\tvalid_1's rmse: 3.67454\n",
      "[1200]\ttraining's rmse: 3.25335\tvalid_1's rmse: 3.67458\n",
      "[1300]\ttraining's rmse: 3.23568\tvalid_1's rmse: 3.67467\n",
      "[1400]\ttraining's rmse: 3.21714\tvalid_1's rmse: 3.6744\n",
      "[1500]\ttraining's rmse: 3.20062\tvalid_1's rmse: 3.67409\n",
      "[1600]\ttraining's rmse: 3.18398\tvalid_1's rmse: 3.67388\n",
      "[1700]\ttraining's rmse: 3.16759\tvalid_1's rmse: 3.67392\n",
      "[1800]\ttraining's rmse: 3.15056\tvalid_1's rmse: 3.67382\n",
      "[1900]\ttraining's rmse: 3.13462\tvalid_1's rmse: 3.6735\n",
      "[2000]\ttraining's rmse: 3.11897\tvalid_1's rmse: 3.6736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100]\ttraining's rmse: 3.10346\tvalid_1's rmse: 3.67354\n",
      "[2200]\ttraining's rmse: 3.08843\tvalid_1's rmse: 3.67375\n",
      "[2300]\ttraining's rmse: 3.07393\tvalid_1's rmse: 3.6736\n",
      "[2400]\ttraining's rmse: 3.05838\tvalid_1's rmse: 3.67379\n",
      "[2500]\ttraining's rmse: 3.04451\tvalid_1's rmse: 3.67399\n",
      "[2600]\ttraining's rmse: 3.03106\tvalid_1's rmse: 3.67413\n",
      "[2700]\ttraining's rmse: 3.01741\tvalid_1's rmse: 3.67463\n",
      "[2800]\ttraining's rmse: 3.004\tvalid_1's rmse: 3.67545\n",
      "[2900]\ttraining's rmse: 2.9904\tvalid_1's rmse: 3.67634\n",
      "Early stopping, best iteration is:\n",
      "[2338]\ttraining's rmse: 3.06783\tvalid_1's rmse: 3.67325\n",
      "fold 6 1590 0.010936855138258357\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64405\tvalid_1's rmse: 3.69235\n",
      "[200]\ttraining's rmse: 3.5528\tvalid_1's rmse: 3.65098\n",
      "[300]\ttraining's rmse: 3.49793\tvalid_1's rmse: 3.63523\n",
      "[400]\ttraining's rmse: 3.45652\tvalid_1's rmse: 3.62658\n",
      "[500]\ttraining's rmse: 3.42253\tvalid_1's rmse: 3.62047\n",
      "[600]\ttraining's rmse: 3.39267\tvalid_1's rmse: 3.61719\n",
      "[700]\ttraining's rmse: 3.36557\tvalid_1's rmse: 3.614\n",
      "[800]\ttraining's rmse: 3.3412\tvalid_1's rmse: 3.61192\n",
      "[900]\ttraining's rmse: 3.31887\tvalid_1's rmse: 3.61075\n",
      "[1000]\ttraining's rmse: 3.2977\tvalid_1's rmse: 3.60921\n",
      "[1100]\ttraining's rmse: 3.27748\tvalid_1's rmse: 3.60832\n",
      "[1200]\ttraining's rmse: 3.25773\tvalid_1's rmse: 3.60837\n",
      "[1300]\ttraining's rmse: 3.23905\tvalid_1's rmse: 3.6076\n",
      "[1400]\ttraining's rmse: 3.22055\tvalid_1's rmse: 3.60735\n",
      "[1500]\ttraining's rmse: 3.20249\tvalid_1's rmse: 3.60821\n",
      "[1600]\ttraining's rmse: 3.18563\tvalid_1's rmse: 3.60714\n",
      "[1700]\ttraining's rmse: 3.16885\tvalid_1's rmse: 3.60685\n",
      "[1800]\ttraining's rmse: 3.15261\tvalid_1's rmse: 3.60717\n",
      "[1900]\ttraining's rmse: 3.13703\tvalid_1's rmse: 3.60666\n",
      "[2000]\ttraining's rmse: 3.12232\tvalid_1's rmse: 3.60628\n",
      "[2100]\ttraining's rmse: 3.10682\tvalid_1's rmse: 3.60661\n",
      "[2200]\ttraining's rmse: 3.09081\tvalid_1's rmse: 3.6069\n",
      "[2300]\ttraining's rmse: 3.07664\tvalid_1's rmse: 3.60717\n",
      "[2400]\ttraining's rmse: 3.06314\tvalid_1's rmse: 3.60809\n",
      "[2500]\ttraining's rmse: 3.0486\tvalid_1's rmse: 3.60878\n",
      "[2600]\ttraining's rmse: 3.03392\tvalid_1's rmse: 3.60893\n",
      "Early stopping, best iteration is:\n",
      "[2039]\ttraining's rmse: 3.11574\tvalid_1's rmse: 3.60607\n",
      "fold 7 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64534\tvalid_1's rmse: 3.70649\n",
      "[200]\ttraining's rmse: 3.55506\tvalid_1's rmse: 3.66486\n",
      "[300]\ttraining's rmse: 3.50111\tvalid_1's rmse: 3.64838\n",
      "[400]\ttraining's rmse: 3.4593\tvalid_1's rmse: 3.63889\n",
      "[500]\ttraining's rmse: 3.426\tvalid_1's rmse: 3.63388\n",
      "[600]\ttraining's rmse: 3.39768\tvalid_1's rmse: 3.6298\n",
      "[700]\ttraining's rmse: 3.37184\tvalid_1's rmse: 3.62757\n",
      "[800]\ttraining's rmse: 3.34817\tvalid_1's rmse: 3.62652\n",
      "[900]\ttraining's rmse: 3.32603\tvalid_1's rmse: 3.62617\n",
      "[1000]\ttraining's rmse: 3.30517\tvalid_1's rmse: 3.62552\n",
      "[1100]\ttraining's rmse: 3.28477\tvalid_1's rmse: 3.62517\n",
      "[1200]\ttraining's rmse: 3.26477\tvalid_1's rmse: 3.62483\n",
      "[1300]\ttraining's rmse: 3.24617\tvalid_1's rmse: 3.62416\n",
      "[1400]\ttraining's rmse: 3.2279\tvalid_1's rmse: 3.62314\n",
      "[1500]\ttraining's rmse: 3.21077\tvalid_1's rmse: 3.62251\n",
      "[1600]\ttraining's rmse: 3.19368\tvalid_1's rmse: 3.62233\n",
      "[1700]\ttraining's rmse: 3.17647\tvalid_1's rmse: 3.62126\n",
      "[1800]\ttraining's rmse: 3.1606\tvalid_1's rmse: 3.62122\n",
      "[1900]\ttraining's rmse: 3.14494\tvalid_1's rmse: 3.62202\n",
      "[2000]\ttraining's rmse: 3.13063\tvalid_1's rmse: 3.622\n",
      "[2100]\ttraining's rmse: 3.11504\tvalid_1's rmse: 3.62093\n",
      "[2200]\ttraining's rmse: 3.1001\tvalid_1's rmse: 3.62018\n",
      "[2300]\ttraining's rmse: 3.085\tvalid_1's rmse: 3.61988\n",
      "[2400]\ttraining's rmse: 3.07002\tvalid_1's rmse: 3.62032\n",
      "[2500]\ttraining's rmse: 3.0549\tvalid_1's rmse: 3.62048\n",
      "[2600]\ttraining's rmse: 3.04051\tvalid_1's rmse: 3.62067\n",
      "[2700]\ttraining's rmse: 3.02667\tvalid_1's rmse: 3.62057\n",
      "[2800]\ttraining's rmse: 3.01319\tvalid_1's rmse: 3.62061\n",
      "[2900]\ttraining's rmse: 2.99982\tvalid_1's rmse: 3.62051\n",
      "Early stopping, best iteration is:\n",
      "[2304]\ttraining's rmse: 3.08419\tvalid_1's rmse: 3.61973\n",
      "fold 8 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.6374\tvalid_1's rmse: 3.73802\n",
      "[200]\ttraining's rmse: 3.54459\tvalid_1's rmse: 3.71207\n",
      "[300]\ttraining's rmse: 3.48985\tvalid_1's rmse: 3.70135\n",
      "[400]\ttraining's rmse: 3.44951\tvalid_1's rmse: 3.69517\n",
      "[500]\ttraining's rmse: 3.41686\tvalid_1's rmse: 3.69207\n",
      "[600]\ttraining's rmse: 3.38852\tvalid_1's rmse: 3.68931\n",
      "[700]\ttraining's rmse: 3.36197\tvalid_1's rmse: 3.68713\n",
      "[800]\ttraining's rmse: 3.338\tvalid_1's rmse: 3.68587\n",
      "[900]\ttraining's rmse: 3.31576\tvalid_1's rmse: 3.68506\n",
      "[1000]\ttraining's rmse: 3.29474\tvalid_1's rmse: 3.68446\n",
      "[1100]\ttraining's rmse: 3.27398\tvalid_1's rmse: 3.68458\n",
      "[1200]\ttraining's rmse: 3.25572\tvalid_1's rmse: 3.68363\n",
      "[1300]\ttraining's rmse: 3.23815\tvalid_1's rmse: 3.68331\n",
      "[1400]\ttraining's rmse: 3.22048\tvalid_1's rmse: 3.68271\n",
      "[1500]\ttraining's rmse: 3.20348\tvalid_1's rmse: 3.68309\n",
      "[1600]\ttraining's rmse: 3.18791\tvalid_1's rmse: 3.68316\n",
      "[1700]\ttraining's rmse: 3.17157\tvalid_1's rmse: 3.68292\n",
      "[1800]\ttraining's rmse: 3.15515\tvalid_1's rmse: 3.68386\n",
      "[1900]\ttraining's rmse: 3.1385\tvalid_1's rmse: 3.68396\n",
      "Early stopping, best iteration is:\n",
      "[1380]\ttraining's rmse: 3.22411\tvalid_1's rmse: 3.68251\n",
      "fold 9 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64099\tvalid_1's rmse: 3.71098\n",
      "[200]\ttraining's rmse: 3.54774\tvalid_1's rmse: 3.69179\n",
      "[300]\ttraining's rmse: 3.49251\tvalid_1's rmse: 3.68578\n",
      "[400]\ttraining's rmse: 3.4514\tvalid_1's rmse: 3.6842\n",
      "[500]\ttraining's rmse: 3.41782\tvalid_1's rmse: 3.68182\n",
      "[600]\ttraining's rmse: 3.38652\tvalid_1's rmse: 3.68058\n",
      "[700]\ttraining's rmse: 3.36001\tvalid_1's rmse: 3.67972\n",
      "[800]\ttraining's rmse: 3.33747\tvalid_1's rmse: 3.68035\n",
      "[900]\ttraining's rmse: 3.31598\tvalid_1's rmse: 3.68069\n",
      "[1000]\ttraining's rmse: 3.29614\tvalid_1's rmse: 3.6812\n",
      "[1100]\ttraining's rmse: 3.27647\tvalid_1's rmse: 3.6814\n",
      "[1200]\ttraining's rmse: 3.2574\tvalid_1's rmse: 3.6809\n",
      "[1300]\ttraining's rmse: 3.23977\tvalid_1's rmse: 3.68143\n",
      "Early stopping, best iteration is:\n",
      "[725]\ttraining's rmse: 3.35421\tvalid_1's rmse: 3.67965\n",
      "fold 0 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64771\tvalid_1's rmse: 3.70797\n",
      "[200]\ttraining's rmse: 3.56106\tvalid_1's rmse: 3.68023\n",
      "[300]\ttraining's rmse: 3.5101\tvalid_1's rmse: 3.66858\n",
      "[400]\ttraining's rmse: 3.47095\tvalid_1's rmse: 3.66468\n",
      "[500]\ttraining's rmse: 3.44025\tvalid_1's rmse: 3.65985\n",
      "[600]\ttraining's rmse: 3.41403\tvalid_1's rmse: 3.65807\n",
      "[700]\ttraining's rmse: 3.3909\tvalid_1's rmse: 3.65557\n",
      "[800]\ttraining's rmse: 3.36875\tvalid_1's rmse: 3.6548\n",
      "[900]\ttraining's rmse: 3.34847\tvalid_1's rmse: 3.65337\n",
      "[1000]\ttraining's rmse: 3.3295\tvalid_1's rmse: 3.65295\n",
      "[1100]\ttraining's rmse: 3.31187\tvalid_1's rmse: 3.65275\n",
      "[1200]\ttraining's rmse: 3.2945\tvalid_1's rmse: 3.65233\n",
      "[1300]\ttraining's rmse: 3.27877\tvalid_1's rmse: 3.65213\n",
      "[1400]\ttraining's rmse: 3.26159\tvalid_1's rmse: 3.65225\n",
      "[1500]\ttraining's rmse: 3.24575\tvalid_1's rmse: 3.65225\n",
      "[1600]\ttraining's rmse: 3.23018\tvalid_1's rmse: 3.65188\n",
      "[1700]\ttraining's rmse: 3.21481\tvalid_1's rmse: 3.65178\n",
      "[1800]\ttraining's rmse: 3.1993\tvalid_1's rmse: 3.65191\n",
      "[1900]\ttraining's rmse: 3.18421\tvalid_1's rmse: 3.65188\n",
      "[2000]\ttraining's rmse: 3.17047\tvalid_1's rmse: 3.65143\n",
      "[2100]\ttraining's rmse: 3.1553\tvalid_1's rmse: 3.65103\n",
      "[2200]\ttraining's rmse: 3.14108\tvalid_1's rmse: 3.65076\n",
      "[2300]\ttraining's rmse: 3.12677\tvalid_1's rmse: 3.65085\n",
      "[2400]\ttraining's rmse: 3.11303\tvalid_1's rmse: 3.65133\n",
      "[2500]\ttraining's rmse: 3.09975\tvalid_1's rmse: 3.65149\n",
      "[2600]\ttraining's rmse: 3.08745\tvalid_1's rmse: 3.6516\n",
      "[2700]\ttraining's rmse: 3.07539\tvalid_1's rmse: 3.65178\n",
      "[2800]\ttraining's rmse: 3.06183\tvalid_1's rmse: 3.65247\n",
      "[2900]\ttraining's rmse: 3.04969\tvalid_1's rmse: 3.65273\n",
      "Early stopping, best iteration is:\n",
      "[2323]\ttraining's rmse: 3.12349\tvalid_1's rmse: 3.65062\n",
      "fold 1 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64794\tvalid_1's rmse: 3.70787\n",
      "[200]\ttraining's rmse: 3.56141\tvalid_1's rmse: 3.67504\n",
      "[300]\ttraining's rmse: 3.5099\tvalid_1's rmse: 3.6611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 3.47222\tvalid_1's rmse: 3.6537\n",
      "[500]\ttraining's rmse: 3.44032\tvalid_1's rmse: 3.64894\n",
      "[600]\ttraining's rmse: 3.41495\tvalid_1's rmse: 3.64622\n",
      "[700]\ttraining's rmse: 3.39158\tvalid_1's rmse: 3.64505\n",
      "[800]\ttraining's rmse: 3.36981\tvalid_1's rmse: 3.64564\n",
      "[900]\ttraining's rmse: 3.34966\tvalid_1's rmse: 3.64478\n",
      "[1000]\ttraining's rmse: 3.32964\tvalid_1's rmse: 3.64545\n",
      "[1100]\ttraining's rmse: 3.31115\tvalid_1's rmse: 3.6452\n",
      "[1200]\ttraining's rmse: 3.29523\tvalid_1's rmse: 3.64443\n",
      "[1300]\ttraining's rmse: 3.27946\tvalid_1's rmse: 3.64525\n",
      "[1400]\ttraining's rmse: 3.2632\tvalid_1's rmse: 3.64522\n",
      "[1500]\ttraining's rmse: 3.247\tvalid_1's rmse: 3.64548\n",
      "[1600]\ttraining's rmse: 3.23151\tvalid_1's rmse: 3.64584\n",
      "[1700]\ttraining's rmse: 3.21636\tvalid_1's rmse: 3.64614\n",
      "[1800]\ttraining's rmse: 3.20188\tvalid_1's rmse: 3.6467\n",
      "Early stopping, best iteration is:\n",
      "[1217]\ttraining's rmse: 3.29277\tvalid_1's rmse: 3.64426\n",
      "fold 2 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64777\tvalid_1's rmse: 3.70876\n",
      "[200]\ttraining's rmse: 3.55945\tvalid_1's rmse: 3.67338\n",
      "[300]\ttraining's rmse: 3.50737\tvalid_1's rmse: 3.66184\n",
      "[400]\ttraining's rmse: 3.46867\tvalid_1's rmse: 3.65716\n",
      "[500]\ttraining's rmse: 3.43622\tvalid_1's rmse: 3.65457\n",
      "[600]\ttraining's rmse: 3.41023\tvalid_1's rmse: 3.65336\n",
      "[700]\ttraining's rmse: 3.38626\tvalid_1's rmse: 3.6524\n",
      "[800]\ttraining's rmse: 3.36475\tvalid_1's rmse: 3.65225\n",
      "[900]\ttraining's rmse: 3.34485\tvalid_1's rmse: 3.65205\n",
      "[1000]\ttraining's rmse: 3.32663\tvalid_1's rmse: 3.65306\n",
      "[1100]\ttraining's rmse: 3.30867\tvalid_1's rmse: 3.65297\n",
      "[1200]\ttraining's rmse: 3.2908\tvalid_1's rmse: 3.65219\n",
      "[1300]\ttraining's rmse: 3.27394\tvalid_1's rmse: 3.65263\n",
      "Early stopping, best iteration is:\n",
      "[768]\ttraining's rmse: 3.37118\tvalid_1's rmse: 3.65148\n",
      "fold 3 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65048\tvalid_1's rmse: 3.69577\n",
      "[200]\ttraining's rmse: 3.56595\tvalid_1's rmse: 3.65164\n",
      "[300]\ttraining's rmse: 3.51465\tvalid_1's rmse: 3.63613\n",
      "[400]\ttraining's rmse: 3.47617\tvalid_1's rmse: 3.62805\n",
      "[500]\ttraining's rmse: 3.44624\tvalid_1's rmse: 3.62168\n",
      "[600]\ttraining's rmse: 3.42136\tvalid_1's rmse: 3.61749\n",
      "[700]\ttraining's rmse: 3.39806\tvalid_1's rmse: 3.6162\n",
      "[800]\ttraining's rmse: 3.37669\tvalid_1's rmse: 3.61417\n",
      "[900]\ttraining's rmse: 3.35653\tvalid_1's rmse: 3.61253\n",
      "[1000]\ttraining's rmse: 3.33698\tvalid_1's rmse: 3.61094\n",
      "[1100]\ttraining's rmse: 3.31886\tvalid_1's rmse: 3.61068\n",
      "[1200]\ttraining's rmse: 3.30143\tvalid_1's rmse: 3.61056\n",
      "[1300]\ttraining's rmse: 3.28349\tvalid_1's rmse: 3.61069\n",
      "[1400]\ttraining's rmse: 3.26655\tvalid_1's rmse: 3.61041\n",
      "[1500]\ttraining's rmse: 3.25149\tvalid_1's rmse: 3.61078\n",
      "[1600]\ttraining's rmse: 3.23658\tvalid_1's rmse: 3.61076\n",
      "[1700]\ttraining's rmse: 3.22131\tvalid_1's rmse: 3.6114\n",
      "Early stopping, best iteration is:\n",
      "[1161]\ttraining's rmse: 3.30813\tvalid_1's rmse: 3.61033\n",
      "fold 4 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64634\tvalid_1's rmse: 3.71503\n",
      "[200]\ttraining's rmse: 3.5605\tvalid_1's rmse: 3.68113\n",
      "[300]\ttraining's rmse: 3.50921\tvalid_1's rmse: 3.66978\n",
      "[400]\ttraining's rmse: 3.47133\tvalid_1's rmse: 3.66312\n",
      "[500]\ttraining's rmse: 3.43869\tvalid_1's rmse: 3.65932\n",
      "[600]\ttraining's rmse: 3.41206\tvalid_1's rmse: 3.65748\n",
      "[700]\ttraining's rmse: 3.38859\tvalid_1's rmse: 3.65575\n",
      "[800]\ttraining's rmse: 3.36717\tvalid_1's rmse: 3.65567\n",
      "[900]\ttraining's rmse: 3.34757\tvalid_1's rmse: 3.65559\n",
      "[1000]\ttraining's rmse: 3.32901\tvalid_1's rmse: 3.65541\n",
      "[1100]\ttraining's rmse: 3.30965\tvalid_1's rmse: 3.65691\n",
      "[1200]\ttraining's rmse: 3.29222\tvalid_1's rmse: 3.65769\n",
      "[1300]\ttraining's rmse: 3.27487\tvalid_1's rmse: 3.65823\n",
      "[1400]\ttraining's rmse: 3.25774\tvalid_1's rmse: 3.65975\n",
      "[1500]\ttraining's rmse: 3.24197\tvalid_1's rmse: 3.66085\n",
      "Early stopping, best iteration is:\n",
      "[971]\ttraining's rmse: 3.33424\tvalid_1's rmse: 3.65519\n",
      "fold 5 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64543\tvalid_1's rmse: 3.71946\n",
      "[200]\ttraining's rmse: 3.55615\tvalid_1's rmse: 3.69203\n",
      "[300]\ttraining's rmse: 3.50327\tvalid_1's rmse: 3.68158\n",
      "[400]\ttraining's rmse: 3.46416\tvalid_1's rmse: 3.67699\n",
      "[500]\ttraining's rmse: 3.43359\tvalid_1's rmse: 3.67401\n",
      "[600]\ttraining's rmse: 3.40783\tvalid_1's rmse: 3.67278\n",
      "[700]\ttraining's rmse: 3.38461\tvalid_1's rmse: 3.67128\n",
      "[800]\ttraining's rmse: 3.36249\tvalid_1's rmse: 3.67082\n",
      "[900]\ttraining's rmse: 3.34321\tvalid_1's rmse: 3.67057\n",
      "[1000]\ttraining's rmse: 3.32372\tvalid_1's rmse: 3.67053\n",
      "[1100]\ttraining's rmse: 3.30586\tvalid_1's rmse: 3.67083\n",
      "[1200]\ttraining's rmse: 3.28856\tvalid_1's rmse: 3.67107\n",
      "[1300]\ttraining's rmse: 3.2718\tvalid_1's rmse: 3.67061\n",
      "[1400]\ttraining's rmse: 3.25464\tvalid_1's rmse: 3.67051\n",
      "Early stopping, best iteration is:\n",
      "[885]\ttraining's rmse: 3.34629\tvalid_1's rmse: 3.67002\n",
      "fold 6 1590 0.010936855138258357\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64944\tvalid_1's rmse: 3.68995\n",
      "[200]\ttraining's rmse: 3.5631\tvalid_1's rmse: 3.64885\n",
      "[300]\ttraining's rmse: 3.51268\tvalid_1's rmse: 3.63126\n",
      "[400]\ttraining's rmse: 3.47396\tvalid_1's rmse: 3.62256\n",
      "[500]\ttraining's rmse: 3.44202\tvalid_1's rmse: 3.61782\n",
      "[600]\ttraining's rmse: 3.41365\tvalid_1's rmse: 3.6153\n",
      "[700]\ttraining's rmse: 3.38866\tvalid_1's rmse: 3.61448\n",
      "[800]\ttraining's rmse: 3.36631\tvalid_1's rmse: 3.61273\n",
      "[900]\ttraining's rmse: 3.34585\tvalid_1's rmse: 3.61338\n",
      "[1000]\ttraining's rmse: 3.32555\tvalid_1's rmse: 3.61344\n",
      "[1100]\ttraining's rmse: 3.30638\tvalid_1's rmse: 3.61383\n",
      "[1200]\ttraining's rmse: 3.28883\tvalid_1's rmse: 3.61339\n",
      "[1300]\ttraining's rmse: 3.27139\tvalid_1's rmse: 3.61353\n",
      "[1400]\ttraining's rmse: 3.25561\tvalid_1's rmse: 3.61304\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's rmse: 3.36631\tvalid_1's rmse: 3.61273\n",
      "fold 7 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64965\tvalid_1's rmse: 3.70041\n",
      "[200]\ttraining's rmse: 3.56463\tvalid_1's rmse: 3.65961\n",
      "[300]\ttraining's rmse: 3.51303\tvalid_1's rmse: 3.64364\n",
      "[400]\ttraining's rmse: 3.4754\tvalid_1's rmse: 3.63471\n",
      "[500]\ttraining's rmse: 3.44338\tvalid_1's rmse: 3.62827\n",
      "[600]\ttraining's rmse: 3.4167\tvalid_1's rmse: 3.62465\n",
      "[700]\ttraining's rmse: 3.39384\tvalid_1's rmse: 3.62237\n",
      "[800]\ttraining's rmse: 3.37297\tvalid_1's rmse: 3.6209\n",
      "[900]\ttraining's rmse: 3.35348\tvalid_1's rmse: 3.61953\n",
      "[1000]\ttraining's rmse: 3.33435\tvalid_1's rmse: 3.61935\n",
      "[1100]\ttraining's rmse: 3.31666\tvalid_1's rmse: 3.61925\n",
      "[1200]\ttraining's rmse: 3.29908\tvalid_1's rmse: 3.61846\n",
      "[1300]\ttraining's rmse: 3.28284\tvalid_1's rmse: 3.61867\n",
      "[1400]\ttraining's rmse: 3.26658\tvalid_1's rmse: 3.61813\n",
      "[1500]\ttraining's rmse: 3.2494\tvalid_1's rmse: 3.61877\n",
      "[1600]\ttraining's rmse: 3.23313\tvalid_1's rmse: 3.61865\n",
      "[1700]\ttraining's rmse: 3.21812\tvalid_1's rmse: 3.61852\n",
      "[1800]\ttraining's rmse: 3.20217\tvalid_1's rmse: 3.61833\n",
      "[1900]\ttraining's rmse: 3.18791\tvalid_1's rmse: 3.6185\n",
      "Early stopping, best iteration is:\n",
      "[1367]\ttraining's rmse: 3.2717\tvalid_1's rmse: 3.61799\n",
      "fold 8 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64227\tvalid_1's rmse: 3.73808\n",
      "[200]\ttraining's rmse: 3.55381\tvalid_1's rmse: 3.71119\n",
      "[300]\ttraining's rmse: 3.50171\tvalid_1's rmse: 3.70135\n",
      "[400]\ttraining's rmse: 3.46391\tvalid_1's rmse: 3.69485\n",
      "[500]\ttraining's rmse: 3.43262\tvalid_1's rmse: 3.69011\n",
      "[600]\ttraining's rmse: 3.40517\tvalid_1's rmse: 3.68765\n",
      "[700]\ttraining's rmse: 3.38081\tvalid_1's rmse: 3.68682\n",
      "[800]\ttraining's rmse: 3.35955\tvalid_1's rmse: 3.68527\n",
      "[900]\ttraining's rmse: 3.33951\tvalid_1's rmse: 3.68504\n",
      "[1000]\ttraining's rmse: 3.32121\tvalid_1's rmse: 3.68435\n",
      "[1100]\ttraining's rmse: 3.30259\tvalid_1's rmse: 3.68435\n",
      "[1200]\ttraining's rmse: 3.28505\tvalid_1's rmse: 3.68426\n",
      "[1300]\ttraining's rmse: 3.26843\tvalid_1's rmse: 3.68386\n",
      "[1400]\ttraining's rmse: 3.25248\tvalid_1's rmse: 3.68396\n",
      "[1500]\ttraining's rmse: 3.23601\tvalid_1's rmse: 3.68441\n",
      "[1600]\ttraining's rmse: 3.22075\tvalid_1's rmse: 3.68495\n",
      "[1700]\ttraining's rmse: 3.20544\tvalid_1's rmse: 3.6858\n",
      "[1800]\ttraining's rmse: 3.19042\tvalid_1's rmse: 3.68576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\ttraining's rmse: 3.17613\tvalid_1's rmse: 3.68672\n",
      "Early stopping, best iteration is:\n",
      "[1333]\ttraining's rmse: 3.26336\tvalid_1's rmse: 3.68354\n",
      "fold 9 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64504\tvalid_1's rmse: 3.70986\n",
      "[200]\ttraining's rmse: 3.55657\tvalid_1's rmse: 3.68939\n",
      "[300]\ttraining's rmse: 3.50426\tvalid_1's rmse: 3.68367\n",
      "[400]\ttraining's rmse: 3.46445\tvalid_1's rmse: 3.68273\n",
      "[500]\ttraining's rmse: 3.43346\tvalid_1's rmse: 3.68109\n",
      "[600]\ttraining's rmse: 3.40632\tvalid_1's rmse: 3.68133\n",
      "[700]\ttraining's rmse: 3.38262\tvalid_1's rmse: 3.68135\n",
      "[800]\ttraining's rmse: 3.36024\tvalid_1's rmse: 3.68242\n",
      "[900]\ttraining's rmse: 3.34055\tvalid_1's rmse: 3.68219\n",
      "[1000]\ttraining's rmse: 3.32169\tvalid_1's rmse: 3.6832\n",
      "[1100]\ttraining's rmse: 3.30391\tvalid_1's rmse: 3.68375\n",
      "Early stopping, best iteration is:\n",
      "[523]\ttraining's rmse: 3.42703\tvalid_1's rmse: 3.68107\n",
      "fold 0 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64946\tvalid_1's rmse: 3.7068\n",
      "[200]\ttraining's rmse: 3.56509\tvalid_1's rmse: 3.67773\n",
      "[300]\ttraining's rmse: 3.51561\tvalid_1's rmse: 3.66686\n",
      "[400]\ttraining's rmse: 3.47767\tvalid_1's rmse: 3.66078\n",
      "[500]\ttraining's rmse: 3.44773\tvalid_1's rmse: 3.65791\n",
      "[600]\ttraining's rmse: 3.42199\tvalid_1's rmse: 3.65581\n",
      "[700]\ttraining's rmse: 3.39856\tvalid_1's rmse: 3.65434\n",
      "[800]\ttraining's rmse: 3.37793\tvalid_1's rmse: 3.65237\n",
      "[900]\ttraining's rmse: 3.35832\tvalid_1's rmse: 3.65117\n",
      "[1000]\ttraining's rmse: 3.33949\tvalid_1's rmse: 3.64998\n",
      "[1100]\ttraining's rmse: 3.32175\tvalid_1's rmse: 3.64942\n",
      "[1200]\ttraining's rmse: 3.3039\tvalid_1's rmse: 3.64969\n",
      "[1300]\ttraining's rmse: 3.28754\tvalid_1's rmse: 3.65022\n",
      "[1400]\ttraining's rmse: 3.27037\tvalid_1's rmse: 3.65073\n",
      "[1500]\ttraining's rmse: 3.25482\tvalid_1's rmse: 3.65142\n",
      "[1600]\ttraining's rmse: 3.2393\tvalid_1's rmse: 3.65121\n",
      "[1700]\ttraining's rmse: 3.22437\tvalid_1's rmse: 3.65162\n",
      "Early stopping, best iteration is:\n",
      "[1151]\ttraining's rmse: 3.31288\tvalid_1's rmse: 3.64896\n",
      "fold 1 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64999\tvalid_1's rmse: 3.70472\n",
      "[200]\ttraining's rmse: 3.56613\tvalid_1's rmse: 3.67141\n",
      "[300]\ttraining's rmse: 3.51518\tvalid_1's rmse: 3.66041\n",
      "[400]\ttraining's rmse: 3.47797\tvalid_1's rmse: 3.65333\n",
      "[500]\ttraining's rmse: 3.44776\tvalid_1's rmse: 3.64942\n",
      "[600]\ttraining's rmse: 3.42213\tvalid_1's rmse: 3.64741\n",
      "[700]\ttraining's rmse: 3.39905\tvalid_1's rmse: 3.64658\n",
      "[800]\ttraining's rmse: 3.37816\tvalid_1's rmse: 3.64647\n",
      "[900]\ttraining's rmse: 3.3586\tvalid_1's rmse: 3.64627\n",
      "[1000]\ttraining's rmse: 3.3397\tvalid_1's rmse: 3.64667\n",
      "[1100]\ttraining's rmse: 3.32096\tvalid_1's rmse: 3.64599\n",
      "[1200]\ttraining's rmse: 3.30415\tvalid_1's rmse: 3.64647\n",
      "[1300]\ttraining's rmse: 3.28815\tvalid_1's rmse: 3.64733\n",
      "[1400]\ttraining's rmse: 3.2716\tvalid_1's rmse: 3.64721\n",
      "Early stopping, best iteration is:\n",
      "[874]\ttraining's rmse: 3.36334\tvalid_1's rmse: 3.64567\n",
      "fold 2 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65069\tvalid_1's rmse: 3.70734\n",
      "[200]\ttraining's rmse: 3.56507\tvalid_1's rmse: 3.67423\n",
      "[300]\ttraining's rmse: 3.51358\tvalid_1's rmse: 3.66393\n",
      "[400]\ttraining's rmse: 3.47687\tvalid_1's rmse: 3.65894\n",
      "[500]\ttraining's rmse: 3.44651\tvalid_1's rmse: 3.65614\n",
      "[600]\ttraining's rmse: 3.41991\tvalid_1's rmse: 3.65573\n",
      "[700]\ttraining's rmse: 3.39635\tvalid_1's rmse: 3.65543\n",
      "[800]\ttraining's rmse: 3.37533\tvalid_1's rmse: 3.65588\n",
      "[900]\ttraining's rmse: 3.35554\tvalid_1's rmse: 3.65603\n",
      "[1000]\ttraining's rmse: 3.33733\tvalid_1's rmse: 3.65614\n",
      "[1100]\ttraining's rmse: 3.31982\tvalid_1's rmse: 3.65537\n",
      "[1200]\ttraining's rmse: 3.30288\tvalid_1's rmse: 3.65465\n",
      "[1300]\ttraining's rmse: 3.28589\tvalid_1's rmse: 3.65532\n",
      "[1400]\ttraining's rmse: 3.27089\tvalid_1's rmse: 3.65566\n",
      "[1500]\ttraining's rmse: 3.25506\tvalid_1's rmse: 3.65646\n",
      "[1600]\ttraining's rmse: 3.24104\tvalid_1's rmse: 3.6569\n",
      "[1700]\ttraining's rmse: 3.22653\tvalid_1's rmse: 3.6573\n",
      "[1800]\ttraining's rmse: 3.21135\tvalid_1's rmse: 3.6581\n",
      "Early stopping, best iteration is:\n",
      "[1225]\ttraining's rmse: 3.29836\tvalid_1's rmse: 3.65444\n",
      "fold 3 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65337\tvalid_1's rmse: 3.69266\n",
      "[200]\ttraining's rmse: 3.57189\tvalid_1's rmse: 3.64807\n",
      "[300]\ttraining's rmse: 3.52137\tvalid_1's rmse: 3.63358\n",
      "[400]\ttraining's rmse: 3.48353\tvalid_1's rmse: 3.62351\n",
      "[500]\ttraining's rmse: 3.45377\tvalid_1's rmse: 3.61945\n",
      "[600]\ttraining's rmse: 3.42822\tvalid_1's rmse: 3.61561\n",
      "[700]\ttraining's rmse: 3.40598\tvalid_1's rmse: 3.61233\n",
      "[800]\ttraining's rmse: 3.38552\tvalid_1's rmse: 3.60938\n",
      "[900]\ttraining's rmse: 3.36611\tvalid_1's rmse: 3.60765\n",
      "[1000]\ttraining's rmse: 3.34763\tvalid_1's rmse: 3.60615\n",
      "[1100]\ttraining's rmse: 3.32972\tvalid_1's rmse: 3.60709\n",
      "[1200]\ttraining's rmse: 3.31274\tvalid_1's rmse: 3.60745\n",
      "[1300]\ttraining's rmse: 3.29619\tvalid_1's rmse: 3.60771\n",
      "[1400]\ttraining's rmse: 3.27972\tvalid_1's rmse: 3.60691\n",
      "[1500]\ttraining's rmse: 3.26407\tvalid_1's rmse: 3.60747\n",
      "Early stopping, best iteration is:\n",
      "[999]\ttraining's rmse: 3.3478\tvalid_1's rmse: 3.60611\n",
      "fold 4 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64818\tvalid_1's rmse: 3.71356\n",
      "[200]\ttraining's rmse: 3.56447\tvalid_1's rmse: 3.68055\n",
      "[300]\ttraining's rmse: 3.51509\tvalid_1's rmse: 3.6674\n",
      "[400]\ttraining's rmse: 3.47661\tvalid_1's rmse: 3.66037\n",
      "[500]\ttraining's rmse: 3.44559\tvalid_1's rmse: 3.65704\n",
      "[600]\ttraining's rmse: 3.41918\tvalid_1's rmse: 3.65416\n",
      "[700]\ttraining's rmse: 3.39637\tvalid_1's rmse: 3.6517\n",
      "[800]\ttraining's rmse: 3.37574\tvalid_1's rmse: 3.65163\n",
      "[900]\ttraining's rmse: 3.35612\tvalid_1's rmse: 3.6521\n",
      "[1000]\ttraining's rmse: 3.33839\tvalid_1's rmse: 3.65264\n",
      "[1100]\ttraining's rmse: 3.31939\tvalid_1's rmse: 3.65377\n",
      "[1200]\ttraining's rmse: 3.30258\tvalid_1's rmse: 3.65367\n",
      "[1300]\ttraining's rmse: 3.28553\tvalid_1's rmse: 3.65457\n",
      "Early stopping, best iteration is:\n",
      "[705]\ttraining's rmse: 3.3955\tvalid_1's rmse: 3.65141\n",
      "fold 5 1589 0.010930051795651366\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64696\tvalid_1's rmse: 3.72024\n",
      "[200]\ttraining's rmse: 3.56036\tvalid_1's rmse: 3.69211\n",
      "[300]\ttraining's rmse: 3.50866\tvalid_1's rmse: 3.68051\n",
      "[400]\ttraining's rmse: 3.47132\tvalid_1's rmse: 3.67717\n",
      "[500]\ttraining's rmse: 3.44168\tvalid_1's rmse: 3.6734\n",
      "[600]\ttraining's rmse: 3.4158\tvalid_1's rmse: 3.67033\n",
      "[700]\ttraining's rmse: 3.392\tvalid_1's rmse: 3.66877\n",
      "[800]\ttraining's rmse: 3.37166\tvalid_1's rmse: 3.66806\n",
      "[900]\ttraining's rmse: 3.35162\tvalid_1's rmse: 3.66785\n",
      "[1000]\ttraining's rmse: 3.33248\tvalid_1's rmse: 3.66816\n",
      "[1100]\ttraining's rmse: 3.31483\tvalid_1's rmse: 3.66797\n",
      "[1200]\ttraining's rmse: 3.29697\tvalid_1's rmse: 3.66794\n",
      "[1300]\ttraining's rmse: 3.28056\tvalid_1's rmse: 3.66749\n",
      "[1400]\ttraining's rmse: 3.26332\tvalid_1's rmse: 3.66737\n",
      "[1500]\ttraining's rmse: 3.24735\tvalid_1's rmse: 3.66745\n",
      "[1600]\ttraining's rmse: 3.23267\tvalid_1's rmse: 3.66701\n",
      "[1700]\ttraining's rmse: 3.21813\tvalid_1's rmse: 3.66694\n",
      "[1800]\ttraining's rmse: 3.20323\tvalid_1's rmse: 3.66775\n",
      "[1900]\ttraining's rmse: 3.18869\tvalid_1's rmse: 3.66804\n",
      "[2000]\ttraining's rmse: 3.17383\tvalid_1's rmse: 3.66867\n",
      "[2100]\ttraining's rmse: 3.16065\tvalid_1's rmse: 3.66859\n",
      "[2200]\ttraining's rmse: 3.14779\tvalid_1's rmse: 3.66877\n",
      "Early stopping, best iteration is:\n",
      "[1646]\ttraining's rmse: 3.22601\tvalid_1's rmse: 3.66676\n",
      "fold 6 1590 0.010936855138258357\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65176\tvalid_1's rmse: 3.68825\n",
      "[200]\ttraining's rmse: 3.56768\tvalid_1's rmse: 3.64552\n",
      "[300]\ttraining's rmse: 3.51707\tvalid_1's rmse: 3.62806\n",
      "[400]\ttraining's rmse: 3.47955\tvalid_1's rmse: 3.61944\n",
      "[500]\ttraining's rmse: 3.4476\tvalid_1's rmse: 3.61538\n",
      "[600]\ttraining's rmse: 3.42015\tvalid_1's rmse: 3.61261\n",
      "[700]\ttraining's rmse: 3.39692\tvalid_1's rmse: 3.61104\n",
      "[800]\ttraining's rmse: 3.3754\tvalid_1's rmse: 3.61115\n",
      "[900]\ttraining's rmse: 3.3546\tvalid_1's rmse: 3.61165\n",
      "[1000]\ttraining's rmse: 3.33509\tvalid_1's rmse: 3.61127\n",
      "[1100]\ttraining's rmse: 3.31775\tvalid_1's rmse: 3.61191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 3.30085\tvalid_1's rmse: 3.61125\n",
      "[1300]\ttraining's rmse: 3.28407\tvalid_1's rmse: 3.61196\n",
      "Early stopping, best iteration is:\n",
      "[774]\ttraining's rmse: 3.38095\tvalid_1's rmse: 3.61062\n",
      "fold 7 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.65161\tvalid_1's rmse: 3.70287\n",
      "[200]\ttraining's rmse: 3.56801\tvalid_1's rmse: 3.66263\n",
      "[300]\ttraining's rmse: 3.51884\tvalid_1's rmse: 3.64526\n",
      "[400]\ttraining's rmse: 3.48203\tvalid_1's rmse: 3.63601\n",
      "[500]\ttraining's rmse: 3.45112\tvalid_1's rmse: 3.62943\n",
      "[600]\ttraining's rmse: 3.42529\tvalid_1's rmse: 3.62513\n",
      "[700]\ttraining's rmse: 3.40331\tvalid_1's rmse: 3.62218\n",
      "[800]\ttraining's rmse: 3.38303\tvalid_1's rmse: 3.62055\n",
      "[900]\ttraining's rmse: 3.3638\tvalid_1's rmse: 3.61913\n",
      "[1000]\ttraining's rmse: 3.34414\tvalid_1's rmse: 3.61954\n",
      "[1100]\ttraining's rmse: 3.32633\tvalid_1's rmse: 3.61888\n",
      "[1200]\ttraining's rmse: 3.30858\tvalid_1's rmse: 3.61891\n",
      "[1300]\ttraining's rmse: 3.29246\tvalid_1's rmse: 3.61872\n",
      "[1400]\ttraining's rmse: 3.2771\tvalid_1's rmse: 3.61833\n",
      "[1500]\ttraining's rmse: 3.26078\tvalid_1's rmse: 3.61883\n",
      "[1600]\ttraining's rmse: 3.24569\tvalid_1's rmse: 3.61828\n",
      "[1700]\ttraining's rmse: 3.23036\tvalid_1's rmse: 3.61836\n",
      "[1800]\ttraining's rmse: 3.21558\tvalid_1's rmse: 3.61799\n",
      "[1900]\ttraining's rmse: 3.20083\tvalid_1's rmse: 3.61889\n",
      "[2000]\ttraining's rmse: 3.187\tvalid_1's rmse: 3.61804\n",
      "[2100]\ttraining's rmse: 3.17387\tvalid_1's rmse: 3.61829\n",
      "[2200]\ttraining's rmse: 3.15971\tvalid_1's rmse: 3.61731\n",
      "[2300]\ttraining's rmse: 3.14626\tvalid_1's rmse: 3.6178\n",
      "[2400]\ttraining's rmse: 3.13252\tvalid_1's rmse: 3.61819\n",
      "[2500]\ttraining's rmse: 3.11938\tvalid_1's rmse: 3.61836\n",
      "[2600]\ttraining's rmse: 3.10585\tvalid_1's rmse: 3.61881\n",
      "[2700]\ttraining's rmse: 3.09393\tvalid_1's rmse: 3.61889\n",
      "Early stopping, best iteration is:\n",
      "[2174]\ttraining's rmse: 3.16309\tvalid_1's rmse: 3.61727\n",
      "fold 8 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64491\tvalid_1's rmse: 3.73594\n",
      "[200]\ttraining's rmse: 3.55971\tvalid_1's rmse: 3.70912\n",
      "[300]\ttraining's rmse: 3.51018\tvalid_1's rmse: 3.6997\n",
      "[400]\ttraining's rmse: 3.4736\tvalid_1's rmse: 3.69306\n",
      "[500]\ttraining's rmse: 3.44345\tvalid_1's rmse: 3.69018\n",
      "[600]\ttraining's rmse: 3.41731\tvalid_1's rmse: 3.68765\n",
      "[700]\ttraining's rmse: 3.39296\tvalid_1's rmse: 3.68617\n",
      "[800]\ttraining's rmse: 3.37182\tvalid_1's rmse: 3.68516\n",
      "[900]\ttraining's rmse: 3.35173\tvalid_1's rmse: 3.68426\n",
      "[1000]\ttraining's rmse: 3.33418\tvalid_1's rmse: 3.68307\n",
      "[1100]\ttraining's rmse: 3.3176\tvalid_1's rmse: 3.68253\n",
      "[1200]\ttraining's rmse: 3.30051\tvalid_1's rmse: 3.68146\n",
      "[1300]\ttraining's rmse: 3.28437\tvalid_1's rmse: 3.68152\n",
      "[1400]\ttraining's rmse: 3.26777\tvalid_1's rmse: 3.68122\n",
      "[1500]\ttraining's rmse: 3.25177\tvalid_1's rmse: 3.68155\n",
      "[1600]\ttraining's rmse: 3.23691\tvalid_1's rmse: 3.68167\n",
      "[1700]\ttraining's rmse: 3.22218\tvalid_1's rmse: 3.68238\n",
      "[1800]\ttraining's rmse: 3.20718\tvalid_1's rmse: 3.683\n",
      "[1900]\ttraining's rmse: 3.19241\tvalid_1's rmse: 3.68361\n",
      "[2000]\ttraining's rmse: 3.17674\tvalid_1's rmse: 3.68369\n",
      "Early stopping, best iteration is:\n",
      "[1448]\ttraining's rmse: 3.26002\tvalid_1's rmse: 3.68092\n",
      "fold 9 1590 0.010936779909341662\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 3.64661\tvalid_1's rmse: 3.71\n",
      "[200]\ttraining's rmse: 3.56129\tvalid_1's rmse: 3.68857\n",
      "[300]\ttraining's rmse: 3.51015\tvalid_1's rmse: 3.68374\n",
      "[400]\ttraining's rmse: 3.47237\tvalid_1's rmse: 3.68289\n",
      "[500]\ttraining's rmse: 3.44096\tvalid_1's rmse: 3.68187\n",
      "[600]\ttraining's rmse: 3.41541\tvalid_1's rmse: 3.68163\n",
      "[700]\ttraining's rmse: 3.39205\tvalid_1's rmse: 3.68224\n",
      "[800]\ttraining's rmse: 3.37088\tvalid_1's rmse: 3.6818\n",
      "[900]\ttraining's rmse: 3.35117\tvalid_1's rmse: 3.68197\n",
      "[1000]\ttraining's rmse: 3.3324\tvalid_1's rmse: 3.68175\n",
      "[1100]\ttraining's rmse: 3.31509\tvalid_1's rmse: 3.6819\n",
      "[1200]\ttraining's rmse: 3.29663\tvalid_1's rmse: 3.68232\n",
      "[1300]\ttraining's rmse: 3.28039\tvalid_1's rmse: 3.68351\n",
      "Early stopping, best iteration is:\n",
      "[730]\ttraining's rmse: 3.3853\tvalid_1's rmse: 3.68128\n"
     ]
    }
   ],
   "source": [
    "feat_names=['feats','feats1','feats2','feats3']\n",
    "df_all=pd.DataFrame()\n",
    "for fold in [5,6,7,8,9,10]:\n",
    "    df_total=pd.DataFrame()\n",
    "    for feat in [feats,feats1,feats2,feats3]:\n",
    "        df=regression(df_train,df_test,fold,feat)\n",
    "        df['feats']=feat_names[[feats,feats1,feats2,feats3].index(feat)] # indicate feat\n",
    "        df_total=pd.concat([df_total,df],axis=0) # data frame for each feat\n",
    "    df_total['num_folds']=fold # indicate fold number\n",
    "    df_all=pd.concat([df_all,df_total],axis=0) # data frame for each fold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"nfold_test_test_size0.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2=df_all.groupby(['num_folds','feats']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cv_error</th>\n",
       "      <th>test_error</th>\n",
       "      <th>fold</th>\n",
       "      <th>ave_cv_error</th>\n",
       "      <th>ave_test_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_folds</th>\n",
       "      <th>feats</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.653910</td>\n",
       "      <td>3.655162</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.653970</td>\n",
       "      <td>3.649424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.652261</td>\n",
       "      <td>3.649562</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.652317</td>\n",
       "      <td>3.643930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.650660</td>\n",
       "      <td>3.649642</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.650718</td>\n",
       "      <td>3.643717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.649356</td>\n",
       "      <td>3.653877</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.649406</td>\n",
       "      <td>3.648436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">6</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.648704</td>\n",
       "      <td>3.653668</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.648760</td>\n",
       "      <td>3.648317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.647888</td>\n",
       "      <td>3.647311</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.647938</td>\n",
       "      <td>3.642108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.647193</td>\n",
       "      <td>3.649252</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.647247</td>\n",
       "      <td>3.644546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.646911</td>\n",
       "      <td>3.651964</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.646979</td>\n",
       "      <td>3.647599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">7</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.650543</td>\n",
       "      <td>3.651557</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.650597</td>\n",
       "      <td>3.646917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.649376</td>\n",
       "      <td>3.646059</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.649430</td>\n",
       "      <td>3.641316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.646996</td>\n",
       "      <td>3.648794</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.647043</td>\n",
       "      <td>3.643946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.647672</td>\n",
       "      <td>3.652425</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.647723</td>\n",
       "      <td>3.647750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">8</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.650727</td>\n",
       "      <td>3.652565</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.650792</td>\n",
       "      <td>3.647719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.648145</td>\n",
       "      <td>3.647509</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.648199</td>\n",
       "      <td>3.642671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.649350</td>\n",
       "      <td>3.648935</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.649403</td>\n",
       "      <td>3.644195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.647073</td>\n",
       "      <td>3.652869</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.647129</td>\n",
       "      <td>3.648053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">9</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.652625</td>\n",
       "      <td>3.652928</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.652709</td>\n",
       "      <td>3.648408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.647698</td>\n",
       "      <td>3.646372</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.647779</td>\n",
       "      <td>3.641638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.648389</td>\n",
       "      <td>3.648739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.648478</td>\n",
       "      <td>3.644503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.647279</td>\n",
       "      <td>3.651997</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.647365</td>\n",
       "      <td>3.647316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.648750</td>\n",
       "      <td>3.652235</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.646921</td>\n",
       "      <td>3.646730</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.647021</td>\n",
       "      <td>3.641431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.647724</td>\n",
       "      <td>3.648746</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.647812</td>\n",
       "      <td>3.644538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.646345</td>\n",
       "      <td>3.650856</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.646436</td>\n",
       "      <td>3.646644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cv_error  test_error  fold  ave_cv_error  ave_test_error\n",
       "num_folds feats                                                           \n",
       "5         feats   3.653910    3.655162   3.0      3.653970        3.649424\n",
       "          feats1  3.652261    3.649562   3.0      3.652317        3.643930\n",
       "          feats2  3.650660    3.649642   3.0      3.650718        3.643717\n",
       "          feats3  3.649356    3.653877   3.0      3.649406        3.648436\n",
       "6         feats   3.648704    3.653668   3.5      3.648760        3.648317\n",
       "          feats1  3.647888    3.647311   3.5      3.647938        3.642108\n",
       "          feats2  3.647193    3.649252   3.5      3.647247        3.644546\n",
       "          feats3  3.646911    3.651964   3.5      3.646979        3.647599\n",
       "7         feats   3.650543    3.651557   4.0      3.650597        3.646917\n",
       "          feats1  3.649376    3.646059   4.0      3.649430        3.641316\n",
       "          feats2  3.646996    3.648794   4.0      3.647043        3.643946\n",
       "          feats3  3.647672    3.652425   4.0      3.647723        3.647750\n",
       "8         feats   3.650727    3.652565   4.5      3.650792        3.647719\n",
       "          feats1  3.648145    3.647509   4.5      3.648199        3.642671\n",
       "          feats2  3.649350    3.648935   4.5      3.649403        3.644195\n",
       "          feats3  3.647073    3.652869   4.5      3.647129        3.648053\n",
       "9         feats   3.652625    3.652928   5.0      3.652709        3.648408\n",
       "          feats1  3.647698    3.646372   5.0      3.647779        3.641638\n",
       "          feats2  3.648389    3.648739   5.0      3.648478        3.644503\n",
       "          feats3  3.647279    3.651997   5.0      3.647365        3.647316\n",
       "10        feats   3.648750    3.652235   5.5      3.648849        3.647493\n",
       "          feats1  3.646921    3.646730   5.5      3.647021        3.641431\n",
       "          feats2  3.647724    3.648746   5.5      3.647812        3.644538\n",
       "          feats3  3.646345    3.650856   5.5      3.646436        3.646644"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28711883550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(5,11):\n",
    "    df=df_all2.loc[i]\n",
    "    df_err=df_all3.loc[i]\n",
    "    plt.plot(df.ave_cv_error,df.ave_test_error,linestyle='-',marker='o',label=i)\n",
    "    #plt.errorbar(df.ave_cv_error,df.ave_test_error,xerr=df_err.cv_error)\n",
    "    plt.ylabel('Test rmse')\n",
    "    plt.xlabel('CV rmse')\n",
    "    plt.legend()\n",
    "    #plt.xlim([3.645,3.655])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x287119db128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(5,11):\n",
    "    df=df_all2.loc[i]\n",
    "    df_err=df_all3.loc[i]\n",
    "    plt.plot(df.cv_error,df.test_error,linestyle='-',marker='o',label=i)\n",
    "    #plt.errorbar(df.ave_cv_error,df.ave_test_error,xerr=df_err.cv_error)\n",
    "    plt.ylabel('Test rmse')\n",
    "    plt.xlabel('CV rmse')\n",
    "    plt.legend()\n",
    "    #plt.xlim([3.645,3.655])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28711a17ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(5,11):\n",
    "    df=df_all2.loc[i]\n",
    "    df_err=df_all3.loc[i]\n",
    "    plt.plot(df.ave_test_error,df.ave_cv_error,linestyle='-',marker='o',label=i)\n",
    "    plt.errorbar(df.ave_cv_error,df.ave_test_error,yerr=df_err.cv_error)\n",
    "    plt.ylabel('CV rmse')\n",
    "    plt.xlabel('Test rmse')\n",
    "    plt.legend()\n",
    "    #plt.xlim([3.645,3.655])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feats1'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names[[feats,feats1,feats2,feats3].index(feat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = RepeatedStratifiedKFold(n_splits=fold,n_repeats=10, random_state=4950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression2(df_train,df_test,fold,feature):\n",
    "    results=pd.DataFrame()\n",
    "    folds = RepeatedStratifiedKFold(n_splits=fold,n_repeats=10,random_state=4950)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "#     predictions_final=np.zeros(len(df_test))\n",
    "    val_error=[]\n",
    "    test_error=[]\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "\n",
    "        # cal the outlier ratio for each fold\n",
    "        cur_fold= df_train.iloc[trn_idx]\n",
    "        number_outliers = len(cur_fold[cur_fold['outliers'] == 1])\n",
    "        total = len(cur_fold)\n",
    "        print(\"fold %s %s %s\" % (fold_,number_outliers, number_outliers / total))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][feature], label=y_train.target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][feature], label=y_train.target.iloc[val_idx])\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 600)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][feature], num_iteration=clf.best_iteration)\n",
    "        oof_test=clf.predict(df_test[feature], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        val_error.append(np.sqrt(mean_squared_error(oof[val_idx], y_train.target.iloc[val_idx])))\n",
    "        test_error.append(np.sqrt(mean_squared_error(oof_test, y_test.target)))\n",
    "        \n",
    "        predictions += clf.predict(df_test[feature], num_iteration=clf.best_iteration) / (fold*10)\n",
    "#         clf2=lgb.train(param, df_train[feature], clf.best_iteration, valid_sets = [df_train[feature]], verbose_eval=1000, early_stopping_rounds = 600)\n",
    "#         predictions_final=clf2.predict(df_test[feature], num_iteration=clf2.best_iteration) / (fold*10)\n",
    "    \n",
    "    results['cv_error']=val_error\n",
    "    results['test_error']=test_error\n",
    "    results['fold']=[i for i in range(1,fold*10+1,1)]\n",
    "    results['ave_cv_error']=np.sqrt(mean_squared_error(oof,  y_train.target))\n",
    "    results['ave_test_error']=np.sqrt(mean_squared_error(predictions, y_test.target))\n",
    "#     results['ave_test_final_error']=np.sqrt(mean_squared_error(predictions_final, y_test.target))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25382\tvalid_1's rmse: 3.6401\n",
      "[2000]\ttraining's rmse: 3.05411\tvalid_1's rmse: 3.63989\n",
      "Early stopping, best iteration is:\n",
      "[1558]\ttraining's rmse: 3.13498\tvalid_1's rmse: 3.63827\n",
      "fold 1 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24485\tvalid_1's rmse: 3.64559\n",
      "Early stopping, best iteration is:\n",
      "[1242]\ttraining's rmse: 3.19237\tvalid_1's rmse: 3.64491\n",
      "fold 2 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25833\tvalid_1's rmse: 3.62849\n",
      "Early stopping, best iteration is:\n",
      "[1241]\ttraining's rmse: 3.20539\tvalid_1's rmse: 3.62829\n",
      "fold 3 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24222\tvalid_1's rmse: 3.66644\n",
      "[2000]\ttraining's rmse: 3.04269\tvalid_1's rmse: 3.66742\n",
      "Early stopping, best iteration is:\n",
      "[1591]\ttraining's rmse: 3.11858\tvalid_1's rmse: 3.66512\n",
      "fold 4 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24023\tvalid_1's rmse: 3.6821\n",
      "Early stopping, best iteration is:\n",
      "[1021]\ttraining's rmse: 3.23516\tvalid_1's rmse: 3.68172\n",
      "fold 5 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25112\tvalid_1's rmse: 3.64305\n",
      "[2000]\ttraining's rmse: 3.0574\tvalid_1's rmse: 3.64107\n",
      "Early stopping, best iteration is:\n",
      "[1941]\ttraining's rmse: 3.0679\tvalid_1's rmse: 3.64085\n",
      "fold 6 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24162\tvalid_1's rmse: 3.66571\n",
      "Early stopping, best iteration is:\n",
      "[1344]\ttraining's rmse: 3.16781\tvalid_1's rmse: 3.66509\n",
      "fold 7 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2411\tvalid_1's rmse: 3.67271\n",
      "Early stopping, best iteration is:\n",
      "[1355]\ttraining's rmse: 3.16325\tvalid_1's rmse: 3.67235\n",
      "fold 8 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25854\tvalid_1's rmse: 3.63309\n",
      "Early stopping, best iteration is:\n",
      "[1177]\ttraining's rmse: 3.21905\tvalid_1's rmse: 3.63283\n",
      "fold 9 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24692\tvalid_1's rmse: 3.6491\n",
      "Early stopping, best iteration is:\n",
      "[899]\ttraining's rmse: 3.26984\tvalid_1's rmse: 3.64853\n",
      "fold 10 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25128\tvalid_1's rmse: 3.63358\n",
      "Early stopping, best iteration is:\n",
      "[1197]\ttraining's rmse: 3.20778\tvalid_1's rmse: 3.63332\n",
      "fold 11 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24075\tvalid_1's rmse: 3.66686\n",
      "[2000]\ttraining's rmse: 3.04377\tvalid_1's rmse: 3.66629\n",
      "Early stopping, best iteration is:\n",
      "[1682]\ttraining's rmse: 3.10011\tvalid_1's rmse: 3.66541\n",
      "fold 12 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26153\tvalid_1's rmse: 3.61664\n",
      "[2000]\ttraining's rmse: 3.06493\tvalid_1's rmse: 3.61588\n",
      "Early stopping, best iteration is:\n",
      "[1805]\ttraining's rmse: 3.09836\tvalid_1's rmse: 3.61487\n",
      "fold 13 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24344\tvalid_1's rmse: 3.66923\n",
      "Early stopping, best iteration is:\n",
      "[1108]\ttraining's rmse: 3.21893\tvalid_1's rmse: 3.6688\n",
      "fold 14 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24593\tvalid_1's rmse: 3.65143\n",
      "[2000]\ttraining's rmse: 3.05108\tvalid_1's rmse: 3.6511\n",
      "Early stopping, best iteration is:\n",
      "[1690]\ttraining's rmse: 3.10876\tvalid_1's rmse: 3.65047\n",
      "fold 15 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25961\tvalid_1's rmse: 3.62443\n",
      "Early stopping, best iteration is:\n",
      "[1357]\ttraining's rmse: 3.18524\tvalid_1's rmse: 3.62365\n",
      "fold 16 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24493\tvalid_1's rmse: 3.6597\n",
      "Early stopping, best iteration is:\n",
      "[867]\ttraining's rmse: 3.27635\tvalid_1's rmse: 3.65924\n",
      "fold 17 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24664\tvalid_1's rmse: 3.65085\n",
      "[2000]\ttraining's rmse: 3.04851\tvalid_1's rmse: 3.64857\n",
      "[3000]\ttraining's rmse: 2.88585\tvalid_1's rmse: 3.64974\n",
      "Early stopping, best iteration is:\n",
      "[2466]\ttraining's rmse: 2.96939\tvalid_1's rmse: 3.64762\n",
      "fold 18 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24165\tvalid_1's rmse: 3.6678\n",
      "Early stopping, best iteration is:\n",
      "[1016]\ttraining's rmse: 3.23739\tvalid_1's rmse: 3.6677\n",
      "fold 19 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24597\tvalid_1's rmse: 3.66339\n",
      "Early stopping, best iteration is:\n",
      "[1048]\ttraining's rmse: 3.23599\tvalid_1's rmse: 3.66303\n",
      "fold 20 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25196\tvalid_1's rmse: 3.65574\n",
      "Early stopping, best iteration is:\n",
      "[960]\ttraining's rmse: 3.26102\tvalid_1's rmse: 3.65564\n",
      "fold 21 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24706\tvalid_1's rmse: 3.65491\n",
      "Early stopping, best iteration is:\n",
      "[841]\ttraining's rmse: 3.2853\tvalid_1's rmse: 3.65466\n",
      "fold 22 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26041\tvalid_1's rmse: 3.63221\n",
      "[2000]\ttraining's rmse: 3.06581\tvalid_1's rmse: 3.63064\n",
      "Early stopping, best iteration is:\n",
      "[2003]\ttraining's rmse: 3.06538\tvalid_1's rmse: 3.63057\n",
      "fold 23 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.23044\tvalid_1's rmse: 3.68059\n",
      "Early stopping, best iteration is:\n",
      "[1345]\ttraining's rmse: 3.15589\tvalid_1's rmse: 3.67905\n",
      "fold 24 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24744\tvalid_1's rmse: 3.6536\n",
      "Early stopping, best iteration is:\n",
      "[1367]\ttraining's rmse: 3.16711\tvalid_1's rmse: 3.65334\n",
      "fold 25 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.23236\tvalid_1's rmse: 3.68404\n",
      "Early stopping, best iteration is:\n",
      "[816]\ttraining's rmse: 3.27531\tvalid_1's rmse: 3.6834\n",
      "fold 26 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25506\tvalid_1's rmse: 3.63244\n",
      "Early stopping, best iteration is:\n",
      "[804]\ttraining's rmse: 3.30084\tvalid_1's rmse: 3.63196\n",
      "fold 27 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25363\tvalid_1's rmse: 3.6341\n",
      "Early stopping, best iteration is:\n",
      "[1355]\ttraining's rmse: 3.17679\tvalid_1's rmse: 3.63286\n",
      "fold 28 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25421\tvalid_1's rmse: 3.65151\n",
      "Early stopping, best iteration is:\n",
      "[1076]\ttraining's rmse: 3.23751\tvalid_1's rmse: 3.65115\n",
      "fold 29 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24781\tvalid_1's rmse: 3.65047\n",
      "Early stopping, best iteration is:\n",
      "[1101]\ttraining's rmse: 3.22517\tvalid_1's rmse: 3.64992\n",
      "fold 30 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26135\tvalid_1's rmse: 3.62379\n",
      "[2000]\ttraining's rmse: 3.06246\tvalid_1's rmse: 3.62021\n",
      "Early stopping, best iteration is:\n",
      "[2292]\ttraining's rmse: 3.01271\tvalid_1's rmse: 3.61971\n",
      "fold 31 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.23889\tvalid_1's rmse: 3.67321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1228]\ttraining's rmse: 3.18936\tvalid_1's rmse: 3.67277\n",
      "fold 32 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24793\tvalid_1's rmse: 3.65652\n",
      "Early stopping, best iteration is:\n",
      "[1183]\ttraining's rmse: 3.20891\tvalid_1's rmse: 3.65575\n",
      "fold 33 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24684\tvalid_1's rmse: 3.65335\n",
      "Early stopping, best iteration is:\n",
      "[1068]\ttraining's rmse: 3.23163\tvalid_1's rmse: 3.65295\n",
      "fold 34 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24392\tvalid_1's rmse: 3.64919\n",
      "Early stopping, best iteration is:\n",
      "[840]\ttraining's rmse: 3.28306\tvalid_1's rmse: 3.64836\n",
      "fold 35 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25131\tvalid_1's rmse: 3.65532\n",
      "Early stopping, best iteration is:\n",
      "[804]\ttraining's rmse: 3.29829\tvalid_1's rmse: 3.65443\n",
      "fold 36 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24275\tvalid_1's rmse: 3.67443\n",
      "Early stopping, best iteration is:\n",
      "[946]\ttraining's rmse: 3.25483\tvalid_1's rmse: 3.67415\n",
      "fold 37 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25875\tvalid_1's rmse: 3.62649\n",
      "Early stopping, best iteration is:\n",
      "[1208]\ttraining's rmse: 3.21296\tvalid_1's rmse: 3.62603\n",
      "fold 38 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2555\tvalid_1's rmse: 3.64198\n",
      "[2000]\ttraining's rmse: 3.06198\tvalid_1's rmse: 3.64256\n",
      "Early stopping, best iteration is:\n",
      "[1519]\ttraining's rmse: 3.15\tvalid_1's rmse: 3.64101\n",
      "fold 39 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.23852\tvalid_1's rmse: 3.67109\n",
      "Early stopping, best iteration is:\n",
      "[1127]\ttraining's rmse: 3.21098\tvalid_1's rmse: 3.67062\n",
      "fold 40 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24435\tvalid_1's rmse: 3.65677\n",
      "Early stopping, best iteration is:\n",
      "[1239]\ttraining's rmse: 3.19352\tvalid_1's rmse: 3.65656\n",
      "fold 41 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24702\tvalid_1's rmse: 3.64985\n",
      "Early stopping, best iteration is:\n",
      "[1159]\ttraining's rmse: 3.21283\tvalid_1's rmse: 3.64976\n",
      "fold 42 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25791\tvalid_1's rmse: 3.62703\n",
      "Early stopping, best iteration is:\n",
      "[1351]\ttraining's rmse: 3.18514\tvalid_1's rmse: 3.62614\n",
      "fold 43 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.23766\tvalid_1's rmse: 3.68004\n",
      "Early stopping, best iteration is:\n",
      "[1144]\ttraining's rmse: 3.20493\tvalid_1's rmse: 3.6791\n",
      "fold 44 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24561\tvalid_1's rmse: 3.65103\n",
      "Early stopping, best iteration is:\n",
      "[1009]\ttraining's rmse: 3.24332\tvalid_1's rmse: 3.65082\n",
      "fold 45 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24351\tvalid_1's rmse: 3.66675\n",
      "[2000]\ttraining's rmse: 3.04794\tvalid_1's rmse: 3.66578\n",
      "Early stopping, best iteration is:\n",
      "[1614]\ttraining's rmse: 3.11688\tvalid_1's rmse: 3.66392\n",
      "fold 46 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2483\tvalid_1's rmse: 3.64116\n",
      "Early stopping, best iteration is:\n",
      "[1138]\ttraining's rmse: 3.21757\tvalid_1's rmse: 3.64084\n",
      "fold 47 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24383\tvalid_1's rmse: 3.66544\n",
      "Early stopping, best iteration is:\n",
      "[1121]\ttraining's rmse: 3.21758\tvalid_1's rmse: 3.66463\n",
      "fold 48 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24231\tvalid_1's rmse: 3.66498\n",
      "Early stopping, best iteration is:\n",
      "[933]\ttraining's rmse: 3.2577\tvalid_1's rmse: 3.66466\n",
      "fold 49 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26007\tvalid_1's rmse: 3.625\n",
      "[2000]\ttraining's rmse: 3.06494\tvalid_1's rmse: 3.62449\n",
      "Early stopping, best iteration is:\n",
      "[1424]\ttraining's rmse: 3.17013\tvalid_1's rmse: 3.62378\n",
      "fold 0 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27912\tvalid_1's rmse: 3.63664\n",
      "Early stopping, best iteration is:\n",
      "[1091]\ttraining's rmse: 3.26034\tvalid_1's rmse: 3.63624\n",
      "fold 1 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27744\tvalid_1's rmse: 3.64284\n",
      "Early stopping, best iteration is:\n",
      "[1267]\ttraining's rmse: 3.22525\tvalid_1's rmse: 3.6421\n",
      "fold 2 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2814\tvalid_1's rmse: 3.62559\n",
      "[2000]\ttraining's rmse: 3.09483\tvalid_1's rmse: 3.62704\n",
      "Early stopping, best iteration is:\n",
      "[1455]\ttraining's rmse: 3.19078\tvalid_1's rmse: 3.62437\n",
      "fold 3 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27009\tvalid_1's rmse: 3.66931\n",
      "Early stopping, best iteration is:\n",
      "[937]\ttraining's rmse: 3.28429\tvalid_1's rmse: 3.66875\n",
      "fold 4 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26544\tvalid_1's rmse: 3.67826\n",
      "Early stopping, best iteration is:\n",
      "[756]\ttraining's rmse: 3.31947\tvalid_1's rmse: 3.67771\n",
      "fold 5 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27727\tvalid_1's rmse: 3.63493\n",
      "[2000]\ttraining's rmse: 3.09397\tvalid_1's rmse: 3.63407\n",
      "Early stopping, best iteration is:\n",
      "[1753]\ttraining's rmse: 3.13452\tvalid_1's rmse: 3.63342\n",
      "fold 6 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27006\tvalid_1's rmse: 3.66437\n",
      "Early stopping, best iteration is:\n",
      "[961]\ttraining's rmse: 3.27884\tvalid_1's rmse: 3.6641\n",
      "fold 7 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26473\tvalid_1's rmse: 3.66981\n",
      "Early stopping, best iteration is:\n",
      "[1342]\ttraining's rmse: 3.19636\tvalid_1's rmse: 3.66918\n",
      "fold 8 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28258\tvalid_1's rmse: 3.63642\n",
      "Early stopping, best iteration is:\n",
      "[931]\ttraining's rmse: 3.29757\tvalid_1's rmse: 3.63595\n",
      "fold 9 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26856\tvalid_1's rmse: 3.64956\n",
      "Early stopping, best iteration is:\n",
      "[718]\ttraining's rmse: 3.33451\tvalid_1's rmse: 3.64833\n",
      "fold 10 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28064\tvalid_1's rmse: 3.63659\n",
      "[2000]\ttraining's rmse: 3.09694\tvalid_1's rmse: 3.63723\n",
      "Early stopping, best iteration is:\n",
      "[1661]\ttraining's rmse: 3.15425\tvalid_1's rmse: 3.63587\n",
      "fold 11 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26673\tvalid_1's rmse: 3.66425\n",
      "[2000]\ttraining's rmse: 3.08366\tvalid_1's rmse: 3.66242\n",
      "Early stopping, best iteration is:\n",
      "[1754]\ttraining's rmse: 3.12459\tvalid_1's rmse: 3.66187\n",
      "fold 12 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28547\tvalid_1's rmse: 3.61397\n",
      "[2000]\ttraining's rmse: 3.10482\tvalid_1's rmse: 3.61407\n",
      "Early stopping, best iteration is:\n",
      "[1622]\ttraining's rmse: 3.16625\tvalid_1's rmse: 3.61267\n",
      "fold 13 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26485\tvalid_1's rmse: 3.66842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1370]\ttraining's rmse: 3.1908\tvalid_1's rmse: 3.66763\n",
      "fold 14 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27523\tvalid_1's rmse: 3.64185\n",
      "Early stopping, best iteration is:\n",
      "[1321]\ttraining's rmse: 3.21101\tvalid_1's rmse: 3.64044\n",
      "fold 15 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29007\tvalid_1's rmse: 3.6196\n",
      "Early stopping, best iteration is:\n",
      "[1107]\ttraining's rmse: 3.26823\tvalid_1's rmse: 3.61887\n",
      "fold 16 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2641\tvalid_1's rmse: 3.65431\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttraining's rmse: 3.2987\tvalid_1's rmse: 3.65411\n",
      "fold 17 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27258\tvalid_1's rmse: 3.64642\n",
      "Early stopping, best iteration is:\n",
      "[1331]\ttraining's rmse: 3.20503\tvalid_1's rmse: 3.64457\n",
      "fold 18 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25983\tvalid_1's rmse: 3.66314\n",
      "Early stopping, best iteration is:\n",
      "[1087]\ttraining's rmse: 3.24185\tvalid_1's rmse: 3.66274\n",
      "fold 19 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27075\tvalid_1's rmse: 3.65835\n",
      "[2000]\ttraining's rmse: 3.08741\tvalid_1's rmse: 3.65689\n",
      "Early stopping, best iteration is:\n",
      "[1974]\ttraining's rmse: 3.09203\tvalid_1's rmse: 3.65674\n",
      "fold 20 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27762\tvalid_1's rmse: 3.65592\n",
      "Early stopping, best iteration is:\n",
      "[804]\ttraining's rmse: 3.32062\tvalid_1's rmse: 3.65475\n",
      "fold 21 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27159\tvalid_1's rmse: 3.65148\n",
      "Early stopping, best iteration is:\n",
      "[838]\ttraining's rmse: 3.30859\tvalid_1's rmse: 3.65067\n",
      "fold 22 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28783\tvalid_1's rmse: 3.62678\n",
      "[2000]\ttraining's rmse: 3.10423\tvalid_1's rmse: 3.6245\n",
      "Early stopping, best iteration is:\n",
      "[1934]\ttraining's rmse: 3.11464\tvalid_1's rmse: 3.6244\n",
      "fold 23 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25716\tvalid_1's rmse: 3.68251\n",
      "Early stopping, best iteration is:\n",
      "[1068]\ttraining's rmse: 3.24169\tvalid_1's rmse: 3.68202\n",
      "fold 24 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26774\tvalid_1's rmse: 3.64606\n",
      "Early stopping, best iteration is:\n",
      "[1211]\ttraining's rmse: 3.22306\tvalid_1's rmse: 3.64494\n",
      "fold 25 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25617\tvalid_1's rmse: 3.68501\n",
      "Early stopping, best iteration is:\n",
      "[919]\ttraining's rmse: 3.27317\tvalid_1's rmse: 3.68469\n",
      "fold 26 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28191\tvalid_1's rmse: 3.62922\n",
      "Early stopping, best iteration is:\n",
      "[940]\ttraining's rmse: 3.29484\tvalid_1's rmse: 3.62906\n",
      "fold 27 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27611\tvalid_1's rmse: 3.62907\n",
      "[2000]\ttraining's rmse: 3.08703\tvalid_1's rmse: 3.62882\n",
      "Early stopping, best iteration is:\n",
      "[1717]\ttraining's rmse: 3.13684\tvalid_1's rmse: 3.62744\n",
      "fold 28 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27685\tvalid_1's rmse: 3.65205\n",
      "Early stopping, best iteration is:\n",
      "[1339]\ttraining's rmse: 3.21002\tvalid_1's rmse: 3.65093\n",
      "fold 29 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27206\tvalid_1's rmse: 3.64676\n",
      "[2000]\ttraining's rmse: 3.08484\tvalid_1's rmse: 3.64556\n",
      "Early stopping, best iteration is:\n",
      "[1878]\ttraining's rmse: 3.10508\tvalid_1's rmse: 3.64518\n",
      "fold 30 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28313\tvalid_1's rmse: 3.62161\n",
      "[2000]\ttraining's rmse: 3.10123\tvalid_1's rmse: 3.61938\n",
      "Early stopping, best iteration is:\n",
      "[1990]\ttraining's rmse: 3.10283\tvalid_1's rmse: 3.61923\n",
      "fold 31 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26178\tvalid_1's rmse: 3.66675\n",
      "Early stopping, best iteration is:\n",
      "[917]\ttraining's rmse: 3.27947\tvalid_1's rmse: 3.66625\n",
      "fold 32 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27182\tvalid_1's rmse: 3.65548\n",
      "[2000]\ttraining's rmse: 3.09046\tvalid_1's rmse: 3.65457\n",
      "Early stopping, best iteration is:\n",
      "[1519]\ttraining's rmse: 3.17127\tvalid_1's rmse: 3.65334\n",
      "fold 33 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27404\tvalid_1's rmse: 3.64808\n",
      "Early stopping, best iteration is:\n",
      "[953]\ttraining's rmse: 3.28493\tvalid_1's rmse: 3.64771\n",
      "fold 34 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26875\tvalid_1's rmse: 3.65017\n",
      "Early stopping, best iteration is:\n",
      "[930]\ttraining's rmse: 3.2845\tvalid_1's rmse: 3.64972\n",
      "fold 35 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27093\tvalid_1's rmse: 3.65108\n",
      "Early stopping, best iteration is:\n",
      "[1382]\ttraining's rmse: 3.19525\tvalid_1's rmse: 3.65034\n",
      "fold 36 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26959\tvalid_1's rmse: 3.67088\n",
      "Early stopping, best iteration is:\n",
      "[986]\ttraining's rmse: 3.27232\tvalid_1's rmse: 3.67074\n",
      "fold 37 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28227\tvalid_1's rmse: 3.62021\n",
      "Early stopping, best iteration is:\n",
      "[1338]\ttraining's rmse: 3.21494\tvalid_1's rmse: 3.6199\n",
      "fold 38 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27791\tvalid_1's rmse: 3.63838\n",
      "Early stopping, best iteration is:\n",
      "[1052]\ttraining's rmse: 3.26587\tvalid_1's rmse: 3.63809\n",
      "fold 39 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26642\tvalid_1's rmse: 3.66678\n",
      "Early stopping, best iteration is:\n",
      "[1278]\ttraining's rmse: 3.21025\tvalid_1's rmse: 3.6663\n",
      "fold 40 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2775\tvalid_1's rmse: 3.64902\n",
      "Early stopping, best iteration is:\n",
      "[1283]\ttraining's rmse: 3.22119\tvalid_1's rmse: 3.64705\n",
      "fold 41 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27417\tvalid_1's rmse: 3.6486\n",
      "Early stopping, best iteration is:\n",
      "[1276]\ttraining's rmse: 3.21677\tvalid_1's rmse: 3.64761\n",
      "fold 42 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28205\tvalid_1's rmse: 3.61879\n",
      "Early stopping, best iteration is:\n",
      "[1344]\ttraining's rmse: 3.21524\tvalid_1's rmse: 3.618\n",
      "fold 43 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26212\tvalid_1's rmse: 3.67346\n",
      "Early stopping, best iteration is:\n",
      "[1254]\ttraining's rmse: 3.20894\tvalid_1's rmse: 3.67294\n",
      "fold 44 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27102\tvalid_1's rmse: 3.65286\n",
      "Early stopping, best iteration is:\n",
      "[1067]\ttraining's rmse: 3.25698\tvalid_1's rmse: 3.65258\n",
      "fold 45 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26718\tvalid_1's rmse: 3.66453\n",
      "[2000]\ttraining's rmse: 3.08106\tvalid_1's rmse: 3.66489\n",
      "Early stopping, best iteration is:\n",
      "[1485]\ttraining's rmse: 3.17163\tvalid_1's rmse: 3.66324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 46 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27128\tvalid_1's rmse: 3.63622\n",
      "Early stopping, best iteration is:\n",
      "[1150]\ttraining's rmse: 3.24022\tvalid_1's rmse: 3.63525\n",
      "fold 47 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27275\tvalid_1's rmse: 3.65994\n",
      "Early stopping, best iteration is:\n",
      "[1051]\ttraining's rmse: 3.26216\tvalid_1's rmse: 3.65952\n",
      "fold 48 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26994\tvalid_1's rmse: 3.66501\n",
      "Early stopping, best iteration is:\n",
      "[1136]\ttraining's rmse: 3.24114\tvalid_1's rmse: 3.66405\n",
      "fold 49 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28903\tvalid_1's rmse: 3.62654\n",
      "[2000]\ttraining's rmse: 3.10516\tvalid_1's rmse: 3.62522\n",
      "Early stopping, best iteration is:\n",
      "[1628]\ttraining's rmse: 3.16957\tvalid_1's rmse: 3.62359\n",
      "fold 0 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31015\tvalid_1's rmse: 3.63265\n",
      "Early stopping, best iteration is:\n",
      "[1164]\ttraining's rmse: 3.27842\tvalid_1's rmse: 3.63243\n",
      "fold 1 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30949\tvalid_1's rmse: 3.64408\n",
      "Early stopping, best iteration is:\n",
      "[927]\ttraining's rmse: 3.32342\tvalid_1's rmse: 3.64287\n",
      "fold 2 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31243\tvalid_1's rmse: 3.62528\n",
      "[2000]\ttraining's rmse: 3.14238\tvalid_1's rmse: 3.62542\n",
      "Early stopping, best iteration is:\n",
      "[1499]\ttraining's rmse: 3.22157\tvalid_1's rmse: 3.62351\n",
      "fold 3 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29725\tvalid_1's rmse: 3.66334\n",
      "Early stopping, best iteration is:\n",
      "[1184]\ttraining's rmse: 3.26072\tvalid_1's rmse: 3.66241\n",
      "fold 4 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2962\tvalid_1's rmse: 3.67935\n",
      "Early stopping, best iteration is:\n",
      "[839]\ttraining's rmse: 3.33052\tvalid_1's rmse: 3.67859\n",
      "fold 5 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30696\tvalid_1's rmse: 3.63558\n",
      "Early stopping, best iteration is:\n",
      "[1390]\ttraining's rmse: 3.23617\tvalid_1's rmse: 3.63468\n",
      "fold 6 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29983\tvalid_1's rmse: 3.66096\n",
      "Early stopping, best iteration is:\n",
      "[978]\ttraining's rmse: 3.30403\tvalid_1's rmse: 3.66089\n",
      "fold 7 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29939\tvalid_1's rmse: 3.66672\n",
      "Early stopping, best iteration is:\n",
      "[1166]\ttraining's rmse: 3.26695\tvalid_1's rmse: 3.666\n",
      "fold 8 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31444\tvalid_1's rmse: 3.63538\n",
      "Early stopping, best iteration is:\n",
      "[1322]\ttraining's rmse: 3.25639\tvalid_1's rmse: 3.63475\n",
      "fold 9 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30639\tvalid_1's rmse: 3.6465\n",
      "Early stopping, best iteration is:\n",
      "[1012]\ttraining's rmse: 3.30425\tvalid_1's rmse: 3.64637\n",
      "fold 10 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31152\tvalid_1's rmse: 3.63664\n",
      "Early stopping, best iteration is:\n",
      "[1280]\ttraining's rmse: 3.26001\tvalid_1's rmse: 3.63619\n",
      "fold 11 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30358\tvalid_1's rmse: 3.65919\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's rmse: 3.24022\tvalid_1's rmse: 3.658\n",
      "fold 12 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31406\tvalid_1's rmse: 3.61224\n",
      "Early stopping, best iteration is:\n",
      "[1264]\ttraining's rmse: 3.26505\tvalid_1's rmse: 3.61194\n",
      "fold 13 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29698\tvalid_1's rmse: 3.66832\n",
      "Early stopping, best iteration is:\n",
      "[1167]\ttraining's rmse: 3.26389\tvalid_1's rmse: 3.66742\n",
      "fold 14 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29933\tvalid_1's rmse: 3.64302\n",
      "[2000]\ttraining's rmse: 3.13138\tvalid_1's rmse: 3.64306\n",
      "Early stopping, best iteration is:\n",
      "[1691]\ttraining's rmse: 3.1796\tvalid_1's rmse: 3.64201\n",
      "fold 15 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31661\tvalid_1's rmse: 3.62114\n",
      "Early stopping, best iteration is:\n",
      "[1089]\ttraining's rmse: 3.29935\tvalid_1's rmse: 3.62073\n",
      "fold 16 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30138\tvalid_1's rmse: 3.65902\n",
      "Early stopping, best iteration is:\n",
      "[1042]\ttraining's rmse: 3.29328\tvalid_1's rmse: 3.65855\n",
      "fold 17 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29868\tvalid_1's rmse: 3.65019\n",
      "Early stopping, best iteration is:\n",
      "[1391]\ttraining's rmse: 3.22671\tvalid_1's rmse: 3.64903\n",
      "fold 18 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29787\tvalid_1's rmse: 3.66188\n",
      "Early stopping, best iteration is:\n",
      "[1017]\ttraining's rmse: 3.29467\tvalid_1's rmse: 3.66181\n",
      "fold 19 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3043\tvalid_1's rmse: 3.65959\n",
      "Early stopping, best iteration is:\n",
      "[1063]\ttraining's rmse: 3.29228\tvalid_1's rmse: 3.65863\n",
      "fold 20 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30572\tvalid_1's rmse: 3.6585\n",
      "Early stopping, best iteration is:\n",
      "[836]\ttraining's rmse: 3.33874\tvalid_1's rmse: 3.65801\n",
      "fold 21 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30161\tvalid_1's rmse: 3.65085\n",
      "Early stopping, best iteration is:\n",
      "[863]\ttraining's rmse: 3.32961\tvalid_1's rmse: 3.65044\n",
      "fold 22 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32073\tvalid_1's rmse: 3.62114\n",
      "[2000]\ttraining's rmse: 3.14623\tvalid_1's rmse: 3.62007\n",
      "Early stopping, best iteration is:\n",
      "[1729]\ttraining's rmse: 3.18935\tvalid_1's rmse: 3.61913\n",
      "fold 23 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28816\tvalid_1's rmse: 3.67281\n",
      "Early stopping, best iteration is:\n",
      "[1082]\ttraining's rmse: 3.27068\tvalid_1's rmse: 3.67252\n",
      "fold 24 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29894\tvalid_1's rmse: 3.64106\n",
      "Early stopping, best iteration is:\n",
      "[1282]\ttraining's rmse: 3.24479\tvalid_1's rmse: 3.64066\n",
      "fold 25 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28922\tvalid_1's rmse: 3.68223\n",
      "Early stopping, best iteration is:\n",
      "[1091]\ttraining's rmse: 3.27148\tvalid_1's rmse: 3.68176\n",
      "fold 26 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31299\tvalid_1's rmse: 3.6335\n",
      "Early stopping, best iteration is:\n",
      "[1096]\ttraining's rmse: 3.29404\tvalid_1's rmse: 3.63272\n",
      "fold 27 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30848\tvalid_1's rmse: 3.63081\n",
      "[2000]\ttraining's rmse: 3.13413\tvalid_1's rmse: 3.63185\n",
      "Early stopping, best iteration is:\n",
      "[1675]\ttraining's rmse: 3.18619\tvalid_1's rmse: 3.63021\n",
      "fold 28 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31003\tvalid_1's rmse: 3.65614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[938]\ttraining's rmse: 3.32237\tvalid_1's rmse: 3.65564\n",
      "fold 29 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30177\tvalid_1's rmse: 3.64473\n",
      "Early stopping, best iteration is:\n",
      "[1365]\ttraining's rmse: 3.23432\tvalid_1's rmse: 3.64459\n",
      "fold 30 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30868\tvalid_1's rmse: 3.62009\n",
      "[2000]\ttraining's rmse: 3.13892\tvalid_1's rmse: 3.61985\n",
      "Early stopping, best iteration is:\n",
      "[1515]\ttraining's rmse: 3.21619\tvalid_1's rmse: 3.61827\n",
      "fold 31 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29902\tvalid_1's rmse: 3.66104\n",
      "[2000]\ttraining's rmse: 3.12726\tvalid_1's rmse: 3.66127\n",
      "Early stopping, best iteration is:\n",
      "[1426]\ttraining's rmse: 3.21914\tvalid_1's rmse: 3.6597\n",
      "fold 32 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30339\tvalid_1's rmse: 3.65302\n",
      "Early stopping, best iteration is:\n",
      "[1379]\ttraining's rmse: 3.23334\tvalid_1's rmse: 3.65224\n",
      "fold 33 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30532\tvalid_1's rmse: 3.64362\n",
      "[2000]\ttraining's rmse: 3.13262\tvalid_1's rmse: 3.64475\n",
      "Early stopping, best iteration is:\n",
      "[1466]\ttraining's rmse: 3.21924\tvalid_1's rmse: 3.64273\n",
      "fold 34 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.303\tvalid_1's rmse: 3.64738\n",
      "Early stopping, best iteration is:\n",
      "[777]\ttraining's rmse: 3.34967\tvalid_1's rmse: 3.64648\n",
      "fold 35 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30119\tvalid_1's rmse: 3.65193\n",
      "Early stopping, best iteration is:\n",
      "[1026]\ttraining's rmse: 3.29663\tvalid_1's rmse: 3.65163\n",
      "fold 36 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29874\tvalid_1's rmse: 3.67101\n",
      "Early stopping, best iteration is:\n",
      "[1233]\ttraining's rmse: 3.25577\tvalid_1's rmse: 3.67044\n",
      "fold 37 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31287\tvalid_1's rmse: 3.62158\n",
      "Early stopping, best iteration is:\n",
      "[821]\ttraining's rmse: 3.35048\tvalid_1's rmse: 3.62104\n",
      "fold 38 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30957\tvalid_1's rmse: 3.63658\n",
      "Early stopping, best iteration is:\n",
      "[1142]\ttraining's rmse: 3.28204\tvalid_1's rmse: 3.6358\n",
      "fold 39 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29596\tvalid_1's rmse: 3.66845\n",
      "Early stopping, best iteration is:\n",
      "[867]\ttraining's rmse: 3.32308\tvalid_1's rmse: 3.66758\n",
      "fold 40 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30301\tvalid_1's rmse: 3.65126\n",
      "[2000]\ttraining's rmse: 3.13318\tvalid_1's rmse: 3.64972\n",
      "Early stopping, best iteration is:\n",
      "[1834]\ttraining's rmse: 3.15925\tvalid_1's rmse: 3.64896\n",
      "fold 41 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3032\tvalid_1's rmse: 3.64737\n",
      "Early stopping, best iteration is:\n",
      "[660]\ttraining's rmse: 3.37815\tvalid_1's rmse: 3.64707\n",
      "fold 42 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31691\tvalid_1's rmse: 3.61481\n",
      "[2000]\ttraining's rmse: 3.15058\tvalid_1's rmse: 3.61397\n",
      "Early stopping, best iteration is:\n",
      "[1681]\ttraining's rmse: 3.2\tvalid_1's rmse: 3.61334\n",
      "fold 43 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29482\tvalid_1's rmse: 3.67622\n",
      "[2000]\ttraining's rmse: 3.12515\tvalid_1's rmse: 3.67894\n",
      "Early stopping, best iteration is:\n",
      "[1468]\ttraining's rmse: 3.21018\tvalid_1's rmse: 3.67604\n",
      "fold 44 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30436\tvalid_1's rmse: 3.64987\n",
      "Early stopping, best iteration is:\n",
      "[878]\ttraining's rmse: 3.32957\tvalid_1's rmse: 3.64905\n",
      "fold 45 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29791\tvalid_1's rmse: 3.66606\n",
      "[2000]\ttraining's rmse: 3.12928\tvalid_1's rmse: 3.66653\n",
      "Early stopping, best iteration is:\n",
      "[1485]\ttraining's rmse: 3.21256\tvalid_1's rmse: 3.66518\n",
      "fold 46 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29919\tvalid_1's rmse: 3.63656\n",
      "Early stopping, best iteration is:\n",
      "[1180]\ttraining's rmse: 3.26294\tvalid_1's rmse: 3.63537\n",
      "fold 47 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30442\tvalid_1's rmse: 3.6623\n",
      "Early stopping, best iteration is:\n",
      "[732]\ttraining's rmse: 3.35978\tvalid_1's rmse: 3.66112\n",
      "fold 48 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30187\tvalid_1's rmse: 3.66761\n",
      "Early stopping, best iteration is:\n",
      "[776]\ttraining's rmse: 3.34761\tvalid_1's rmse: 3.66647\n",
      "fold 49 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32263\tvalid_1's rmse: 3.6233\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's rmse: 3.2613\tvalid_1's rmse: 3.62234\n",
      "fold 0 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31855\tvalid_1's rmse: 3.6274\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's rmse: 3.32203\tvalid_1's rmse: 3.6273\n",
      "fold 1 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31816\tvalid_1's rmse: 3.63953\n",
      "Early stopping, best iteration is:\n",
      "[1193]\ttraining's rmse: 3.2835\tvalid_1's rmse: 3.63897\n",
      "fold 2 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32344\tvalid_1's rmse: 3.6189\n",
      "Early stopping, best iteration is:\n",
      "[1077]\ttraining's rmse: 3.30891\tvalid_1's rmse: 3.61836\n",
      "fold 3 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30948\tvalid_1's rmse: 3.66294\n",
      "Early stopping, best iteration is:\n",
      "[1156]\ttraining's rmse: 3.28\tvalid_1's rmse: 3.662\n",
      "fold 4 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30536\tvalid_1's rmse: 3.67794\n",
      "Early stopping, best iteration is:\n",
      "[778]\ttraining's rmse: 3.35103\tvalid_1's rmse: 3.67654\n",
      "fold 5 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31883\tvalid_1's rmse: 3.63793\n",
      "[2000]\ttraining's rmse: 3.15128\tvalid_1's rmse: 3.63693\n",
      "Early stopping, best iteration is:\n",
      "[1566]\ttraining's rmse: 3.21959\tvalid_1's rmse: 3.63628\n",
      "fold 6 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30968\tvalid_1's rmse: 3.66274\n",
      "Early stopping, best iteration is:\n",
      "[1197]\ttraining's rmse: 3.27294\tvalid_1's rmse: 3.66218\n",
      "fold 7 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3124\tvalid_1's rmse: 3.66368\n",
      "Early stopping, best iteration is:\n",
      "[1010]\ttraining's rmse: 3.31035\tvalid_1's rmse: 3.66327\n",
      "fold 8 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32067\tvalid_1's rmse: 3.63408\n",
      "Early stopping, best iteration is:\n",
      "[975]\ttraining's rmse: 3.32577\tvalid_1's rmse: 3.63379\n",
      "fold 9 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31592\tvalid_1's rmse: 3.64756\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttraining's rmse: 3.34656\tvalid_1's rmse: 3.64698\n",
      "fold 10 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3208\tvalid_1's rmse: 3.6331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1150]\ttraining's rmse: 3.29271\tvalid_1's rmse: 3.63279\n",
      "fold 11 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3113\tvalid_1's rmse: 3.65978\n",
      "[2000]\ttraining's rmse: 3.14576\tvalid_1's rmse: 3.65927\n",
      "Early stopping, best iteration is:\n",
      "[1492]\ttraining's rmse: 3.22314\tvalid_1's rmse: 3.65786\n",
      "fold 12 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32768\tvalid_1's rmse: 3.60961\n",
      "Early stopping, best iteration is:\n",
      "[1003]\ttraining's rmse: 3.32703\tvalid_1's rmse: 3.60953\n",
      "fold 13 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30725\tvalid_1's rmse: 3.66331\n",
      "Early stopping, best iteration is:\n",
      "[948]\ttraining's rmse: 3.3177\tvalid_1's rmse: 3.66299\n",
      "fold 14 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31115\tvalid_1's rmse: 3.63965\n",
      "[2000]\ttraining's rmse: 3.14582\tvalid_1's rmse: 3.64016\n",
      "Early stopping, best iteration is:\n",
      "[1489]\ttraining's rmse: 3.22631\tvalid_1's rmse: 3.63836\n",
      "fold 15 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32733\tvalid_1's rmse: 3.61837\n",
      "Early stopping, best iteration is:\n",
      "[1328]\ttraining's rmse: 3.27052\tvalid_1's rmse: 3.61736\n",
      "fold 16 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.308\tvalid_1's rmse: 3.65418\n",
      "Early stopping, best iteration is:\n",
      "[930]\ttraining's rmse: 3.32158\tvalid_1's rmse: 3.65354\n",
      "fold 17 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31387\tvalid_1's rmse: 3.64828\n",
      "Early stopping, best iteration is:\n",
      "[1184]\ttraining's rmse: 3.27913\tvalid_1's rmse: 3.64716\n",
      "fold 18 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.304\tvalid_1's rmse: 3.66244\n",
      "Early stopping, best iteration is:\n",
      "[696]\ttraining's rmse: 3.37091\tvalid_1's rmse: 3.66145\n",
      "fold 19 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31218\tvalid_1's rmse: 3.6593\n",
      "Early stopping, best iteration is:\n",
      "[678]\ttraining's rmse: 3.38114\tvalid_1's rmse: 3.65866\n",
      "fold 20 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31893\tvalid_1's rmse: 3.65241\n",
      "Early stopping, best iteration is:\n",
      "[997]\ttraining's rmse: 3.31945\tvalid_1's rmse: 3.65238\n",
      "fold 21 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31362\tvalid_1's rmse: 3.64977\n",
      "Early stopping, best iteration is:\n",
      "[987]\ttraining's rmse: 3.31612\tvalid_1's rmse: 3.64972\n",
      "fold 22 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33101\tvalid_1's rmse: 3.62137\n",
      "Early stopping, best iteration is:\n",
      "[1395]\ttraining's rmse: 3.25874\tvalid_1's rmse: 3.62004\n",
      "fold 23 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30208\tvalid_1's rmse: 3.67514\n",
      "Early stopping, best iteration is:\n",
      "[1349]\ttraining's rmse: 3.23676\tvalid_1's rmse: 3.67371\n",
      "fold 24 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31146\tvalid_1's rmse: 3.63851\n",
      "[2000]\ttraining's rmse: 3.14397\tvalid_1's rmse: 3.63921\n",
      "Early stopping, best iteration is:\n",
      "[1452]\ttraining's rmse: 3.23168\tvalid_1's rmse: 3.63729\n",
      "fold 25 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29968\tvalid_1's rmse: 3.68039\n",
      "Early stopping, best iteration is:\n",
      "[665]\ttraining's rmse: 3.37258\tvalid_1's rmse: 3.6795\n",
      "fold 26 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32378\tvalid_1's rmse: 3.62923\n",
      "Early stopping, best iteration is:\n",
      "[1264]\ttraining's rmse: 3.27542\tvalid_1's rmse: 3.62904\n",
      "fold 27 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32172\tvalid_1's rmse: 3.62661\n",
      "Early stopping, best iteration is:\n",
      "[1167]\ttraining's rmse: 3.29106\tvalid_1's rmse: 3.62599\n",
      "fold 28 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31775\tvalid_1's rmse: 3.65417\n",
      "Early stopping, best iteration is:\n",
      "[1346]\ttraining's rmse: 3.2553\tvalid_1's rmse: 3.65297\n",
      "fold 29 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31443\tvalid_1's rmse: 3.64802\n",
      "[2000]\ttraining's rmse: 3.1442\tvalid_1's rmse: 3.64976\n",
      "Early stopping, best iteration is:\n",
      "[1465]\ttraining's rmse: 3.23124\tvalid_1's rmse: 3.64779\n",
      "fold 30 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32407\tvalid_1's rmse: 3.62335\n",
      "Early stopping, best iteration is:\n",
      "[1253]\ttraining's rmse: 3.27749\tvalid_1's rmse: 3.62221\n",
      "fold 31 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30832\tvalid_1's rmse: 3.66054\n",
      "Early stopping, best iteration is:\n",
      "[961]\ttraining's rmse: 3.31604\tvalid_1's rmse: 3.66\n",
      "fold 32 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31411\tvalid_1's rmse: 3.65297\n",
      "Early stopping, best iteration is:\n",
      "[863]\ttraining's rmse: 3.3405\tvalid_1's rmse: 3.65237\n",
      "fold 33 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31676\tvalid_1's rmse: 3.64339\n",
      "Early stopping, best iteration is:\n",
      "[941]\ttraining's rmse: 3.32896\tvalid_1's rmse: 3.64302\n",
      "fold 34 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31306\tvalid_1's rmse: 3.65332\n",
      "Early stopping, best iteration is:\n",
      "[795]\ttraining's rmse: 3.35522\tvalid_1's rmse: 3.65259\n",
      "fold 35 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31331\tvalid_1's rmse: 3.65338\n",
      "Early stopping, best iteration is:\n",
      "[777]\ttraining's rmse: 3.35978\tvalid_1's rmse: 3.65228\n",
      "fold 36 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31084\tvalid_1's rmse: 3.67208\n",
      "[2000]\ttraining's rmse: 3.14382\tvalid_1's rmse: 3.67247\n",
      "Early stopping, best iteration is:\n",
      "[1415]\ttraining's rmse: 3.23749\tvalid_1's rmse: 3.67073\n",
      "fold 37 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32512\tvalid_1's rmse: 3.62148\n",
      "Early stopping, best iteration is:\n",
      "[814]\ttraining's rmse: 3.36361\tvalid_1's rmse: 3.62032\n",
      "fold 38 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32086\tvalid_1's rmse: 3.63735\n",
      "Early stopping, best iteration is:\n",
      "[1069]\ttraining's rmse: 3.30733\tvalid_1's rmse: 3.63685\n",
      "fold 39 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3088\tvalid_1's rmse: 3.66869\n",
      "Early stopping, best iteration is:\n",
      "[774]\ttraining's rmse: 3.35534\tvalid_1's rmse: 3.66808\n",
      "fold 40 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31764\tvalid_1's rmse: 3.64598\n",
      "[2000]\ttraining's rmse: 3.15119\tvalid_1's rmse: 3.64479\n",
      "Early stopping, best iteration is:\n",
      "[1819]\ttraining's rmse: 3.17818\tvalid_1's rmse: 3.64388\n",
      "fold 41 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31149\tvalid_1's rmse: 3.65324\n",
      "Early stopping, best iteration is:\n",
      "[834]\ttraining's rmse: 3.34645\tvalid_1's rmse: 3.65147\n",
      "fold 42 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32721\tvalid_1's rmse: 3.6163\n",
      "[2000]\ttraining's rmse: 3.16358\tvalid_1's rmse: 3.6153\n",
      "Early stopping, best iteration is:\n",
      "[1737]\ttraining's rmse: 3.20286\tvalid_1's rmse: 3.61465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 43 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30564\tvalid_1's rmse: 3.67493\n",
      "Early stopping, best iteration is:\n",
      "[1168]\ttraining's rmse: 3.27367\tvalid_1's rmse: 3.67374\n",
      "fold 44 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31607\tvalid_1's rmse: 3.65079\n",
      "Early stopping, best iteration is:\n",
      "[727]\ttraining's rmse: 3.3708\tvalid_1's rmse: 3.6505\n",
      "fold 45 1412 0.010926678274327722\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30878\tvalid_1's rmse: 3.66516\n",
      "Early stopping, best iteration is:\n",
      "[1021]\ttraining's rmse: 3.30446\tvalid_1's rmse: 3.66487\n",
      "fold 46 1413 0.010934332100351322\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31276\tvalid_1's rmse: 3.63806\n",
      "Early stopping, best iteration is:\n",
      "[1269]\ttraining's rmse: 3.2616\tvalid_1's rmse: 3.63712\n",
      "fold 47 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31373\tvalid_1's rmse: 3.65871\n",
      "Early stopping, best iteration is:\n",
      "[745]\ttraining's rmse: 3.36774\tvalid_1's rmse: 3.65777\n",
      "fold 48 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31179\tvalid_1's rmse: 3.66687\n",
      "Early stopping, best iteration is:\n",
      "[936]\ttraining's rmse: 3.32412\tvalid_1's rmse: 3.66633\n",
      "fold 49 1413 0.010934247486980275\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32828\tvalid_1's rmse: 3.6238\n",
      "Early stopping, best iteration is:\n",
      "[1327]\ttraining's rmse: 3.26707\tvalid_1's rmse: 3.62176\n",
      "fold 0 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26388\tvalid_1's rmse: 3.64056\n",
      "Early stopping, best iteration is:\n",
      "[1322]\ttraining's rmse: 3.19455\tvalid_1's rmse: 3.63842\n",
      "fold 1 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24748\tvalid_1's rmse: 3.67005\n",
      "Early stopping, best iteration is:\n",
      "[855]\ttraining's rmse: 3.28062\tvalid_1's rmse: 3.66902\n",
      "fold 2 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27593\tvalid_1's rmse: 3.61679\n",
      "Early stopping, best iteration is:\n",
      "[1059]\ttraining's rmse: 3.26101\tvalid_1's rmse: 3.61621\n",
      "fold 3 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25414\tvalid_1's rmse: 3.64567\n",
      "[2000]\ttraining's rmse: 3.06067\tvalid_1's rmse: 3.64642\n",
      "Early stopping, best iteration is:\n",
      "[1461]\ttraining's rmse: 3.15776\tvalid_1's rmse: 3.64524\n",
      "fold 4 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26087\tvalid_1's rmse: 3.67492\n",
      "[2000]\ttraining's rmse: 3.06349\tvalid_1's rmse: 3.67385\n",
      "Early stopping, best iteration is:\n",
      "[1428]\ttraining's rmse: 3.17029\tvalid_1's rmse: 3.6733\n",
      "fold 5 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25213\tvalid_1's rmse: 3.67213\n",
      "Early stopping, best iteration is:\n",
      "[1108]\ttraining's rmse: 3.22882\tvalid_1's rmse: 3.67138\n",
      "fold 6 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25395\tvalid_1's rmse: 3.66289\n",
      "[2000]\ttraining's rmse: 3.06078\tvalid_1's rmse: 3.66208\n",
      "Early stopping, best iteration is:\n",
      "[1449]\ttraining's rmse: 3.16298\tvalid_1's rmse: 3.66117\n",
      "fold 7 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26352\tvalid_1's rmse: 3.64151\n",
      "[2000]\ttraining's rmse: 3.07283\tvalid_1's rmse: 3.64129\n",
      "Early stopping, best iteration is:\n",
      "[1595]\ttraining's rmse: 3.14578\tvalid_1's rmse: 3.63969\n",
      "fold 8 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25594\tvalid_1's rmse: 3.66261\n",
      "Early stopping, best iteration is:\n",
      "[1075]\ttraining's rmse: 3.23951\tvalid_1's rmse: 3.66218\n",
      "fold 9 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25709\tvalid_1's rmse: 3.6495\n",
      "[2000]\ttraining's rmse: 3.06835\tvalid_1's rmse: 3.65056\n",
      "Early stopping, best iteration is:\n",
      "[1651]\ttraining's rmse: 3.12973\tvalid_1's rmse: 3.64847\n",
      "fold 10 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2681\tvalid_1's rmse: 3.62257\n",
      "Early stopping, best iteration is:\n",
      "[1213]\ttraining's rmse: 3.22277\tvalid_1's rmse: 3.6217\n",
      "fold 11 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25482\tvalid_1's rmse: 3.6615\n",
      "Early stopping, best iteration is:\n",
      "[1010]\ttraining's rmse: 3.25242\tvalid_1's rmse: 3.66131\n",
      "fold 12 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26482\tvalid_1's rmse: 3.62879\n",
      "Early stopping, best iteration is:\n",
      "[874]\ttraining's rmse: 3.2923\tvalid_1's rmse: 3.62831\n",
      "fold 13 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24522\tvalid_1's rmse: 3.6865\n",
      "[2000]\ttraining's rmse: 3.05075\tvalid_1's rmse: 3.6856\n",
      "Early stopping, best iteration is:\n",
      "[1584]\ttraining's rmse: 3.12673\tvalid_1's rmse: 3.68536\n",
      "fold 14 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26281\tvalid_1's rmse: 3.63786\n",
      "[2000]\ttraining's rmse: 3.07174\tvalid_1's rmse: 3.63832\n",
      "Early stopping, best iteration is:\n",
      "[1545]\ttraining's rmse: 3.15354\tvalid_1's rmse: 3.6367\n",
      "fold 15 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25954\tvalid_1's rmse: 3.64324\n",
      "Early stopping, best iteration is:\n",
      "[1172]\ttraining's rmse: 3.22217\tvalid_1's rmse: 3.64232\n",
      "fold 16 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25704\tvalid_1's rmse: 3.64497\n",
      "[2000]\ttraining's rmse: 3.06373\tvalid_1's rmse: 3.64404\n",
      "Early stopping, best iteration is:\n",
      "[1582]\ttraining's rmse: 3.13908\tvalid_1's rmse: 3.64265\n",
      "fold 17 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25816\tvalid_1's rmse: 3.65202\n",
      "[2000]\ttraining's rmse: 3.06715\tvalid_1's rmse: 3.6508\n",
      "Early stopping, best iteration is:\n",
      "[1769]\ttraining's rmse: 3.10753\tvalid_1's rmse: 3.64919\n",
      "fold 18 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27107\tvalid_1's rmse: 3.61007\n",
      "[2000]\ttraining's rmse: 3.07634\tvalid_1's rmse: 3.60946\n",
      "Early stopping, best iteration is:\n",
      "[1548]\ttraining's rmse: 3.15784\tvalid_1's rmse: 3.60817\n",
      "fold 19 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26051\tvalid_1's rmse: 3.64221\n",
      "Early stopping, best iteration is:\n",
      "[966]\ttraining's rmse: 3.26832\tvalid_1's rmse: 3.64147\n",
      "fold 20 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26043\tvalid_1's rmse: 3.64647\n",
      "[2000]\ttraining's rmse: 3.07144\tvalid_1's rmse: 3.64651\n",
      "Early stopping, best iteration is:\n",
      "[1791]\ttraining's rmse: 3.10783\tvalid_1's rmse: 3.64531\n",
      "fold 21 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25089\tvalid_1's rmse: 3.66873\n",
      "[2000]\ttraining's rmse: 3.05837\tvalid_1's rmse: 3.66741\n",
      "Early stopping, best iteration is:\n",
      "[1534]\ttraining's rmse: 3.14321\tvalid_1's rmse: 3.66585\n",
      "fold 22 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24807\tvalid_1's rmse: 3.66539\n",
      "Early stopping, best iteration is:\n",
      "[1074]\ttraining's rmse: 3.23091\tvalid_1's rmse: 3.66487\n",
      "fold 23 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25762\tvalid_1's rmse: 3.6581\n",
      "[2000]\ttraining's rmse: 3.06548\tvalid_1's rmse: 3.65459\n",
      "Early stopping, best iteration is:\n",
      "[1823]\ttraining's rmse: 3.09658\tvalid_1's rmse: 3.65422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 24 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2622\tvalid_1's rmse: 3.65013\n",
      "Early stopping, best iteration is:\n",
      "[975]\ttraining's rmse: 3.26782\tvalid_1's rmse: 3.64976\n",
      "fold 25 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25661\tvalid_1's rmse: 3.66871\n",
      "[2000]\ttraining's rmse: 3.06436\tvalid_1's rmse: 3.66942\n",
      "Early stopping, best iteration is:\n",
      "[1700]\ttraining's rmse: 3.11641\tvalid_1's rmse: 3.66799\n",
      "fold 26 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26709\tvalid_1's rmse: 3.62457\n",
      "Early stopping, best iteration is:\n",
      "[934]\ttraining's rmse: 3.28224\tvalid_1's rmse: 3.62402\n",
      "fold 27 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25667\tvalid_1's rmse: 3.65598\n",
      "[2000]\ttraining's rmse: 3.06837\tvalid_1's rmse: 3.6532\n",
      "Early stopping, best iteration is:\n",
      "[2091]\ttraining's rmse: 3.05353\tvalid_1's rmse: 3.65279\n",
      "fold 28 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24671\tvalid_1's rmse: 3.67543\n",
      "[2000]\ttraining's rmse: 3.05312\tvalid_1's rmse: 3.67265\n",
      "Early stopping, best iteration is:\n",
      "[1655]\ttraining's rmse: 3.11549\tvalid_1's rmse: 3.67222\n",
      "fold 29 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25522\tvalid_1's rmse: 3.64943\n",
      "[2000]\ttraining's rmse: 3.06137\tvalid_1's rmse: 3.64936\n",
      "Early stopping, best iteration is:\n",
      "[1607]\ttraining's rmse: 3.13063\tvalid_1's rmse: 3.64864\n",
      "fold 30 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24693\tvalid_1's rmse: 3.68302\n",
      "Early stopping, best iteration is:\n",
      "[1340]\ttraining's rmse: 3.17831\tvalid_1's rmse: 3.68268\n",
      "fold 31 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26368\tvalid_1's rmse: 3.64778\n",
      "Early stopping, best iteration is:\n",
      "[707]\ttraining's rmse: 3.33314\tvalid_1's rmse: 3.64642\n",
      "fold 32 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25869\tvalid_1's rmse: 3.62993\n",
      "[2000]\ttraining's rmse: 3.06419\tvalid_1's rmse: 3.63037\n",
      "Early stopping, best iteration is:\n",
      "[1558]\ttraining's rmse: 3.14478\tvalid_1's rmse: 3.62887\n",
      "fold 33 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25979\tvalid_1's rmse: 3.65888\n",
      "[2000]\ttraining's rmse: 3.06597\tvalid_1's rmse: 3.65853\n",
      "Early stopping, best iteration is:\n",
      "[1430]\ttraining's rmse: 3.16981\tvalid_1's rmse: 3.65704\n",
      "fold 34 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26799\tvalid_1's rmse: 3.63371\n",
      "Early stopping, best iteration is:\n",
      "[1357]\ttraining's rmse: 3.19395\tvalid_1's rmse: 3.63123\n",
      "fold 35 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24942\tvalid_1's rmse: 3.66393\n",
      "[2000]\ttraining's rmse: 3.05451\tvalid_1's rmse: 3.66475\n",
      "Early stopping, best iteration is:\n",
      "[1452]\ttraining's rmse: 3.1532\tvalid_1's rmse: 3.66282\n",
      "fold 36 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26614\tvalid_1's rmse: 3.62892\n",
      "[2000]\ttraining's rmse: 3.07241\tvalid_1's rmse: 3.62579\n",
      "Early stopping, best iteration is:\n",
      "[1990]\ttraining's rmse: 3.07468\tvalid_1's rmse: 3.62552\n",
      "fold 37 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26191\tvalid_1's rmse: 3.63112\n",
      "[2000]\ttraining's rmse: 3.06983\tvalid_1's rmse: 3.63121\n",
      "Early stopping, best iteration is:\n",
      "[1460]\ttraining's rmse: 3.16734\tvalid_1's rmse: 3.62922\n",
      "fold 38 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2446\tvalid_1's rmse: 3.69793\n",
      "Early stopping, best iteration is:\n",
      "[1143]\ttraining's rmse: 3.21311\tvalid_1's rmse: 3.69763\n",
      "fold 39 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26365\tvalid_1's rmse: 3.64499\n",
      "[2000]\ttraining's rmse: 3.06722\tvalid_1's rmse: 3.64309\n",
      "Early stopping, best iteration is:\n",
      "[1992]\ttraining's rmse: 3.06865\tvalid_1's rmse: 3.64289\n",
      "fold 40 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26131\tvalid_1's rmse: 3.64869\n",
      "Early stopping, best iteration is:\n",
      "[877]\ttraining's rmse: 3.28986\tvalid_1's rmse: 3.64839\n",
      "fold 41 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25477\tvalid_1's rmse: 3.65471\n",
      "Early stopping, best iteration is:\n",
      "[758]\ttraining's rmse: 3.31215\tvalid_1's rmse: 3.65361\n",
      "fold 42 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25583\tvalid_1's rmse: 3.66348\n",
      "Early stopping, best iteration is:\n",
      "[1379]\ttraining's rmse: 3.17677\tvalid_1's rmse: 3.66262\n",
      "fold 43 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25685\tvalid_1's rmse: 3.66132\n",
      "Early stopping, best iteration is:\n",
      "[1075]\ttraining's rmse: 3.2398\tvalid_1's rmse: 3.66106\n",
      "fold 44 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25894\tvalid_1's rmse: 3.64301\n",
      "Early stopping, best iteration is:\n",
      "[938]\ttraining's rmse: 3.27257\tvalid_1's rmse: 3.64258\n",
      "fold 45 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26615\tvalid_1's rmse: 3.63566\n",
      "Early stopping, best iteration is:\n",
      "[778]\ttraining's rmse: 3.31749\tvalid_1's rmse: 3.63546\n",
      "fold 46 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26715\tvalid_1's rmse: 3.62251\n",
      "Early stopping, best iteration is:\n",
      "[1152]\ttraining's rmse: 3.23467\tvalid_1's rmse: 3.62066\n",
      "fold 47 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24649\tvalid_1's rmse: 3.68696\n",
      "Early stopping, best iteration is:\n",
      "[971]\ttraining's rmse: 3.25327\tvalid_1's rmse: 3.6867\n",
      "fold 48 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25566\tvalid_1's rmse: 3.66245\n",
      "[2000]\ttraining's rmse: 3.06366\tvalid_1's rmse: 3.65967\n",
      "Early stopping, best iteration is:\n",
      "[2138]\ttraining's rmse: 3.03968\tvalid_1's rmse: 3.65905\n",
      "fold 49 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25556\tvalid_1's rmse: 3.66524\n",
      "Early stopping, best iteration is:\n",
      "[1352]\ttraining's rmse: 3.18382\tvalid_1's rmse: 3.6637\n",
      "fold 50 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26947\tvalid_1's rmse: 3.60673\n",
      "[2000]\ttraining's rmse: 3.07566\tvalid_1's rmse: 3.60709\n",
      "Early stopping, best iteration is:\n",
      "[1454]\ttraining's rmse: 3.17615\tvalid_1's rmse: 3.60528\n",
      "fold 51 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2575\tvalid_1's rmse: 3.66018\n",
      "Early stopping, best iteration is:\n",
      "[1216]\ttraining's rmse: 3.2124\tvalid_1's rmse: 3.65876\n",
      "fold 52 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25584\tvalid_1's rmse: 3.66351\n",
      "Early stopping, best iteration is:\n",
      "[1030]\ttraining's rmse: 3.2485\tvalid_1's rmse: 3.66295\n",
      "fold 53 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.254\tvalid_1's rmse: 3.65055\n",
      "Early stopping, best iteration is:\n",
      "[1180]\ttraining's rmse: 3.21552\tvalid_1's rmse: 3.65018\n",
      "fold 54 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25126\tvalid_1's rmse: 3.6741\n",
      "Early stopping, best iteration is:\n",
      "[949]\ttraining's rmse: 3.26282\tvalid_1's rmse: 3.6738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 55 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2569\tvalid_1's rmse: 3.63572\n",
      "[2000]\ttraining's rmse: 3.05752\tvalid_1's rmse: 3.63479\n",
      "Early stopping, best iteration is:\n",
      "[1631]\ttraining's rmse: 3.12659\tvalid_1's rmse: 3.6341\n",
      "fold 56 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24988\tvalid_1's rmse: 3.66515\n",
      "[2000]\ttraining's rmse: 3.05886\tvalid_1's rmse: 3.66259\n",
      "Early stopping, best iteration is:\n",
      "[1776]\ttraining's rmse: 3.09684\tvalid_1's rmse: 3.66189\n",
      "fold 57 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25817\tvalid_1's rmse: 3.6452\n",
      "Early stopping, best iteration is:\n",
      "[1167]\ttraining's rmse: 3.22057\tvalid_1's rmse: 3.64457\n",
      "fold 58 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25523\tvalid_1's rmse: 3.67215\n",
      "Early stopping, best iteration is:\n",
      "[890]\ttraining's rmse: 3.28138\tvalid_1's rmse: 3.67166\n",
      "fold 59 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2727\tvalid_1's rmse: 3.61839\n",
      "[2000]\ttraining's rmse: 3.08073\tvalid_1's rmse: 3.61817\n",
      "Early stopping, best iteration is:\n",
      "[1433]\ttraining's rmse: 3.18261\tvalid_1's rmse: 3.61658\n",
      "fold 0 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28743\tvalid_1's rmse: 3.63537\n",
      "Early stopping, best iteration is:\n",
      "[918]\ttraining's rmse: 3.30571\tvalid_1's rmse: 3.63495\n",
      "fold 1 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27605\tvalid_1's rmse: 3.66578\n",
      "Early stopping, best iteration is:\n",
      "[782]\ttraining's rmse: 3.32474\tvalid_1's rmse: 3.66557\n",
      "fold 2 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30094\tvalid_1's rmse: 3.61085\n",
      "[2000]\ttraining's rmse: 3.12077\tvalid_1's rmse: 3.61304\n",
      "Early stopping, best iteration is:\n",
      "[1604]\ttraining's rmse: 3.18818\tvalid_1's rmse: 3.61032\n",
      "fold 3 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27897\tvalid_1's rmse: 3.64138\n",
      "Early stopping, best iteration is:\n",
      "[984]\ttraining's rmse: 3.28273\tvalid_1's rmse: 3.64124\n",
      "fold 4 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27911\tvalid_1's rmse: 3.67198\n",
      "[2000]\ttraining's rmse: 3.0988\tvalid_1's rmse: 3.67141\n",
      "[3000]\ttraining's rmse: 2.95338\tvalid_1's rmse: 3.67282\n",
      "Early stopping, best iteration is:\n",
      "[2437]\ttraining's rmse: 3.03267\tvalid_1's rmse: 3.67092\n",
      "fold 5 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27616\tvalid_1's rmse: 3.67024\n",
      "Early stopping, best iteration is:\n",
      "[1113]\ttraining's rmse: 3.25355\tvalid_1's rmse: 3.66991\n",
      "fold 6 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27925\tvalid_1's rmse: 3.65499\n",
      "[2000]\ttraining's rmse: 3.09816\tvalid_1's rmse: 3.65386\n",
      "Early stopping, best iteration is:\n",
      "[2222]\ttraining's rmse: 3.06324\tvalid_1's rmse: 3.65329\n",
      "fold 7 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28824\tvalid_1's rmse: 3.63911\n",
      "[2000]\ttraining's rmse: 3.11011\tvalid_1's rmse: 3.63596\n",
      "Early stopping, best iteration is:\n",
      "[2154]\ttraining's rmse: 3.08439\tvalid_1's rmse: 3.63519\n",
      "fold 8 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27895\tvalid_1's rmse: 3.65664\n",
      "Early stopping, best iteration is:\n",
      "[1040]\ttraining's rmse: 3.27079\tvalid_1's rmse: 3.65611\n",
      "fold 9 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2824\tvalid_1's rmse: 3.64964\n",
      "[2000]\ttraining's rmse: 3.10543\tvalid_1's rmse: 3.65005\n",
      "Early stopping, best iteration is:\n",
      "[1421]\ttraining's rmse: 3.20191\tvalid_1's rmse: 3.64797\n",
      "fold 10 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29137\tvalid_1's rmse: 3.62282\n",
      "[2000]\ttraining's rmse: 3.11214\tvalid_1's rmse: 3.62285\n",
      "Early stopping, best iteration is:\n",
      "[1441]\ttraining's rmse: 3.20717\tvalid_1's rmse: 3.62197\n",
      "fold 11 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2787\tvalid_1's rmse: 3.66322\n",
      "Early stopping, best iteration is:\n",
      "[823]\ttraining's rmse: 3.31827\tvalid_1's rmse: 3.66263\n",
      "fold 12 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29012\tvalid_1's rmse: 3.63103\n",
      "Early stopping, best iteration is:\n",
      "[1294]\ttraining's rmse: 3.23248\tvalid_1's rmse: 3.63055\n",
      "fold 13 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26834\tvalid_1's rmse: 3.68097\n",
      "[2000]\ttraining's rmse: 3.08441\tvalid_1's rmse: 3.67873\n",
      "Early stopping, best iteration is:\n",
      "[2274]\ttraining's rmse: 3.04163\tvalid_1's rmse: 3.67741\n",
      "fold 14 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28617\tvalid_1's rmse: 3.63447\n",
      "[2000]\ttraining's rmse: 3.10909\tvalid_1's rmse: 3.63527\n",
      "Early stopping, best iteration is:\n",
      "[1456]\ttraining's rmse: 3.20084\tvalid_1's rmse: 3.63313\n",
      "fold 15 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28781\tvalid_1's rmse: 3.6383\n",
      "[2000]\ttraining's rmse: 3.10684\tvalid_1's rmse: 3.63762\n",
      "Early stopping, best iteration is:\n",
      "[1861]\ttraining's rmse: 3.12886\tvalid_1's rmse: 3.63709\n",
      "fold 16 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28375\tvalid_1's rmse: 3.64544\n",
      "Early stopping, best iteration is:\n",
      "[1395]\ttraining's rmse: 3.20584\tvalid_1's rmse: 3.64439\n",
      "fold 17 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27805\tvalid_1's rmse: 3.64474\n",
      "Early stopping, best iteration is:\n",
      "[1370]\ttraining's rmse: 3.20433\tvalid_1's rmse: 3.64228\n",
      "fold 18 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29648\tvalid_1's rmse: 3.609\n",
      "[2000]\ttraining's rmse: 3.11918\tvalid_1's rmse: 3.60612\n",
      "Early stopping, best iteration is:\n",
      "[1633]\ttraining's rmse: 3.17837\tvalid_1's rmse: 3.60556\n",
      "fold 19 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28437\tvalid_1's rmse: 3.63568\n",
      "Early stopping, best iteration is:\n",
      "[1015]\ttraining's rmse: 3.28126\tvalid_1's rmse: 3.63536\n",
      "fold 20 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28011\tvalid_1's rmse: 3.64361\n",
      "Early stopping, best iteration is:\n",
      "[955]\ttraining's rmse: 3.28929\tvalid_1's rmse: 3.64338\n",
      "fold 21 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27669\tvalid_1's rmse: 3.66566\n",
      "[2000]\ttraining's rmse: 3.09565\tvalid_1's rmse: 3.66245\n",
      "Early stopping, best iteration is:\n",
      "[2027]\ttraining's rmse: 3.09131\tvalid_1's rmse: 3.6622\n",
      "fold 22 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27301\tvalid_1's rmse: 3.66857\n",
      "Early stopping, best iteration is:\n",
      "[900]\ttraining's rmse: 3.29431\tvalid_1's rmse: 3.6685\n",
      "fold 23 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28212\tvalid_1's rmse: 3.65437\n",
      "[2000]\ttraining's rmse: 3.09986\tvalid_1's rmse: 3.65296\n",
      "Early stopping, best iteration is:\n",
      "[1934]\ttraining's rmse: 3.11158\tvalid_1's rmse: 3.65261\n",
      "fold 24 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28852\tvalid_1's rmse: 3.64121\n",
      "Early stopping, best iteration is:\n",
      "[1154]\ttraining's rmse: 3.25871\tvalid_1's rmse: 3.6407\n",
      "fold 25 1471 0.010927865686056014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27688\tvalid_1's rmse: 3.66946\n",
      "Early stopping, best iteration is:\n",
      "[1278]\ttraining's rmse: 3.22052\tvalid_1's rmse: 3.66882\n",
      "fold 26 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29202\tvalid_1's rmse: 3.61727\n",
      "Early stopping, best iteration is:\n",
      "[967]\ttraining's rmse: 3.29936\tvalid_1's rmse: 3.61708\n",
      "fold 27 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28599\tvalid_1's rmse: 3.64799\n",
      "[2000]\ttraining's rmse: 3.10718\tvalid_1's rmse: 3.64795\n",
      "Early stopping, best iteration is:\n",
      "[1634]\ttraining's rmse: 3.1682\tvalid_1's rmse: 3.64638\n",
      "fold 28 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26809\tvalid_1's rmse: 3.66807\n",
      "[2000]\ttraining's rmse: 3.08385\tvalid_1's rmse: 3.66604\n",
      "Early stopping, best iteration is:\n",
      "[1837]\ttraining's rmse: 3.11121\tvalid_1's rmse: 3.66555\n",
      "fold 29 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27883\tvalid_1's rmse: 3.64696\n",
      "[2000]\ttraining's rmse: 3.09519\tvalid_1's rmse: 3.64549\n",
      "Early stopping, best iteration is:\n",
      "[2008]\ttraining's rmse: 3.0939\tvalid_1's rmse: 3.64541\n",
      "fold 30 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26907\tvalid_1's rmse: 3.68279\n",
      "Early stopping, best iteration is:\n",
      "[1088]\ttraining's rmse: 3.25079\tvalid_1's rmse: 3.68233\n",
      "fold 31 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28846\tvalid_1's rmse: 3.64268\n",
      "Early stopping, best iteration is:\n",
      "[774]\ttraining's rmse: 3.33878\tvalid_1's rmse: 3.64206\n",
      "fold 32 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28266\tvalid_1's rmse: 3.6264\n",
      "[2000]\ttraining's rmse: 3.10295\tvalid_1's rmse: 3.62572\n",
      "Early stopping, best iteration is:\n",
      "[2364]\ttraining's rmse: 3.04696\tvalid_1's rmse: 3.62535\n",
      "fold 33 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28414\tvalid_1's rmse: 3.65379\n",
      "Early stopping, best iteration is:\n",
      "[1169]\ttraining's rmse: 3.24963\tvalid_1's rmse: 3.6528\n",
      "fold 34 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29093\tvalid_1's rmse: 3.62797\n",
      "[2000]\ttraining's rmse: 3.11109\tvalid_1's rmse: 3.62813\n",
      "Early stopping, best iteration is:\n",
      "[1611]\ttraining's rmse: 3.17711\tvalid_1's rmse: 3.62689\n",
      "fold 35 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27747\tvalid_1's rmse: 3.65909\n",
      "[2000]\ttraining's rmse: 3.09817\tvalid_1's rmse: 3.65831\n",
      "Early stopping, best iteration is:\n",
      "[1823]\ttraining's rmse: 3.12662\tvalid_1's rmse: 3.65722\n",
      "fold 36 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29177\tvalid_1's rmse: 3.62807\n",
      "[2000]\ttraining's rmse: 3.11285\tvalid_1's rmse: 3.62549\n",
      "Early stopping, best iteration is:\n",
      "[1707]\ttraining's rmse: 3.16137\tvalid_1's rmse: 3.62533\n",
      "fold 37 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28636\tvalid_1's rmse: 3.63149\n",
      "Early stopping, best iteration is:\n",
      "[1345]\ttraining's rmse: 3.22035\tvalid_1's rmse: 3.62987\n",
      "fold 38 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26972\tvalid_1's rmse: 3.6986\n",
      "Early stopping, best iteration is:\n",
      "[1126]\ttraining's rmse: 3.24512\tvalid_1's rmse: 3.69801\n",
      "fold 39 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28921\tvalid_1's rmse: 3.64121\n",
      "[2000]\ttraining's rmse: 3.10708\tvalid_1's rmse: 3.64003\n",
      "Early stopping, best iteration is:\n",
      "[1415]\ttraining's rmse: 3.20702\tvalid_1's rmse: 3.63934\n",
      "fold 40 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28522\tvalid_1's rmse: 3.64727\n",
      "Early stopping, best iteration is:\n",
      "[1064]\ttraining's rmse: 3.27206\tvalid_1's rmse: 3.64676\n",
      "fold 41 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27937\tvalid_1's rmse: 3.6522\n",
      "Early stopping, best iteration is:\n",
      "[749]\ttraining's rmse: 3.33518\tvalid_1's rmse: 3.65165\n",
      "fold 42 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27622\tvalid_1's rmse: 3.66458\n",
      "[2000]\ttraining's rmse: 3.09896\tvalid_1's rmse: 3.66572\n",
      "Early stopping, best iteration is:\n",
      "[1482]\ttraining's rmse: 3.18421\tvalid_1's rmse: 3.66331\n",
      "fold 43 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27791\tvalid_1's rmse: 3.65451\n",
      "Early stopping, best iteration is:\n",
      "[1338]\ttraining's rmse: 3.21329\tvalid_1's rmse: 3.65316\n",
      "fold 44 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28097\tvalid_1's rmse: 3.63607\n",
      "[2000]\ttraining's rmse: 3.09904\tvalid_1's rmse: 3.6334\n",
      "Early stopping, best iteration is:\n",
      "[1997]\ttraining's rmse: 3.0993\tvalid_1's rmse: 3.63335\n",
      "fold 45 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28971\tvalid_1's rmse: 3.62771\n",
      "Early stopping, best iteration is:\n",
      "[1105]\ttraining's rmse: 3.26928\tvalid_1's rmse: 3.62691\n",
      "fold 46 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29081\tvalid_1's rmse: 3.61718\n",
      "Early stopping, best iteration is:\n",
      "[1250]\ttraining's rmse: 3.24105\tvalid_1's rmse: 3.6164\n",
      "fold 47 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27156\tvalid_1's rmse: 3.68147\n",
      "Early stopping, best iteration is:\n",
      "[929]\ttraining's rmse: 3.28696\tvalid_1's rmse: 3.68067\n",
      "fold 48 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2822\tvalid_1's rmse: 3.65307\n",
      "[2000]\ttraining's rmse: 3.10079\tvalid_1's rmse: 3.65263\n",
      "Early stopping, best iteration is:\n",
      "[1409]\ttraining's rmse: 3.20221\tvalid_1's rmse: 3.65079\n",
      "fold 49 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27966\tvalid_1's rmse: 3.66609\n",
      "[2000]\ttraining's rmse: 3.09957\tvalid_1's rmse: 3.66686\n",
      "Early stopping, best iteration is:\n",
      "[1749]\ttraining's rmse: 3.14154\tvalid_1's rmse: 3.66529\n",
      "fold 50 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29355\tvalid_1's rmse: 3.60294\n",
      "Early stopping, best iteration is:\n",
      "[1328]\ttraining's rmse: 3.22921\tvalid_1's rmse: 3.60211\n",
      "fold 51 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27669\tvalid_1's rmse: 3.65436\n",
      "Early stopping, best iteration is:\n",
      "[1314]\ttraining's rmse: 3.21525\tvalid_1's rmse: 3.65328\n",
      "fold 52 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27837\tvalid_1's rmse: 3.66396\n",
      "Early stopping, best iteration is:\n",
      "[1355]\ttraining's rmse: 3.20792\tvalid_1's rmse: 3.66305\n",
      "fold 53 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28099\tvalid_1's rmse: 3.65027\n",
      "Early stopping, best iteration is:\n",
      "[923]\ttraining's rmse: 3.2979\tvalid_1's rmse: 3.64997\n",
      "fold 54 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27695\tvalid_1's rmse: 3.67049\n",
      "[2000]\ttraining's rmse: 3.09915\tvalid_1's rmse: 3.67104\n",
      "Early stopping, best iteration is:\n",
      "[1536]\ttraining's rmse: 3.17456\tvalid_1's rmse: 3.66888\n",
      "fold 55 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2845\tvalid_1's rmse: 3.62892\n",
      "[2000]\ttraining's rmse: 3.09852\tvalid_1's rmse: 3.6265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1838]\ttraining's rmse: 3.12641\tvalid_1's rmse: 3.62595\n",
      "fold 56 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27362\tvalid_1's rmse: 3.66331\n",
      "Early stopping, best iteration is:\n",
      "[1166]\ttraining's rmse: 3.2402\tvalid_1's rmse: 3.66291\n",
      "fold 57 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28269\tvalid_1's rmse: 3.64666\n",
      "[2000]\ttraining's rmse: 3.10275\tvalid_1's rmse: 3.64614\n",
      "Early stopping, best iteration is:\n",
      "[1498]\ttraining's rmse: 3.18785\tvalid_1's rmse: 3.64477\n",
      "fold 58 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27908\tvalid_1's rmse: 3.67932\n",
      "Early stopping, best iteration is:\n",
      "[860]\ttraining's rmse: 3.30955\tvalid_1's rmse: 3.67874\n",
      "fold 59 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29881\tvalid_1's rmse: 3.61379\n",
      "[2000]\ttraining's rmse: 3.11874\tvalid_1's rmse: 3.61117\n",
      "Early stopping, best iteration is:\n",
      "[2190]\ttraining's rmse: 3.08727\tvalid_1's rmse: 3.61027\n",
      "fold 0 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3197\tvalid_1's rmse: 3.63\n",
      "Early stopping, best iteration is:\n",
      "[828]\ttraining's rmse: 3.35433\tvalid_1's rmse: 3.62921\n",
      "fold 1 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30735\tvalid_1's rmse: 3.6685\n",
      "Early stopping, best iteration is:\n",
      "[854]\ttraining's rmse: 3.33668\tvalid_1's rmse: 3.66768\n",
      "fold 2 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32886\tvalid_1's rmse: 3.6125\n",
      "Early stopping, best iteration is:\n",
      "[1153]\ttraining's rmse: 3.29991\tvalid_1's rmse: 3.61151\n",
      "fold 3 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3095\tvalid_1's rmse: 3.64362\n",
      "[2000]\ttraining's rmse: 3.13803\tvalid_1's rmse: 3.64464\n",
      "Early stopping, best iteration is:\n",
      "[1568]\ttraining's rmse: 3.2066\tvalid_1's rmse: 3.64303\n",
      "fold 4 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31142\tvalid_1's rmse: 3.6652\n",
      "Early stopping, best iteration is:\n",
      "[1210]\ttraining's rmse: 3.27406\tvalid_1's rmse: 3.66386\n",
      "fold 5 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30407\tvalid_1's rmse: 3.66993\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttraining's rmse: 3.33385\tvalid_1's rmse: 3.66949\n",
      "fold 6 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30907\tvalid_1's rmse: 3.65676\n",
      "[2000]\ttraining's rmse: 3.14042\tvalid_1's rmse: 3.65674\n",
      "Early stopping, best iteration is:\n",
      "[1553]\ttraining's rmse: 3.21142\tvalid_1's rmse: 3.65604\n",
      "fold 7 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31961\tvalid_1's rmse: 3.63833\n",
      "[2000]\ttraining's rmse: 3.15659\tvalid_1's rmse: 3.63751\n",
      "Early stopping, best iteration is:\n",
      "[1648]\ttraining's rmse: 3.21054\tvalid_1's rmse: 3.63655\n",
      "fold 8 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30745\tvalid_1's rmse: 3.65192\n",
      "Early stopping, best iteration is:\n",
      "[1018]\ttraining's rmse: 3.30446\tvalid_1's rmse: 3.65176\n",
      "fold 9 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30832\tvalid_1's rmse: 3.64912\n",
      "Early stopping, best iteration is:\n",
      "[1121]\ttraining's rmse: 3.28588\tvalid_1's rmse: 3.64868\n",
      "fold 10 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32076\tvalid_1's rmse: 3.62344\n",
      "Early stopping, best iteration is:\n",
      "[1012]\ttraining's rmse: 3.31861\tvalid_1's rmse: 3.62321\n",
      "fold 11 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30668\tvalid_1's rmse: 3.66054\n",
      "Early stopping, best iteration is:\n",
      "[1140]\ttraining's rmse: 3.27986\tvalid_1's rmse: 3.66007\n",
      "fold 12 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32009\tvalid_1's rmse: 3.62503\n",
      "Early stopping, best iteration is:\n",
      "[901]\ttraining's rmse: 3.33824\tvalid_1's rmse: 3.62438\n",
      "fold 13 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29969\tvalid_1's rmse: 3.68202\n",
      "[2000]\ttraining's rmse: 3.12924\tvalid_1's rmse: 3.68202\n",
      "Early stopping, best iteration is:\n",
      "[1536]\ttraining's rmse: 3.20249\tvalid_1's rmse: 3.68102\n",
      "fold 14 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3157\tvalid_1's rmse: 3.63412\n",
      "Early stopping, best iteration is:\n",
      "[1220]\ttraining's rmse: 3.27533\tvalid_1's rmse: 3.63355\n",
      "fold 15 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31768\tvalid_1's rmse: 3.63235\n",
      "[2000]\ttraining's rmse: 3.14717\tvalid_1's rmse: 3.63127\n",
      "Early stopping, best iteration is:\n",
      "[1496]\ttraining's rmse: 3.22877\tvalid_1's rmse: 3.63088\n",
      "fold 16 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31358\tvalid_1's rmse: 3.64199\n",
      "Early stopping, best iteration is:\n",
      "[1383]\ttraining's rmse: 3.24508\tvalid_1's rmse: 3.64134\n",
      "fold 17 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31056\tvalid_1's rmse: 3.6394\n",
      "Early stopping, best iteration is:\n",
      "[1306]\ttraining's rmse: 3.25467\tvalid_1's rmse: 3.63836\n",
      "fold 18 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3262\tvalid_1's rmse: 3.61448\n",
      "[2000]\ttraining's rmse: 3.15879\tvalid_1's rmse: 3.61239\n",
      "Early stopping, best iteration is:\n",
      "[1846]\ttraining's rmse: 3.18327\tvalid_1's rmse: 3.61227\n",
      "fold 19 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31517\tvalid_1's rmse: 3.63829\n",
      "Early stopping, best iteration is:\n",
      "[789]\ttraining's rmse: 3.35802\tvalid_1's rmse: 3.63792\n",
      "fold 20 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31017\tvalid_1's rmse: 3.64079\n",
      "[2000]\ttraining's rmse: 3.14358\tvalid_1's rmse: 3.64076\n",
      "Early stopping, best iteration is:\n",
      "[1521]\ttraining's rmse: 3.21757\tvalid_1's rmse: 3.64007\n",
      "fold 21 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30591\tvalid_1's rmse: 3.66541\n",
      "[2000]\ttraining's rmse: 3.13718\tvalid_1's rmse: 3.66703\n",
      "Early stopping, best iteration is:\n",
      "[1482]\ttraining's rmse: 3.22036\tvalid_1's rmse: 3.66357\n",
      "fold 22 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30345\tvalid_1's rmse: 3.6651\n",
      "Early stopping, best iteration is:\n",
      "[988]\ttraining's rmse: 3.30605\tvalid_1's rmse: 3.66479\n",
      "fold 23 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31518\tvalid_1's rmse: 3.65411\n",
      "Early stopping, best iteration is:\n",
      "[1067]\ttraining's rmse: 3.30232\tvalid_1's rmse: 3.65359\n",
      "fold 24 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31798\tvalid_1's rmse: 3.64497\n",
      "Early stopping, best iteration is:\n",
      "[948]\ttraining's rmse: 3.32818\tvalid_1's rmse: 3.64485\n",
      "fold 25 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30509\tvalid_1's rmse: 3.66757\n",
      "[2000]\ttraining's rmse: 3.13964\tvalid_1's rmse: 3.66808\n",
      "Early stopping, best iteration is:\n",
      "[1516]\ttraining's rmse: 3.21332\tvalid_1's rmse: 3.66606\n",
      "fold 26 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32122\tvalid_1's rmse: 3.6177\n",
      "Early stopping, best iteration is:\n",
      "[1062]\ttraining's rmse: 3.30894\tvalid_1's rmse: 3.61699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 27 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31349\tvalid_1's rmse: 3.64982\n",
      "Early stopping, best iteration is:\n",
      "[1132]\ttraining's rmse: 3.28856\tvalid_1's rmse: 3.64894\n",
      "fold 28 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30121\tvalid_1's rmse: 3.66585\n",
      "Early stopping, best iteration is:\n",
      "[1105]\ttraining's rmse: 3.28113\tvalid_1's rmse: 3.66514\n",
      "fold 29 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31382\tvalid_1's rmse: 3.64694\n",
      "Early stopping, best iteration is:\n",
      "[844]\ttraining's rmse: 3.34552\tvalid_1's rmse: 3.64624\n",
      "fold 30 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29822\tvalid_1's rmse: 3.68065\n",
      "Early stopping, best iteration is:\n",
      "[803]\ttraining's rmse: 3.33806\tvalid_1's rmse: 3.68008\n",
      "fold 31 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31879\tvalid_1's rmse: 3.63741\n",
      "Early stopping, best iteration is:\n",
      "[795]\ttraining's rmse: 3.362\tvalid_1's rmse: 3.63653\n",
      "fold 32 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31262\tvalid_1's rmse: 3.6306\n",
      "Early stopping, best iteration is:\n",
      "[1159]\ttraining's rmse: 3.2825\tvalid_1's rmse: 3.63004\n",
      "fold 33 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31666\tvalid_1's rmse: 3.64982\n",
      "[2000]\ttraining's rmse: 3.14858\tvalid_1's rmse: 3.64903\n",
      "Early stopping, best iteration is:\n",
      "[1595]\ttraining's rmse: 3.21097\tvalid_1's rmse: 3.64778\n",
      "fold 34 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32021\tvalid_1's rmse: 3.63297\n",
      "Early stopping, best iteration is:\n",
      "[1159]\ttraining's rmse: 3.29121\tvalid_1's rmse: 3.63262\n",
      "fold 35 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30744\tvalid_1's rmse: 3.66017\n",
      "[2000]\ttraining's rmse: 3.14224\tvalid_1's rmse: 3.65989\n",
      "Early stopping, best iteration is:\n",
      "[1692]\ttraining's rmse: 3.1882\tvalid_1's rmse: 3.65854\n",
      "fold 36 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31565\tvalid_1's rmse: 3.63313\n",
      "[2000]\ttraining's rmse: 3.14982\tvalid_1's rmse: 3.6329\n",
      "Early stopping, best iteration is:\n",
      "[1624]\ttraining's rmse: 3.21131\tvalid_1's rmse: 3.63065\n",
      "fold 37 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31653\tvalid_1's rmse: 3.62151\n",
      "[2000]\ttraining's rmse: 3.14809\tvalid_1's rmse: 3.62012\n",
      "Early stopping, best iteration is:\n",
      "[1629]\ttraining's rmse: 3.20454\tvalid_1's rmse: 3.61806\n",
      "fold 38 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29655\tvalid_1's rmse: 3.70063\n",
      "Early stopping, best iteration is:\n",
      "[653]\ttraining's rmse: 3.37214\tvalid_1's rmse: 3.70037\n",
      "fold 39 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31807\tvalid_1's rmse: 3.64161\n",
      "Early stopping, best iteration is:\n",
      "[917]\ttraining's rmse: 3.33455\tvalid_1's rmse: 3.64097\n",
      "fold 40 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31357\tvalid_1's rmse: 3.63579\n",
      "Early stopping, best iteration is:\n",
      "[1210]\ttraining's rmse: 3.2754\tvalid_1's rmse: 3.63537\n",
      "fold 41 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30845\tvalid_1's rmse: 3.65445\n",
      "Early stopping, best iteration is:\n",
      "[756]\ttraining's rmse: 3.35986\tvalid_1's rmse: 3.65357\n",
      "fold 42 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30714\tvalid_1's rmse: 3.6631\n",
      "Early stopping, best iteration is:\n",
      "[934]\ttraining's rmse: 3.32054\tvalid_1's rmse: 3.66262\n",
      "fold 43 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30699\tvalid_1's rmse: 3.65688\n",
      "Early stopping, best iteration is:\n",
      "[1230]\ttraining's rmse: 3.2642\tvalid_1's rmse: 3.65563\n",
      "fold 44 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3129\tvalid_1's rmse: 3.63354\n",
      "[2000]\ttraining's rmse: 3.14224\tvalid_1's rmse: 3.63265\n",
      "Early stopping, best iteration is:\n",
      "[1543]\ttraining's rmse: 3.21511\tvalid_1's rmse: 3.63136\n",
      "fold 45 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31927\tvalid_1's rmse: 3.62661\n",
      "Early stopping, best iteration is:\n",
      "[1081]\ttraining's rmse: 3.30481\tvalid_1's rmse: 3.6262\n",
      "fold 46 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32337\tvalid_1's rmse: 3.622\n",
      "Early stopping, best iteration is:\n",
      "[895]\ttraining's rmse: 3.34437\tvalid_1's rmse: 3.62115\n",
      "fold 47 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29557\tvalid_1's rmse: 3.68502\n",
      "Early stopping, best iteration is:\n",
      "[932]\ttraining's rmse: 3.31013\tvalid_1's rmse: 3.68421\n",
      "fold 48 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30938\tvalid_1's rmse: 3.65075\n",
      "Early stopping, best iteration is:\n",
      "[1251]\ttraining's rmse: 3.26336\tvalid_1's rmse: 3.64991\n",
      "fold 49 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30887\tvalid_1's rmse: 3.66392\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's rmse: 3.36136\tvalid_1's rmse: 3.66334\n",
      "fold 50 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32646\tvalid_1's rmse: 3.6058\n",
      "Early stopping, best iteration is:\n",
      "[1226]\ttraining's rmse: 3.28636\tvalid_1's rmse: 3.60472\n",
      "fold 51 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31151\tvalid_1's rmse: 3.65524\n",
      "[2000]\ttraining's rmse: 3.14675\tvalid_1's rmse: 3.65114\n",
      "Early stopping, best iteration is:\n",
      "[2126]\ttraining's rmse: 3.12818\tvalid_1's rmse: 3.65072\n",
      "fold 52 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30608\tvalid_1's rmse: 3.6619\n",
      "Early stopping, best iteration is:\n",
      "[1015]\ttraining's rmse: 3.30291\tvalid_1's rmse: 3.66183\n",
      "fold 53 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31152\tvalid_1's rmse: 3.64611\n",
      "Early stopping, best iteration is:\n",
      "[824]\ttraining's rmse: 3.34553\tvalid_1's rmse: 3.64566\n",
      "fold 54 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30566\tvalid_1's rmse: 3.67388\n",
      "Early stopping, best iteration is:\n",
      "[724]\ttraining's rmse: 3.3635\tvalid_1's rmse: 3.67325\n",
      "fold 55 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31597\tvalid_1's rmse: 3.63035\n",
      "[2000]\ttraining's rmse: 3.14698\tvalid_1's rmse: 3.63048\n",
      "Early stopping, best iteration is:\n",
      "[1409]\ttraining's rmse: 3.24392\tvalid_1's rmse: 3.62853\n",
      "fold 56 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30299\tvalid_1's rmse: 3.65749\n",
      "Early stopping, best iteration is:\n",
      "[1024]\ttraining's rmse: 3.29868\tvalid_1's rmse: 3.65723\n",
      "fold 57 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31461\tvalid_1's rmse: 3.6484\n",
      "Early stopping, best iteration is:\n",
      "[844]\ttraining's rmse: 3.34672\tvalid_1's rmse: 3.64777\n",
      "fold 58 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31196\tvalid_1's rmse: 3.66946\n",
      "Early stopping, best iteration is:\n",
      "[815]\ttraining's rmse: 3.34874\tvalid_1's rmse: 3.66746\n",
      "fold 59 1472 0.010935132083320953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32706\tvalid_1's rmse: 3.6143\n",
      "[2000]\ttraining's rmse: 3.15903\tvalid_1's rmse: 3.61383\n",
      "Early stopping, best iteration is:\n",
      "[1701]\ttraining's rmse: 3.20538\tvalid_1's rmse: 3.61178\n",
      "fold 0 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32947\tvalid_1's rmse: 3.63003\n",
      "Early stopping, best iteration is:\n",
      "[1160]\ttraining's rmse: 3.30037\tvalid_1's rmse: 3.62929\n",
      "fold 1 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31705\tvalid_1's rmse: 3.6649\n",
      "Early stopping, best iteration is:\n",
      "[870]\ttraining's rmse: 3.34201\tvalid_1's rmse: 3.66429\n",
      "fold 2 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33629\tvalid_1's rmse: 3.61372\n",
      "Early stopping, best iteration is:\n",
      "[1084]\ttraining's rmse: 3.32093\tvalid_1's rmse: 3.61294\n",
      "fold 3 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32237\tvalid_1's rmse: 3.63895\n",
      "Early stopping, best iteration is:\n",
      "[972]\ttraining's rmse: 3.3278\tvalid_1's rmse: 3.63831\n",
      "fold 4 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32199\tvalid_1's rmse: 3.66461\n",
      "Early stopping, best iteration is:\n",
      "[1003]\ttraining's rmse: 3.32136\tvalid_1's rmse: 3.6644\n",
      "fold 5 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31753\tvalid_1's rmse: 3.67261\n",
      "Early stopping, best iteration is:\n",
      "[1208]\ttraining's rmse: 3.27977\tvalid_1's rmse: 3.67217\n",
      "fold 6 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31851\tvalid_1's rmse: 3.65591\n",
      "Early stopping, best iteration is:\n",
      "[1249]\ttraining's rmse: 3.27415\tvalid_1's rmse: 3.65517\n",
      "fold 7 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32812\tvalid_1's rmse: 3.63983\n",
      "[2000]\ttraining's rmse: 3.16555\tvalid_1's rmse: 3.63851\n",
      "Early stopping, best iteration is:\n",
      "[1427]\ttraining's rmse: 3.25549\tvalid_1's rmse: 3.63835\n",
      "fold 8 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32088\tvalid_1's rmse: 3.65152\n",
      "[2000]\ttraining's rmse: 3.15657\tvalid_1's rmse: 3.65135\n",
      "Early stopping, best iteration is:\n",
      "[1601]\ttraining's rmse: 3.21919\tvalid_1's rmse: 3.65025\n",
      "fold 9 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31979\tvalid_1's rmse: 3.65446\n",
      "Early stopping, best iteration is:\n",
      "[1321]\ttraining's rmse: 3.26383\tvalid_1's rmse: 3.65359\n",
      "fold 10 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32936\tvalid_1's rmse: 3.62373\n",
      "Early stopping, best iteration is:\n",
      "[1214]\ttraining's rmse: 3.29091\tvalid_1's rmse: 3.62328\n",
      "fold 11 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32091\tvalid_1's rmse: 3.65906\n",
      "Early stopping, best iteration is:\n",
      "[958]\ttraining's rmse: 3.32968\tvalid_1's rmse: 3.65882\n",
      "fold 12 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33072\tvalid_1's rmse: 3.62867\n",
      "Early stopping, best iteration is:\n",
      "[1007]\ttraining's rmse: 3.32932\tvalid_1's rmse: 3.62854\n",
      "fold 13 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3107\tvalid_1's rmse: 3.67955\n",
      "Early stopping, best iteration is:\n",
      "[1182]\ttraining's rmse: 3.27647\tvalid_1's rmse: 3.67762\n",
      "fold 14 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32745\tvalid_1's rmse: 3.63324\n",
      "Early stopping, best iteration is:\n",
      "[1224]\ttraining's rmse: 3.28756\tvalid_1's rmse: 3.63175\n",
      "fold 15 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32693\tvalid_1's rmse: 3.64024\n",
      "[2000]\ttraining's rmse: 3.16107\tvalid_1's rmse: 3.63906\n",
      "Early stopping, best iteration is:\n",
      "[1735]\ttraining's rmse: 3.20083\tvalid_1's rmse: 3.63868\n",
      "fold 16 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32118\tvalid_1's rmse: 3.63968\n",
      "Early stopping, best iteration is:\n",
      "[805]\ttraining's rmse: 3.36203\tvalid_1's rmse: 3.63872\n",
      "fold 17 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31963\tvalid_1's rmse: 3.63963\n",
      "[2000]\ttraining's rmse: 3.15433\tvalid_1's rmse: 3.63935\n",
      "Early stopping, best iteration is:\n",
      "[1424]\ttraining's rmse: 3.24433\tvalid_1's rmse: 3.63702\n",
      "fold 18 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3374\tvalid_1's rmse: 3.60721\n",
      "[2000]\ttraining's rmse: 3.17726\tvalid_1's rmse: 3.60681\n",
      "Early stopping, best iteration is:\n",
      "[1477]\ttraining's rmse: 3.25401\tvalid_1's rmse: 3.60527\n",
      "fold 19 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32421\tvalid_1's rmse: 3.63142\n",
      "Early stopping, best iteration is:\n",
      "[718]\ttraining's rmse: 3.38195\tvalid_1's rmse: 3.6308\n",
      "fold 20 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3237\tvalid_1's rmse: 3.64649\n",
      "Early stopping, best iteration is:\n",
      "[824]\ttraining's rmse: 3.35793\tvalid_1's rmse: 3.64552\n",
      "fold 21 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31742\tvalid_1's rmse: 3.66874\n",
      "Early stopping, best iteration is:\n",
      "[1228]\ttraining's rmse: 3.2768\tvalid_1's rmse: 3.66779\n",
      "fold 22 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31521\tvalid_1's rmse: 3.66671\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttraining's rmse: 3.33824\tvalid_1's rmse: 3.66601\n",
      "fold 23 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32398\tvalid_1's rmse: 3.65357\n",
      "Early stopping, best iteration is:\n",
      "[1397]\ttraining's rmse: 3.25235\tvalid_1's rmse: 3.6527\n",
      "fold 24 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32651\tvalid_1's rmse: 3.64447\n",
      "Early stopping, best iteration is:\n",
      "[885]\ttraining's rmse: 3.34903\tvalid_1's rmse: 3.64403\n",
      "fold 25 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31822\tvalid_1's rmse: 3.66067\n",
      "[2000]\ttraining's rmse: 3.15431\tvalid_1's rmse: 3.65998\n",
      "Early stopping, best iteration is:\n",
      "[1416]\ttraining's rmse: 3.24384\tvalid_1's rmse: 3.65855\n",
      "fold 26 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33048\tvalid_1's rmse: 3.61989\n",
      "Early stopping, best iteration is:\n",
      "[1133]\ttraining's rmse: 3.30664\tvalid_1's rmse: 3.61863\n",
      "fold 27 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32468\tvalid_1's rmse: 3.65092\n",
      "[2000]\ttraining's rmse: 3.16108\tvalid_1's rmse: 3.64974\n",
      "Early stopping, best iteration is:\n",
      "[1812]\ttraining's rmse: 3.18824\tvalid_1's rmse: 3.6494\n",
      "fold 28 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31213\tvalid_1's rmse: 3.66362\n",
      "Early stopping, best iteration is:\n",
      "[1167]\ttraining's rmse: 3.28084\tvalid_1's rmse: 3.66284\n",
      "fold 29 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32286\tvalid_1's rmse: 3.64341\n",
      "Early stopping, best iteration is:\n",
      "[1028]\ttraining's rmse: 3.31704\tvalid_1's rmse: 3.643\n",
      "fold 30 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31037\tvalid_1's rmse: 3.68127\n",
      "[2000]\ttraining's rmse: 3.1477\tvalid_1's rmse: 3.6806\n",
      "Early stopping, best iteration is:\n",
      "[1835]\ttraining's rmse: 3.17301\tvalid_1's rmse: 3.67928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 31 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33051\tvalid_1's rmse: 3.63612\n",
      "Early stopping, best iteration is:\n",
      "[1294]\ttraining's rmse: 3.27709\tvalid_1's rmse: 3.6354\n",
      "fold 32 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32703\tvalid_1's rmse: 3.63006\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttraining's rmse: 3.3565\tvalid_1's rmse: 3.62884\n",
      "fold 33 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32526\tvalid_1's rmse: 3.65112\n",
      "Early stopping, best iteration is:\n",
      "[1281]\ttraining's rmse: 3.27405\tvalid_1's rmse: 3.64983\n",
      "fold 34 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33091\tvalid_1's rmse: 3.62697\n",
      "Early stopping, best iteration is:\n",
      "[1136]\ttraining's rmse: 3.30584\tvalid_1's rmse: 3.62664\n",
      "fold 35 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31851\tvalid_1's rmse: 3.65841\n",
      "Early stopping, best iteration is:\n",
      "[999]\ttraining's rmse: 3.31878\tvalid_1's rmse: 3.65837\n",
      "fold 36 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33135\tvalid_1's rmse: 3.63135\n",
      "[2000]\ttraining's rmse: 3.16907\tvalid_1's rmse: 3.6337\n",
      "Early stopping, best iteration is:\n",
      "[1456]\ttraining's rmse: 3.25219\tvalid_1's rmse: 3.63078\n",
      "fold 37 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32646\tvalid_1's rmse: 3.62498\n",
      "Early stopping, best iteration is:\n",
      "[1263]\ttraining's rmse: 3.27715\tvalid_1's rmse: 3.62383\n",
      "fold 38 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30767\tvalid_1's rmse: 3.69784\n",
      "Early stopping, best iteration is:\n",
      "[734]\ttraining's rmse: 3.36208\tvalid_1's rmse: 3.69725\n",
      "fold 39 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3302\tvalid_1's rmse: 3.64271\n",
      "Early stopping, best iteration is:\n",
      "[1321]\ttraining's rmse: 3.27241\tvalid_1's rmse: 3.64189\n",
      "fold 40 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32491\tvalid_1's rmse: 3.64238\n",
      "Early stopping, best iteration is:\n",
      "[1075]\ttraining's rmse: 3.31101\tvalid_1's rmse: 3.64184\n",
      "fold 41 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3202\tvalid_1's rmse: 3.65694\n",
      "Early stopping, best iteration is:\n",
      "[590]\ttraining's rmse: 3.40795\tvalid_1's rmse: 3.65641\n",
      "fold 42 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31926\tvalid_1's rmse: 3.66332\n",
      "Early stopping, best iteration is:\n",
      "[681]\ttraining's rmse: 3.38703\tvalid_1's rmse: 3.66116\n",
      "fold 43 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32117\tvalid_1's rmse: 3.65815\n",
      "Early stopping, best iteration is:\n",
      "[910]\ttraining's rmse: 3.33832\tvalid_1's rmse: 3.65791\n",
      "fold 44 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32175\tvalid_1's rmse: 3.62894\n",
      "[2000]\ttraining's rmse: 3.15721\tvalid_1's rmse: 3.62613\n",
      "Early stopping, best iteration is:\n",
      "[1955]\ttraining's rmse: 3.16404\tvalid_1's rmse: 3.62579\n",
      "fold 45 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32775\tvalid_1's rmse: 3.62763\n",
      "Early stopping, best iteration is:\n",
      "[793]\ttraining's rmse: 3.37008\tvalid_1's rmse: 3.62632\n",
      "fold 46 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33277\tvalid_1's rmse: 3.61445\n",
      "Early stopping, best iteration is:\n",
      "[1123]\ttraining's rmse: 3.30992\tvalid_1's rmse: 3.61376\n",
      "fold 47 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31241\tvalid_1's rmse: 3.68506\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's rmse: 3.31589\tvalid_1's rmse: 3.68494\n",
      "fold 48 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32225\tvalid_1's rmse: 3.64702\n",
      "[2000]\ttraining's rmse: 3.15935\tvalid_1's rmse: 3.647\n",
      "Early stopping, best iteration is:\n",
      "[1405]\ttraining's rmse: 3.25138\tvalid_1's rmse: 3.64552\n",
      "fold 49 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31947\tvalid_1's rmse: 3.66635\n",
      "Early stopping, best iteration is:\n",
      "[811]\ttraining's rmse: 3.35895\tvalid_1's rmse: 3.66622\n",
      "fold 50 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33679\tvalid_1's rmse: 3.60219\n",
      "[2000]\ttraining's rmse: 3.17175\tvalid_1's rmse: 3.60132\n",
      "Early stopping, best iteration is:\n",
      "[1477]\ttraining's rmse: 3.25252\tvalid_1's rmse: 3.59974\n",
      "fold 51 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32366\tvalid_1's rmse: 3.65072\n",
      "[2000]\ttraining's rmse: 3.16046\tvalid_1's rmse: 3.64808\n",
      "Early stopping, best iteration is:\n",
      "[1852]\ttraining's rmse: 3.18248\tvalid_1's rmse: 3.64747\n",
      "fold 52 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3156\tvalid_1's rmse: 3.66477\n",
      "Early stopping, best iteration is:\n",
      "[689]\ttraining's rmse: 3.38213\tvalid_1's rmse: 3.66404\n",
      "fold 53 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32232\tvalid_1's rmse: 3.64908\n",
      "Early stopping, best iteration is:\n",
      "[1076]\ttraining's rmse: 3.30869\tvalid_1's rmse: 3.64874\n",
      "fold 54 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31409\tvalid_1's rmse: 3.67343\n",
      "Early stopping, best iteration is:\n",
      "[1021]\ttraining's rmse: 3.30987\tvalid_1's rmse: 3.67321\n",
      "fold 55 1471 0.010927865686056014\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3255\tvalid_1's rmse: 3.62903\n",
      "Early stopping, best iteration is:\n",
      "[1117]\ttraining's rmse: 3.30404\tvalid_1's rmse: 3.62759\n",
      "fold 56 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31747\tvalid_1's rmse: 3.66059\n",
      "[2000]\ttraining's rmse: 3.15156\tvalid_1's rmse: 3.66221\n",
      "Early stopping, best iteration is:\n",
      "[1610]\ttraining's rmse: 3.2114\tvalid_1's rmse: 3.65993\n",
      "fold 57 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32588\tvalid_1's rmse: 3.64676\n",
      "Early stopping, best iteration is:\n",
      "[745]\ttraining's rmse: 3.3795\tvalid_1's rmse: 3.64657\n",
      "fold 58 1472 0.010935213318376656\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32191\tvalid_1's rmse: 3.66993\n",
      "Early stopping, best iteration is:\n",
      "[999]\ttraining's rmse: 3.32219\tvalid_1's rmse: 3.66989\n",
      "fold 59 1472 0.010935132083320953\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3351\tvalid_1's rmse: 3.60904\n",
      "[2000]\ttraining's rmse: 3.17176\tvalid_1's rmse: 3.60792\n",
      "Early stopping, best iteration is:\n",
      "[1608]\ttraining's rmse: 3.23261\tvalid_1's rmse: 3.60665\n",
      "fold 0 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2771\tvalid_1's rmse: 3.62614\n",
      "[2000]\ttraining's rmse: 3.08302\tvalid_1's rmse: 3.62578\n",
      "Early stopping, best iteration is:\n",
      "[1521]\ttraining's rmse: 3.16953\tvalid_1's rmse: 3.62428\n",
      "fold 1 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25651\tvalid_1's rmse: 3.67158\n",
      "Early stopping, best iteration is:\n",
      "[1323]\ttraining's rmse: 3.19219\tvalid_1's rmse: 3.67097\n",
      "fold 2 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27372\tvalid_1's rmse: 3.62651\n",
      "[2000]\ttraining's rmse: 3.08607\tvalid_1's rmse: 3.62694\n",
      "Early stopping, best iteration is:\n",
      "[1826]\ttraining's rmse: 3.11634\tvalid_1's rmse: 3.62582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2708\tvalid_1's rmse: 3.62448\n",
      "[2000]\ttraining's rmse: 3.07966\tvalid_1's rmse: 3.62126\n",
      "Early stopping, best iteration is:\n",
      "[1932]\ttraining's rmse: 3.09078\tvalid_1's rmse: 3.62092\n",
      "fold 4 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25492\tvalid_1's rmse: 3.6794\n",
      "Early stopping, best iteration is:\n",
      "[1177]\ttraining's rmse: 3.21722\tvalid_1's rmse: 3.67896\n",
      "fold 5 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26384\tvalid_1's rmse: 3.66377\n",
      "Early stopping, best iteration is:\n",
      "[982]\ttraining's rmse: 3.26784\tvalid_1's rmse: 3.66321\n",
      "fold 6 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25585\tvalid_1's rmse: 3.67649\n",
      "Early stopping, best iteration is:\n",
      "[816]\ttraining's rmse: 3.29765\tvalid_1's rmse: 3.67605\n",
      "fold 7 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26298\tvalid_1's rmse: 3.64943\n",
      "[2000]\ttraining's rmse: 3.07675\tvalid_1's rmse: 3.64835\n",
      "Early stopping, best iteration is:\n",
      "[1669]\ttraining's rmse: 3.13269\tvalid_1's rmse: 3.64726\n",
      "fold 8 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27368\tvalid_1's rmse: 3.6327\n",
      "[2000]\ttraining's rmse: 3.08385\tvalid_1's rmse: 3.63199\n",
      "Early stopping, best iteration is:\n",
      "[1877]\ttraining's rmse: 3.10479\tvalid_1's rmse: 3.63126\n",
      "fold 9 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.24911\tvalid_1's rmse: 3.6857\n",
      "Early stopping, best iteration is:\n",
      "[912]\ttraining's rmse: 3.26947\tvalid_1's rmse: 3.68544\n",
      "fold 10 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26238\tvalid_1's rmse: 3.66722\n",
      "[2000]\ttraining's rmse: 3.07504\tvalid_1's rmse: 3.66721\n",
      "Early stopping, best iteration is:\n",
      "[1441]\ttraining's rmse: 3.17335\tvalid_1's rmse: 3.66542\n",
      "fold 11 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26893\tvalid_1's rmse: 3.64924\n",
      "Early stopping, best iteration is:\n",
      "[936]\ttraining's rmse: 3.28354\tvalid_1's rmse: 3.6485\n",
      "fold 12 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27362\tvalid_1's rmse: 3.59968\n",
      "[2000]\ttraining's rmse: 3.08822\tvalid_1's rmse: 3.59967\n",
      "Early stopping, best iteration is:\n",
      "[1466]\ttraining's rmse: 3.18195\tvalid_1's rmse: 3.59815\n",
      "fold 13 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26068\tvalid_1's rmse: 3.666\n",
      "Early stopping, best iteration is:\n",
      "[958]\ttraining's rmse: 3.27125\tvalid_1's rmse: 3.66579\n",
      "fold 14 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26801\tvalid_1's rmse: 3.63783\n",
      "Early stopping, best iteration is:\n",
      "[1119]\ttraining's rmse: 3.24349\tvalid_1's rmse: 3.63735\n",
      "fold 15 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25525\tvalid_1's rmse: 3.68372\n",
      "Early stopping, best iteration is:\n",
      "[1211]\ttraining's rmse: 3.20997\tvalid_1's rmse: 3.68279\n",
      "fold 16 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27118\tvalid_1's rmse: 3.63241\n",
      "[2000]\ttraining's rmse: 3.08221\tvalid_1's rmse: 3.63052\n",
      "[3000]\ttraining's rmse: 2.92691\tvalid_1's rmse: 3.63196\n",
      "Early stopping, best iteration is:\n",
      "[2464]\ttraining's rmse: 3.00709\tvalid_1's rmse: 3.62989\n",
      "fold 17 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27171\tvalid_1's rmse: 3.63702\n",
      "Early stopping, best iteration is:\n",
      "[1280]\ttraining's rmse: 3.21282\tvalid_1's rmse: 3.63583\n",
      "fold 18 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25802\tvalid_1's rmse: 3.66668\n",
      "[2000]\ttraining's rmse: 3.06753\tvalid_1's rmse: 3.66633\n",
      "Early stopping, best iteration is:\n",
      "[1730]\ttraining's rmse: 3.11572\tvalid_1's rmse: 3.66568\n",
      "fold 19 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26841\tvalid_1's rmse: 3.64288\n",
      "Early stopping, best iteration is:\n",
      "[1152]\ttraining's rmse: 3.23566\tvalid_1's rmse: 3.6424\n",
      "fold 20 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26512\tvalid_1's rmse: 3.64706\n",
      "[2000]\ttraining's rmse: 3.07663\tvalid_1's rmse: 3.645\n",
      "Early stopping, best iteration is:\n",
      "[1797]\ttraining's rmse: 3.11182\tvalid_1's rmse: 3.64449\n",
      "fold 21 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27257\tvalid_1's rmse: 3.61647\n",
      "[2000]\ttraining's rmse: 3.08401\tvalid_1's rmse: 3.61443\n",
      "Early stopping, best iteration is:\n",
      "[1603]\ttraining's rmse: 3.15468\tvalid_1's rmse: 3.61368\n",
      "fold 22 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26415\tvalid_1's rmse: 3.6345\n",
      "Early stopping, best iteration is:\n",
      "[958]\ttraining's rmse: 3.27365\tvalid_1's rmse: 3.63428\n",
      "fold 23 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2633\tvalid_1's rmse: 3.65129\n",
      "Early stopping, best iteration is:\n",
      "[1252]\ttraining's rmse: 3.21123\tvalid_1's rmse: 3.64947\n",
      "fold 24 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26498\tvalid_1's rmse: 3.64925\n",
      "[2000]\ttraining's rmse: 3.07584\tvalid_1's rmse: 3.6469\n",
      "Early stopping, best iteration is:\n",
      "[1580]\ttraining's rmse: 3.14929\tvalid_1's rmse: 3.64645\n",
      "fold 25 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26384\tvalid_1's rmse: 3.66401\n",
      "Early stopping, best iteration is:\n",
      "[987]\ttraining's rmse: 3.26677\tvalid_1's rmse: 3.66381\n",
      "fold 26 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25492\tvalid_1's rmse: 3.67765\n",
      "Early stopping, best iteration is:\n",
      "[1339]\ttraining's rmse: 3.18629\tvalid_1's rmse: 3.6767\n",
      "fold 27 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26509\tvalid_1's rmse: 3.64633\n",
      "[2000]\ttraining's rmse: 3.07587\tvalid_1's rmse: 3.64387\n",
      "Early stopping, best iteration is:\n",
      "[1751]\ttraining's rmse: 3.11915\tvalid_1's rmse: 3.64341\n",
      "fold 28 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26256\tvalid_1's rmse: 3.66046\n",
      "Early stopping, best iteration is:\n",
      "[1173]\ttraining's rmse: 3.22645\tvalid_1's rmse: 3.65996\n",
      "fold 29 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26832\tvalid_1's rmse: 3.65984\n",
      "Early stopping, best iteration is:\n",
      "[1327]\ttraining's rmse: 3.20059\tvalid_1's rmse: 3.65853\n",
      "fold 30 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26523\tvalid_1's rmse: 3.64989\n",
      "Early stopping, best iteration is:\n",
      "[1319]\ttraining's rmse: 3.20104\tvalid_1's rmse: 3.64974\n",
      "fold 31 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2775\tvalid_1's rmse: 3.60992\n",
      "Early stopping, best iteration is:\n",
      "[1253]\ttraining's rmse: 3.22416\tvalid_1's rmse: 3.60931\n",
      "fold 32 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25411\tvalid_1's rmse: 3.6776\n",
      "Early stopping, best iteration is:\n",
      "[1215]\ttraining's rmse: 3.20946\tvalid_1's rmse: 3.67654\n",
      "fold 33 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25774\tvalid_1's rmse: 3.6517\n",
      "[2000]\ttraining's rmse: 3.06658\tvalid_1's rmse: 3.65208\n",
      "Early stopping, best iteration is:\n",
      "[1586]\ttraining's rmse: 3.14088\tvalid_1's rmse: 3.65035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 34 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26163\tvalid_1's rmse: 3.65304\n",
      "[2000]\ttraining's rmse: 3.07339\tvalid_1's rmse: 3.65173\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's rmse: 3.1378\tvalid_1's rmse: 3.65051\n",
      "fold 35 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25459\tvalid_1's rmse: 3.6881\n",
      "Early stopping, best iteration is:\n",
      "[1080]\ttraining's rmse: 3.2391\tvalid_1's rmse: 3.68784\n",
      "fold 36 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26983\tvalid_1's rmse: 3.63165\n",
      "Early stopping, best iteration is:\n",
      "[910]\ttraining's rmse: 3.28954\tvalid_1's rmse: 3.63116\n",
      "fold 37 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26688\tvalid_1's rmse: 3.6253\n",
      "[2000]\ttraining's rmse: 3.07585\tvalid_1's rmse: 3.62277\n",
      "Early stopping, best iteration is:\n",
      "[1890]\ttraining's rmse: 3.09414\tvalid_1's rmse: 3.62233\n",
      "fold 38 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26305\tvalid_1's rmse: 3.66007\n",
      "[2000]\ttraining's rmse: 3.07509\tvalid_1's rmse: 3.66076\n",
      "Early stopping, best iteration is:\n",
      "[1406]\ttraining's rmse: 3.18059\tvalid_1's rmse: 3.65852\n",
      "fold 39 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26764\tvalid_1's rmse: 3.6372\n",
      "Early stopping, best iteration is:\n",
      "[1367]\ttraining's rmse: 3.19191\tvalid_1's rmse: 3.63653\n",
      "fold 40 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26771\tvalid_1's rmse: 3.64588\n",
      "Early stopping, best iteration is:\n",
      "[1332]\ttraining's rmse: 3.2008\tvalid_1's rmse: 3.64371\n",
      "fold 41 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26103\tvalid_1's rmse: 3.65696\n",
      "Early stopping, best iteration is:\n",
      "[1286]\ttraining's rmse: 3.20045\tvalid_1's rmse: 3.65579\n",
      "fold 42 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2672\tvalid_1's rmse: 3.63474\n",
      "[2000]\ttraining's rmse: 3.07861\tvalid_1's rmse: 3.63414\n",
      "Early stopping, best iteration is:\n",
      "[1756]\ttraining's rmse: 3.1208\tvalid_1's rmse: 3.63341\n",
      "fold 43 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27087\tvalid_1's rmse: 3.62305\n",
      "Early stopping, best iteration is:\n",
      "[1281]\ttraining's rmse: 3.21279\tvalid_1's rmse: 3.62136\n",
      "fold 44 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25724\tvalid_1's rmse: 3.67813\n",
      "[2000]\ttraining's rmse: 3.06692\tvalid_1's rmse: 3.67831\n",
      "Early stopping, best iteration is:\n",
      "[1672]\ttraining's rmse: 3.12519\tvalid_1's rmse: 3.67731\n",
      "fold 45 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26382\tvalid_1's rmse: 3.65857\n",
      "Early stopping, best iteration is:\n",
      "[1090]\ttraining's rmse: 3.24433\tvalid_1's rmse: 3.65845\n",
      "fold 46 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26733\tvalid_1's rmse: 3.64793\n",
      "[2000]\ttraining's rmse: 3.07518\tvalid_1's rmse: 3.64805\n",
      "Early stopping, best iteration is:\n",
      "[1483]\ttraining's rmse: 3.16793\tvalid_1's rmse: 3.64708\n",
      "fold 47 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26418\tvalid_1's rmse: 3.64748\n",
      "[2000]\ttraining's rmse: 3.07712\tvalid_1's rmse: 3.64707\n",
      "Early stopping, best iteration is:\n",
      "[1433]\ttraining's rmse: 3.17762\tvalid_1's rmse: 3.6464\n",
      "fold 48 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26121\tvalid_1's rmse: 3.65407\n",
      "Early stopping, best iteration is:\n",
      "[1047]\ttraining's rmse: 3.25136\tvalid_1's rmse: 3.65376\n",
      "fold 49 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25625\tvalid_1's rmse: 3.68022\n",
      "[2000]\ttraining's rmse: 3.06922\tvalid_1's rmse: 3.6805\n",
      "Early stopping, best iteration is:\n",
      "[1617]\ttraining's rmse: 3.13582\tvalid_1's rmse: 3.67948\n",
      "fold 50 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26643\tvalid_1's rmse: 3.64649\n",
      "Early stopping, best iteration is:\n",
      "[1128]\ttraining's rmse: 3.23786\tvalid_1's rmse: 3.64526\n",
      "fold 51 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2691\tvalid_1's rmse: 3.65361\n",
      "Early stopping, best iteration is:\n",
      "[1191]\ttraining's rmse: 3.22705\tvalid_1's rmse: 3.65249\n",
      "fold 52 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26613\tvalid_1's rmse: 3.62993\n",
      "Early stopping, best iteration is:\n",
      "[942]\ttraining's rmse: 3.27918\tvalid_1's rmse: 3.62944\n",
      "fold 53 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27369\tvalid_1's rmse: 3.64229\n",
      "Early stopping, best iteration is:\n",
      "[1244]\ttraining's rmse: 3.22398\tvalid_1's rmse: 3.64152\n",
      "fold 54 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26559\tvalid_1's rmse: 3.65419\n",
      "Early stopping, best iteration is:\n",
      "[1107]\ttraining's rmse: 3.24362\tvalid_1's rmse: 3.65409\n",
      "fold 55 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25875\tvalid_1's rmse: 3.67736\n",
      "Early stopping, best iteration is:\n",
      "[929]\ttraining's rmse: 3.27459\tvalid_1's rmse: 3.67658\n",
      "fold 56 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26544\tvalid_1's rmse: 3.65112\n",
      "[2000]\ttraining's rmse: 3.07263\tvalid_1's rmse: 3.64746\n",
      "Early stopping, best iteration is:\n",
      "[1842]\ttraining's rmse: 3.09995\tvalid_1's rmse: 3.64681\n",
      "fold 57 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26339\tvalid_1's rmse: 3.66065\n",
      "Early stopping, best iteration is:\n",
      "[1307]\ttraining's rmse: 3.19873\tvalid_1's rmse: 3.65982\n",
      "fold 58 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26581\tvalid_1's rmse: 3.638\n",
      "[2000]\ttraining's rmse: 3.07709\tvalid_1's rmse: 3.63638\n",
      "Early stopping, best iteration is:\n",
      "[2119]\ttraining's rmse: 3.0561\tvalid_1's rmse: 3.63597\n",
      "fold 59 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28023\tvalid_1's rmse: 3.60057\n",
      "Early stopping, best iteration is:\n",
      "[1346]\ttraining's rmse: 3.21058\tvalid_1's rmse: 3.60023\n",
      "fold 60 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25539\tvalid_1's rmse: 3.69221\n",
      "Early stopping, best iteration is:\n",
      "[1272]\ttraining's rmse: 3.19901\tvalid_1's rmse: 3.69145\n",
      "fold 61 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26025\tvalid_1's rmse: 3.65862\n",
      "Early stopping, best iteration is:\n",
      "[1167]\ttraining's rmse: 3.22476\tvalid_1's rmse: 3.65785\n",
      "fold 62 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26645\tvalid_1's rmse: 3.65304\n",
      "Early stopping, best iteration is:\n",
      "[878]\ttraining's rmse: 3.29359\tvalid_1's rmse: 3.65257\n",
      "fold 63 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26158\tvalid_1's rmse: 3.67082\n",
      "Early stopping, best iteration is:\n",
      "[1080]\ttraining's rmse: 3.24521\tvalid_1's rmse: 3.6705\n",
      "fold 64 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.25876\tvalid_1's rmse: 3.66089\n",
      "[2000]\ttraining's rmse: 3.06725\tvalid_1's rmse: 3.65954\n",
      "Early stopping, best iteration is:\n",
      "[1726]\ttraining's rmse: 3.1148\tvalid_1's rmse: 3.65921\n",
      "fold 65 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.26034\tvalid_1's rmse: 3.63544\n",
      "Early stopping, best iteration is:\n",
      "[1228]\ttraining's rmse: 3.2121\tvalid_1's rmse: 3.63457\n",
      "fold 66 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26787\tvalid_1's rmse: 3.65004\n",
      "Early stopping, best iteration is:\n",
      "[886]\ttraining's rmse: 3.29362\tvalid_1's rmse: 3.64965\n",
      "fold 67 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26232\tvalid_1's rmse: 3.65926\n",
      "[2000]\ttraining's rmse: 3.0748\tvalid_1's rmse: 3.65654\n",
      "Early stopping, best iteration is:\n",
      "[1709]\ttraining's rmse: 3.12595\tvalid_1's rmse: 3.65576\n",
      "fold 68 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26183\tvalid_1's rmse: 3.67665\n",
      "Early stopping, best iteration is:\n",
      "[816]\ttraining's rmse: 3.30585\tvalid_1's rmse: 3.67555\n",
      "fold 69 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27711\tvalid_1's rmse: 3.60005\n",
      "[2000]\ttraining's rmse: 3.08937\tvalid_1's rmse: 3.59962\n",
      "Early stopping, best iteration is:\n",
      "[1509]\ttraining's rmse: 3.17474\tvalid_1's rmse: 3.5985\n",
      "fold 0 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29343\tvalid_1's rmse: 3.61722\n",
      "Early stopping, best iteration is:\n",
      "[1038]\ttraining's rmse: 3.28536\tvalid_1's rmse: 3.61679\n",
      "fold 1 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2789\tvalid_1's rmse: 3.65953\n",
      "Early stopping, best iteration is:\n",
      "[1105]\ttraining's rmse: 3.25786\tvalid_1's rmse: 3.65863\n",
      "fold 2 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29637\tvalid_1's rmse: 3.62034\n",
      "Early stopping, best iteration is:\n",
      "[938]\ttraining's rmse: 3.30916\tvalid_1's rmse: 3.62\n",
      "fold 3 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29518\tvalid_1's rmse: 3.62511\n",
      "Early stopping, best iteration is:\n",
      "[1284]\ttraining's rmse: 3.23777\tvalid_1's rmse: 3.62334\n",
      "fold 4 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2811\tvalid_1's rmse: 3.67662\n",
      "Early stopping, best iteration is:\n",
      "[1196]\ttraining's rmse: 3.24155\tvalid_1's rmse: 3.67575\n",
      "fold 5 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28518\tvalid_1's rmse: 3.6592\n",
      "Early stopping, best iteration is:\n",
      "[1342]\ttraining's rmse: 3.21943\tvalid_1's rmse: 3.65754\n",
      "fold 6 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28239\tvalid_1's rmse: 3.67455\n",
      "Early stopping, best iteration is:\n",
      "[931]\ttraining's rmse: 3.29658\tvalid_1's rmse: 3.67401\n",
      "fold 7 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29173\tvalid_1's rmse: 3.64207\n",
      "[2000]\ttraining's rmse: 3.11252\tvalid_1's rmse: 3.63773\n",
      "Early stopping, best iteration is:\n",
      "[2207]\ttraining's rmse: 3.08088\tvalid_1's rmse: 3.63727\n",
      "fold 8 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29721\tvalid_1's rmse: 3.62837\n",
      "[2000]\ttraining's rmse: 3.11703\tvalid_1's rmse: 3.62368\n",
      "Early stopping, best iteration is:\n",
      "[2297]\ttraining's rmse: 3.07125\tvalid_1's rmse: 3.62345\n",
      "fold 9 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27656\tvalid_1's rmse: 3.6839\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's rmse: 3.34455\tvalid_1's rmse: 3.68282\n",
      "fold 10 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28524\tvalid_1's rmse: 3.66537\n",
      "Early stopping, best iteration is:\n",
      "[1341]\ttraining's rmse: 3.21855\tvalid_1's rmse: 3.66498\n",
      "fold 11 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29067\tvalid_1's rmse: 3.64071\n",
      "Early stopping, best iteration is:\n",
      "[1282]\ttraining's rmse: 3.23489\tvalid_1's rmse: 3.64058\n",
      "fold 12 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29686\tvalid_1's rmse: 3.59981\n",
      "Early stopping, best iteration is:\n",
      "[1275]\ttraining's rmse: 3.24351\tvalid_1's rmse: 3.59752\n",
      "fold 13 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28383\tvalid_1's rmse: 3.65731\n",
      "[2000]\ttraining's rmse: 3.10883\tvalid_1's rmse: 3.65907\n",
      "Early stopping, best iteration is:\n",
      "[1409]\ttraining's rmse: 3.20617\tvalid_1's rmse: 3.65635\n",
      "fold 14 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29078\tvalid_1's rmse: 3.63947\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's rmse: 3.29384\tvalid_1's rmse: 3.63911\n",
      "fold 15 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27901\tvalid_1's rmse: 3.68172\n",
      "Early stopping, best iteration is:\n",
      "[1339]\ttraining's rmse: 3.2128\tvalid_1's rmse: 3.68144\n",
      "fold 16 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29566\tvalid_1's rmse: 3.63572\n",
      "[2000]\ttraining's rmse: 3.11968\tvalid_1's rmse: 3.63511\n",
      "Early stopping, best iteration is:\n",
      "[1494]\ttraining's rmse: 3.20173\tvalid_1's rmse: 3.63417\n",
      "fold 17 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29361\tvalid_1's rmse: 3.62944\n",
      "Early stopping, best iteration is:\n",
      "[1053]\ttraining's rmse: 3.28281\tvalid_1's rmse: 3.62878\n",
      "fold 18 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28233\tvalid_1's rmse: 3.66647\n",
      "[2000]\ttraining's rmse: 3.10428\tvalid_1's rmse: 3.66582\n",
      "Early stopping, best iteration is:\n",
      "[1491]\ttraining's rmse: 3.19002\tvalid_1's rmse: 3.66431\n",
      "fold 19 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29141\tvalid_1's rmse: 3.63991\n",
      "Early stopping, best iteration is:\n",
      "[1023]\ttraining's rmse: 3.28652\tvalid_1's rmse: 3.63977\n",
      "fold 20 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28948\tvalid_1's rmse: 3.63868\n",
      "Early stopping, best iteration is:\n",
      "[1279]\ttraining's rmse: 3.23473\tvalid_1's rmse: 3.63789\n",
      "fold 21 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29727\tvalid_1's rmse: 3.61507\n",
      "[2000]\ttraining's rmse: 3.11989\tvalid_1's rmse: 3.61324\n",
      "Early stopping, best iteration is:\n",
      "[2354]\ttraining's rmse: 3.06599\tvalid_1's rmse: 3.61208\n",
      "fold 22 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29085\tvalid_1's rmse: 3.63122\n",
      "Early stopping, best iteration is:\n",
      "[1007]\ttraining's rmse: 3.28904\tvalid_1's rmse: 3.63107\n",
      "fold 23 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28739\tvalid_1's rmse: 3.64655\n",
      "Early stopping, best iteration is:\n",
      "[1039]\ttraining's rmse: 3.27929\tvalid_1's rmse: 3.64599\n",
      "fold 24 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28947\tvalid_1's rmse: 3.64569\n",
      "[2000]\ttraining's rmse: 3.10967\tvalid_1's rmse: 3.64469\n",
      "Early stopping, best iteration is:\n",
      "[1823]\ttraining's rmse: 3.13786\tvalid_1's rmse: 3.64404\n",
      "fold 25 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28289\tvalid_1's rmse: 3.66767\n",
      "Early stopping, best iteration is:\n",
      "[852]\ttraining's rmse: 3.31464\tvalid_1's rmse: 3.66663\n",
      "fold 26 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27894\tvalid_1's rmse: 3.67287\n",
      "Early stopping, best iteration is:\n",
      "[910]\ttraining's rmse: 3.29733\tvalid_1's rmse: 3.67223\n",
      "fold 27 1514 0.010934723887388233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28799\tvalid_1's rmse: 3.63936\n",
      "[2000]\ttraining's rmse: 3.10731\tvalid_1's rmse: 3.63545\n",
      "Early stopping, best iteration is:\n",
      "[1922]\ttraining's rmse: 3.12016\tvalid_1's rmse: 3.63513\n",
      "fold 28 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2905\tvalid_1's rmse: 3.655\n",
      "Early stopping, best iteration is:\n",
      "[980]\ttraining's rmse: 3.29459\tvalid_1's rmse: 3.65482\n",
      "fold 29 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28862\tvalid_1's rmse: 3.65299\n",
      "Early stopping, best iteration is:\n",
      "[1373]\ttraining's rmse: 3.21589\tvalid_1's rmse: 3.65265\n",
      "fold 30 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29182\tvalid_1's rmse: 3.64705\n",
      "Early stopping, best iteration is:\n",
      "[1313]\ttraining's rmse: 3.23359\tvalid_1's rmse: 3.64647\n",
      "fold 31 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30137\tvalid_1's rmse: 3.60345\n",
      "[2000]\ttraining's rmse: 3.12651\tvalid_1's rmse: 3.60155\n",
      "Early stopping, best iteration is:\n",
      "[1919]\ttraining's rmse: 3.13924\tvalid_1's rmse: 3.60098\n",
      "fold 32 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28014\tvalid_1's rmse: 3.67387\n",
      "Early stopping, best iteration is:\n",
      "[1132]\ttraining's rmse: 3.25378\tvalid_1's rmse: 3.67318\n",
      "fold 33 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28263\tvalid_1's rmse: 3.65422\n",
      "Early stopping, best iteration is:\n",
      "[1097]\ttraining's rmse: 3.26379\tvalid_1's rmse: 3.65373\n",
      "fold 34 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28242\tvalid_1's rmse: 3.64807\n",
      "Early stopping, best iteration is:\n",
      "[1184]\ttraining's rmse: 3.24538\tvalid_1's rmse: 3.64694\n",
      "fold 35 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27748\tvalid_1's rmse: 3.68522\n",
      "[2000]\ttraining's rmse: 3.10598\tvalid_1's rmse: 3.68558\n",
      "Early stopping, best iteration is:\n",
      "[1604]\ttraining's rmse: 3.16799\tvalid_1's rmse: 3.68453\n",
      "fold 36 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29766\tvalid_1's rmse: 3.63088\n",
      "[2000]\ttraining's rmse: 3.12169\tvalid_1's rmse: 3.62922\n",
      "Early stopping, best iteration is:\n",
      "[1515]\ttraining's rmse: 3.20126\tvalid_1's rmse: 3.62867\n",
      "fold 37 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28788\tvalid_1's rmse: 3.61851\n",
      "Early stopping, best iteration is:\n",
      "[1103]\ttraining's rmse: 3.26659\tvalid_1's rmse: 3.61737\n",
      "fold 38 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28508\tvalid_1's rmse: 3.6557\n",
      "[2000]\ttraining's rmse: 3.10926\tvalid_1's rmse: 3.65447\n",
      "Early stopping, best iteration is:\n",
      "[1646]\ttraining's rmse: 3.16602\tvalid_1's rmse: 3.65369\n",
      "fold 39 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29166\tvalid_1's rmse: 3.63812\n",
      "[2000]\ttraining's rmse: 3.11605\tvalid_1's rmse: 3.63855\n",
      "Early stopping, best iteration is:\n",
      "[1807]\ttraining's rmse: 3.14622\tvalid_1's rmse: 3.63739\n",
      "fold 40 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2884\tvalid_1's rmse: 3.64504\n",
      "[2000]\ttraining's rmse: 3.10765\tvalid_1's rmse: 3.64553\n",
      "Early stopping, best iteration is:\n",
      "[1404]\ttraining's rmse: 3.20991\tvalid_1's rmse: 3.64432\n",
      "fold 41 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28754\tvalid_1's rmse: 3.65284\n",
      "[2000]\ttraining's rmse: 3.10932\tvalid_1's rmse: 3.6511\n",
      "Early stopping, best iteration is:\n",
      "[1442]\ttraining's rmse: 3.20194\tvalid_1's rmse: 3.65031\n",
      "fold 42 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29271\tvalid_1's rmse: 3.63324\n",
      "Early stopping, best iteration is:\n",
      "[1054]\ttraining's rmse: 3.28221\tvalid_1's rmse: 3.63234\n",
      "fold 43 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29539\tvalid_1's rmse: 3.62405\n",
      "[2000]\ttraining's rmse: 3.11826\tvalid_1's rmse: 3.62383\n",
      "Early stopping, best iteration is:\n",
      "[1514]\ttraining's rmse: 3.19763\tvalid_1's rmse: 3.62156\n",
      "fold 44 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28376\tvalid_1's rmse: 3.67732\n",
      "Early stopping, best iteration is:\n",
      "[1263]\ttraining's rmse: 3.23301\tvalid_1's rmse: 3.67671\n",
      "fold 45 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28743\tvalid_1's rmse: 3.66132\n",
      "Early stopping, best iteration is:\n",
      "[1037]\ttraining's rmse: 3.27974\tvalid_1's rmse: 3.66066\n",
      "fold 46 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29236\tvalid_1's rmse: 3.64297\n",
      "[2000]\ttraining's rmse: 3.11204\tvalid_1's rmse: 3.64313\n",
      "Early stopping, best iteration is:\n",
      "[1540]\ttraining's rmse: 3.18957\tvalid_1's rmse: 3.64136\n",
      "fold 47 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28777\tvalid_1's rmse: 3.64143\n",
      "[2000]\ttraining's rmse: 3.11078\tvalid_1's rmse: 3.63856\n",
      "Early stopping, best iteration is:\n",
      "[1707]\ttraining's rmse: 3.15943\tvalid_1's rmse: 3.63777\n",
      "fold 48 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28434\tvalid_1's rmse: 3.65639\n",
      "Early stopping, best iteration is:\n",
      "[866]\ttraining's rmse: 3.31406\tvalid_1's rmse: 3.65501\n",
      "fold 49 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27626\tvalid_1's rmse: 3.68297\n",
      "Early stopping, best iteration is:\n",
      "[1163]\ttraining's rmse: 3.24285\tvalid_1's rmse: 3.68246\n",
      "fold 50 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29075\tvalid_1's rmse: 3.64255\n",
      "Early stopping, best iteration is:\n",
      "[1015]\ttraining's rmse: 3.2878\tvalid_1's rmse: 3.64225\n",
      "fold 51 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29194\tvalid_1's rmse: 3.64825\n",
      "Early stopping, best iteration is:\n",
      "[1182]\ttraining's rmse: 3.25525\tvalid_1's rmse: 3.64704\n",
      "fold 52 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29212\tvalid_1's rmse: 3.62394\n",
      "Early stopping, best iteration is:\n",
      "[1192]\ttraining's rmse: 3.2527\tvalid_1's rmse: 3.62367\n",
      "fold 53 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29527\tvalid_1's rmse: 3.63376\n",
      "[2000]\ttraining's rmse: 3.12036\tvalid_1's rmse: 3.6307\n",
      "Early stopping, best iteration is:\n",
      "[2000]\ttraining's rmse: 3.12036\tvalid_1's rmse: 3.6307\n",
      "fold 54 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28702\tvalid_1's rmse: 3.64496\n",
      "[2000]\ttraining's rmse: 3.11016\tvalid_1's rmse: 3.64515\n",
      "Early stopping, best iteration is:\n",
      "[1765]\ttraining's rmse: 3.14841\tvalid_1's rmse: 3.64347\n",
      "fold 55 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28263\tvalid_1's rmse: 3.67282\n",
      "Early stopping, best iteration is:\n",
      "[916]\ttraining's rmse: 3.30035\tvalid_1's rmse: 3.67223\n",
      "fold 56 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28926\tvalid_1's rmse: 3.64511\n",
      "[2000]\ttraining's rmse: 3.11132\tvalid_1's rmse: 3.64325\n",
      "Early stopping, best iteration is:\n",
      "[1815]\ttraining's rmse: 3.14144\tvalid_1's rmse: 3.64259\n",
      "fold 57 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2879\tvalid_1's rmse: 3.65779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[840]\ttraining's rmse: 3.32303\tvalid_1's rmse: 3.65703\n",
      "fold 58 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.29487\tvalid_1's rmse: 3.62843\n",
      "[2000]\ttraining's rmse: 3.11373\tvalid_1's rmse: 3.62586\n",
      "[3000]\ttraining's rmse: 2.96506\tvalid_1's rmse: 3.6259\n",
      "Early stopping, best iteration is:\n",
      "[2578]\ttraining's rmse: 3.02307\tvalid_1's rmse: 3.62482\n",
      "fold 59 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30191\tvalid_1's rmse: 3.60287\n",
      "Early stopping, best iteration is:\n",
      "[1079]\ttraining's rmse: 3.28653\tvalid_1's rmse: 3.60219\n",
      "fold 60 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27673\tvalid_1's rmse: 3.69069\n",
      "Early stopping, best iteration is:\n",
      "[1148]\ttraining's rmse: 3.24617\tvalid_1's rmse: 3.68975\n",
      "fold 61 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28545\tvalid_1's rmse: 3.65407\n",
      "Early stopping, best iteration is:\n",
      "[1149]\ttraining's rmse: 3.25554\tvalid_1's rmse: 3.65367\n",
      "fold 62 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28679\tvalid_1's rmse: 3.65615\n",
      "Early stopping, best iteration is:\n",
      "[1020]\ttraining's rmse: 3.28278\tvalid_1's rmse: 3.65592\n",
      "fold 63 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28181\tvalid_1's rmse: 3.67009\n",
      "[2000]\ttraining's rmse: 3.105\tvalid_1's rmse: 3.67086\n",
      "Early stopping, best iteration is:\n",
      "[1693]\ttraining's rmse: 3.15504\tvalid_1's rmse: 3.6694\n",
      "fold 64 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28652\tvalid_1's rmse: 3.65616\n",
      "[2000]\ttraining's rmse: 3.1035\tvalid_1's rmse: 3.65268\n",
      "Early stopping, best iteration is:\n",
      "[1967]\ttraining's rmse: 3.10916\tvalid_1's rmse: 3.65224\n",
      "fold 65 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28659\tvalid_1's rmse: 3.62988\n",
      "Early stopping, best iteration is:\n",
      "[1235]\ttraining's rmse: 3.24079\tvalid_1's rmse: 3.62897\n",
      "fold 66 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28714\tvalid_1's rmse: 3.64612\n",
      "Early stopping, best iteration is:\n",
      "[1167]\ttraining's rmse: 3.25271\tvalid_1's rmse: 3.6452\n",
      "fold 67 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28621\tvalid_1's rmse: 3.657\n",
      "[2000]\ttraining's rmse: 3.1059\tvalid_1's rmse: 3.65458\n",
      "Early stopping, best iteration is:\n",
      "[1781]\ttraining's rmse: 3.1449\tvalid_1's rmse: 3.65429\n",
      "fold 68 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28701\tvalid_1's rmse: 3.67461\n",
      "Early stopping, best iteration is:\n",
      "[804]\ttraining's rmse: 3.32965\tvalid_1's rmse: 3.67347\n",
      "fold 69 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.302\tvalid_1's rmse: 3.59731\n",
      "Early stopping, best iteration is:\n",
      "[1314]\ttraining's rmse: 3.24005\tvalid_1's rmse: 3.59546\n",
      "fold 0 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32589\tvalid_1's rmse: 3.61571\n",
      "Early stopping, best iteration is:\n",
      "[1040]\ttraining's rmse: 3.3186\tvalid_1's rmse: 3.61543\n",
      "fold 1 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31441\tvalid_1's rmse: 3.66352\n",
      "Early stopping, best iteration is:\n",
      "[780]\ttraining's rmse: 3.35855\tvalid_1's rmse: 3.66278\n",
      "fold 2 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32715\tvalid_1's rmse: 3.62363\n",
      "Early stopping, best iteration is:\n",
      "[1190]\ttraining's rmse: 3.29339\tvalid_1's rmse: 3.62317\n",
      "fold 3 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32171\tvalid_1's rmse: 3.62242\n",
      "Early stopping, best iteration is:\n",
      "[1374]\ttraining's rmse: 3.25545\tvalid_1's rmse: 3.62112\n",
      "fold 4 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31023\tvalid_1's rmse: 3.67678\n",
      "Early stopping, best iteration is:\n",
      "[1313]\ttraining's rmse: 3.25452\tvalid_1's rmse: 3.67587\n",
      "fold 5 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31694\tvalid_1's rmse: 3.66082\n",
      "Early stopping, best iteration is:\n",
      "[1261]\ttraining's rmse: 3.26825\tvalid_1's rmse: 3.6599\n",
      "fold 6 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31158\tvalid_1's rmse: 3.67197\n",
      "Early stopping, best iteration is:\n",
      "[1060]\ttraining's rmse: 3.30016\tvalid_1's rmse: 3.67156\n",
      "fold 7 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32196\tvalid_1's rmse: 3.6345\n",
      "Early stopping, best iteration is:\n",
      "[1242]\ttraining's rmse: 3.27754\tvalid_1's rmse: 3.63302\n",
      "fold 8 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32754\tvalid_1's rmse: 3.62228\n",
      "[2000]\ttraining's rmse: 3.16052\tvalid_1's rmse: 3.61982\n",
      "Early stopping, best iteration is:\n",
      "[1542]\ttraining's rmse: 3.23079\tvalid_1's rmse: 3.61841\n",
      "fold 9 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30793\tvalid_1's rmse: 3.67946\n",
      "Early stopping, best iteration is:\n",
      "[890]\ttraining's rmse: 3.32972\tvalid_1's rmse: 3.67843\n",
      "fold 10 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31586\tvalid_1's rmse: 3.66623\n",
      "Early stopping, best iteration is:\n",
      "[1038]\ttraining's rmse: 3.30909\tvalid_1's rmse: 3.66613\n",
      "fold 11 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32141\tvalid_1's rmse: 3.64014\n",
      "Early stopping, best iteration is:\n",
      "[951]\ttraining's rmse: 3.33073\tvalid_1's rmse: 3.6398\n",
      "fold 12 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32756\tvalid_1's rmse: 3.59933\n",
      "Early stopping, best iteration is:\n",
      "[967]\ttraining's rmse: 3.33373\tvalid_1's rmse: 3.59905\n",
      "fold 13 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31694\tvalid_1's rmse: 3.66359\n",
      "[2000]\ttraining's rmse: 3.15389\tvalid_1's rmse: 3.66572\n",
      "Early stopping, best iteration is:\n",
      "[1426]\ttraining's rmse: 3.24299\tvalid_1's rmse: 3.66256\n",
      "fold 14 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32189\tvalid_1's rmse: 3.63478\n",
      "Early stopping, best iteration is:\n",
      "[854]\ttraining's rmse: 3.35108\tvalid_1's rmse: 3.6344\n",
      "fold 15 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31055\tvalid_1's rmse: 3.68458\n",
      "Early stopping, best iteration is:\n",
      "[928]\ttraining's rmse: 3.32468\tvalid_1's rmse: 3.68375\n",
      "fold 16 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32213\tvalid_1's rmse: 3.63323\n",
      "Early stopping, best iteration is:\n",
      "[1204]\ttraining's rmse: 3.28506\tvalid_1's rmse: 3.63171\n",
      "fold 17 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3256\tvalid_1's rmse: 3.62685\n",
      "Early stopping, best iteration is:\n",
      "[1174]\ttraining's rmse: 3.29361\tvalid_1's rmse: 3.62636\n",
      "fold 18 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30914\tvalid_1's rmse: 3.66317\n",
      "Early stopping, best iteration is:\n",
      "[1305]\ttraining's rmse: 3.25503\tvalid_1's rmse: 3.66221\n",
      "fold 19 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31965\tvalid_1's rmse: 3.63899\n",
      "Early stopping, best iteration is:\n",
      "[1060]\ttraining's rmse: 3.30857\tvalid_1's rmse: 3.63824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 20 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31454\tvalid_1's rmse: 3.64033\n",
      "[2000]\ttraining's rmse: 3.14988\tvalid_1's rmse: 3.63892\n",
      "Early stopping, best iteration is:\n",
      "[1676]\ttraining's rmse: 3.19796\tvalid_1's rmse: 3.63807\n",
      "fold 21 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32704\tvalid_1's rmse: 3.61841\n",
      "Early stopping, best iteration is:\n",
      "[1113]\ttraining's rmse: 3.30634\tvalid_1's rmse: 3.61776\n",
      "fold 22 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3189\tvalid_1's rmse: 3.62571\n",
      "Early stopping, best iteration is:\n",
      "[923]\ttraining's rmse: 3.33341\tvalid_1's rmse: 3.62561\n",
      "fold 23 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31918\tvalid_1's rmse: 3.64537\n",
      "Early stopping, best iteration is:\n",
      "[968]\ttraining's rmse: 3.32557\tvalid_1's rmse: 3.64504\n",
      "fold 24 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31797\tvalid_1's rmse: 3.64947\n",
      "[2000]\ttraining's rmse: 3.15392\tvalid_1's rmse: 3.64979\n",
      "Early stopping, best iteration is:\n",
      "[1695]\ttraining's rmse: 3.20069\tvalid_1's rmse: 3.64853\n",
      "fold 25 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31159\tvalid_1's rmse: 3.66428\n",
      "Early stopping, best iteration is:\n",
      "[852]\ttraining's rmse: 3.34124\tvalid_1's rmse: 3.66407\n",
      "fold 26 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31319\tvalid_1's rmse: 3.6676\n",
      "[2000]\ttraining's rmse: 3.14652\tvalid_1's rmse: 3.66747\n",
      "Early stopping, best iteration is:\n",
      "[1636]\ttraining's rmse: 3.20539\tvalid_1's rmse: 3.66671\n",
      "fold 27 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3186\tvalid_1's rmse: 3.64507\n",
      "[2000]\ttraining's rmse: 3.15052\tvalid_1's rmse: 3.64436\n",
      "Early stopping, best iteration is:\n",
      "[1413]\ttraining's rmse: 3.24518\tvalid_1's rmse: 3.64369\n",
      "fold 28 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32057\tvalid_1's rmse: 3.66178\n",
      "Early stopping, best iteration is:\n",
      "[728]\ttraining's rmse: 3.37534\tvalid_1's rmse: 3.65998\n",
      "fold 29 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31734\tvalid_1's rmse: 3.64995\n",
      "[2000]\ttraining's rmse: 3.15326\tvalid_1's rmse: 3.64748\n",
      "Early stopping, best iteration is:\n",
      "[1770]\ttraining's rmse: 3.18825\tvalid_1's rmse: 3.64693\n",
      "fold 30 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32054\tvalid_1's rmse: 3.65041\n",
      "Early stopping, best iteration is:\n",
      "[1199]\ttraining's rmse: 3.28415\tvalid_1's rmse: 3.64981\n",
      "fold 31 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33252\tvalid_1's rmse: 3.60437\n",
      "[2000]\ttraining's rmse: 3.16515\tvalid_1's rmse: 3.60188\n",
      "Early stopping, best iteration is:\n",
      "[2157]\ttraining's rmse: 3.14293\tvalid_1's rmse: 3.60144\n",
      "fold 32 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30825\tvalid_1's rmse: 3.67495\n",
      "[2000]\ttraining's rmse: 3.1429\tvalid_1's rmse: 3.67704\n",
      "Early stopping, best iteration is:\n",
      "[1512]\ttraining's rmse: 3.21946\tvalid_1's rmse: 3.67442\n",
      "fold 33 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31408\tvalid_1's rmse: 3.65054\n",
      "Early stopping, best iteration is:\n",
      "[1124]\ttraining's rmse: 3.29106\tvalid_1's rmse: 3.64981\n",
      "fold 34 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3195\tvalid_1's rmse: 3.64576\n",
      "[2000]\ttraining's rmse: 3.15249\tvalid_1's rmse: 3.64594\n",
      "Early stopping, best iteration is:\n",
      "[1422]\ttraining's rmse: 3.24327\tvalid_1's rmse: 3.6443\n",
      "fold 35 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30658\tvalid_1's rmse: 3.68022\n",
      "Early stopping, best iteration is:\n",
      "[790]\ttraining's rmse: 3.34855\tvalid_1's rmse: 3.67967\n",
      "fold 36 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32689\tvalid_1's rmse: 3.62266\n",
      "[2000]\ttraining's rmse: 3.16438\tvalid_1's rmse: 3.62352\n",
      "Early stopping, best iteration is:\n",
      "[1622]\ttraining's rmse: 3.21976\tvalid_1's rmse: 3.62139\n",
      "fold 37 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32131\tvalid_1's rmse: 3.61819\n",
      "Early stopping, best iteration is:\n",
      "[1134]\ttraining's rmse: 3.29678\tvalid_1's rmse: 3.61702\n",
      "fold 38 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31859\tvalid_1's rmse: 3.65786\n",
      "Early stopping, best iteration is:\n",
      "[1151]\ttraining's rmse: 3.29106\tvalid_1's rmse: 3.6568\n",
      "fold 39 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32382\tvalid_1's rmse: 3.64278\n",
      "[2000]\ttraining's rmse: 3.15769\tvalid_1's rmse: 3.64473\n",
      "Early stopping, best iteration is:\n",
      "[1455]\ttraining's rmse: 3.24171\tvalid_1's rmse: 3.64209\n",
      "fold 40 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32149\tvalid_1's rmse: 3.64717\n",
      "Early stopping, best iteration is:\n",
      "[1168]\ttraining's rmse: 3.29099\tvalid_1's rmse: 3.64593\n",
      "fold 41 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31769\tvalid_1's rmse: 3.65011\n",
      "[2000]\ttraining's rmse: 3.15078\tvalid_1's rmse: 3.64819\n",
      "Early stopping, best iteration is:\n",
      "[1671]\ttraining's rmse: 3.2019\tvalid_1's rmse: 3.64765\n",
      "fold 42 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31927\tvalid_1's rmse: 3.64055\n",
      "[2000]\ttraining's rmse: 3.15585\tvalid_1's rmse: 3.64117\n",
      "Early stopping, best iteration is:\n",
      "[1562]\ttraining's rmse: 3.22434\tvalid_1's rmse: 3.63923\n",
      "fold 43 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32296\tvalid_1's rmse: 3.61609\n",
      "Early stopping, best iteration is:\n",
      "[1238]\ttraining's rmse: 3.28029\tvalid_1's rmse: 3.6145\n",
      "fold 44 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31231\tvalid_1's rmse: 3.67766\n",
      "[2000]\ttraining's rmse: 3.14946\tvalid_1's rmse: 3.67719\n",
      "Early stopping, best iteration is:\n",
      "[1463]\ttraining's rmse: 3.2304\tvalid_1's rmse: 3.6763\n",
      "fold 45 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31559\tvalid_1's rmse: 3.66302\n",
      "Early stopping, best iteration is:\n",
      "[768]\ttraining's rmse: 3.36387\tvalid_1's rmse: 3.66202\n",
      "fold 46 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32259\tvalid_1's rmse: 3.63547\n",
      "[2000]\ttraining's rmse: 3.1553\tvalid_1's rmse: 3.63397\n",
      "Early stopping, best iteration is:\n",
      "[1553]\ttraining's rmse: 3.22476\tvalid_1's rmse: 3.63295\n",
      "fold 47 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32009\tvalid_1's rmse: 3.64508\n",
      "Early stopping, best iteration is:\n",
      "[1176]\ttraining's rmse: 3.28842\tvalid_1's rmse: 3.64369\n",
      "fold 48 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31443\tvalid_1's rmse: 3.65427\n",
      "Early stopping, best iteration is:\n",
      "[653]\ttraining's rmse: 3.38897\tvalid_1's rmse: 3.65228\n",
      "fold 49 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30654\tvalid_1's rmse: 3.68169\n",
      "Early stopping, best iteration is:\n",
      "[729]\ttraining's rmse: 3.36408\tvalid_1's rmse: 3.67982\n",
      "fold 50 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32137\tvalid_1's rmse: 3.63548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1045]\ttraining's rmse: 3.31249\tvalid_1's rmse: 3.63514\n",
      "fold 51 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31833\tvalid_1's rmse: 3.64815\n",
      "Early stopping, best iteration is:\n",
      "[1168]\ttraining's rmse: 3.28733\tvalid_1's rmse: 3.64786\n",
      "fold 52 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31955\tvalid_1's rmse: 3.62352\n",
      "Early stopping, best iteration is:\n",
      "[957]\ttraining's rmse: 3.3287\tvalid_1's rmse: 3.6233\n",
      "fold 53 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32636\tvalid_1's rmse: 3.63056\n",
      "[2000]\ttraining's rmse: 3.16503\tvalid_1's rmse: 3.63009\n",
      "Early stopping, best iteration is:\n",
      "[1784]\ttraining's rmse: 3.19718\tvalid_1's rmse: 3.62928\n",
      "fold 54 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3177\tvalid_1's rmse: 3.6475\n",
      "[2000]\ttraining's rmse: 3.15434\tvalid_1's rmse: 3.64894\n",
      "Early stopping, best iteration is:\n",
      "[1433]\ttraining's rmse: 3.24181\tvalid_1's rmse: 3.64584\n",
      "fold 55 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31015\tvalid_1's rmse: 3.67991\n",
      "Early stopping, best iteration is:\n",
      "[788]\ttraining's rmse: 3.35234\tvalid_1's rmse: 3.67896\n",
      "fold 56 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31622\tvalid_1's rmse: 3.64464\n",
      "[2000]\ttraining's rmse: 3.15119\tvalid_1's rmse: 3.64416\n",
      "Early stopping, best iteration is:\n",
      "[1602]\ttraining's rmse: 3.21258\tvalid_1's rmse: 3.64342\n",
      "fold 57 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31678\tvalid_1's rmse: 3.66056\n",
      "Early stopping, best iteration is:\n",
      "[866]\ttraining's rmse: 3.34327\tvalid_1's rmse: 3.6593\n",
      "fold 58 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32025\tvalid_1's rmse: 3.63595\n",
      "[2000]\ttraining's rmse: 3.15534\tvalid_1's rmse: 3.63367\n",
      "Early stopping, best iteration is:\n",
      "[1739]\ttraining's rmse: 3.19572\tvalid_1's rmse: 3.63222\n",
      "fold 59 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32954\tvalid_1's rmse: 3.59449\n",
      "[2000]\ttraining's rmse: 3.16912\tvalid_1's rmse: 3.59168\n",
      "[3000]\ttraining's rmse: 3.03185\tvalid_1's rmse: 3.59096\n",
      "Early stopping, best iteration is:\n",
      "[2536]\ttraining's rmse: 3.09254\tvalid_1's rmse: 3.59042\n",
      "fold 60 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.30614\tvalid_1's rmse: 3.6896\n",
      "[2000]\ttraining's rmse: 3.14186\tvalid_1's rmse: 3.68695\n",
      "Early stopping, best iteration is:\n",
      "[1962]\ttraining's rmse: 3.14741\tvalid_1's rmse: 3.68677\n",
      "fold 61 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31388\tvalid_1's rmse: 3.65632\n",
      "Early stopping, best iteration is:\n",
      "[1070]\ttraining's rmse: 3.29991\tvalid_1's rmse: 3.65596\n",
      "fold 62 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31488\tvalid_1's rmse: 3.65099\n",
      "Early stopping, best iteration is:\n",
      "[848]\ttraining's rmse: 3.34447\tvalid_1's rmse: 3.64903\n",
      "fold 63 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31182\tvalid_1's rmse: 3.67102\n",
      "Early stopping, best iteration is:\n",
      "[1105]\ttraining's rmse: 3.29175\tvalid_1's rmse: 3.67084\n",
      "fold 64 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31788\tvalid_1's rmse: 3.65689\n",
      "[2000]\ttraining's rmse: 3.15135\tvalid_1's rmse: 3.65268\n",
      "Early stopping, best iteration is:\n",
      "[2301]\ttraining's rmse: 3.10495\tvalid_1's rmse: 3.65183\n",
      "fold 65 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31718\tvalid_1's rmse: 3.62681\n",
      "[2000]\ttraining's rmse: 3.15228\tvalid_1's rmse: 3.62577\n",
      "Early stopping, best iteration is:\n",
      "[1524]\ttraining's rmse: 3.22637\tvalid_1's rmse: 3.62468\n",
      "fold 66 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31763\tvalid_1's rmse: 3.65211\n",
      "Early stopping, best iteration is:\n",
      "[714]\ttraining's rmse: 3.37919\tvalid_1's rmse: 3.65048\n",
      "fold 67 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31652\tvalid_1's rmse: 3.65764\n",
      "Early stopping, best iteration is:\n",
      "[1385]\ttraining's rmse: 3.24863\tvalid_1's rmse: 3.65587\n",
      "fold 68 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31478\tvalid_1's rmse: 3.6681\n",
      "Early stopping, best iteration is:\n",
      "[794]\ttraining's rmse: 3.35633\tvalid_1's rmse: 3.66699\n",
      "fold 69 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33303\tvalid_1's rmse: 3.60142\n",
      "[2000]\ttraining's rmse: 3.16887\tvalid_1's rmse: 3.6005\n",
      "Early stopping, best iteration is:\n",
      "[1422]\ttraining's rmse: 3.25717\tvalid_1's rmse: 3.59869\n",
      "fold 0 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3359\tvalid_1's rmse: 3.61364\n",
      "Early stopping, best iteration is:\n",
      "[1383]\ttraining's rmse: 3.26966\tvalid_1's rmse: 3.61231\n",
      "fold 1 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32155\tvalid_1's rmse: 3.66689\n",
      "Early stopping, best iteration is:\n",
      "[1058]\ttraining's rmse: 3.31047\tvalid_1's rmse: 3.66648\n",
      "fold 2 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33876\tvalid_1's rmse: 3.61747\n",
      "Early stopping, best iteration is:\n",
      "[1062]\ttraining's rmse: 3.32654\tvalid_1's rmse: 3.61697\n",
      "fold 3 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33516\tvalid_1's rmse: 3.62344\n",
      "[2000]\ttraining's rmse: 3.17353\tvalid_1's rmse: 3.6252\n",
      "Early stopping, best iteration is:\n",
      "[1451]\ttraining's rmse: 3.25637\tvalid_1's rmse: 3.62223\n",
      "fold 4 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32103\tvalid_1's rmse: 3.67259\n",
      "Early stopping, best iteration is:\n",
      "[1384]\ttraining's rmse: 3.25381\tvalid_1's rmse: 3.67186\n",
      "fold 5 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3252\tvalid_1's rmse: 3.65741\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's rmse: 3.26713\tvalid_1's rmse: 3.6555\n",
      "fold 6 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32403\tvalid_1's rmse: 3.67523\n",
      "Early stopping, best iteration is:\n",
      "[960]\ttraining's rmse: 3.33137\tvalid_1's rmse: 3.67493\n",
      "fold 7 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32928\tvalid_1's rmse: 3.64364\n",
      "[2000]\ttraining's rmse: 3.17017\tvalid_1's rmse: 3.64403\n",
      "Early stopping, best iteration is:\n",
      "[1436]\ttraining's rmse: 3.25381\tvalid_1's rmse: 3.64308\n",
      "fold 8 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33619\tvalid_1's rmse: 3.62645\n",
      "Early stopping, best iteration is:\n",
      "[1376]\ttraining's rmse: 3.27004\tvalid_1's rmse: 3.62485\n",
      "fold 9 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31683\tvalid_1's rmse: 3.67303\n",
      "Early stopping, best iteration is:\n",
      "[931]\ttraining's rmse: 3.33053\tvalid_1's rmse: 3.67291\n",
      "fold 10 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32656\tvalid_1's rmse: 3.66514\n",
      "Early stopping, best iteration is:\n",
      "[1390]\ttraining's rmse: 3.26049\tvalid_1's rmse: 3.6645\n",
      "fold 11 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33044\tvalid_1's rmse: 3.64345\n",
      "Early stopping, best iteration is:\n",
      "[895]\ttraining's rmse: 3.35093\tvalid_1's rmse: 3.64274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 12 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33488\tvalid_1's rmse: 3.60276\n",
      "Early stopping, best iteration is:\n",
      "[1076]\ttraining's rmse: 3.32106\tvalid_1's rmse: 3.60215\n",
      "fold 13 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32634\tvalid_1's rmse: 3.66069\n",
      "Early stopping, best iteration is:\n",
      "[1083]\ttraining's rmse: 3.3112\tvalid_1's rmse: 3.65968\n",
      "fold 14 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33352\tvalid_1's rmse: 3.63676\n",
      "Early stopping, best iteration is:\n",
      "[861]\ttraining's rmse: 3.36014\tvalid_1's rmse: 3.6362\n",
      "fold 15 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32048\tvalid_1's rmse: 3.68133\n",
      "Early stopping, best iteration is:\n",
      "[1211]\ttraining's rmse: 3.28152\tvalid_1's rmse: 3.67959\n",
      "fold 16 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33201\tvalid_1's rmse: 3.63306\n",
      "Early stopping, best iteration is:\n",
      "[1050]\ttraining's rmse: 3.32327\tvalid_1's rmse: 3.63241\n",
      "fold 17 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33632\tvalid_1's rmse: 3.62587\n",
      "Early stopping, best iteration is:\n",
      "[1184]\ttraining's rmse: 3.30412\tvalid_1's rmse: 3.6253\n",
      "fold 18 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32382\tvalid_1's rmse: 3.66409\n",
      "[2000]\ttraining's rmse: 3.15808\tvalid_1's rmse: 3.6661\n",
      "Early stopping, best iteration is:\n",
      "[1450]\ttraining's rmse: 3.24399\tvalid_1's rmse: 3.66386\n",
      "fold 19 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33073\tvalid_1's rmse: 3.63902\n",
      "Early stopping, best iteration is:\n",
      "[826]\ttraining's rmse: 3.36522\tvalid_1's rmse: 3.63829\n",
      "fold 20 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32536\tvalid_1's rmse: 3.63625\n",
      "[2000]\ttraining's rmse: 3.16514\tvalid_1's rmse: 3.63253\n",
      "Early stopping, best iteration is:\n",
      "[1844]\ttraining's rmse: 3.18814\tvalid_1's rmse: 3.63144\n",
      "fold 21 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33527\tvalid_1's rmse: 3.61415\n",
      "Early stopping, best iteration is:\n",
      "[1156]\ttraining's rmse: 3.3069\tvalid_1's rmse: 3.61384\n",
      "fold 22 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3316\tvalid_1's rmse: 3.6292\n",
      "Early stopping, best iteration is:\n",
      "[1262]\ttraining's rmse: 3.28363\tvalid_1's rmse: 3.62865\n",
      "fold 23 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33024\tvalid_1's rmse: 3.64528\n",
      "Early stopping, best iteration is:\n",
      "[962]\ttraining's rmse: 3.33673\tvalid_1's rmse: 3.64507\n",
      "fold 24 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32843\tvalid_1's rmse: 3.64742\n",
      "[2000]\ttraining's rmse: 3.1707\tvalid_1's rmse: 3.64692\n",
      "Early stopping, best iteration is:\n",
      "[1691]\ttraining's rmse: 3.21502\tvalid_1's rmse: 3.64638\n",
      "fold 25 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32542\tvalid_1's rmse: 3.67006\n",
      "Early stopping, best iteration is:\n",
      "[1070]\ttraining's rmse: 3.31248\tvalid_1's rmse: 3.66928\n",
      "fold 26 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32315\tvalid_1's rmse: 3.67094\n",
      "[2000]\ttraining's rmse: 3.16389\tvalid_1's rmse: 3.67068\n",
      "Early stopping, best iteration is:\n",
      "[1629]\ttraining's rmse: 3.21927\tvalid_1's rmse: 3.66838\n",
      "fold 27 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32934\tvalid_1's rmse: 3.64714\n",
      "[2000]\ttraining's rmse: 3.16609\tvalid_1's rmse: 3.64424\n",
      "Early stopping, best iteration is:\n",
      "[1865]\ttraining's rmse: 3.18526\tvalid_1's rmse: 3.64366\n",
      "fold 28 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33067\tvalid_1's rmse: 3.65899\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's rmse: 3.40393\tvalid_1's rmse: 3.65822\n",
      "fold 29 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32804\tvalid_1's rmse: 3.65003\n",
      "Early stopping, best iteration is:\n",
      "[1366]\ttraining's rmse: 3.26577\tvalid_1's rmse: 3.64802\n",
      "fold 30 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3272\tvalid_1's rmse: 3.65414\n",
      "[2000]\ttraining's rmse: 3.1702\tvalid_1's rmse: 3.6533\n",
      "Early stopping, best iteration is:\n",
      "[1487]\ttraining's rmse: 3.24706\tvalid_1's rmse: 3.65209\n",
      "fold 31 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.34095\tvalid_1's rmse: 3.60595\n",
      "[2000]\ttraining's rmse: 3.18133\tvalid_1's rmse: 3.60568\n",
      "Early stopping, best iteration is:\n",
      "[1691]\ttraining's rmse: 3.22712\tvalid_1's rmse: 3.60509\n",
      "fold 32 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32068\tvalid_1's rmse: 3.67022\n",
      "Early stopping, best iteration is:\n",
      "[992]\ttraining's rmse: 3.32237\tvalid_1's rmse: 3.67009\n",
      "fold 33 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32438\tvalid_1's rmse: 3.6519\n",
      "Early stopping, best iteration is:\n",
      "[1119]\ttraining's rmse: 3.30228\tvalid_1's rmse: 3.65111\n",
      "fold 34 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3267\tvalid_1's rmse: 3.64517\n",
      "[2000]\ttraining's rmse: 3.16726\tvalid_1's rmse: 3.64551\n",
      "Early stopping, best iteration is:\n",
      "[1661]\ttraining's rmse: 3.21825\tvalid_1's rmse: 3.64322\n",
      "fold 35 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31731\tvalid_1's rmse: 3.67916\n",
      "Early stopping, best iteration is:\n",
      "[1160]\ttraining's rmse: 3.2882\tvalid_1's rmse: 3.67841\n",
      "fold 36 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33656\tvalid_1's rmse: 3.62464\n",
      "[2000]\ttraining's rmse: 3.1767\tvalid_1's rmse: 3.62484\n",
      "Early stopping, best iteration is:\n",
      "[1524]\ttraining's rmse: 3.249\tvalid_1's rmse: 3.62338\n",
      "fold 37 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33003\tvalid_1's rmse: 3.61986\n",
      "[2000]\ttraining's rmse: 3.1673\tvalid_1's rmse: 3.61765\n",
      "Early stopping, best iteration is:\n",
      "[1916]\ttraining's rmse: 3.17913\tvalid_1's rmse: 3.61745\n",
      "fold 38 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32728\tvalid_1's rmse: 3.65361\n",
      "[2000]\ttraining's rmse: 3.16757\tvalid_1's rmse: 3.65171\n",
      "Early stopping, best iteration is:\n",
      "[2203]\ttraining's rmse: 3.13837\tvalid_1's rmse: 3.65149\n",
      "fold 39 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33501\tvalid_1's rmse: 3.63689\n",
      "Early stopping, best iteration is:\n",
      "[1157]\ttraining's rmse: 3.30718\tvalid_1's rmse: 3.6363\n",
      "fold 40 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3258\tvalid_1's rmse: 3.64574\n",
      "Early stopping, best iteration is:\n",
      "[1095]\ttraining's rmse: 3.3077\tvalid_1's rmse: 3.64517\n",
      "fold 41 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32835\tvalid_1's rmse: 3.65274\n",
      "[2000]\ttraining's rmse: 3.16392\tvalid_1's rmse: 3.65413\n",
      "Early stopping, best iteration is:\n",
      "[1428]\ttraining's rmse: 3.25131\tvalid_1's rmse: 3.65211\n",
      "fold 42 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32917\tvalid_1's rmse: 3.63951\n",
      "Early stopping, best iteration is:\n",
      "[1195]\ttraining's rmse: 3.29476\tvalid_1's rmse: 3.63897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 43 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33535\tvalid_1's rmse: 3.6191\n",
      "Early stopping, best iteration is:\n",
      "[1208]\ttraining's rmse: 3.29914\tvalid_1's rmse: 3.61793\n",
      "fold 44 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31916\tvalid_1's rmse: 3.67568\n",
      "Early stopping, best iteration is:\n",
      "[895]\ttraining's rmse: 3.33922\tvalid_1's rmse: 3.67478\n",
      "fold 45 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32628\tvalid_1's rmse: 3.661\n",
      "[2000]\ttraining's rmse: 3.1654\tvalid_1's rmse: 3.66201\n",
      "Early stopping, best iteration is:\n",
      "[1451]\ttraining's rmse: 3.24804\tvalid_1's rmse: 3.66083\n",
      "fold 46 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33334\tvalid_1's rmse: 3.63958\n",
      "[2000]\ttraining's rmse: 3.17378\tvalid_1's rmse: 3.63737\n",
      "Early stopping, best iteration is:\n",
      "[1677]\ttraining's rmse: 3.22182\tvalid_1's rmse: 3.636\n",
      "fold 47 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3321\tvalid_1's rmse: 3.63996\n",
      "Early stopping, best iteration is:\n",
      "[971]\ttraining's rmse: 3.33761\tvalid_1's rmse: 3.63916\n",
      "fold 48 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32799\tvalid_1's rmse: 3.65714\n",
      "Early stopping, best iteration is:\n",
      "[607]\ttraining's rmse: 3.40947\tvalid_1's rmse: 3.65613\n",
      "fold 49 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31869\tvalid_1's rmse: 3.68198\n",
      "Early stopping, best iteration is:\n",
      "[728]\ttraining's rmse: 3.37605\tvalid_1's rmse: 3.68042\n",
      "fold 50 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32753\tvalid_1's rmse: 3.63954\n",
      "Early stopping, best iteration is:\n",
      "[1101]\ttraining's rmse: 3.30897\tvalid_1's rmse: 3.63868\n",
      "fold 51 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33109\tvalid_1's rmse: 3.64819\n",
      "[2000]\ttraining's rmse: 3.17146\tvalid_1's rmse: 3.64856\n",
      "Early stopping, best iteration is:\n",
      "[1555]\ttraining's rmse: 3.23648\tvalid_1's rmse: 3.64665\n",
      "fold 52 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32918\tvalid_1's rmse: 3.61969\n",
      "Early stopping, best iteration is:\n",
      "[970]\ttraining's rmse: 3.33483\tvalid_1's rmse: 3.61925\n",
      "fold 53 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33675\tvalid_1's rmse: 3.63665\n",
      "[2000]\ttraining's rmse: 3.17722\tvalid_1's rmse: 3.63597\n",
      "Early stopping, best iteration is:\n",
      "[1515]\ttraining's rmse: 3.24962\tvalid_1's rmse: 3.63482\n",
      "fold 54 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33112\tvalid_1's rmse: 3.6397\n",
      "Early stopping, best iteration is:\n",
      "[1373]\ttraining's rmse: 3.26591\tvalid_1's rmse: 3.63672\n",
      "fold 55 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32254\tvalid_1's rmse: 3.67224\n",
      "Early stopping, best iteration is:\n",
      "[974]\ttraining's rmse: 3.32835\tvalid_1's rmse: 3.6719\n",
      "fold 56 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32939\tvalid_1's rmse: 3.64042\n",
      "[2000]\ttraining's rmse: 3.16675\tvalid_1's rmse: 3.63959\n",
      "Early stopping, best iteration is:\n",
      "[1714]\ttraining's rmse: 3.20894\tvalid_1's rmse: 3.63781\n",
      "fold 57 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32685\tvalid_1's rmse: 3.66051\n",
      "Early stopping, best iteration is:\n",
      "[825]\ttraining's rmse: 3.36194\tvalid_1's rmse: 3.66005\n",
      "fold 58 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33157\tvalid_1's rmse: 3.63657\n",
      "Early stopping, best iteration is:\n",
      "[1000]\ttraining's rmse: 3.33157\tvalid_1's rmse: 3.63657\n",
      "fold 59 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.33976\tvalid_1's rmse: 3.59418\n",
      "[2000]\ttraining's rmse: 3.18105\tvalid_1's rmse: 3.59312\n",
      "Early stopping, best iteration is:\n",
      "[1625]\ttraining's rmse: 3.23592\tvalid_1's rmse: 3.59146\n",
      "fold 60 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.31699\tvalid_1's rmse: 3.68534\n",
      "[2000]\ttraining's rmse: 3.15497\tvalid_1's rmse: 3.68293\n",
      "Early stopping, best iteration is:\n",
      "[2034]\ttraining's rmse: 3.14971\tvalid_1's rmse: 3.6828\n",
      "fold 61 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.3257\tvalid_1's rmse: 3.6591\n",
      "Early stopping, best iteration is:\n",
      "[777]\ttraining's rmse: 3.37063\tvalid_1's rmse: 3.65817\n",
      "fold 62 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32856\tvalid_1's rmse: 3.651\n",
      "Early stopping, best iteration is:\n",
      "[901]\ttraining's rmse: 3.34752\tvalid_1's rmse: 3.65043\n",
      "fold 63 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32338\tvalid_1's rmse: 3.66588\n",
      "Early stopping, best iteration is:\n",
      "[1052]\ttraining's rmse: 3.31403\tvalid_1's rmse: 3.66571\n",
      "fold 64 1513 0.010927659328595365\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32775\tvalid_1's rmse: 3.65699\n",
      "[2000]\ttraining's rmse: 3.16732\tvalid_1's rmse: 3.65323\n",
      "Early stopping, best iteration is:\n",
      "[1875]\ttraining's rmse: 3.1856\tvalid_1's rmse: 3.65235\n",
      "fold 65 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32801\tvalid_1's rmse: 3.62344\n",
      "Early stopping, best iteration is:\n",
      "[1234]\ttraining's rmse: 3.28706\tvalid_1's rmse: 3.62157\n",
      "fold 66 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.332\tvalid_1's rmse: 3.65004\n",
      "Early stopping, best iteration is:\n",
      "[789]\ttraining's rmse: 3.37448\tvalid_1's rmse: 3.64925\n",
      "fold 67 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32805\tvalid_1's rmse: 3.66254\n",
      "[2000]\ttraining's rmse: 3.16681\tvalid_1's rmse: 3.66156\n",
      "Early stopping, best iteration is:\n",
      "[1919]\ttraining's rmse: 3.17859\tvalid_1's rmse: 3.66113\n",
      "fold 68 1514 0.01093480286298273\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.32559\tvalid_1's rmse: 3.66386\n",
      "Early stopping, best iteration is:\n",
      "[947]\ttraining's rmse: 3.33578\tvalid_1's rmse: 3.66345\n",
      "fold 69 1514 0.010934723887388233\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.34039\tvalid_1's rmse: 3.59921\n",
      "Early stopping, best iteration is:\n",
      "[1330]\ttraining's rmse: 3.28258\tvalid_1's rmse: 3.59697\n",
      "fold 0 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27678\tvalid_1's rmse: 3.62607\n",
      "[2000]\ttraining's rmse: 3.08827\tvalid_1's rmse: 3.62513\n",
      "Early stopping, best iteration is:\n",
      "[1662]\ttraining's rmse: 3.14867\tvalid_1's rmse: 3.62398\n",
      "fold 1 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26238\tvalid_1's rmse: 3.66505\n",
      "Early stopping, best iteration is:\n",
      "[712]\ttraining's rmse: 3.33183\tvalid_1's rmse: 3.66281\n",
      "fold 2 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26599\tvalid_1's rmse: 3.65752\n",
      "[2000]\ttraining's rmse: 3.07667\tvalid_1's rmse: 3.65663\n",
      "Early stopping, best iteration is:\n",
      "[1863]\ttraining's rmse: 3.09941\tvalid_1's rmse: 3.65586\n",
      "fold 3 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.28252\tvalid_1's rmse: 3.61467\n",
      "[2000]\ttraining's rmse: 3.09683\tvalid_1's rmse: 3.61499\n",
      "Early stopping, best iteration is:\n",
      "[1610]\ttraining's rmse: 3.16269\tvalid_1's rmse: 3.61369\n",
      "fold 4 1545 0.010931010817809412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26776\tvalid_1's rmse: 3.64309\n",
      "[2000]\ttraining's rmse: 3.08103\tvalid_1's rmse: 3.64257\n",
      "Early stopping, best iteration is:\n",
      "[2200]\ttraining's rmse: 3.04654\tvalid_1's rmse: 3.64226\n",
      "fold 5 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2747\tvalid_1's rmse: 3.64269\n",
      "[2000]\ttraining's rmse: 3.08406\tvalid_1's rmse: 3.64453\n",
      "Early stopping, best iteration is:\n",
      "[1594]\ttraining's rmse: 3.15531\tvalid_1's rmse: 3.64216\n",
      "fold 6 1546 0.010938008518345574\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2567\tvalid_1's rmse: 3.70841\n",
      "Early stopping, best iteration is:\n",
      "[946]\ttraining's rmse: 3.26876\tvalid_1's rmse: 3.70799\n",
      "fold 7 1546 0.010937931132068797\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26703\tvalid_1's rmse: 3.66615\n",
      "Early stopping, best iteration is:\n",
      "[946]\ttraining's rmse: 3.27869\tvalid_1's rmse: 3.66541\n",
      "fold 8 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26828\tvalid_1's rmse: 3.65123\n",
      "[2000]\ttraining's rmse: 3.08248\tvalid_1's rmse: 3.65054\n",
      "Early stopping, best iteration is:\n",
      "[1781]\ttraining's rmse: 3.12024\tvalid_1's rmse: 3.64947\n",
      "fold 9 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27845\tvalid_1's rmse: 3.62689\n",
      "[2000]\ttraining's rmse: 3.09391\tvalid_1's rmse: 3.62607\n",
      "Early stopping, best iteration is:\n",
      "[1457]\ttraining's rmse: 3.18956\tvalid_1's rmse: 3.62553\n",
      "fold 10 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26587\tvalid_1's rmse: 3.67207\n",
      "Early stopping, best iteration is:\n",
      "[980]\ttraining's rmse: 3.27012\tvalid_1's rmse: 3.67194\n",
      "fold 11 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26932\tvalid_1's rmse: 3.66313\n",
      "Early stopping, best iteration is:\n",
      "[1109]\ttraining's rmse: 3.24693\tvalid_1's rmse: 3.66263\n",
      "fold 12 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26561\tvalid_1's rmse: 3.65754\n",
      "Early stopping, best iteration is:\n",
      "[1144]\ttraining's rmse: 3.23558\tvalid_1's rmse: 3.65657\n",
      "fold 13 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2703\tvalid_1's rmse: 3.64232\n",
      "[2000]\ttraining's rmse: 3.08534\tvalid_1's rmse: 3.64149\n",
      "Early stopping, best iteration is:\n",
      "[1525]\ttraining's rmse: 3.16821\tvalid_1's rmse: 3.64019\n",
      "fold 14 1546 0.010938008518345574\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2769\tvalid_1's rmse: 3.60296\n",
      "Early stopping, best iteration is:\n",
      "[1347]\ttraining's rmse: 3.20644\tvalid_1's rmse: 3.60171\n",
      "fold 15 1546 0.010937931132068797\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26729\tvalid_1's rmse: 3.66088\n",
      "Early stopping, best iteration is:\n",
      "[1036]\ttraining's rmse: 3.25903\tvalid_1's rmse: 3.66066\n",
      "fold 16 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27182\tvalid_1's rmse: 3.65078\n",
      "Early stopping, best iteration is:\n",
      "[1092]\ttraining's rmse: 3.25279\tvalid_1's rmse: 3.64995\n",
      "fold 17 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26857\tvalid_1's rmse: 3.64643\n",
      "[2000]\ttraining's rmse: 3.08204\tvalid_1's rmse: 3.64619\n",
      "Early stopping, best iteration is:\n",
      "[1713]\ttraining's rmse: 3.13261\tvalid_1's rmse: 3.64565\n",
      "fold 18 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26767\tvalid_1's rmse: 3.6617\n",
      "[2000]\ttraining's rmse: 3.07834\tvalid_1's rmse: 3.66195\n",
      "Early stopping, best iteration is:\n",
      "[1526]\ttraining's rmse: 3.16154\tvalid_1's rmse: 3.65993\n",
      "fold 19 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27115\tvalid_1's rmse: 3.64739\n",
      "[2000]\ttraining's rmse: 3.08394\tvalid_1's rmse: 3.64743\n",
      "Early stopping, best iteration is:\n",
      "[1690]\ttraining's rmse: 3.1374\tvalid_1's rmse: 3.64557\n",
      "fold 20 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27678\tvalid_1's rmse: 3.62958\n",
      "[2000]\ttraining's rmse: 3.09082\tvalid_1's rmse: 3.62755\n",
      "Early stopping, best iteration is:\n",
      "[1874]\ttraining's rmse: 3.11178\tvalid_1's rmse: 3.62742\n",
      "fold 21 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26636\tvalid_1's rmse: 3.6691\n",
      "[2000]\ttraining's rmse: 3.078\tvalid_1's rmse: 3.66602\n",
      "[3000]\ttraining's rmse: 2.92377\tvalid_1's rmse: 3.66642\n",
      "Early stopping, best iteration is:\n",
      "[2645]\ttraining's rmse: 2.97501\tvalid_1's rmse: 3.66522\n",
      "fold 22 1546 0.010938008518345574\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27495\tvalid_1's rmse: 3.62977\n",
      "Early stopping, best iteration is:\n",
      "[1347]\ttraining's rmse: 3.20494\tvalid_1's rmse: 3.62831\n",
      "fold 23 1546 0.010937931132068797\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.2673\tvalid_1's rmse: 3.66771\n",
      "[2000]\ttraining's rmse: 3.08108\tvalid_1's rmse: 3.66578\n",
      "Early stopping, best iteration is:\n",
      "[1680]\ttraining's rmse: 3.13635\tvalid_1's rmse: 3.66485\n",
      "fold 24 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27568\tvalid_1's rmse: 3.61442\n",
      "[2000]\ttraining's rmse: 3.08938\tvalid_1's rmse: 3.61367\n",
      "Early stopping, best iteration is:\n",
      "[1480]\ttraining's rmse: 3.17931\tvalid_1's rmse: 3.61262\n",
      "fold 25 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27019\tvalid_1's rmse: 3.63865\n",
      "Early stopping, best iteration is:\n",
      "[1251]\ttraining's rmse: 3.21817\tvalid_1's rmse: 3.63749\n",
      "fold 26 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26959\tvalid_1's rmse: 3.66161\n",
      "Early stopping, best iteration is:\n",
      "[1131]\ttraining's rmse: 3.24381\tvalid_1's rmse: 3.66121\n",
      "fold 27 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26915\tvalid_1's rmse: 3.63366\n",
      "[2000]\ttraining's rmse: 3.08206\tvalid_1's rmse: 3.6358\n",
      "Early stopping, best iteration is:\n",
      "[1472]\ttraining's rmse: 3.1753\tvalid_1's rmse: 3.63224\n",
      "fold 28 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26517\tvalid_1's rmse: 3.6696\n",
      "[2000]\ttraining's rmse: 3.07828\tvalid_1's rmse: 3.66801\n",
      "Early stopping, best iteration is:\n",
      "[1531]\ttraining's rmse: 3.16086\tvalid_1's rmse: 3.66676\n",
      "fold 29 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26129\tvalid_1's rmse: 3.67208\n",
      "Early stopping, best iteration is:\n",
      "[1094]\ttraining's rmse: 3.24127\tvalid_1's rmse: 3.67132\n",
      "fold 30 1546 0.010938008518345574\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26808\tvalid_1's rmse: 3.66594\n",
      "Early stopping, best iteration is:\n",
      "[1058]\ttraining's rmse: 3.25549\tvalid_1's rmse: 3.66551\n",
      "fold 31 1546 0.010937931132068797\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26893\tvalid_1's rmse: 3.6473\n",
      "Early stopping, best iteration is:\n",
      "[1335]\ttraining's rmse: 3.20244\tvalid_1's rmse: 3.64543\n",
      "fold 32 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26513\tvalid_1's rmse: 3.67353\n",
      "[2000]\ttraining's rmse: 3.08051\tvalid_1's rmse: 3.67333\n",
      "Early stopping, best iteration is:\n",
      "[1402]\ttraining's rmse: 3.18598\tvalid_1's rmse: 3.67202\n",
      "fold 33 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.27814\tvalid_1's rmse: 3.6368\n",
      "Early stopping, best iteration is:\n",
      "[1269]\ttraining's rmse: 3.22315\tvalid_1's rmse: 3.63613\n",
      "fold 34 1545 0.010931010817809412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[1000]\ttraining's rmse: 3.26947\tvalid_1's rmse: 3.66094\n",
      "[2000]\ttraining's rmse: 3.08239\tvalid_1's rmse: 3.65966\n",
      "Early stopping, best iteration is:\n",
      "[1817]\ttraining's rmse: 3.11519\tvalid_1's rmse: 3.6581\n",
      "fold 35 1545 0.010931010817809412\n",
      "Training until validation scores don't improve for 600 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-d23963ebe3a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeats1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeats2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeats3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregression2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feats'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeat_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeats1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeats2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeats3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# indicate feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdf_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_total\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# data frame for each feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-6a3f8a40d5c0>\u001b[0m in \u001b[0;36mregression2\u001b[1;34m(df_train, df_test, fold, feature)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mnum_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0moof\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moof_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    214\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1783\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1784\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1785\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1786\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feat_names=['feats','feats1','feats2','feats3']\n",
    "df_all=pd.DataFrame()\n",
    "for fold in [5,6,7,8,9,10]:\n",
    "    df_total=pd.DataFrame()\n",
    "    for feat in [feats,feats1,feats2,feats3]:\n",
    "        df=regression2(df_train,df_test,fold,feat)\n",
    "        df['feats']=feat_names[[feats,feats1,feats2,feats3].index(feat)] # indicate feat\n",
    "        df_total=pd.concat([df_total,df],axis=0) # data frame for each feat\n",
    "    df_total['num_folds']=fold # indicate fold number\n",
    "    df_all=pd.concat([df_all,df_total],axis=0) # data frame for each fold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all2=df_all.groupby(['num_folds','feats']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"repeated_nfold_test_test_size0.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cv_error</th>\n",
       "      <th>test_error</th>\n",
       "      <th>fold</th>\n",
       "      <th>ave_cv_error</th>\n",
       "      <th>ave_test_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_folds</th>\n",
       "      <th>feats</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.651413</td>\n",
       "      <td>3.653991</td>\n",
       "      <td>25.5</td>\n",
       "      <td>3.651607</td>\n",
       "      <td>3.647563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.648304</td>\n",
       "      <td>3.648700</td>\n",
       "      <td>25.5</td>\n",
       "      <td>3.649167</td>\n",
       "      <td>3.642233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.647666</td>\n",
       "      <td>3.649841</td>\n",
       "      <td>25.5</td>\n",
       "      <td>3.650139</td>\n",
       "      <td>3.643590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.646687</td>\n",
       "      <td>3.653300</td>\n",
       "      <td>25.5</td>\n",
       "      <td>3.649614</td>\n",
       "      <td>3.647203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">6</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.650098</td>\n",
       "      <td>3.653135</td>\n",
       "      <td>30.5</td>\n",
       "      <td>3.650493</td>\n",
       "      <td>3.647384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.646898</td>\n",
       "      <td>3.647726</td>\n",
       "      <td>30.5</td>\n",
       "      <td>3.648668</td>\n",
       "      <td>3.641631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.646317</td>\n",
       "      <td>3.649622</td>\n",
       "      <td>30.5</td>\n",
       "      <td>3.647735</td>\n",
       "      <td>3.644171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.645892</td>\n",
       "      <td>3.652326</td>\n",
       "      <td>30.5</td>\n",
       "      <td>3.647386</td>\n",
       "      <td>3.646845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">7</th>\n",
       "      <th>feats</th>\n",
       "      <td>3.649488</td>\n",
       "      <td>3.652757</td>\n",
       "      <td>35.5</td>\n",
       "      <td>3.649185</td>\n",
       "      <td>3.647471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats1</th>\n",
       "      <td>3.645985</td>\n",
       "      <td>3.647593</td>\n",
       "      <td>35.5</td>\n",
       "      <td>3.645658</td>\n",
       "      <td>3.642262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats2</th>\n",
       "      <td>3.645547</td>\n",
       "      <td>3.648628</td>\n",
       "      <td>35.5</td>\n",
       "      <td>3.645703</td>\n",
       "      <td>3.643489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats3</th>\n",
       "      <td>3.645209</td>\n",
       "      <td>3.651512</td>\n",
       "      <td>35.5</td>\n",
       "      <td>3.644425</td>\n",
       "      <td>3.646339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cv_error  test_error  fold  ave_cv_error  ave_test_error\n",
       "num_folds feats                                                           \n",
       "5         feats   3.651413    3.653991  25.5      3.651607        3.647563\n",
       "          feats1  3.648304    3.648700  25.5      3.649167        3.642233\n",
       "          feats2  3.647666    3.649841  25.5      3.650139        3.643590\n",
       "          feats3  3.646687    3.653300  25.5      3.649614        3.647203\n",
       "6         feats   3.650098    3.653135  30.5      3.650493        3.647384\n",
       "          feats1  3.646898    3.647726  30.5      3.648668        3.641631\n",
       "          feats2  3.646317    3.649622  30.5      3.647735        3.644171\n",
       "          feats3  3.645892    3.652326  30.5      3.647386        3.646845\n",
       "7         feats   3.649488    3.652757  35.5      3.649185        3.647471\n",
       "          feats1  3.645985    3.647593  35.5      3.645658        3.642262\n",
       "          feats2  3.645547    3.648628  35.5      3.645703        3.643489\n",
       "          feats3  3.645209    3.651512  35.5      3.644425        3.646339"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2872bdd8160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(5,8):\n",
    "    df=df_all2.loc[i]\n",
    "    #df_err=df_all3.loc[i]\n",
    "    plt.plot(df.cv_error,df.test_error,linestyle='-',marker='o',label=i)\n",
    "    #plt.errorbar(df.ave_cv_error,df.ave_test_error,xerr=df_err.cv_error)\n",
    "    plt.ylabel('Test rmse')\n",
    "    plt.xlabel('CV rmse')\n",
    "    plt.legend()\n",
    "    #plt.xlim([3.645,3.655])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 91)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[feats2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It seems that feat2 is the best for both cv and test . Let's try to submit results for feat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's rmse: 3.711 + 0.0298158\n",
      "[200]\tcv_agg's rmse: 3.67736 + 0.0282109\n",
      "[300]\tcv_agg's rmse: 3.66458 + 0.0274447\n",
      "[400]\tcv_agg's rmse: 3.65761 + 0.0267827\n",
      "[500]\tcv_agg's rmse: 3.6536 + 0.0259917\n",
      "[600]\tcv_agg's rmse: 3.6512 + 0.0254979\n",
      "[700]\tcv_agg's rmse: 3.64957 + 0.0250862\n",
      "[800]\tcv_agg's rmse: 3.6487 + 0.0248244\n",
      "[900]\tcv_agg's rmse: 3.64811 + 0.024628\n",
      "[1000]\tcv_agg's rmse: 3.64775 + 0.0245095\n",
      "[1100]\tcv_agg's rmse: 3.64784 + 0.0244008\n",
      "[1200]\tcv_agg's rmse: 3.64777 + 0.0243944\n",
      "[1300]\tcv_agg's rmse: 3.64754 + 0.0241296\n",
      "[1400]\tcv_agg's rmse: 3.64744 + 0.0238907\n",
      "[1500]\tcv_agg's rmse: 3.64749 + 0.0236543\n",
      "[1600]\tcv_agg's rmse: 3.64747 + 0.0235358\n",
      "[1700]\tcv_agg's rmse: 3.64732 + 0.0232504\n",
      "[1800]\tcv_agg's rmse: 3.64744 + 0.0231041\n",
      "[1900]\tcv_agg's rmse: 3.64761 + 0.023002\n",
      "[2000]\tcv_agg's rmse: 3.64772 + 0.0226289\n",
      "[2100]\tcv_agg's rmse: 3.64764 + 0.0224156\n",
      "[2200]\tcv_agg's rmse: 3.64799 + 0.0222649\n",
      "[100]\tcv_agg's rmse: 3.70954 + 0.0488879\n",
      "[200]\tcv_agg's rmse: 3.67586 + 0.0460198\n",
      "[300]\tcv_agg's rmse: 3.66364 + 0.0446789\n",
      "[400]\tcv_agg's rmse: 3.65655 + 0.0441851\n",
      "[500]\tcv_agg's rmse: 3.65226 + 0.0439644\n",
      "[600]\tcv_agg's rmse: 3.64963 + 0.0434962\n",
      "[700]\tcv_agg's rmse: 3.64787 + 0.0433552\n",
      "[800]\tcv_agg's rmse: 3.64662 + 0.0428846\n",
      "[900]\tcv_agg's rmse: 3.64592 + 0.0427579\n",
      "[1000]\tcv_agg's rmse: 3.64538 + 0.042635\n",
      "[1100]\tcv_agg's rmse: 3.64482 + 0.0427739\n",
      "[1200]\tcv_agg's rmse: 3.6448 + 0.0429013\n",
      "[1300]\tcv_agg's rmse: 3.64457 + 0.0430635\n",
      "[1400]\tcv_agg's rmse: 3.6443 + 0.0430746\n",
      "[1500]\tcv_agg's rmse: 3.6444 + 0.0432158\n",
      "[1600]\tcv_agg's rmse: 3.64438 + 0.0432492\n",
      "[1700]\tcv_agg's rmse: 3.64433 + 0.0430093\n",
      "[1800]\tcv_agg's rmse: 3.6445 + 0.0428982\n",
      "[1900]\tcv_agg's rmse: 3.6445 + 0.0429222\n",
      "[2000]\tcv_agg's rmse: 3.64457 + 0.0429928\n",
      "[2100]\tcv_agg's rmse: 3.64464 + 0.0431052\n",
      "[100]\tcv_agg's rmse: 3.70982 + 0.0282359\n",
      "[200]\tcv_agg's rmse: 3.67593 + 0.0261998\n",
      "[300]\tcv_agg's rmse: 3.66373 + 0.0253404\n",
      "[400]\tcv_agg's rmse: 3.65707 + 0.0248493\n",
      "[500]\tcv_agg's rmse: 3.65295 + 0.0240028\n",
      "[600]\tcv_agg's rmse: 3.65003 + 0.0237183\n",
      "[700]\tcv_agg's rmse: 3.64839 + 0.0236103\n",
      "[800]\tcv_agg's rmse: 3.64719 + 0.0233818\n",
      "[900]\tcv_agg's rmse: 3.64658 + 0.0235981\n",
      "[1000]\tcv_agg's rmse: 3.64626 + 0.0236858\n",
      "[1100]\tcv_agg's rmse: 3.64624 + 0.0235931\n",
      "[1200]\tcv_agg's rmse: 3.6458 + 0.0236206\n",
      "[1300]\tcv_agg's rmse: 3.6458 + 0.0235521\n",
      "[1400]\tcv_agg's rmse: 3.64584 + 0.0237108\n",
      "[1500]\tcv_agg's rmse: 3.64589 + 0.0237629\n",
      "[1600]\tcv_agg's rmse: 3.6462 + 0.0237751\n",
      "[1700]\tcv_agg's rmse: 3.64645 + 0.0237073\n",
      "[1800]\tcv_agg's rmse: 3.64649 + 0.0237013\n",
      "[100]\tcv_agg's rmse: 3.70959 + 0.071434\n",
      "[200]\tcv_agg's rmse: 3.67505 + 0.0694315\n",
      "[300]\tcv_agg's rmse: 3.66181 + 0.068341\n",
      "[400]\tcv_agg's rmse: 3.6549 + 0.0680322\n",
      "[500]\tcv_agg's rmse: 3.65063 + 0.0677879\n",
      "[600]\tcv_agg's rmse: 3.64776 + 0.0677268\n",
      "[700]\tcv_agg's rmse: 3.64611 + 0.0677842\n",
      "[800]\tcv_agg's rmse: 3.64493 + 0.0678805\n",
      "[900]\tcv_agg's rmse: 3.644 + 0.0680386\n",
      "[1000]\tcv_agg's rmse: 3.64347 + 0.0682031\n",
      "[1100]\tcv_agg's rmse: 3.6432 + 0.0682522\n",
      "[1200]\tcv_agg's rmse: 3.64325 + 0.0683854\n",
      "[1300]\tcv_agg's rmse: 3.64295 + 0.0685795\n",
      "[1400]\tcv_agg's rmse: 3.64286 + 0.0684152\n",
      "[1500]\tcv_agg's rmse: 3.64262 + 0.0683907\n",
      "[1600]\tcv_agg's rmse: 3.64272 + 0.0683481\n",
      "[1700]\tcv_agg's rmse: 3.64282 + 0.068235\n",
      "[1800]\tcv_agg's rmse: 3.64308 + 0.0681436\n",
      "[1900]\tcv_agg's rmse: 3.64344 + 0.0680338\n",
      "[2000]\tcv_agg's rmse: 3.64345 + 0.0680068\n",
      "[100]\tcv_agg's rmse: 3.70967 + 0.0477613\n",
      "[200]\tcv_agg's rmse: 3.67605 + 0.047185\n",
      "[300]\tcv_agg's rmse: 3.66361 + 0.0468771\n",
      "[400]\tcv_agg's rmse: 3.65685 + 0.0466844\n",
      "[500]\tcv_agg's rmse: 3.65296 + 0.0466349\n",
      "[600]\tcv_agg's rmse: 3.65014 + 0.0467857\n",
      "[700]\tcv_agg's rmse: 3.64846 + 0.0467268\n",
      "[800]\tcv_agg's rmse: 3.64732 + 0.0465645\n",
      "[900]\tcv_agg's rmse: 3.64669 + 0.0463865\n",
      "[1000]\tcv_agg's rmse: 3.64618 + 0.0465648\n",
      "[1100]\tcv_agg's rmse: 3.64567 + 0.0461792\n",
      "[1200]\tcv_agg's rmse: 3.64531 + 0.0460427\n",
      "[1300]\tcv_agg's rmse: 3.64532 + 0.046026\n",
      "[1400]\tcv_agg's rmse: 3.64516 + 0.0459659\n",
      "[1500]\tcv_agg's rmse: 3.645 + 0.0460661\n",
      "[1600]\tcv_agg's rmse: 3.64507 + 0.0459956\n",
      "[1700]\tcv_agg's rmse: 3.6451 + 0.0461345\n",
      "[1800]\tcv_agg's rmse: 3.64511 + 0.046243\n",
      "[1900]\tcv_agg's rmse: 3.64533 + 0.0462222\n",
      "[2000]\tcv_agg's rmse: 3.64563 + 0.0462299\n",
      "[2100]\tcv_agg's rmse: 3.64582 + 0.0461685\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "train_data = lgb.Dataset(train[feats2], label=train.target)\n",
    "df_submission=pd.DataFrame()\n",
    "df_summary=pd.DataFrame()\n",
    "num=[]\n",
    "for fold in range(5,10):\n",
    "    cv_score = lgb.cv(param, train_data, 10000, early_stopping_rounds=600, verbose_eval=100,nfold=fold,stratified=False)\n",
    "    clf=lgb.train(param,train_data,len(cv_score['rmse-mean']), verbose_eval=100)\n",
    "    predictions=clf.predict(test[feats2],num_iteration=clf.best_iteration)\n",
    "    df_submission[fold]=predictions\n",
    "    df_summary[fold]=[cv_score['rmse-mean'],cv_score['rmse-stdv'],len(cv_score['rmse-mean'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3.8476860812985243, 3.844774068979722, 3.8420...</td>\n",
       "      <td>[3.847360978754626, 3.8444943178571305, 3.8416...</td>\n",
       "      <td>[3.8475783525511305, 3.8448144871572074, 3.841...</td>\n",
       "      <td>[3.8468864660991016, 3.844097124237644, 3.8413...</td>\n",
       "      <td>[3.847436659729316, 3.8446576711524707, 3.8418...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.031625000601743, 0.031467441634504156, 0.03...</td>\n",
       "      <td>[0.053752643662047864, 0.05382501345169446, 0....</td>\n",
       "      <td>[0.03188243151969365, 0.03177326565063012, 0.0...</td>\n",
       "      <td>[0.07742830382736555, 0.07740921213506777, 0.0...</td>\n",
       "      <td>[0.04762410795972947, 0.04766023124372953, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1690</td>\n",
       "      <td>1528</td>\n",
       "      <td>1225</td>\n",
       "      <td>1486</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   5  \\\n",
       "0  [3.8476860812985243, 3.844774068979722, 3.8420...   \n",
       "1  [0.031625000601743, 0.031467441634504156, 0.03...   \n",
       "2                                               1690   \n",
       "\n",
       "                                                   6  \\\n",
       "0  [3.847360978754626, 3.8444943178571305, 3.8416...   \n",
       "1  [0.053752643662047864, 0.05382501345169446, 0....   \n",
       "2                                               1528   \n",
       "\n",
       "                                                   7  \\\n",
       "0  [3.8475783525511305, 3.8448144871572074, 3.841...   \n",
       "1  [0.03188243151969365, 0.03177326565063012, 0.0...   \n",
       "2                                               1225   \n",
       "\n",
       "                                                   8  \\\n",
       "0  [3.8468864660991016, 3.844097124237644, 3.8413...   \n",
       "1  [0.07742830382736555, 0.07740921213506777, 0.0...   \n",
       "2                                               1486   \n",
       "\n",
       "                                                   9  \n",
       "0  [3.847436659729316, 3.8446576711524707, 3.8418...  \n",
       "1  [0.04762410795972947, 0.04766023124372953, 0.0...  \n",
       "2                                               1521  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1690\n",
       "6    1528\n",
       "7    1225\n",
       "8    1486\n",
       "9    1521\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.iloc[2,:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6473160701723373\n",
      "3.644267167356267\n",
      "3.64573621467503\n",
      "3.6426146492571756\n",
      "3.6449329066333984\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,10):\n",
    "    print(min(df_summary.loc[0,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025572451885198293\n",
      "0.04418199929533809\n",
      "0.024757300461217435\n",
      "0.06871544215955824\n",
      "0.04663307609261487\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,10):\n",
    "    print(sum(df_summary.loc[1,i])/len(df_summary.loc[1,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['card_id']=test.card_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(\"submission_with_different_kfolds.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_submission[['card_id',5]].copy()\n",
    "df.columns=['card_id','target']\n",
    "df.to_csv('submission_5fold_feature_elimination_50.csv',index=False)\n",
    "#LB:3.681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_submission[['card_id',7]].copy()\n",
    "df.columns=['card_id','target']\n",
    "df.to_csv('submission_7fold_feature_elimination_50.csv',index=False)\n",
    "#LB:3.682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data might be to noisy due to outliers. Outliers can drastically effect performance of algorithm. Let's try to train without outliers and see if cv score correlates to test score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats1=pd.read_csv('threshold_feature_elimination30_8extra_test10_without_outliers.csv',squeeze=True).tolist()\n",
    "feats2=pd.read_csv('threshold_feature_elimination80_8extra_test10_without_outliers.csv',squeeze=True).tolist()\n",
    "feats3=pd.read_csv('threshold_feature_elimination95_8extra_test10_without_outliers.csv',squeeze=True).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 80, 63, 54)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats),len(feats1),len(feats2),len(feats3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('merchants_map.csv')\n",
    "df_train=df_train.merge(data,on='card_id')\n",
    "df_test=df_test.merge(data,on='card_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(df_train,df_test,fold,feature):\n",
    "    results=pd.DataFrame()\n",
    "    folds = StratifiedKFold(n_splits=fold, shuffle=True, random_state=4950)\n",
    "    oof = np.zeros(len(df_train))\n",
    "    predictions = np.zeros(len(df_test))\n",
    "    val_error=[]\n",
    "    test_error=[]\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "\n",
    "        # cal the outlier ratio for each fold\n",
    "        cur_fold= df_train.iloc[trn_idx]\n",
    "        number_outliers = len(cur_fold[cur_fold['outliers'] == 1])\n",
    "        total = len(cur_fold)\n",
    "        print(\"fold %s %s %s\" % (fold_,number_outliers, number_outliers / total))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][feature], label=df_train.target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][feature], label=df_train.target.iloc[val_idx])\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 600)\n",
    "        oof[val_idx] = clf.predict(df_train.iloc[val_idx][feature], num_iteration=clf.best_iteration)\n",
    "        oof_test=clf.predict(df_test[feature], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        val_error.append(np.sqrt(mean_squared_error(oof[val_idx], df_train.target.iloc[val_idx])))\n",
    "        test_error.append(np.sqrt(mean_squared_error(oof_test, df_test.target)))\n",
    "        \n",
    "        predictions += clf.predict(df_test[feature], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    results['cv_error']=val_error\n",
    "    results['test_error']=test_error\n",
    "    results['fold']=[i for i in range(1,fold+1,1)]\n",
    "    results['ave_cv_error']=np.sqrt(mean_squared_error(oof,  df_train.target))\n",
    "    results['ave_test_error']=np.sqrt(mean_squared_error(predictions, df_test.target))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60681\tvalid_1's rmse: 1.60474\n",
      "[200]\ttraining's rmse: 1.57336\tvalid_1's rmse: 1.57764\n",
      "[300]\ttraining's rmse: 1.55666\tvalid_1's rmse: 1.56722\n",
      "[400]\ttraining's rmse: 1.54499\tvalid_1's rmse: 1.56178\n",
      "[500]\ttraining's rmse: 1.5356\tvalid_1's rmse: 1.55861\n",
      "[600]\ttraining's rmse: 1.52754\tvalid_1's rmse: 1.55662\n",
      "[700]\ttraining's rmse: 1.52027\tvalid_1's rmse: 1.55535\n",
      "[800]\ttraining's rmse: 1.51376\tvalid_1's rmse: 1.55446\n",
      "[900]\ttraining's rmse: 1.50772\tvalid_1's rmse: 1.55385\n",
      "[1000]\ttraining's rmse: 1.50196\tvalid_1's rmse: 1.55336\n",
      "[1100]\ttraining's rmse: 1.49637\tvalid_1's rmse: 1.55303\n",
      "[1200]\ttraining's rmse: 1.49104\tvalid_1's rmse: 1.55283\n",
      "[1300]\ttraining's rmse: 1.4858\tvalid_1's rmse: 1.55255\n",
      "[1400]\ttraining's rmse: 1.48064\tvalid_1's rmse: 1.5524\n",
      "[1500]\ttraining's rmse: 1.47566\tvalid_1's rmse: 1.55224\n",
      "[1600]\ttraining's rmse: 1.47078\tvalid_1's rmse: 1.5521\n",
      "[1700]\ttraining's rmse: 1.46593\tvalid_1's rmse: 1.55201\n",
      "[1800]\ttraining's rmse: 1.46104\tvalid_1's rmse: 1.55183\n",
      "[1900]\ttraining's rmse: 1.4562\tvalid_1's rmse: 1.5518\n",
      "[2000]\ttraining's rmse: 1.45157\tvalid_1's rmse: 1.55172\n",
      "[2100]\ttraining's rmse: 1.44695\tvalid_1's rmse: 1.55176\n",
      "[2200]\ttraining's rmse: 1.44251\tvalid_1's rmse: 1.55176\n",
      "[2300]\ttraining's rmse: 1.43804\tvalid_1's rmse: 1.55173\n",
      "[2400]\ttraining's rmse: 1.43356\tvalid_1's rmse: 1.55172\n",
      "[2500]\ttraining's rmse: 1.42922\tvalid_1's rmse: 1.55167\n",
      "[2600]\ttraining's rmse: 1.42489\tvalid_1's rmse: 1.55162\n",
      "[2700]\ttraining's rmse: 1.42061\tvalid_1's rmse: 1.55166\n",
      "[2800]\ttraining's rmse: 1.41639\tvalid_1's rmse: 1.55158\n",
      "[2900]\ttraining's rmse: 1.41227\tvalid_1's rmse: 1.55168\n",
      "[3000]\ttraining's rmse: 1.40794\tvalid_1's rmse: 1.5517\n",
      "[3100]\ttraining's rmse: 1.40387\tvalid_1's rmse: 1.55165\n",
      "[3200]\ttraining's rmse: 1.39975\tvalid_1's rmse: 1.55167\n",
      "[3300]\ttraining's rmse: 1.3957\tvalid_1's rmse: 1.55174\n",
      "[3400]\ttraining's rmse: 1.39165\tvalid_1's rmse: 1.55174\n",
      "Early stopping, best iteration is:\n",
      "[2804]\ttraining's rmse: 1.41621\tvalid_1's rmse: 1.55156\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60203\tvalid_1's rmse: 1.62609\n",
      "[200]\ttraining's rmse: 1.56836\tvalid_1's rmse: 1.59853\n",
      "[300]\ttraining's rmse: 1.55177\tvalid_1's rmse: 1.58771\n",
      "[400]\ttraining's rmse: 1.53999\tvalid_1's rmse: 1.58194\n",
      "[500]\ttraining's rmse: 1.53049\tvalid_1's rmse: 1.57833\n",
      "[600]\ttraining's rmse: 1.52228\tvalid_1's rmse: 1.57626\n",
      "[700]\ttraining's rmse: 1.51514\tvalid_1's rmse: 1.57482\n",
      "[800]\ttraining's rmse: 1.50853\tvalid_1's rmse: 1.57385\n",
      "[900]\ttraining's rmse: 1.50233\tvalid_1's rmse: 1.57322\n",
      "[1000]\ttraining's rmse: 1.49667\tvalid_1's rmse: 1.57274\n",
      "[1100]\ttraining's rmse: 1.49099\tvalid_1's rmse: 1.57228\n",
      "[1200]\ttraining's rmse: 1.48562\tvalid_1's rmse: 1.57203\n",
      "[1300]\ttraining's rmse: 1.48027\tvalid_1's rmse: 1.57177\n",
      "[1400]\ttraining's rmse: 1.47516\tvalid_1's rmse: 1.57156\n",
      "[1500]\ttraining's rmse: 1.47028\tvalid_1's rmse: 1.57139\n",
      "[1600]\ttraining's rmse: 1.46537\tvalid_1's rmse: 1.57127\n",
      "[1700]\ttraining's rmse: 1.4607\tvalid_1's rmse: 1.57118\n",
      "[1800]\ttraining's rmse: 1.45608\tvalid_1's rmse: 1.57106\n",
      "[1900]\ttraining's rmse: 1.45148\tvalid_1's rmse: 1.57099\n",
      "[2000]\ttraining's rmse: 1.44696\tvalid_1's rmse: 1.5709\n",
      "[2100]\ttraining's rmse: 1.44232\tvalid_1's rmse: 1.57086\n",
      "[2200]\ttraining's rmse: 1.43767\tvalid_1's rmse: 1.57071\n",
      "[2300]\ttraining's rmse: 1.43336\tvalid_1's rmse: 1.57066\n",
      "[2400]\ttraining's rmse: 1.42902\tvalid_1's rmse: 1.57064\n",
      "[2500]\ttraining's rmse: 1.42475\tvalid_1's rmse: 1.57055\n",
      "[2600]\ttraining's rmse: 1.42049\tvalid_1's rmse: 1.57053\n",
      "[2700]\ttraining's rmse: 1.4162\tvalid_1's rmse: 1.57038\n",
      "[2800]\ttraining's rmse: 1.41199\tvalid_1's rmse: 1.57038\n",
      "[2900]\ttraining's rmse: 1.40783\tvalid_1's rmse: 1.57036\n",
      "[3000]\ttraining's rmse: 1.40365\tvalid_1's rmse: 1.57033\n",
      "[3100]\ttraining's rmse: 1.3995\tvalid_1's rmse: 1.57021\n",
      "[3200]\ttraining's rmse: 1.39546\tvalid_1's rmse: 1.57014\n",
      "[3300]\ttraining's rmse: 1.39153\tvalid_1's rmse: 1.57007\n",
      "[3400]\ttraining's rmse: 1.38759\tvalid_1's rmse: 1.57003\n",
      "[3500]\ttraining's rmse: 1.38365\tvalid_1's rmse: 1.57\n",
      "[3600]\ttraining's rmse: 1.37966\tvalid_1's rmse: 1.56999\n",
      "[3700]\ttraining's rmse: 1.37573\tvalid_1's rmse: 1.56996\n",
      "[3800]\ttraining's rmse: 1.37173\tvalid_1's rmse: 1.57005\n",
      "[3900]\ttraining's rmse: 1.36783\tvalid_1's rmse: 1.57004\n",
      "[4000]\ttraining's rmse: 1.36409\tvalid_1's rmse: 1.57011\n",
      "[4100]\ttraining's rmse: 1.36034\tvalid_1's rmse: 1.57006\n",
      "[4200]\ttraining's rmse: 1.35656\tvalid_1's rmse: 1.57009\n",
      "Early stopping, best iteration is:\n",
      "[3631]\ttraining's rmse: 1.37845\tvalid_1's rmse: 1.56995\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60875\tvalid_1's rmse: 1.59708\n",
      "[200]\ttraining's rmse: 1.57527\tvalid_1's rmse: 1.57039\n",
      "[300]\ttraining's rmse: 1.55829\tvalid_1's rmse: 1.56012\n",
      "[400]\ttraining's rmse: 1.54659\tvalid_1's rmse: 1.55504\n",
      "[500]\ttraining's rmse: 1.53701\tvalid_1's rmse: 1.55197\n",
      "[600]\ttraining's rmse: 1.52895\tvalid_1's rmse: 1.5501\n",
      "[700]\ttraining's rmse: 1.52166\tvalid_1's rmse: 1.549\n",
      "[800]\ttraining's rmse: 1.51503\tvalid_1's rmse: 1.54832\n",
      "[900]\ttraining's rmse: 1.50876\tvalid_1's rmse: 1.54772\n",
      "[1000]\ttraining's rmse: 1.50298\tvalid_1's rmse: 1.5475\n",
      "[1100]\ttraining's rmse: 1.49742\tvalid_1's rmse: 1.54729\n",
      "[1200]\ttraining's rmse: 1.4921\tvalid_1's rmse: 1.5472\n",
      "[1300]\ttraining's rmse: 1.48692\tvalid_1's rmse: 1.5471\n",
      "[1400]\ttraining's rmse: 1.48185\tvalid_1's rmse: 1.54697\n",
      "[1500]\ttraining's rmse: 1.47684\tvalid_1's rmse: 1.54684\n",
      "[1600]\ttraining's rmse: 1.47196\tvalid_1's rmse: 1.54679\n",
      "[1700]\ttraining's rmse: 1.4672\tvalid_1's rmse: 1.54676\n",
      "[1800]\ttraining's rmse: 1.46238\tvalid_1's rmse: 1.54665\n",
      "[1900]\ttraining's rmse: 1.45767\tvalid_1's rmse: 1.54661\n",
      "[2000]\ttraining's rmse: 1.45312\tvalid_1's rmse: 1.5466\n",
      "[2100]\ttraining's rmse: 1.44861\tvalid_1's rmse: 1.54654\n",
      "[2200]\ttraining's rmse: 1.44403\tvalid_1's rmse: 1.54643\n",
      "[2300]\ttraining's rmse: 1.43952\tvalid_1's rmse: 1.54651\n",
      "[2400]\ttraining's rmse: 1.43505\tvalid_1's rmse: 1.5465\n",
      "[2500]\ttraining's rmse: 1.43071\tvalid_1's rmse: 1.54659\n",
      "[2600]\ttraining's rmse: 1.42644\tvalid_1's rmse: 1.54658\n",
      "[2700]\ttraining's rmse: 1.42217\tvalid_1's rmse: 1.54657\n",
      "[2800]\ttraining's rmse: 1.41796\tvalid_1's rmse: 1.54649\n",
      "Early stopping, best iteration is:\n",
      "[2254]\ttraining's rmse: 1.44161\tvalid_1's rmse: 1.5464\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60563\tvalid_1's rmse: 1.61198\n",
      "[200]\ttraining's rmse: 1.57257\tvalid_1's rmse: 1.58286\n",
      "[300]\ttraining's rmse: 1.55604\tvalid_1's rmse: 1.57125\n",
      "[400]\ttraining's rmse: 1.54464\tvalid_1's rmse: 1.56522\n",
      "[500]\ttraining's rmse: 1.53521\tvalid_1's rmse: 1.56152\n",
      "[600]\ttraining's rmse: 1.52704\tvalid_1's rmse: 1.55936\n",
      "[700]\ttraining's rmse: 1.51967\tvalid_1's rmse: 1.55796\n",
      "[800]\ttraining's rmse: 1.51295\tvalid_1's rmse: 1.55704\n",
      "[900]\ttraining's rmse: 1.50679\tvalid_1's rmse: 1.55641\n",
      "[1000]\ttraining's rmse: 1.50109\tvalid_1's rmse: 1.55596\n",
      "[1100]\ttraining's rmse: 1.49555\tvalid_1's rmse: 1.55558\n",
      "[1200]\ttraining's rmse: 1.4902\tvalid_1's rmse: 1.55528\n",
      "[1300]\ttraining's rmse: 1.4849\tvalid_1's rmse: 1.55504\n",
      "[1400]\ttraining's rmse: 1.47985\tvalid_1's rmse: 1.55486\n",
      "[1500]\ttraining's rmse: 1.47495\tvalid_1's rmse: 1.55469\n",
      "[1600]\ttraining's rmse: 1.47003\tvalid_1's rmse: 1.55462\n",
      "[1700]\ttraining's rmse: 1.46518\tvalid_1's rmse: 1.55451\n",
      "[1800]\ttraining's rmse: 1.46066\tvalid_1's rmse: 1.55438\n",
      "[1900]\ttraining's rmse: 1.45603\tvalid_1's rmse: 1.55425\n",
      "[2000]\ttraining's rmse: 1.45135\tvalid_1's rmse: 1.55423\n",
      "[2100]\ttraining's rmse: 1.44677\tvalid_1's rmse: 1.5541\n",
      "[2200]\ttraining's rmse: 1.44215\tvalid_1's rmse: 1.55394\n",
      "[2300]\ttraining's rmse: 1.43769\tvalid_1's rmse: 1.55391\n",
      "[2400]\ttraining's rmse: 1.43321\tvalid_1's rmse: 1.55386\n",
      "[2500]\ttraining's rmse: 1.42881\tvalid_1's rmse: 1.55374\n",
      "[2600]\ttraining's rmse: 1.42445\tvalid_1's rmse: 1.55357\n",
      "[2700]\ttraining's rmse: 1.42008\tvalid_1's rmse: 1.5535\n",
      "[2800]\ttraining's rmse: 1.41577\tvalid_1's rmse: 1.55341\n",
      "[2900]\ttraining's rmse: 1.41152\tvalid_1's rmse: 1.5533\n",
      "[3000]\ttraining's rmse: 1.40733\tvalid_1's rmse: 1.55318\n",
      "[3100]\ttraining's rmse: 1.40313\tvalid_1's rmse: 1.55312\n",
      "[3200]\ttraining's rmse: 1.39901\tvalid_1's rmse: 1.55311\n",
      "[3300]\ttraining's rmse: 1.39492\tvalid_1's rmse: 1.55312\n",
      "[3400]\ttraining's rmse: 1.3909\tvalid_1's rmse: 1.55302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3500]\ttraining's rmse: 1.38684\tvalid_1's rmse: 1.553\n",
      "[3600]\ttraining's rmse: 1.38282\tvalid_1's rmse: 1.55303\n",
      "[3700]\ttraining's rmse: 1.379\tvalid_1's rmse: 1.55301\n",
      "[3800]\ttraining's rmse: 1.37503\tvalid_1's rmse: 1.55307\n",
      "[3900]\ttraining's rmse: 1.37104\tvalid_1's rmse: 1.55315\n",
      "[4000]\ttraining's rmse: 1.36715\tvalid_1's rmse: 1.55324\n",
      "[4100]\ttraining's rmse: 1.36318\tvalid_1's rmse: 1.55326\n",
      "Early stopping, best iteration is:\n",
      "[3510]\ttraining's rmse: 1.38646\tvalid_1's rmse: 1.55298\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60368\tvalid_1's rmse: 1.61692\n",
      "[200]\ttraining's rmse: 1.57009\tvalid_1's rmse: 1.59032\n",
      "[300]\ttraining's rmse: 1.55333\tvalid_1's rmse: 1.5807\n",
      "[400]\ttraining's rmse: 1.54182\tvalid_1's rmse: 1.57586\n",
      "[500]\ttraining's rmse: 1.53238\tvalid_1's rmse: 1.57284\n",
      "[600]\ttraining's rmse: 1.52419\tvalid_1's rmse: 1.57097\n",
      "[700]\ttraining's rmse: 1.51678\tvalid_1's rmse: 1.5696\n",
      "[800]\ttraining's rmse: 1.51019\tvalid_1's rmse: 1.56887\n",
      "[900]\ttraining's rmse: 1.50407\tvalid_1's rmse: 1.56849\n",
      "[1000]\ttraining's rmse: 1.49821\tvalid_1's rmse: 1.56811\n",
      "[1100]\ttraining's rmse: 1.49269\tvalid_1's rmse: 1.56784\n",
      "[1200]\ttraining's rmse: 1.48732\tvalid_1's rmse: 1.56766\n",
      "[1300]\ttraining's rmse: 1.48214\tvalid_1's rmse: 1.56759\n",
      "[1400]\ttraining's rmse: 1.47692\tvalid_1's rmse: 1.56746\n",
      "[1500]\ttraining's rmse: 1.47186\tvalid_1's rmse: 1.56737\n",
      "[1600]\ttraining's rmse: 1.46691\tvalid_1's rmse: 1.56732\n",
      "[1700]\ttraining's rmse: 1.46202\tvalid_1's rmse: 1.56713\n",
      "[1800]\ttraining's rmse: 1.45728\tvalid_1's rmse: 1.56702\n",
      "[1900]\ttraining's rmse: 1.4525\tvalid_1's rmse: 1.56699\n",
      "[2000]\ttraining's rmse: 1.44777\tvalid_1's rmse: 1.56692\n",
      "[2100]\ttraining's rmse: 1.44329\tvalid_1's rmse: 1.56693\n",
      "[2200]\ttraining's rmse: 1.43872\tvalid_1's rmse: 1.56697\n",
      "[2300]\ttraining's rmse: 1.43421\tvalid_1's rmse: 1.56699\n",
      "[2400]\ttraining's rmse: 1.42984\tvalid_1's rmse: 1.56708\n",
      "[2500]\ttraining's rmse: 1.4254\tvalid_1's rmse: 1.56724\n",
      "Early stopping, best iteration is:\n",
      "[1990]\ttraining's rmse: 1.44819\tvalid_1's rmse: 1.56687\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60322\tvalid_1's rmse: 1.60049\n",
      "[200]\ttraining's rmse: 1.56987\tvalid_1's rmse: 1.57267\n",
      "[300]\ttraining's rmse: 1.55421\tvalid_1's rmse: 1.56221\n",
      "[400]\ttraining's rmse: 1.54405\tvalid_1's rmse: 1.55715\n",
      "[500]\ttraining's rmse: 1.53638\tvalid_1's rmse: 1.5546\n",
      "[600]\ttraining's rmse: 1.52988\tvalid_1's rmse: 1.55305\n",
      "[700]\ttraining's rmse: 1.52432\tvalid_1's rmse: 1.55207\n",
      "[800]\ttraining's rmse: 1.5194\tvalid_1's rmse: 1.5514\n",
      "[900]\ttraining's rmse: 1.51485\tvalid_1's rmse: 1.55108\n",
      "[1000]\ttraining's rmse: 1.51042\tvalid_1's rmse: 1.55081\n",
      "[1100]\ttraining's rmse: 1.50618\tvalid_1's rmse: 1.55054\n",
      "[1200]\ttraining's rmse: 1.502\tvalid_1's rmse: 1.55038\n",
      "[1300]\ttraining's rmse: 1.49802\tvalid_1's rmse: 1.5502\n",
      "[1400]\ttraining's rmse: 1.4941\tvalid_1's rmse: 1.55009\n",
      "[1500]\ttraining's rmse: 1.49015\tvalid_1's rmse: 1.55005\n",
      "[1600]\ttraining's rmse: 1.48634\tvalid_1's rmse: 1.55004\n",
      "[1700]\ttraining's rmse: 1.48266\tvalid_1's rmse: 1.54995\n",
      "[1800]\ttraining's rmse: 1.47896\tvalid_1's rmse: 1.5499\n",
      "[1900]\ttraining's rmse: 1.47543\tvalid_1's rmse: 1.54992\n",
      "[2000]\ttraining's rmse: 1.47199\tvalid_1's rmse: 1.54997\n",
      "[2100]\ttraining's rmse: 1.46832\tvalid_1's rmse: 1.54995\n",
      "[2200]\ttraining's rmse: 1.46475\tvalid_1's rmse: 1.55\n",
      "[2300]\ttraining's rmse: 1.46118\tvalid_1's rmse: 1.55004\n",
      "[2400]\ttraining's rmse: 1.45766\tvalid_1's rmse: 1.55007\n",
      "Early stopping, best iteration is:\n",
      "[1823]\ttraining's rmse: 1.47816\tvalid_1's rmse: 1.54987\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59816\tvalid_1's rmse: 1.62168\n",
      "[200]\ttraining's rmse: 1.56486\tvalid_1's rmse: 1.5933\n",
      "[300]\ttraining's rmse: 1.54931\tvalid_1's rmse: 1.58244\n",
      "[400]\ttraining's rmse: 1.53911\tvalid_1's rmse: 1.57681\n",
      "[500]\ttraining's rmse: 1.53149\tvalid_1's rmse: 1.57357\n",
      "[600]\ttraining's rmse: 1.5251\tvalid_1's rmse: 1.57161\n",
      "[700]\ttraining's rmse: 1.5195\tvalid_1's rmse: 1.57037\n",
      "[800]\ttraining's rmse: 1.51455\tvalid_1's rmse: 1.56964\n",
      "[900]\ttraining's rmse: 1.50992\tvalid_1's rmse: 1.56911\n",
      "[1000]\ttraining's rmse: 1.50556\tvalid_1's rmse: 1.56871\n",
      "[1100]\ttraining's rmse: 1.50123\tvalid_1's rmse: 1.56824\n",
      "[1200]\ttraining's rmse: 1.4972\tvalid_1's rmse: 1.56801\n",
      "[1300]\ttraining's rmse: 1.49307\tvalid_1's rmse: 1.56781\n",
      "[1400]\ttraining's rmse: 1.48914\tvalid_1's rmse: 1.56759\n",
      "[1500]\ttraining's rmse: 1.48551\tvalid_1's rmse: 1.56743\n",
      "[1600]\ttraining's rmse: 1.48183\tvalid_1's rmse: 1.56725\n",
      "[1700]\ttraining's rmse: 1.47816\tvalid_1's rmse: 1.56715\n",
      "[1800]\ttraining's rmse: 1.47462\tvalid_1's rmse: 1.56696\n",
      "[1900]\ttraining's rmse: 1.4709\tvalid_1's rmse: 1.56676\n",
      "[2000]\ttraining's rmse: 1.46739\tvalid_1's rmse: 1.56674\n",
      "[2100]\ttraining's rmse: 1.46386\tvalid_1's rmse: 1.56669\n",
      "[2200]\ttraining's rmse: 1.46037\tvalid_1's rmse: 1.56658\n",
      "[2300]\ttraining's rmse: 1.4569\tvalid_1's rmse: 1.56643\n",
      "[2400]\ttraining's rmse: 1.45344\tvalid_1's rmse: 1.56642\n",
      "[2500]\ttraining's rmse: 1.45006\tvalid_1's rmse: 1.56648\n",
      "[2600]\ttraining's rmse: 1.44666\tvalid_1's rmse: 1.56649\n",
      "[2700]\ttraining's rmse: 1.44329\tvalid_1's rmse: 1.56648\n",
      "[2800]\ttraining's rmse: 1.43999\tvalid_1's rmse: 1.56645\n",
      "[2900]\ttraining's rmse: 1.43684\tvalid_1's rmse: 1.5664\n",
      "[3000]\ttraining's rmse: 1.43349\tvalid_1's rmse: 1.56644\n",
      "[3100]\ttraining's rmse: 1.43025\tvalid_1's rmse: 1.56648\n",
      "[3200]\ttraining's rmse: 1.42702\tvalid_1's rmse: 1.56653\n",
      "[3300]\ttraining's rmse: 1.4238\tvalid_1's rmse: 1.56649\n",
      "[3400]\ttraining's rmse: 1.42054\tvalid_1's rmse: 1.56657\n",
      "[3500]\ttraining's rmse: 1.41736\tvalid_1's rmse: 1.56663\n",
      "Early stopping, best iteration is:\n",
      "[2912]\ttraining's rmse: 1.43645\tvalid_1's rmse: 1.56638\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60472\tvalid_1's rmse: 1.59398\n",
      "[200]\ttraining's rmse: 1.57134\tvalid_1's rmse: 1.56632\n",
      "[300]\ttraining's rmse: 1.55554\tvalid_1's rmse: 1.55589\n",
      "[400]\ttraining's rmse: 1.54536\tvalid_1's rmse: 1.55097\n",
      "[500]\ttraining's rmse: 1.53754\tvalid_1's rmse: 1.54835\n",
      "[600]\ttraining's rmse: 1.53109\tvalid_1's rmse: 1.54706\n",
      "[700]\ttraining's rmse: 1.52548\tvalid_1's rmse: 1.54616\n",
      "[800]\ttraining's rmse: 1.52041\tvalid_1's rmse: 1.54564\n",
      "[900]\ttraining's rmse: 1.51569\tvalid_1's rmse: 1.54537\n",
      "[1000]\ttraining's rmse: 1.51115\tvalid_1's rmse: 1.54512\n",
      "[1100]\ttraining's rmse: 1.50684\tvalid_1's rmse: 1.54504\n",
      "[1200]\ttraining's rmse: 1.50274\tvalid_1's rmse: 1.54501\n",
      "[1300]\ttraining's rmse: 1.49871\tvalid_1's rmse: 1.54496\n",
      "[1400]\ttraining's rmse: 1.49477\tvalid_1's rmse: 1.54494\n",
      "[1500]\ttraining's rmse: 1.49092\tvalid_1's rmse: 1.54495\n",
      "[1600]\ttraining's rmse: 1.48712\tvalid_1's rmse: 1.54499\n",
      "[1700]\ttraining's rmse: 1.48339\tvalid_1's rmse: 1.545\n",
      "[1800]\ttraining's rmse: 1.47981\tvalid_1's rmse: 1.54507\n",
      "[1900]\ttraining's rmse: 1.47627\tvalid_1's rmse: 1.54514\n",
      "Early stopping, best iteration is:\n",
      "[1378]\ttraining's rmse: 1.49566\tvalid_1's rmse: 1.5449\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60212\tvalid_1's rmse: 1.6072\n",
      "[200]\ttraining's rmse: 1.56905\tvalid_1's rmse: 1.57713\n",
      "[300]\ttraining's rmse: 1.55372\tvalid_1's rmse: 1.5656\n",
      "[400]\ttraining's rmse: 1.54361\tvalid_1's rmse: 1.5595\n",
      "[500]\ttraining's rmse: 1.53601\tvalid_1's rmse: 1.55625\n",
      "[600]\ttraining's rmse: 1.52968\tvalid_1's rmse: 1.55421\n",
      "[700]\ttraining's rmse: 1.52414\tvalid_1's rmse: 1.55299\n",
      "[800]\ttraining's rmse: 1.5191\tvalid_1's rmse: 1.55215\n",
      "[900]\ttraining's rmse: 1.51453\tvalid_1's rmse: 1.55164\n",
      "[1000]\ttraining's rmse: 1.5101\tvalid_1's rmse: 1.55113\n",
      "[1100]\ttraining's rmse: 1.50592\tvalid_1's rmse: 1.55081\n",
      "[1200]\ttraining's rmse: 1.5018\tvalid_1's rmse: 1.55053\n",
      "[1300]\ttraining's rmse: 1.49785\tvalid_1's rmse: 1.55031\n",
      "[1400]\ttraining's rmse: 1.49402\tvalid_1's rmse: 1.55015\n",
      "[1500]\ttraining's rmse: 1.49018\tvalid_1's rmse: 1.55001\n",
      "[1600]\ttraining's rmse: 1.48643\tvalid_1's rmse: 1.54986\n",
      "[1700]\ttraining's rmse: 1.48281\tvalid_1's rmse: 1.54972\n",
      "[1800]\ttraining's rmse: 1.47917\tvalid_1's rmse: 1.54956\n",
      "[1900]\ttraining's rmse: 1.47569\tvalid_1's rmse: 1.54941\n",
      "[2000]\ttraining's rmse: 1.472\tvalid_1's rmse: 1.54929\n",
      "[2100]\ttraining's rmse: 1.46853\tvalid_1's rmse: 1.54913\n",
      "[2200]\ttraining's rmse: 1.46501\tvalid_1's rmse: 1.549\n",
      "[2300]\ttraining's rmse: 1.46153\tvalid_1's rmse: 1.54886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2400]\ttraining's rmse: 1.45813\tvalid_1's rmse: 1.54882\n",
      "[2500]\ttraining's rmse: 1.45462\tvalid_1's rmse: 1.5488\n",
      "[2600]\ttraining's rmse: 1.45134\tvalid_1's rmse: 1.54886\n",
      "[2700]\ttraining's rmse: 1.44808\tvalid_1's rmse: 1.54883\n",
      "[2800]\ttraining's rmse: 1.44474\tvalid_1's rmse: 1.54882\n",
      "[2900]\ttraining's rmse: 1.44165\tvalid_1's rmse: 1.54877\n",
      "[3000]\ttraining's rmse: 1.4384\tvalid_1's rmse: 1.54869\n",
      "[3100]\ttraining's rmse: 1.43517\tvalid_1's rmse: 1.54865\n",
      "[3200]\ttraining's rmse: 1.43206\tvalid_1's rmse: 1.54868\n",
      "[3300]\ttraining's rmse: 1.42888\tvalid_1's rmse: 1.54873\n",
      "[3400]\ttraining's rmse: 1.4256\tvalid_1's rmse: 1.54877\n",
      "[3500]\ttraining's rmse: 1.42243\tvalid_1's rmse: 1.54889\n",
      "[3600]\ttraining's rmse: 1.41928\tvalid_1's rmse: 1.54894\n",
      "Early stopping, best iteration is:\n",
      "[3093]\ttraining's rmse: 1.4354\tvalid_1's rmse: 1.54861\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59974\tvalid_1's rmse: 1.61359\n",
      "[200]\ttraining's rmse: 1.56631\tvalid_1's rmse: 1.58669\n",
      "[300]\ttraining's rmse: 1.55073\tvalid_1's rmse: 1.57697\n",
      "[400]\ttraining's rmse: 1.54061\tvalid_1's rmse: 1.57211\n",
      "[500]\ttraining's rmse: 1.53296\tvalid_1's rmse: 1.56944\n",
      "[600]\ttraining's rmse: 1.52653\tvalid_1's rmse: 1.56774\n",
      "[700]\ttraining's rmse: 1.52093\tvalid_1's rmse: 1.56675\n",
      "[800]\ttraining's rmse: 1.5159\tvalid_1's rmse: 1.56603\n",
      "[900]\ttraining's rmse: 1.5113\tvalid_1's rmse: 1.56557\n",
      "[1000]\ttraining's rmse: 1.50689\tvalid_1's rmse: 1.56526\n",
      "[1100]\ttraining's rmse: 1.5026\tvalid_1's rmse: 1.56485\n",
      "[1200]\ttraining's rmse: 1.49847\tvalid_1's rmse: 1.56477\n",
      "[1300]\ttraining's rmse: 1.49459\tvalid_1's rmse: 1.56458\n",
      "[1400]\ttraining's rmse: 1.49068\tvalid_1's rmse: 1.56452\n",
      "[1500]\ttraining's rmse: 1.48685\tvalid_1's rmse: 1.5644\n",
      "[1600]\ttraining's rmse: 1.48299\tvalid_1's rmse: 1.56434\n",
      "[1700]\ttraining's rmse: 1.47937\tvalid_1's rmse: 1.5643\n",
      "[1800]\ttraining's rmse: 1.47574\tvalid_1's rmse: 1.56422\n",
      "[1900]\ttraining's rmse: 1.4721\tvalid_1's rmse: 1.56419\n",
      "[2000]\ttraining's rmse: 1.46854\tvalid_1's rmse: 1.56419\n",
      "[2100]\ttraining's rmse: 1.46503\tvalid_1's rmse: 1.56426\n",
      "[2200]\ttraining's rmse: 1.46155\tvalid_1's rmse: 1.56412\n",
      "[2300]\ttraining's rmse: 1.45794\tvalid_1's rmse: 1.56415\n",
      "[2400]\ttraining's rmse: 1.45448\tvalid_1's rmse: 1.56423\n",
      "[2500]\ttraining's rmse: 1.45109\tvalid_1's rmse: 1.56429\n",
      "[2600]\ttraining's rmse: 1.4478\tvalid_1's rmse: 1.56426\n",
      "[2700]\ttraining's rmse: 1.44461\tvalid_1's rmse: 1.56439\n",
      "[2800]\ttraining's rmse: 1.44124\tvalid_1's rmse: 1.56446\n",
      "Early stopping, best iteration is:\n",
      "[2215]\ttraining's rmse: 1.46097\tvalid_1's rmse: 1.56407\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60331\tvalid_1's rmse: 1.60063\n",
      "[200]\ttraining's rmse: 1.57002\tvalid_1's rmse: 1.57278\n",
      "[300]\ttraining's rmse: 1.55458\tvalid_1's rmse: 1.56232\n",
      "[400]\ttraining's rmse: 1.54479\tvalid_1's rmse: 1.55734\n",
      "[500]\ttraining's rmse: 1.53735\tvalid_1's rmse: 1.5547\n",
      "[600]\ttraining's rmse: 1.53127\tvalid_1's rmse: 1.5532\n",
      "[700]\ttraining's rmse: 1.52595\tvalid_1's rmse: 1.55222\n",
      "[800]\ttraining's rmse: 1.52118\tvalid_1's rmse: 1.55157\n",
      "[900]\ttraining's rmse: 1.51691\tvalid_1's rmse: 1.55135\n",
      "[1000]\ttraining's rmse: 1.51272\tvalid_1's rmse: 1.55106\n",
      "[1100]\ttraining's rmse: 1.50878\tvalid_1's rmse: 1.55081\n",
      "[1200]\ttraining's rmse: 1.5049\tvalid_1's rmse: 1.55069\n",
      "[1300]\ttraining's rmse: 1.50114\tvalid_1's rmse: 1.55059\n",
      "[1400]\ttraining's rmse: 1.49737\tvalid_1's rmse: 1.55054\n",
      "[1500]\ttraining's rmse: 1.49372\tvalid_1's rmse: 1.55045\n",
      "[1600]\ttraining's rmse: 1.49009\tvalid_1's rmse: 1.55052\n",
      "[1700]\ttraining's rmse: 1.4866\tvalid_1's rmse: 1.5505\n",
      "[1800]\ttraining's rmse: 1.48315\tvalid_1's rmse: 1.55051\n",
      "[1900]\ttraining's rmse: 1.47962\tvalid_1's rmse: 1.55049\n",
      "[2000]\ttraining's rmse: 1.47625\tvalid_1's rmse: 1.55055\n",
      "[2100]\ttraining's rmse: 1.47281\tvalid_1's rmse: 1.55051\n",
      "[2200]\ttraining's rmse: 1.4695\tvalid_1's rmse: 1.55052\n",
      "[2300]\ttraining's rmse: 1.46618\tvalid_1's rmse: 1.55053\n",
      "[2400]\ttraining's rmse: 1.46294\tvalid_1's rmse: 1.55057\n",
      "Early stopping, best iteration is:\n",
      "[1851]\ttraining's rmse: 1.48138\tvalid_1's rmse: 1.55045\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59822\tvalid_1's rmse: 1.62158\n",
      "[200]\ttraining's rmse: 1.56502\tvalid_1's rmse: 1.59309\n",
      "[300]\ttraining's rmse: 1.54973\tvalid_1's rmse: 1.58224\n",
      "[400]\ttraining's rmse: 1.53981\tvalid_1's rmse: 1.57646\n",
      "[500]\ttraining's rmse: 1.53248\tvalid_1's rmse: 1.57331\n",
      "[600]\ttraining's rmse: 1.52643\tvalid_1's rmse: 1.57152\n",
      "[700]\ttraining's rmse: 1.52123\tvalid_1's rmse: 1.57044\n",
      "[800]\ttraining's rmse: 1.51655\tvalid_1's rmse: 1.56972\n",
      "[900]\ttraining's rmse: 1.51215\tvalid_1's rmse: 1.56919\n",
      "[1000]\ttraining's rmse: 1.50806\tvalid_1's rmse: 1.56887\n",
      "[1100]\ttraining's rmse: 1.50411\tvalid_1's rmse: 1.56854\n",
      "[1200]\ttraining's rmse: 1.50038\tvalid_1's rmse: 1.56834\n",
      "[1300]\ttraining's rmse: 1.4965\tvalid_1's rmse: 1.5682\n",
      "[1400]\ttraining's rmse: 1.49283\tvalid_1's rmse: 1.5681\n",
      "[1500]\ttraining's rmse: 1.48918\tvalid_1's rmse: 1.56794\n",
      "[1600]\ttraining's rmse: 1.48548\tvalid_1's rmse: 1.56772\n",
      "[1700]\ttraining's rmse: 1.48196\tvalid_1's rmse: 1.56753\n",
      "[1800]\ttraining's rmse: 1.47853\tvalid_1's rmse: 1.56746\n",
      "[1900]\ttraining's rmse: 1.47508\tvalid_1's rmse: 1.56729\n",
      "[2000]\ttraining's rmse: 1.47179\tvalid_1's rmse: 1.56717\n",
      "[2100]\ttraining's rmse: 1.46849\tvalid_1's rmse: 1.56716\n",
      "[2200]\ttraining's rmse: 1.46511\tvalid_1's rmse: 1.5672\n",
      "[2300]\ttraining's rmse: 1.46194\tvalid_1's rmse: 1.56716\n",
      "[2400]\ttraining's rmse: 1.45874\tvalid_1's rmse: 1.56716\n",
      "[2500]\ttraining's rmse: 1.45558\tvalid_1's rmse: 1.56703\n",
      "[2600]\ttraining's rmse: 1.45244\tvalid_1's rmse: 1.56709\n",
      "[2700]\ttraining's rmse: 1.44923\tvalid_1's rmse: 1.5671\n",
      "[2800]\ttraining's rmse: 1.44613\tvalid_1's rmse: 1.56715\n",
      "[2900]\ttraining's rmse: 1.44302\tvalid_1's rmse: 1.56714\n",
      "[3000]\ttraining's rmse: 1.43992\tvalid_1's rmse: 1.56716\n",
      "[3100]\ttraining's rmse: 1.43686\tvalid_1's rmse: 1.56721\n",
      "Early stopping, best iteration is:\n",
      "[2535]\ttraining's rmse: 1.45449\tvalid_1's rmse: 1.56701\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60469\tvalid_1's rmse: 1.5938\n",
      "[200]\ttraining's rmse: 1.57151\tvalid_1's rmse: 1.56626\n",
      "[300]\ttraining's rmse: 1.55594\tvalid_1's rmse: 1.55578\n",
      "[400]\ttraining's rmse: 1.54598\tvalid_1's rmse: 1.55078\n",
      "[500]\ttraining's rmse: 1.53847\tvalid_1's rmse: 1.54839\n",
      "[600]\ttraining's rmse: 1.53237\tvalid_1's rmse: 1.54696\n",
      "[700]\ttraining's rmse: 1.52706\tvalid_1's rmse: 1.5464\n",
      "[800]\ttraining's rmse: 1.52237\tvalid_1's rmse: 1.54584\n",
      "[900]\ttraining's rmse: 1.51787\tvalid_1's rmse: 1.54565\n",
      "[1000]\ttraining's rmse: 1.51361\tvalid_1's rmse: 1.54543\n",
      "[1100]\ttraining's rmse: 1.50959\tvalid_1's rmse: 1.54542\n",
      "[1200]\ttraining's rmse: 1.5057\tvalid_1's rmse: 1.54526\n",
      "[1300]\ttraining's rmse: 1.50186\tvalid_1's rmse: 1.54519\n",
      "[1400]\ttraining's rmse: 1.49807\tvalid_1's rmse: 1.54518\n",
      "[1500]\ttraining's rmse: 1.49442\tvalid_1's rmse: 1.54519\n",
      "[1600]\ttraining's rmse: 1.49083\tvalid_1's rmse: 1.54518\n",
      "[1700]\ttraining's rmse: 1.48744\tvalid_1's rmse: 1.54519\n",
      "[1800]\ttraining's rmse: 1.48392\tvalid_1's rmse: 1.54528\n",
      "[1900]\ttraining's rmse: 1.48043\tvalid_1's rmse: 1.54531\n",
      "[2000]\ttraining's rmse: 1.47692\tvalid_1's rmse: 1.54535\n",
      "[2100]\ttraining's rmse: 1.47356\tvalid_1's rmse: 1.54534\n",
      "[2200]\ttraining's rmse: 1.47024\tvalid_1's rmse: 1.54544\n",
      "Early stopping, best iteration is:\n",
      "[1669]\ttraining's rmse: 1.4885\tvalid_1's rmse: 1.54514\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60216\tvalid_1's rmse: 1.60744\n",
      "[200]\ttraining's rmse: 1.56922\tvalid_1's rmse: 1.5775\n",
      "[300]\ttraining's rmse: 1.55402\tvalid_1's rmse: 1.5658\n",
      "[400]\ttraining's rmse: 1.54429\tvalid_1's rmse: 1.5599\n",
      "[500]\ttraining's rmse: 1.53701\tvalid_1's rmse: 1.55669\n",
      "[600]\ttraining's rmse: 1.53107\tvalid_1's rmse: 1.55472\n",
      "[700]\ttraining's rmse: 1.52577\tvalid_1's rmse: 1.55352\n",
      "[800]\ttraining's rmse: 1.5211\tvalid_1's rmse: 1.55281\n",
      "[900]\ttraining's rmse: 1.5166\tvalid_1's rmse: 1.55227\n",
      "[1000]\ttraining's rmse: 1.51245\tvalid_1's rmse: 1.55186\n",
      "[1100]\ttraining's rmse: 1.50852\tvalid_1's rmse: 1.55166\n",
      "[1200]\ttraining's rmse: 1.50458\tvalid_1's rmse: 1.55144\n",
      "[1300]\ttraining's rmse: 1.50078\tvalid_1's rmse: 1.55124\n",
      "[1400]\ttraining's rmse: 1.49706\tvalid_1's rmse: 1.55114\n",
      "[1500]\ttraining's rmse: 1.49344\tvalid_1's rmse: 1.551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\ttraining's rmse: 1.48988\tvalid_1's rmse: 1.5509\n",
      "[1700]\ttraining's rmse: 1.48642\tvalid_1's rmse: 1.55078\n",
      "[1800]\ttraining's rmse: 1.48294\tvalid_1's rmse: 1.55068\n",
      "[1900]\ttraining's rmse: 1.47942\tvalid_1's rmse: 1.55063\n",
      "[2000]\ttraining's rmse: 1.47604\tvalid_1's rmse: 1.55054\n",
      "[2100]\ttraining's rmse: 1.47272\tvalid_1's rmse: 1.5505\n",
      "[2200]\ttraining's rmse: 1.46936\tvalid_1's rmse: 1.55052\n",
      "[2300]\ttraining's rmse: 1.4661\tvalid_1's rmse: 1.55057\n",
      "[2400]\ttraining's rmse: 1.46282\tvalid_1's rmse: 1.55066\n",
      "[2500]\ttraining's rmse: 1.45947\tvalid_1's rmse: 1.5507\n",
      "[2600]\ttraining's rmse: 1.45641\tvalid_1's rmse: 1.55078\n",
      "Early stopping, best iteration is:\n",
      "[2081]\ttraining's rmse: 1.47332\tvalid_1's rmse: 1.55047\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59973\tvalid_1's rmse: 1.61345\n",
      "[200]\ttraining's rmse: 1.56631\tvalid_1's rmse: 1.58643\n",
      "[300]\ttraining's rmse: 1.55093\tvalid_1's rmse: 1.57681\n",
      "[400]\ttraining's rmse: 1.54116\tvalid_1's rmse: 1.57204\n",
      "[500]\ttraining's rmse: 1.53375\tvalid_1's rmse: 1.56951\n",
      "[600]\ttraining's rmse: 1.52771\tvalid_1's rmse: 1.56787\n",
      "[700]\ttraining's rmse: 1.52245\tvalid_1's rmse: 1.56692\n",
      "[800]\ttraining's rmse: 1.51782\tvalid_1's rmse: 1.56638\n",
      "[900]\ttraining's rmse: 1.51352\tvalid_1's rmse: 1.56607\n",
      "[1000]\ttraining's rmse: 1.50943\tvalid_1's rmse: 1.56575\n",
      "[1100]\ttraining's rmse: 1.50544\tvalid_1's rmse: 1.56552\n",
      "[1200]\ttraining's rmse: 1.50159\tvalid_1's rmse: 1.56539\n",
      "[1300]\ttraining's rmse: 1.4979\tvalid_1's rmse: 1.56532\n",
      "[1400]\ttraining's rmse: 1.49416\tvalid_1's rmse: 1.56513\n",
      "[1500]\ttraining's rmse: 1.49056\tvalid_1's rmse: 1.56513\n",
      "[1600]\ttraining's rmse: 1.48693\tvalid_1's rmse: 1.56508\n",
      "[1700]\ttraining's rmse: 1.48331\tvalid_1's rmse: 1.56506\n",
      "[1800]\ttraining's rmse: 1.47984\tvalid_1's rmse: 1.56513\n",
      "[1900]\ttraining's rmse: 1.47639\tvalid_1's rmse: 1.56512\n",
      "[2000]\ttraining's rmse: 1.47307\tvalid_1's rmse: 1.56508\n",
      "[2100]\ttraining's rmse: 1.4697\tvalid_1's rmse: 1.56517\n",
      "[2200]\ttraining's rmse: 1.46639\tvalid_1's rmse: 1.56514\n",
      "Early stopping, best iteration is:\n",
      "[1666]\ttraining's rmse: 1.48456\tvalid_1's rmse: 1.56504\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60336\tvalid_1's rmse: 1.60058\n",
      "[200]\ttraining's rmse: 1.57028\tvalid_1's rmse: 1.57285\n",
      "[300]\ttraining's rmse: 1.55495\tvalid_1's rmse: 1.5625\n",
      "[400]\ttraining's rmse: 1.54531\tvalid_1's rmse: 1.55768\n",
      "[500]\ttraining's rmse: 1.53808\tvalid_1's rmse: 1.55513\n",
      "[600]\ttraining's rmse: 1.53243\tvalid_1's rmse: 1.55369\n",
      "[700]\ttraining's rmse: 1.52751\tvalid_1's rmse: 1.55288\n",
      "[800]\ttraining's rmse: 1.52297\tvalid_1's rmse: 1.55232\n",
      "[900]\ttraining's rmse: 1.51885\tvalid_1's rmse: 1.55199\n",
      "[1000]\ttraining's rmse: 1.51474\tvalid_1's rmse: 1.55169\n",
      "[1100]\ttraining's rmse: 1.51096\tvalid_1's rmse: 1.55159\n",
      "[1200]\ttraining's rmse: 1.5073\tvalid_1's rmse: 1.55145\n",
      "[1300]\ttraining's rmse: 1.50356\tvalid_1's rmse: 1.55124\n",
      "[1400]\ttraining's rmse: 1.50002\tvalid_1's rmse: 1.55109\n",
      "[1500]\ttraining's rmse: 1.4965\tvalid_1's rmse: 1.55095\n",
      "[1600]\ttraining's rmse: 1.49294\tvalid_1's rmse: 1.55092\n",
      "[1700]\ttraining's rmse: 1.4895\tvalid_1's rmse: 1.55086\n",
      "[1800]\ttraining's rmse: 1.48619\tvalid_1's rmse: 1.55083\n",
      "[1900]\ttraining's rmse: 1.48284\tvalid_1's rmse: 1.55086\n",
      "[2000]\ttraining's rmse: 1.47954\tvalid_1's rmse: 1.55091\n",
      "[2100]\ttraining's rmse: 1.4762\tvalid_1's rmse: 1.55083\n",
      "[2200]\ttraining's rmse: 1.47292\tvalid_1's rmse: 1.55081\n",
      "[2300]\ttraining's rmse: 1.46965\tvalid_1's rmse: 1.551\n",
      "[2400]\ttraining's rmse: 1.46633\tvalid_1's rmse: 1.55109\n",
      "Early stopping, best iteration is:\n",
      "[1878]\ttraining's rmse: 1.48354\tvalid_1's rmse: 1.55079\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59836\tvalid_1's rmse: 1.6217\n",
      "[200]\ttraining's rmse: 1.5654\tvalid_1's rmse: 1.59332\n",
      "[300]\ttraining's rmse: 1.55019\tvalid_1's rmse: 1.5824\n",
      "[400]\ttraining's rmse: 1.54056\tvalid_1's rmse: 1.57681\n",
      "[500]\ttraining's rmse: 1.53333\tvalid_1's rmse: 1.57362\n",
      "[600]\ttraining's rmse: 1.5275\tvalid_1's rmse: 1.57183\n",
      "[700]\ttraining's rmse: 1.52247\tvalid_1's rmse: 1.57064\n",
      "[800]\ttraining's rmse: 1.51794\tvalid_1's rmse: 1.57001\n",
      "[900]\ttraining's rmse: 1.51384\tvalid_1's rmse: 1.56957\n",
      "[1000]\ttraining's rmse: 1.50982\tvalid_1's rmse: 1.5691\n",
      "[1100]\ttraining's rmse: 1.50595\tvalid_1's rmse: 1.56882\n",
      "[1200]\ttraining's rmse: 1.5023\tvalid_1's rmse: 1.56853\n",
      "[1300]\ttraining's rmse: 1.49853\tvalid_1's rmse: 1.56836\n",
      "[1400]\ttraining's rmse: 1.49499\tvalid_1's rmse: 1.5682\n",
      "[1500]\ttraining's rmse: 1.49153\tvalid_1's rmse: 1.56803\n",
      "[1600]\ttraining's rmse: 1.48808\tvalid_1's rmse: 1.56798\n",
      "[1700]\ttraining's rmse: 1.48471\tvalid_1's rmse: 1.56788\n",
      "[1800]\ttraining's rmse: 1.4813\tvalid_1's rmse: 1.56785\n",
      "[1900]\ttraining's rmse: 1.47788\tvalid_1's rmse: 1.56763\n",
      "[2000]\ttraining's rmse: 1.47454\tvalid_1's rmse: 1.56749\n",
      "[2100]\ttraining's rmse: 1.47128\tvalid_1's rmse: 1.56744\n",
      "[2200]\ttraining's rmse: 1.46789\tvalid_1's rmse: 1.56748\n",
      "[2300]\ttraining's rmse: 1.4647\tvalid_1's rmse: 1.56736\n",
      "[2400]\ttraining's rmse: 1.46142\tvalid_1's rmse: 1.56732\n",
      "[2500]\ttraining's rmse: 1.45823\tvalid_1's rmse: 1.56733\n",
      "[2600]\ttraining's rmse: 1.45518\tvalid_1's rmse: 1.56736\n",
      "[2700]\ttraining's rmse: 1.45214\tvalid_1's rmse: 1.56736\n",
      "[2800]\ttraining's rmse: 1.44903\tvalid_1's rmse: 1.56738\n",
      "[2900]\ttraining's rmse: 1.44596\tvalid_1's rmse: 1.56748\n",
      "[3000]\ttraining's rmse: 1.44289\tvalid_1's rmse: 1.56747\n",
      "Early stopping, best iteration is:\n",
      "[2458]\ttraining's rmse: 1.45964\tvalid_1's rmse: 1.56729\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60484\tvalid_1's rmse: 1.59389\n",
      "[200]\ttraining's rmse: 1.57167\tvalid_1's rmse: 1.56633\n",
      "[300]\ttraining's rmse: 1.55613\tvalid_1's rmse: 1.55598\n",
      "[400]\ttraining's rmse: 1.54644\tvalid_1's rmse: 1.55116\n",
      "[500]\ttraining's rmse: 1.5392\tvalid_1's rmse: 1.54884\n",
      "[600]\ttraining's rmse: 1.53323\tvalid_1's rmse: 1.54767\n",
      "[700]\ttraining's rmse: 1.52806\tvalid_1's rmse: 1.54696\n",
      "[800]\ttraining's rmse: 1.52349\tvalid_1's rmse: 1.54655\n",
      "[900]\ttraining's rmse: 1.51919\tvalid_1's rmse: 1.54621\n",
      "[1000]\ttraining's rmse: 1.51517\tvalid_1's rmse: 1.54598\n",
      "[1100]\ttraining's rmse: 1.51123\tvalid_1's rmse: 1.54587\n",
      "[1200]\ttraining's rmse: 1.50747\tvalid_1's rmse: 1.54588\n",
      "[1300]\ttraining's rmse: 1.50375\tvalid_1's rmse: 1.54586\n",
      "[1400]\ttraining's rmse: 1.50022\tvalid_1's rmse: 1.54583\n",
      "[1500]\ttraining's rmse: 1.49668\tvalid_1's rmse: 1.5458\n",
      "[1600]\ttraining's rmse: 1.49321\tvalid_1's rmse: 1.54578\n",
      "[1700]\ttraining's rmse: 1.48979\tvalid_1's rmse: 1.54575\n",
      "[1800]\ttraining's rmse: 1.48638\tvalid_1's rmse: 1.54577\n",
      "[1900]\ttraining's rmse: 1.48304\tvalid_1's rmse: 1.5457\n",
      "[2000]\ttraining's rmse: 1.47969\tvalid_1's rmse: 1.54571\n",
      "[2100]\ttraining's rmse: 1.47638\tvalid_1's rmse: 1.54572\n",
      "[2200]\ttraining's rmse: 1.47305\tvalid_1's rmse: 1.54581\n",
      "[2300]\ttraining's rmse: 1.46972\tvalid_1's rmse: 1.54578\n",
      "[2400]\ttraining's rmse: 1.46662\tvalid_1's rmse: 1.54575\n",
      "[2500]\ttraining's rmse: 1.4635\tvalid_1's rmse: 1.54577\n",
      "[2600]\ttraining's rmse: 1.46029\tvalid_1's rmse: 1.54575\n",
      "[2700]\ttraining's rmse: 1.45727\tvalid_1's rmse: 1.54588\n",
      "[2800]\ttraining's rmse: 1.45422\tvalid_1's rmse: 1.54594\n",
      "[2900]\ttraining's rmse: 1.4512\tvalid_1's rmse: 1.54592\n",
      "Early stopping, best iteration is:\n",
      "[2329]\ttraining's rmse: 1.46878\tvalid_1's rmse: 1.54568\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60214\tvalid_1's rmse: 1.60741\n",
      "[200]\ttraining's rmse: 1.5693\tvalid_1's rmse: 1.57758\n",
      "[300]\ttraining's rmse: 1.55427\tvalid_1's rmse: 1.56587\n",
      "[400]\ttraining's rmse: 1.54476\tvalid_1's rmse: 1.56015\n",
      "[500]\ttraining's rmse: 1.53771\tvalid_1's rmse: 1.55682\n",
      "[600]\ttraining's rmse: 1.53193\tvalid_1's rmse: 1.55511\n",
      "[700]\ttraining's rmse: 1.52687\tvalid_1's rmse: 1.55403\n",
      "[800]\ttraining's rmse: 1.52236\tvalid_1's rmse: 1.55328\n",
      "[900]\ttraining's rmse: 1.5181\tvalid_1's rmse: 1.55279\n",
      "[1000]\ttraining's rmse: 1.51417\tvalid_1's rmse: 1.55247\n",
      "[1100]\ttraining's rmse: 1.51036\tvalid_1's rmse: 1.55228\n",
      "[1200]\ttraining's rmse: 1.50666\tvalid_1's rmse: 1.55223\n",
      "[1300]\ttraining's rmse: 1.50296\tvalid_1's rmse: 1.55206\n",
      "[1400]\ttraining's rmse: 1.49941\tvalid_1's rmse: 1.55192\n",
      "[1500]\ttraining's rmse: 1.49597\tvalid_1's rmse: 1.55182\n",
      "[1600]\ttraining's rmse: 1.49249\tvalid_1's rmse: 1.55181\n",
      "[1700]\ttraining's rmse: 1.48911\tvalid_1's rmse: 1.55167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800]\ttraining's rmse: 1.48573\tvalid_1's rmse: 1.55162\n",
      "[1900]\ttraining's rmse: 1.4825\tvalid_1's rmse: 1.5516\n",
      "[2000]\ttraining's rmse: 1.47905\tvalid_1's rmse: 1.5516\n",
      "[2100]\ttraining's rmse: 1.47573\tvalid_1's rmse: 1.5516\n",
      "[2200]\ttraining's rmse: 1.4724\tvalid_1's rmse: 1.55162\n",
      "[2300]\ttraining's rmse: 1.46915\tvalid_1's rmse: 1.55151\n",
      "[2400]\ttraining's rmse: 1.46589\tvalid_1's rmse: 1.55152\n",
      "[2500]\ttraining's rmse: 1.46254\tvalid_1's rmse: 1.55146\n",
      "[2600]\ttraining's rmse: 1.45938\tvalid_1's rmse: 1.55153\n",
      "[2700]\ttraining's rmse: 1.4563\tvalid_1's rmse: 1.55155\n",
      "[2800]\ttraining's rmse: 1.45308\tvalid_1's rmse: 1.55155\n",
      "[2900]\ttraining's rmse: 1.45013\tvalid_1's rmse: 1.55162\n",
      "[3000]\ttraining's rmse: 1.44704\tvalid_1's rmse: 1.55161\n",
      "[3100]\ttraining's rmse: 1.444\tvalid_1's rmse: 1.55162\n",
      "Early stopping, best iteration is:\n",
      "[2526]\ttraining's rmse: 1.46172\tvalid_1's rmse: 1.55143\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59979\tvalid_1's rmse: 1.61345\n",
      "[200]\ttraining's rmse: 1.56665\tvalid_1's rmse: 1.58664\n",
      "[300]\ttraining's rmse: 1.55127\tvalid_1's rmse: 1.57679\n",
      "[400]\ttraining's rmse: 1.54178\tvalid_1's rmse: 1.57207\n",
      "[500]\ttraining's rmse: 1.53457\tvalid_1's rmse: 1.56953\n",
      "[600]\ttraining's rmse: 1.52877\tvalid_1's rmse: 1.56797\n",
      "[700]\ttraining's rmse: 1.52366\tvalid_1's rmse: 1.56703\n",
      "[800]\ttraining's rmse: 1.51915\tvalid_1's rmse: 1.56645\n",
      "[900]\ttraining's rmse: 1.51497\tvalid_1's rmse: 1.56609\n",
      "[1000]\ttraining's rmse: 1.51101\tvalid_1's rmse: 1.56579\n",
      "[1100]\ttraining's rmse: 1.50711\tvalid_1's rmse: 1.56552\n",
      "[1200]\ttraining's rmse: 1.50332\tvalid_1's rmse: 1.56548\n",
      "[1300]\ttraining's rmse: 1.4997\tvalid_1's rmse: 1.56538\n",
      "[1400]\ttraining's rmse: 1.49622\tvalid_1's rmse: 1.56536\n",
      "[1500]\ttraining's rmse: 1.49273\tvalid_1's rmse: 1.56526\n",
      "[1600]\ttraining's rmse: 1.48924\tvalid_1's rmse: 1.56527\n",
      "[1700]\ttraining's rmse: 1.48593\tvalid_1's rmse: 1.5653\n",
      "[1800]\ttraining's rmse: 1.48246\tvalid_1's rmse: 1.56535\n",
      "[1900]\ttraining's rmse: 1.4791\tvalid_1's rmse: 1.56531\n",
      "[2000]\ttraining's rmse: 1.47588\tvalid_1's rmse: 1.56535\n",
      "[2100]\ttraining's rmse: 1.47266\tvalid_1's rmse: 1.56541\n",
      "Early stopping, best iteration is:\n",
      "[1555]\ttraining's rmse: 1.49082\tvalid_1's rmse: 1.56523\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60899\tvalid_1's rmse: 1.5935\n",
      "[200]\ttraining's rmse: 1.5757\tvalid_1's rmse: 1.56638\n",
      "[300]\ttraining's rmse: 1.55924\tvalid_1's rmse: 1.55605\n",
      "[400]\ttraining's rmse: 1.54769\tvalid_1's rmse: 1.55062\n",
      "[500]\ttraining's rmse: 1.53849\tvalid_1's rmse: 1.54754\n",
      "[600]\ttraining's rmse: 1.53047\tvalid_1's rmse: 1.54549\n",
      "[700]\ttraining's rmse: 1.52337\tvalid_1's rmse: 1.54405\n",
      "[800]\ttraining's rmse: 1.51702\tvalid_1's rmse: 1.54322\n",
      "[900]\ttraining's rmse: 1.51109\tvalid_1's rmse: 1.5427\n",
      "[1000]\ttraining's rmse: 1.50564\tvalid_1's rmse: 1.54226\n",
      "[1100]\ttraining's rmse: 1.50008\tvalid_1's rmse: 1.5419\n",
      "[1200]\ttraining's rmse: 1.49477\tvalid_1's rmse: 1.54157\n",
      "[1300]\ttraining's rmse: 1.48968\tvalid_1's rmse: 1.54142\n",
      "[1400]\ttraining's rmse: 1.48468\tvalid_1's rmse: 1.54126\n",
      "[1500]\ttraining's rmse: 1.47973\tvalid_1's rmse: 1.54103\n",
      "[1600]\ttraining's rmse: 1.47487\tvalid_1's rmse: 1.5408\n",
      "[1700]\ttraining's rmse: 1.47025\tvalid_1's rmse: 1.54069\n",
      "[1800]\ttraining's rmse: 1.46555\tvalid_1's rmse: 1.54054\n",
      "[1900]\ttraining's rmse: 1.46088\tvalid_1's rmse: 1.54052\n",
      "[2000]\ttraining's rmse: 1.4563\tvalid_1's rmse: 1.54042\n",
      "[2100]\ttraining's rmse: 1.45189\tvalid_1's rmse: 1.54027\n",
      "[2200]\ttraining's rmse: 1.44749\tvalid_1's rmse: 1.54021\n",
      "[2300]\ttraining's rmse: 1.4432\tvalid_1's rmse: 1.54012\n",
      "[2400]\ttraining's rmse: 1.4389\tvalid_1's rmse: 1.5401\n",
      "[2500]\ttraining's rmse: 1.4346\tvalid_1's rmse: 1.54007\n",
      "[2600]\ttraining's rmse: 1.43039\tvalid_1's rmse: 1.53999\n",
      "[2700]\ttraining's rmse: 1.42615\tvalid_1's rmse: 1.53999\n",
      "[2800]\ttraining's rmse: 1.42189\tvalid_1's rmse: 1.54007\n",
      "[2900]\ttraining's rmse: 1.41784\tvalid_1's rmse: 1.54007\n",
      "[3000]\ttraining's rmse: 1.41398\tvalid_1's rmse: 1.54019\n",
      "[3100]\ttraining's rmse: 1.4099\tvalid_1's rmse: 1.54021\n",
      "[3200]\ttraining's rmse: 1.40586\tvalid_1's rmse: 1.54021\n",
      "[3300]\ttraining's rmse: 1.40204\tvalid_1's rmse: 1.5402\n",
      "Early stopping, best iteration is:\n",
      "[2740]\ttraining's rmse: 1.42447\tvalid_1's rmse: 1.53994\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60065\tvalid_1's rmse: 1.63745\n",
      "[200]\ttraining's rmse: 1.56757\tvalid_1's rmse: 1.60926\n",
      "[300]\ttraining's rmse: 1.55123\tvalid_1's rmse: 1.59791\n",
      "[400]\ttraining's rmse: 1.53977\tvalid_1's rmse: 1.59188\n",
      "[500]\ttraining's rmse: 1.53045\tvalid_1's rmse: 1.58834\n",
      "[600]\ttraining's rmse: 1.52244\tvalid_1's rmse: 1.58606\n",
      "[700]\ttraining's rmse: 1.51525\tvalid_1's rmse: 1.5847\n",
      "[800]\ttraining's rmse: 1.50878\tvalid_1's rmse: 1.58383\n",
      "[900]\ttraining's rmse: 1.50277\tvalid_1's rmse: 1.58318\n",
      "[1000]\ttraining's rmse: 1.49717\tvalid_1's rmse: 1.58265\n",
      "[1100]\ttraining's rmse: 1.49185\tvalid_1's rmse: 1.58232\n",
      "[1200]\ttraining's rmse: 1.48666\tvalid_1's rmse: 1.58202\n",
      "[1300]\ttraining's rmse: 1.48155\tvalid_1's rmse: 1.58192\n",
      "[1400]\ttraining's rmse: 1.47665\tvalid_1's rmse: 1.58172\n",
      "[1500]\ttraining's rmse: 1.47175\tvalid_1's rmse: 1.58154\n",
      "[1600]\ttraining's rmse: 1.46711\tvalid_1's rmse: 1.58146\n",
      "[1700]\ttraining's rmse: 1.46254\tvalid_1's rmse: 1.5813\n",
      "[1800]\ttraining's rmse: 1.45795\tvalid_1's rmse: 1.58126\n",
      "[1900]\ttraining's rmse: 1.4533\tvalid_1's rmse: 1.58114\n",
      "[2000]\ttraining's rmse: 1.44883\tvalid_1's rmse: 1.5812\n",
      "[2100]\ttraining's rmse: 1.44436\tvalid_1's rmse: 1.58106\n",
      "[2200]\ttraining's rmse: 1.44004\tvalid_1's rmse: 1.58099\n",
      "[2300]\ttraining's rmse: 1.43561\tvalid_1's rmse: 1.58103\n",
      "[2400]\ttraining's rmse: 1.43132\tvalid_1's rmse: 1.58106\n",
      "[2500]\ttraining's rmse: 1.42699\tvalid_1's rmse: 1.58103\n",
      "[2600]\ttraining's rmse: 1.4228\tvalid_1's rmse: 1.58107\n",
      "[2700]\ttraining's rmse: 1.41877\tvalid_1's rmse: 1.58101\n",
      "[2800]\ttraining's rmse: 1.41465\tvalid_1's rmse: 1.58103\n",
      "Early stopping, best iteration is:\n",
      "[2232]\ttraining's rmse: 1.43862\tvalid_1's rmse: 1.58094\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60726\tvalid_1's rmse: 1.60191\n",
      "[200]\ttraining's rmse: 1.57418\tvalid_1's rmse: 1.5749\n",
      "[300]\ttraining's rmse: 1.55761\tvalid_1's rmse: 1.56434\n",
      "[400]\ttraining's rmse: 1.54618\tvalid_1's rmse: 1.55881\n",
      "[500]\ttraining's rmse: 1.53688\tvalid_1's rmse: 1.55549\n",
      "[600]\ttraining's rmse: 1.52885\tvalid_1's rmse: 1.55335\n",
      "[700]\ttraining's rmse: 1.52176\tvalid_1's rmse: 1.55206\n",
      "[800]\ttraining's rmse: 1.5153\tvalid_1's rmse: 1.55118\n",
      "[900]\ttraining's rmse: 1.50934\tvalid_1's rmse: 1.55057\n",
      "[1000]\ttraining's rmse: 1.50384\tvalid_1's rmse: 1.55024\n",
      "[1100]\ttraining's rmse: 1.49853\tvalid_1's rmse: 1.54997\n",
      "[1200]\ttraining's rmse: 1.49326\tvalid_1's rmse: 1.54978\n",
      "[1300]\ttraining's rmse: 1.48829\tvalid_1's rmse: 1.54963\n",
      "[1400]\ttraining's rmse: 1.48334\tvalid_1's rmse: 1.54946\n",
      "[1500]\ttraining's rmse: 1.47866\tvalid_1's rmse: 1.54942\n",
      "[1600]\ttraining's rmse: 1.47393\tvalid_1's rmse: 1.54931\n",
      "[1700]\ttraining's rmse: 1.46931\tvalid_1's rmse: 1.54919\n",
      "[1800]\ttraining's rmse: 1.46481\tvalid_1's rmse: 1.54904\n",
      "[1900]\ttraining's rmse: 1.46037\tvalid_1's rmse: 1.54896\n",
      "[2000]\ttraining's rmse: 1.45603\tvalid_1's rmse: 1.54896\n",
      "[2100]\ttraining's rmse: 1.45164\tvalid_1's rmse: 1.54897\n",
      "[2200]\ttraining's rmse: 1.44719\tvalid_1's rmse: 1.54898\n",
      "[2300]\ttraining's rmse: 1.44291\tvalid_1's rmse: 1.54898\n",
      "[2400]\ttraining's rmse: 1.43844\tvalid_1's rmse: 1.54898\n",
      "[2500]\ttraining's rmse: 1.43422\tvalid_1's rmse: 1.54902\n",
      "[2600]\ttraining's rmse: 1.43004\tvalid_1's rmse: 1.54901\n",
      "Early stopping, best iteration is:\n",
      "[2017]\ttraining's rmse: 1.45524\tvalid_1's rmse: 1.54886\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60896\tvalid_1's rmse: 1.5933\n",
      "[200]\ttraining's rmse: 1.57567\tvalid_1's rmse: 1.56726\n",
      "[300]\ttraining's rmse: 1.55907\tvalid_1's rmse: 1.55727\n",
      "[400]\ttraining's rmse: 1.54751\tvalid_1's rmse: 1.55223\n",
      "[500]\ttraining's rmse: 1.53832\tvalid_1's rmse: 1.54943\n",
      "[600]\ttraining's rmse: 1.5303\tvalid_1's rmse: 1.5478\n",
      "[700]\ttraining's rmse: 1.52308\tvalid_1's rmse: 1.54667\n",
      "[800]\ttraining's rmse: 1.51663\tvalid_1's rmse: 1.54614\n",
      "[900]\ttraining's rmse: 1.51062\tvalid_1's rmse: 1.54554\n",
      "[1000]\ttraining's rmse: 1.50494\tvalid_1's rmse: 1.54519\n",
      "[1100]\ttraining's rmse: 1.49955\tvalid_1's rmse: 1.54507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 1.49437\tvalid_1's rmse: 1.54483\n",
      "[1300]\ttraining's rmse: 1.48927\tvalid_1's rmse: 1.54457\n",
      "[1400]\ttraining's rmse: 1.48429\tvalid_1's rmse: 1.54444\n",
      "[1500]\ttraining's rmse: 1.47943\tvalid_1's rmse: 1.54443\n",
      "[1600]\ttraining's rmse: 1.47464\tvalid_1's rmse: 1.54436\n",
      "[1700]\ttraining's rmse: 1.47012\tvalid_1's rmse: 1.54428\n",
      "[1800]\ttraining's rmse: 1.46543\tvalid_1's rmse: 1.54413\n",
      "[1900]\ttraining's rmse: 1.46093\tvalid_1's rmse: 1.54425\n",
      "[2000]\ttraining's rmse: 1.45628\tvalid_1's rmse: 1.54422\n",
      "[2100]\ttraining's rmse: 1.45191\tvalid_1's rmse: 1.54412\n",
      "[2200]\ttraining's rmse: 1.4475\tvalid_1's rmse: 1.54409\n",
      "[2300]\ttraining's rmse: 1.44313\tvalid_1's rmse: 1.54408\n",
      "[2400]\ttraining's rmse: 1.43891\tvalid_1's rmse: 1.54404\n",
      "[2500]\ttraining's rmse: 1.43466\tvalid_1's rmse: 1.54402\n",
      "[2600]\ttraining's rmse: 1.43043\tvalid_1's rmse: 1.54404\n",
      "[2700]\ttraining's rmse: 1.42629\tvalid_1's rmse: 1.5441\n",
      "[2800]\ttraining's rmse: 1.4222\tvalid_1's rmse: 1.54406\n",
      "[2900]\ttraining's rmse: 1.41805\tvalid_1's rmse: 1.54411\n",
      "[3000]\ttraining's rmse: 1.4139\tvalid_1's rmse: 1.54413\n",
      "Early stopping, best iteration is:\n",
      "[2461]\ttraining's rmse: 1.43638\tvalid_1's rmse: 1.54397\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60211\tvalid_1's rmse: 1.62905\n",
      "[200]\ttraining's rmse: 1.56912\tvalid_1's rmse: 1.60056\n",
      "[300]\ttraining's rmse: 1.55292\tvalid_1's rmse: 1.58926\n",
      "[400]\ttraining's rmse: 1.54164\tvalid_1's rmse: 1.58299\n",
      "[500]\ttraining's rmse: 1.53252\tvalid_1's rmse: 1.57922\n",
      "[600]\ttraining's rmse: 1.52469\tvalid_1's rmse: 1.57697\n",
      "[700]\ttraining's rmse: 1.51762\tvalid_1's rmse: 1.5755\n",
      "[800]\ttraining's rmse: 1.51119\tvalid_1's rmse: 1.57437\n",
      "[900]\ttraining's rmse: 1.50535\tvalid_1's rmse: 1.57363\n",
      "[1000]\ttraining's rmse: 1.4998\tvalid_1's rmse: 1.57318\n",
      "[1100]\ttraining's rmse: 1.49456\tvalid_1's rmse: 1.57275\n",
      "[1200]\ttraining's rmse: 1.48934\tvalid_1's rmse: 1.57247\n",
      "[1300]\ttraining's rmse: 1.48438\tvalid_1's rmse: 1.57217\n",
      "[1400]\ttraining's rmse: 1.47934\tvalid_1's rmse: 1.57201\n",
      "[1500]\ttraining's rmse: 1.47457\tvalid_1's rmse: 1.57187\n",
      "[1600]\ttraining's rmse: 1.4698\tvalid_1's rmse: 1.57173\n",
      "[1700]\ttraining's rmse: 1.46506\tvalid_1's rmse: 1.57162\n",
      "[1800]\ttraining's rmse: 1.46044\tvalid_1's rmse: 1.57151\n",
      "[1900]\ttraining's rmse: 1.4559\tvalid_1's rmse: 1.57137\n",
      "[2000]\ttraining's rmse: 1.4516\tvalid_1's rmse: 1.57129\n",
      "[2100]\ttraining's rmse: 1.44716\tvalid_1's rmse: 1.57128\n",
      "[2200]\ttraining's rmse: 1.44285\tvalid_1's rmse: 1.57115\n",
      "[2300]\ttraining's rmse: 1.43844\tvalid_1's rmse: 1.57109\n",
      "[2400]\ttraining's rmse: 1.4342\tvalid_1's rmse: 1.57112\n",
      "[2500]\ttraining's rmse: 1.43002\tvalid_1's rmse: 1.57116\n",
      "[2600]\ttraining's rmse: 1.42592\tvalid_1's rmse: 1.57117\n",
      "[2700]\ttraining's rmse: 1.42169\tvalid_1's rmse: 1.5712\n",
      "[2800]\ttraining's rmse: 1.41754\tvalid_1's rmse: 1.57123\n",
      "[2900]\ttraining's rmse: 1.41342\tvalid_1's rmse: 1.57131\n",
      "Early stopping, best iteration is:\n",
      "[2327]\ttraining's rmse: 1.4373\tvalid_1's rmse: 1.57107\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60529\tvalid_1's rmse: 1.61208\n",
      "[200]\ttraining's rmse: 1.57202\tvalid_1's rmse: 1.58503\n",
      "[300]\ttraining's rmse: 1.55558\tvalid_1's rmse: 1.5752\n",
      "[400]\ttraining's rmse: 1.54419\tvalid_1's rmse: 1.57017\n",
      "[500]\ttraining's rmse: 1.5349\tvalid_1's rmse: 1.56714\n",
      "[600]\ttraining's rmse: 1.52699\tvalid_1's rmse: 1.5653\n",
      "[700]\ttraining's rmse: 1.5198\tvalid_1's rmse: 1.56418\n",
      "[800]\ttraining's rmse: 1.51333\tvalid_1's rmse: 1.56354\n",
      "[900]\ttraining's rmse: 1.50733\tvalid_1's rmse: 1.56312\n",
      "[1000]\ttraining's rmse: 1.50159\tvalid_1's rmse: 1.5628\n",
      "[1100]\ttraining's rmse: 1.49608\tvalid_1's rmse: 1.5626\n",
      "[1200]\ttraining's rmse: 1.4908\tvalid_1's rmse: 1.56243\n",
      "[1300]\ttraining's rmse: 1.48588\tvalid_1's rmse: 1.56239\n",
      "[1400]\ttraining's rmse: 1.48089\tvalid_1's rmse: 1.56235\n",
      "[1500]\ttraining's rmse: 1.47594\tvalid_1's rmse: 1.56221\n",
      "[1600]\ttraining's rmse: 1.47113\tvalid_1's rmse: 1.56218\n",
      "[1700]\ttraining's rmse: 1.46643\tvalid_1's rmse: 1.56228\n",
      "[1800]\ttraining's rmse: 1.4618\tvalid_1's rmse: 1.56225\n",
      "[1900]\ttraining's rmse: 1.45736\tvalid_1's rmse: 1.56233\n",
      "[2000]\ttraining's rmse: 1.4529\tvalid_1's rmse: 1.56227\n",
      "[2100]\ttraining's rmse: 1.44837\tvalid_1's rmse: 1.56234\n",
      "Early stopping, best iteration is:\n",
      "[1581]\ttraining's rmse: 1.472\tvalid_1's rmse: 1.56216\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60555\tvalid_1's rmse: 1.58839\n",
      "[200]\ttraining's rmse: 1.57222\tvalid_1's rmse: 1.56048\n",
      "[300]\ttraining's rmse: 1.55662\tvalid_1's rmse: 1.55016\n",
      "[400]\ttraining's rmse: 1.54652\tvalid_1's rmse: 1.54486\n",
      "[500]\ttraining's rmse: 1.53903\tvalid_1's rmse: 1.54223\n",
      "[600]\ttraining's rmse: 1.53273\tvalid_1's rmse: 1.54066\n",
      "[700]\ttraining's rmse: 1.52732\tvalid_1's rmse: 1.53973\n",
      "[800]\ttraining's rmse: 1.52253\tvalid_1's rmse: 1.53919\n",
      "[900]\ttraining's rmse: 1.51804\tvalid_1's rmse: 1.53871\n",
      "[1000]\ttraining's rmse: 1.5138\tvalid_1's rmse: 1.53851\n",
      "[1100]\ttraining's rmse: 1.50973\tvalid_1's rmse: 1.53824\n",
      "[1200]\ttraining's rmse: 1.50584\tvalid_1's rmse: 1.53804\n",
      "[1300]\ttraining's rmse: 1.50197\tvalid_1's rmse: 1.53795\n",
      "[1400]\ttraining's rmse: 1.49826\tvalid_1's rmse: 1.53782\n",
      "[1500]\ttraining's rmse: 1.49436\tvalid_1's rmse: 1.53777\n",
      "[1600]\ttraining's rmse: 1.49067\tvalid_1's rmse: 1.53765\n",
      "[1700]\ttraining's rmse: 1.48702\tvalid_1's rmse: 1.53765\n",
      "[1800]\ttraining's rmse: 1.48353\tvalid_1's rmse: 1.53754\n",
      "[1900]\ttraining's rmse: 1.48005\tvalid_1's rmse: 1.53749\n",
      "[2000]\ttraining's rmse: 1.47658\tvalid_1's rmse: 1.53758\n",
      "[2100]\ttraining's rmse: 1.47314\tvalid_1's rmse: 1.53765\n",
      "[2200]\ttraining's rmse: 1.46966\tvalid_1's rmse: 1.53769\n",
      "[2300]\ttraining's rmse: 1.46633\tvalid_1's rmse: 1.5377\n",
      "[2400]\ttraining's rmse: 1.46293\tvalid_1's rmse: 1.53785\n",
      "Early stopping, best iteration is:\n",
      "[1840]\ttraining's rmse: 1.4821\tvalid_1's rmse: 1.53743\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59678\tvalid_1's rmse: 1.63378\n",
      "[200]\ttraining's rmse: 1.56393\tvalid_1's rmse: 1.60489\n",
      "[300]\ttraining's rmse: 1.54852\tvalid_1's rmse: 1.59365\n",
      "[400]\ttraining's rmse: 1.53843\tvalid_1's rmse: 1.58798\n",
      "[500]\ttraining's rmse: 1.531\tvalid_1's rmse: 1.58475\n",
      "[600]\ttraining's rmse: 1.52474\tvalid_1's rmse: 1.58269\n",
      "[700]\ttraining's rmse: 1.5193\tvalid_1's rmse: 1.58152\n",
      "[800]\ttraining's rmse: 1.51443\tvalid_1's rmse: 1.58073\n",
      "[900]\ttraining's rmse: 1.5098\tvalid_1's rmse: 1.58006\n",
      "[1000]\ttraining's rmse: 1.50554\tvalid_1's rmse: 1.57976\n",
      "[1100]\ttraining's rmse: 1.50154\tvalid_1's rmse: 1.57953\n",
      "[1200]\ttraining's rmse: 1.49755\tvalid_1's rmse: 1.5792\n",
      "[1300]\ttraining's rmse: 1.49387\tvalid_1's rmse: 1.57894\n",
      "[1400]\ttraining's rmse: 1.49007\tvalid_1's rmse: 1.57876\n",
      "[1500]\ttraining's rmse: 1.48641\tvalid_1's rmse: 1.57862\n",
      "[1600]\ttraining's rmse: 1.48276\tvalid_1's rmse: 1.57839\n",
      "[1700]\ttraining's rmse: 1.47924\tvalid_1's rmse: 1.57816\n",
      "[1800]\ttraining's rmse: 1.47571\tvalid_1's rmse: 1.57809\n",
      "[1900]\ttraining's rmse: 1.4722\tvalid_1's rmse: 1.57796\n",
      "[2000]\ttraining's rmse: 1.46884\tvalid_1's rmse: 1.57787\n",
      "[2100]\ttraining's rmse: 1.46538\tvalid_1's rmse: 1.57778\n",
      "[2200]\ttraining's rmse: 1.46193\tvalid_1's rmse: 1.57774\n",
      "[2300]\ttraining's rmse: 1.45849\tvalid_1's rmse: 1.57764\n",
      "[2400]\ttraining's rmse: 1.45525\tvalid_1's rmse: 1.57771\n",
      "[2500]\ttraining's rmse: 1.45199\tvalid_1's rmse: 1.57772\n",
      "[2600]\ttraining's rmse: 1.44883\tvalid_1's rmse: 1.57763\n",
      "[2700]\ttraining's rmse: 1.4457\tvalid_1's rmse: 1.57766\n",
      "[2800]\ttraining's rmse: 1.4425\tvalid_1's rmse: 1.5777\n",
      "[2900]\ttraining's rmse: 1.43927\tvalid_1's rmse: 1.57772\n",
      "[3000]\ttraining's rmse: 1.43602\tvalid_1's rmse: 1.5777\n",
      "[3100]\ttraining's rmse: 1.4328\tvalid_1's rmse: 1.57772\n",
      "[3200]\ttraining's rmse: 1.42969\tvalid_1's rmse: 1.57784\n",
      "Early stopping, best iteration is:\n",
      "[2651]\ttraining's rmse: 1.44718\tvalid_1's rmse: 1.57758\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60345\tvalid_1's rmse: 1.598\n",
      "[200]\ttraining's rmse: 1.57028\tvalid_1's rmse: 1.56986\n",
      "[300]\ttraining's rmse: 1.55484\tvalid_1's rmse: 1.55929\n",
      "[400]\ttraining's rmse: 1.54479\tvalid_1's rmse: 1.55399\n",
      "[500]\ttraining's rmse: 1.53718\tvalid_1's rmse: 1.551\n",
      "[600]\ttraining's rmse: 1.53088\tvalid_1's rmse: 1.54916\n",
      "[700]\ttraining's rmse: 1.52553\tvalid_1's rmse: 1.54813\n",
      "[800]\ttraining's rmse: 1.52068\tvalid_1's rmse: 1.54748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttraining's rmse: 1.51604\tvalid_1's rmse: 1.54705\n",
      "[1000]\ttraining's rmse: 1.51172\tvalid_1's rmse: 1.54666\n",
      "[1100]\ttraining's rmse: 1.50767\tvalid_1's rmse: 1.54645\n",
      "[1200]\ttraining's rmse: 1.50364\tvalid_1's rmse: 1.54616\n",
      "[1300]\ttraining's rmse: 1.49972\tvalid_1's rmse: 1.54604\n",
      "[1400]\ttraining's rmse: 1.4959\tvalid_1's rmse: 1.5459\n",
      "[1500]\ttraining's rmse: 1.49225\tvalid_1's rmse: 1.54583\n",
      "[1600]\ttraining's rmse: 1.48863\tvalid_1's rmse: 1.54572\n",
      "[1700]\ttraining's rmse: 1.48504\tvalid_1's rmse: 1.54561\n",
      "[1800]\ttraining's rmse: 1.48154\tvalid_1's rmse: 1.54559\n",
      "[1900]\ttraining's rmse: 1.47808\tvalid_1's rmse: 1.54563\n",
      "[2000]\ttraining's rmse: 1.47469\tvalid_1's rmse: 1.54564\n",
      "[2100]\ttraining's rmse: 1.47127\tvalid_1's rmse: 1.54555\n",
      "[2200]\ttraining's rmse: 1.46792\tvalid_1's rmse: 1.54544\n",
      "[2300]\ttraining's rmse: 1.46453\tvalid_1's rmse: 1.54544\n",
      "[2400]\ttraining's rmse: 1.4613\tvalid_1's rmse: 1.54551\n",
      "[2500]\ttraining's rmse: 1.45802\tvalid_1's rmse: 1.54545\n",
      "[2600]\ttraining's rmse: 1.45482\tvalid_1's rmse: 1.54547\n",
      "[2700]\ttraining's rmse: 1.45169\tvalid_1's rmse: 1.5455\n",
      "[2800]\ttraining's rmse: 1.44854\tvalid_1's rmse: 1.54554\n",
      "[2900]\ttraining's rmse: 1.44525\tvalid_1's rmse: 1.54571\n",
      "[3000]\ttraining's rmse: 1.44211\tvalid_1's rmse: 1.54579\n",
      "[3100]\ttraining's rmse: 1.43895\tvalid_1's rmse: 1.54582\n",
      "Early stopping, best iteration is:\n",
      "[2534]\ttraining's rmse: 1.45686\tvalid_1's rmse: 1.5454\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60517\tvalid_1's rmse: 1.58896\n",
      "[200]\ttraining's rmse: 1.57193\tvalid_1's rmse: 1.56165\n",
      "[300]\ttraining's rmse: 1.55633\tvalid_1's rmse: 1.55137\n",
      "[400]\ttraining's rmse: 1.54623\tvalid_1's rmse: 1.54647\n",
      "[500]\ttraining's rmse: 1.53865\tvalid_1's rmse: 1.54386\n",
      "[600]\ttraining's rmse: 1.53238\tvalid_1's rmse: 1.54233\n",
      "[700]\ttraining's rmse: 1.52694\tvalid_1's rmse: 1.54148\n",
      "[800]\ttraining's rmse: 1.52199\tvalid_1's rmse: 1.54093\n",
      "[900]\ttraining's rmse: 1.51737\tvalid_1's rmse: 1.54058\n",
      "[1000]\ttraining's rmse: 1.51302\tvalid_1's rmse: 1.54043\n",
      "[1100]\ttraining's rmse: 1.5089\tvalid_1's rmse: 1.54028\n",
      "[1200]\ttraining's rmse: 1.50488\tvalid_1's rmse: 1.54003\n",
      "[1300]\ttraining's rmse: 1.50096\tvalid_1's rmse: 1.53992\n",
      "[1400]\ttraining's rmse: 1.49709\tvalid_1's rmse: 1.53989\n",
      "[1500]\ttraining's rmse: 1.49334\tvalid_1's rmse: 1.53997\n",
      "[1600]\ttraining's rmse: 1.48971\tvalid_1's rmse: 1.53991\n",
      "[1700]\ttraining's rmse: 1.48607\tvalid_1's rmse: 1.53992\n",
      "[1800]\ttraining's rmse: 1.48251\tvalid_1's rmse: 1.53995\n",
      "[1900]\ttraining's rmse: 1.4789\tvalid_1's rmse: 1.53996\n",
      "[2000]\ttraining's rmse: 1.47546\tvalid_1's rmse: 1.53995\n",
      "[2100]\ttraining's rmse: 1.472\tvalid_1's rmse: 1.53994\n",
      "[2200]\ttraining's rmse: 1.46861\tvalid_1's rmse: 1.54008\n",
      "Early stopping, best iteration is:\n",
      "[1655]\ttraining's rmse: 1.48762\tvalid_1's rmse: 1.53985\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59858\tvalid_1's rmse: 1.62452\n",
      "[200]\ttraining's rmse: 1.5655\tvalid_1's rmse: 1.59546\n",
      "[300]\ttraining's rmse: 1.55022\tvalid_1's rmse: 1.58411\n",
      "[400]\ttraining's rmse: 1.54033\tvalid_1's rmse: 1.57831\n",
      "[500]\ttraining's rmse: 1.53284\tvalid_1's rmse: 1.57493\n",
      "[600]\ttraining's rmse: 1.5267\tvalid_1's rmse: 1.5729\n",
      "[700]\ttraining's rmse: 1.5213\tvalid_1's rmse: 1.57159\n",
      "[800]\ttraining's rmse: 1.51648\tvalid_1's rmse: 1.57076\n",
      "[900]\ttraining's rmse: 1.51206\tvalid_1's rmse: 1.57016\n",
      "[1000]\ttraining's rmse: 1.50793\tvalid_1's rmse: 1.56995\n",
      "[1100]\ttraining's rmse: 1.50387\tvalid_1's rmse: 1.56966\n",
      "[1200]\ttraining's rmse: 1.49989\tvalid_1's rmse: 1.56946\n",
      "[1300]\ttraining's rmse: 1.49603\tvalid_1's rmse: 1.56924\n",
      "[1400]\ttraining's rmse: 1.49225\tvalid_1's rmse: 1.56912\n",
      "[1500]\ttraining's rmse: 1.48854\tvalid_1's rmse: 1.56909\n",
      "[1600]\ttraining's rmse: 1.48494\tvalid_1's rmse: 1.56887\n",
      "[1700]\ttraining's rmse: 1.48137\tvalid_1's rmse: 1.56872\n",
      "[1800]\ttraining's rmse: 1.47785\tvalid_1's rmse: 1.56862\n",
      "[1900]\ttraining's rmse: 1.47438\tvalid_1's rmse: 1.56859\n",
      "[2000]\ttraining's rmse: 1.47089\tvalid_1's rmse: 1.5685\n",
      "[2100]\ttraining's rmse: 1.4675\tvalid_1's rmse: 1.5684\n",
      "[2200]\ttraining's rmse: 1.46421\tvalid_1's rmse: 1.56839\n",
      "[2300]\ttraining's rmse: 1.46087\tvalid_1's rmse: 1.5684\n",
      "[2400]\ttraining's rmse: 1.45765\tvalid_1's rmse: 1.56838\n",
      "[2500]\ttraining's rmse: 1.45428\tvalid_1's rmse: 1.56836\n",
      "[2600]\ttraining's rmse: 1.45109\tvalid_1's rmse: 1.56824\n",
      "[2700]\ttraining's rmse: 1.44795\tvalid_1's rmse: 1.56824\n",
      "[2800]\ttraining's rmse: 1.44486\tvalid_1's rmse: 1.56827\n",
      "[2900]\ttraining's rmse: 1.44165\tvalid_1's rmse: 1.56832\n",
      "[3000]\ttraining's rmse: 1.4385\tvalid_1's rmse: 1.56842\n",
      "[3100]\ttraining's rmse: 1.43534\tvalid_1's rmse: 1.56848\n",
      "Early stopping, best iteration is:\n",
      "[2592]\ttraining's rmse: 1.45132\tvalid_1's rmse: 1.5682\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60127\tvalid_1's rmse: 1.60934\n",
      "[200]\ttraining's rmse: 1.56801\tvalid_1's rmse: 1.58205\n",
      "[300]\ttraining's rmse: 1.55258\tvalid_1's rmse: 1.5723\n",
      "[400]\ttraining's rmse: 1.54254\tvalid_1's rmse: 1.56736\n",
      "[500]\ttraining's rmse: 1.53494\tvalid_1's rmse: 1.5646\n",
      "[600]\ttraining's rmse: 1.52872\tvalid_1's rmse: 1.56287\n",
      "[700]\ttraining's rmse: 1.52329\tvalid_1's rmse: 1.56193\n",
      "[800]\ttraining's rmse: 1.51838\tvalid_1's rmse: 1.56116\n",
      "[900]\ttraining's rmse: 1.51382\tvalid_1's rmse: 1.56059\n",
      "[1000]\ttraining's rmse: 1.50957\tvalid_1's rmse: 1.56028\n",
      "[1100]\ttraining's rmse: 1.50553\tvalid_1's rmse: 1.56006\n",
      "[1200]\ttraining's rmse: 1.50158\tvalid_1's rmse: 1.55991\n",
      "[1300]\ttraining's rmse: 1.49766\tvalid_1's rmse: 1.55992\n",
      "[1400]\ttraining's rmse: 1.49387\tvalid_1's rmse: 1.5598\n",
      "[1500]\ttraining's rmse: 1.49019\tvalid_1's rmse: 1.55968\n",
      "[1600]\ttraining's rmse: 1.48658\tvalid_1's rmse: 1.55962\n",
      "[1700]\ttraining's rmse: 1.48294\tvalid_1's rmse: 1.5596\n",
      "[1800]\ttraining's rmse: 1.47936\tvalid_1's rmse: 1.55949\n",
      "[1900]\ttraining's rmse: 1.47586\tvalid_1's rmse: 1.55943\n",
      "[2000]\ttraining's rmse: 1.47233\tvalid_1's rmse: 1.55928\n",
      "[2100]\ttraining's rmse: 1.46897\tvalid_1's rmse: 1.55923\n",
      "[2200]\ttraining's rmse: 1.46567\tvalid_1's rmse: 1.55919\n",
      "[2300]\ttraining's rmse: 1.46227\tvalid_1's rmse: 1.55916\n",
      "[2400]\ttraining's rmse: 1.45877\tvalid_1's rmse: 1.55919\n",
      "[2500]\ttraining's rmse: 1.45554\tvalid_1's rmse: 1.55917\n",
      "[2600]\ttraining's rmse: 1.45219\tvalid_1's rmse: 1.55931\n",
      "[2700]\ttraining's rmse: 1.44891\tvalid_1's rmse: 1.55948\n",
      "[2800]\ttraining's rmse: 1.44568\tvalid_1's rmse: 1.55957\n",
      "[2900]\ttraining's rmse: 1.44241\tvalid_1's rmse: 1.55964\n",
      "Early stopping, best iteration is:\n",
      "[2336]\ttraining's rmse: 1.46103\tvalid_1's rmse: 1.55913\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60569\tvalid_1's rmse: 1.58863\n",
      "[200]\ttraining's rmse: 1.57246\tvalid_1's rmse: 1.56083\n",
      "[300]\ttraining's rmse: 1.55704\tvalid_1's rmse: 1.55073\n",
      "[400]\ttraining's rmse: 1.54726\tvalid_1's rmse: 1.54572\n",
      "[500]\ttraining's rmse: 1.53998\tvalid_1's rmse: 1.54296\n",
      "[600]\ttraining's rmse: 1.53406\tvalid_1's rmse: 1.54151\n",
      "[700]\ttraining's rmse: 1.52894\tvalid_1's rmse: 1.54051\n",
      "[800]\ttraining's rmse: 1.52426\tvalid_1's rmse: 1.53982\n",
      "[900]\ttraining's rmse: 1.52012\tvalid_1's rmse: 1.53949\n",
      "[1000]\ttraining's rmse: 1.51613\tvalid_1's rmse: 1.53932\n",
      "[1100]\ttraining's rmse: 1.51228\tvalid_1's rmse: 1.53918\n",
      "[1200]\ttraining's rmse: 1.50845\tvalid_1's rmse: 1.53912\n",
      "[1300]\ttraining's rmse: 1.50479\tvalid_1's rmse: 1.53898\n",
      "[1400]\ttraining's rmse: 1.50123\tvalid_1's rmse: 1.53897\n",
      "[1500]\ttraining's rmse: 1.49759\tvalid_1's rmse: 1.53884\n",
      "[1600]\ttraining's rmse: 1.49409\tvalid_1's rmse: 1.53871\n",
      "[1700]\ttraining's rmse: 1.49056\tvalid_1's rmse: 1.53868\n",
      "[1800]\ttraining's rmse: 1.48725\tvalid_1's rmse: 1.53858\n",
      "[1900]\ttraining's rmse: 1.48395\tvalid_1's rmse: 1.53845\n",
      "[2000]\ttraining's rmse: 1.48069\tvalid_1's rmse: 1.53848\n",
      "[2100]\ttraining's rmse: 1.47744\tvalid_1's rmse: 1.53848\n",
      "[2200]\ttraining's rmse: 1.47413\tvalid_1's rmse: 1.53854\n",
      "[2300]\ttraining's rmse: 1.47097\tvalid_1's rmse: 1.53856\n",
      "[2400]\ttraining's rmse: 1.46778\tvalid_1's rmse: 1.53859\n",
      "[2500]\ttraining's rmse: 1.46452\tvalid_1's rmse: 1.53862\n",
      "Early stopping, best iteration is:\n",
      "[1923]\ttraining's rmse: 1.48327\tvalid_1's rmse: 1.5384\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59688\tvalid_1's rmse: 1.63387\n",
      "[200]\ttraining's rmse: 1.56402\tvalid_1's rmse: 1.605\n",
      "[300]\ttraining's rmse: 1.54896\tvalid_1's rmse: 1.59373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 1.53926\tvalid_1's rmse: 1.58802\n",
      "[500]\ttraining's rmse: 1.53207\tvalid_1's rmse: 1.58488\n",
      "[600]\ttraining's rmse: 1.52613\tvalid_1's rmse: 1.58291\n",
      "[700]\ttraining's rmse: 1.52088\tvalid_1's rmse: 1.58161\n",
      "[800]\ttraining's rmse: 1.51625\tvalid_1's rmse: 1.58089\n",
      "[900]\ttraining's rmse: 1.51188\tvalid_1's rmse: 1.58035\n",
      "[1000]\ttraining's rmse: 1.5078\tvalid_1's rmse: 1.58\n",
      "[1100]\ttraining's rmse: 1.50411\tvalid_1's rmse: 1.57969\n",
      "[1200]\ttraining's rmse: 1.5004\tvalid_1's rmse: 1.57947\n",
      "[1300]\ttraining's rmse: 1.49681\tvalid_1's rmse: 1.57928\n",
      "[1400]\ttraining's rmse: 1.49318\tvalid_1's rmse: 1.57911\n",
      "[1500]\ttraining's rmse: 1.4897\tvalid_1's rmse: 1.5789\n",
      "[1600]\ttraining's rmse: 1.48623\tvalid_1's rmse: 1.57884\n",
      "[1700]\ttraining's rmse: 1.48281\tvalid_1's rmse: 1.57871\n",
      "[1800]\ttraining's rmse: 1.47953\tvalid_1's rmse: 1.57866\n",
      "[1900]\ttraining's rmse: 1.47623\tvalid_1's rmse: 1.57867\n",
      "[2000]\ttraining's rmse: 1.47288\tvalid_1's rmse: 1.57861\n",
      "[2100]\ttraining's rmse: 1.46969\tvalid_1's rmse: 1.57863\n",
      "[2200]\ttraining's rmse: 1.46644\tvalid_1's rmse: 1.57862\n",
      "[2300]\ttraining's rmse: 1.46321\tvalid_1's rmse: 1.57862\n",
      "[2400]\ttraining's rmse: 1.46003\tvalid_1's rmse: 1.57855\n",
      "[2500]\ttraining's rmse: 1.45681\tvalid_1's rmse: 1.57859\n",
      "[2600]\ttraining's rmse: 1.45368\tvalid_1's rmse: 1.57853\n",
      "[2700]\ttraining's rmse: 1.45059\tvalid_1's rmse: 1.57863\n",
      "[2800]\ttraining's rmse: 1.4475\tvalid_1's rmse: 1.57865\n",
      "[2900]\ttraining's rmse: 1.44434\tvalid_1's rmse: 1.57872\n",
      "[3000]\ttraining's rmse: 1.44132\tvalid_1's rmse: 1.57887\n",
      "[3100]\ttraining's rmse: 1.43833\tvalid_1's rmse: 1.57896\n",
      "[3200]\ttraining's rmse: 1.43534\tvalid_1's rmse: 1.57908\n",
      "Early stopping, best iteration is:\n",
      "[2634]\ttraining's rmse: 1.45256\tvalid_1's rmse: 1.57848\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60345\tvalid_1's rmse: 1.59805\n",
      "[200]\ttraining's rmse: 1.57038\tvalid_1's rmse: 1.57007\n",
      "[300]\ttraining's rmse: 1.55511\tvalid_1's rmse: 1.5594\n",
      "[400]\ttraining's rmse: 1.54536\tvalid_1's rmse: 1.55399\n",
      "[500]\ttraining's rmse: 1.5381\tvalid_1's rmse: 1.551\n",
      "[600]\ttraining's rmse: 1.53209\tvalid_1's rmse: 1.5493\n",
      "[700]\ttraining's rmse: 1.52696\tvalid_1's rmse: 1.54818\n",
      "[800]\ttraining's rmse: 1.52235\tvalid_1's rmse: 1.5476\n",
      "[900]\ttraining's rmse: 1.51809\tvalid_1's rmse: 1.54723\n",
      "[1000]\ttraining's rmse: 1.51401\tvalid_1's rmse: 1.54702\n",
      "[1100]\ttraining's rmse: 1.51026\tvalid_1's rmse: 1.54685\n",
      "[1200]\ttraining's rmse: 1.5065\tvalid_1's rmse: 1.54677\n",
      "[1300]\ttraining's rmse: 1.50296\tvalid_1's rmse: 1.54661\n",
      "[1400]\ttraining's rmse: 1.4995\tvalid_1's rmse: 1.54656\n",
      "[1500]\ttraining's rmse: 1.49601\tvalid_1's rmse: 1.54648\n",
      "[1600]\ttraining's rmse: 1.49249\tvalid_1's rmse: 1.54647\n",
      "[1700]\ttraining's rmse: 1.4891\tvalid_1's rmse: 1.54638\n",
      "[1800]\ttraining's rmse: 1.48579\tvalid_1's rmse: 1.54632\n",
      "[1900]\ttraining's rmse: 1.48238\tvalid_1's rmse: 1.54629\n",
      "[2000]\ttraining's rmse: 1.47906\tvalid_1's rmse: 1.54625\n",
      "[2100]\ttraining's rmse: 1.47588\tvalid_1's rmse: 1.54627\n",
      "[2200]\ttraining's rmse: 1.47264\tvalid_1's rmse: 1.54628\n",
      "[2300]\ttraining's rmse: 1.46955\tvalid_1's rmse: 1.54629\n",
      "[2400]\ttraining's rmse: 1.46642\tvalid_1's rmse: 1.54629\n",
      "[2500]\ttraining's rmse: 1.46327\tvalid_1's rmse: 1.54628\n",
      "[2600]\ttraining's rmse: 1.46016\tvalid_1's rmse: 1.54624\n",
      "Early stopping, best iteration is:\n",
      "[2011]\ttraining's rmse: 1.4787\tvalid_1's rmse: 1.5462\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60517\tvalid_1's rmse: 1.58893\n",
      "[200]\ttraining's rmse: 1.57198\tvalid_1's rmse: 1.5617\n",
      "[300]\ttraining's rmse: 1.55667\tvalid_1's rmse: 1.5515\n",
      "[400]\ttraining's rmse: 1.54689\tvalid_1's rmse: 1.54669\n",
      "[500]\ttraining's rmse: 1.53964\tvalid_1's rmse: 1.54428\n",
      "[600]\ttraining's rmse: 1.53369\tvalid_1's rmse: 1.54303\n",
      "[700]\ttraining's rmse: 1.52847\tvalid_1's rmse: 1.54232\n",
      "[800]\ttraining's rmse: 1.52389\tvalid_1's rmse: 1.54198\n",
      "[900]\ttraining's rmse: 1.51951\tvalid_1's rmse: 1.54181\n",
      "[1000]\ttraining's rmse: 1.51544\tvalid_1's rmse: 1.54168\n",
      "[1100]\ttraining's rmse: 1.51152\tvalid_1's rmse: 1.54153\n",
      "[1200]\ttraining's rmse: 1.5078\tvalid_1's rmse: 1.54145\n",
      "[1300]\ttraining's rmse: 1.50407\tvalid_1's rmse: 1.54134\n",
      "[1400]\ttraining's rmse: 1.50044\tvalid_1's rmse: 1.54128\n",
      "[1500]\ttraining's rmse: 1.49695\tvalid_1's rmse: 1.54127\n",
      "[1600]\ttraining's rmse: 1.49338\tvalid_1's rmse: 1.54131\n",
      "[1700]\ttraining's rmse: 1.49003\tvalid_1's rmse: 1.54133\n",
      "[1800]\ttraining's rmse: 1.48657\tvalid_1's rmse: 1.54136\n",
      "[1900]\ttraining's rmse: 1.48317\tvalid_1's rmse: 1.54138\n",
      "[2000]\ttraining's rmse: 1.47988\tvalid_1's rmse: 1.5413\n",
      "Early stopping, best iteration is:\n",
      "[1430]\ttraining's rmse: 1.49943\tvalid_1's rmse: 1.54122\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59857\tvalid_1's rmse: 1.62452\n",
      "[200]\ttraining's rmse: 1.56555\tvalid_1's rmse: 1.5955\n",
      "[300]\ttraining's rmse: 1.55059\tvalid_1's rmse: 1.58422\n",
      "[400]\ttraining's rmse: 1.54088\tvalid_1's rmse: 1.57836\n",
      "[500]\ttraining's rmse: 1.53377\tvalid_1's rmse: 1.57506\n",
      "[600]\ttraining's rmse: 1.52791\tvalid_1's rmse: 1.57305\n",
      "[700]\ttraining's rmse: 1.52287\tvalid_1's rmse: 1.57191\n",
      "[800]\ttraining's rmse: 1.51835\tvalid_1's rmse: 1.57122\n",
      "[900]\ttraining's rmse: 1.51421\tvalid_1's rmse: 1.57074\n",
      "[1000]\ttraining's rmse: 1.5102\tvalid_1's rmse: 1.57046\n",
      "[1100]\ttraining's rmse: 1.50644\tvalid_1's rmse: 1.57025\n",
      "[1200]\ttraining's rmse: 1.50276\tvalid_1's rmse: 1.56999\n",
      "[1300]\ttraining's rmse: 1.49908\tvalid_1's rmse: 1.56992\n",
      "[1400]\ttraining's rmse: 1.4955\tvalid_1's rmse: 1.56972\n",
      "[1500]\ttraining's rmse: 1.49198\tvalid_1's rmse: 1.56977\n",
      "[1600]\ttraining's rmse: 1.48858\tvalid_1's rmse: 1.56958\n",
      "[1700]\ttraining's rmse: 1.48522\tvalid_1's rmse: 1.5695\n",
      "[1800]\ttraining's rmse: 1.48184\tvalid_1's rmse: 1.56945\n",
      "[1900]\ttraining's rmse: 1.47853\tvalid_1's rmse: 1.56938\n",
      "[2000]\ttraining's rmse: 1.47533\tvalid_1's rmse: 1.56929\n",
      "[2100]\ttraining's rmse: 1.47211\tvalid_1's rmse: 1.56932\n",
      "[2200]\ttraining's rmse: 1.46898\tvalid_1's rmse: 1.56931\n",
      "[2300]\ttraining's rmse: 1.46575\tvalid_1's rmse: 1.56936\n",
      "[2400]\ttraining's rmse: 1.46258\tvalid_1's rmse: 1.5693\n",
      "[2500]\ttraining's rmse: 1.45938\tvalid_1's rmse: 1.56934\n",
      "Early stopping, best iteration is:\n",
      "[1980]\ttraining's rmse: 1.47599\tvalid_1's rmse: 1.56927\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60135\tvalid_1's rmse: 1.60899\n",
      "[200]\ttraining's rmse: 1.56812\tvalid_1's rmse: 1.58168\n",
      "[300]\ttraining's rmse: 1.55289\tvalid_1's rmse: 1.572\n",
      "[400]\ttraining's rmse: 1.54314\tvalid_1's rmse: 1.5672\n",
      "[500]\ttraining's rmse: 1.53588\tvalid_1's rmse: 1.56447\n",
      "[600]\ttraining's rmse: 1.53002\tvalid_1's rmse: 1.56298\n",
      "[700]\ttraining's rmse: 1.52496\tvalid_1's rmse: 1.5621\n",
      "[800]\ttraining's rmse: 1.52046\tvalid_1's rmse: 1.56143\n",
      "[900]\ttraining's rmse: 1.51619\tvalid_1's rmse: 1.561\n",
      "[1000]\ttraining's rmse: 1.51215\tvalid_1's rmse: 1.56075\n",
      "[1100]\ttraining's rmse: 1.50845\tvalid_1's rmse: 1.56055\n",
      "[1200]\ttraining's rmse: 1.50475\tvalid_1's rmse: 1.56034\n",
      "[1300]\ttraining's rmse: 1.5011\tvalid_1's rmse: 1.56021\n",
      "[1400]\ttraining's rmse: 1.49752\tvalid_1's rmse: 1.56015\n",
      "[1500]\ttraining's rmse: 1.49399\tvalid_1's rmse: 1.56008\n",
      "[1600]\ttraining's rmse: 1.49053\tvalid_1's rmse: 1.56014\n",
      "[1700]\ttraining's rmse: 1.487\tvalid_1's rmse: 1.56014\n",
      "[1800]\ttraining's rmse: 1.48356\tvalid_1's rmse: 1.56023\n",
      "[1900]\ttraining's rmse: 1.48014\tvalid_1's rmse: 1.5602\n",
      "[2000]\ttraining's rmse: 1.47677\tvalid_1's rmse: 1.56014\n",
      "[2100]\ttraining's rmse: 1.47353\tvalid_1's rmse: 1.56014\n",
      "Early stopping, best iteration is:\n",
      "[1527]\ttraining's rmse: 1.49304\tvalid_1's rmse: 1.56002\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60575\tvalid_1's rmse: 1.58871\n",
      "[200]\ttraining's rmse: 1.5725\tvalid_1's rmse: 1.56086\n",
      "[300]\ttraining's rmse: 1.55722\tvalid_1's rmse: 1.55057\n",
      "[400]\ttraining's rmse: 1.54766\tvalid_1's rmse: 1.54572\n",
      "[500]\ttraining's rmse: 1.54061\tvalid_1's rmse: 1.54326\n",
      "[600]\ttraining's rmse: 1.53498\tvalid_1's rmse: 1.54173\n",
      "[700]\ttraining's rmse: 1.53011\tvalid_1's rmse: 1.54105\n",
      "[800]\ttraining's rmse: 1.52574\tvalid_1's rmse: 1.54061\n",
      "[900]\ttraining's rmse: 1.52169\tvalid_1's rmse: 1.54029\n",
      "[1000]\ttraining's rmse: 1.51783\tvalid_1's rmse: 1.54003\n",
      "[1100]\ttraining's rmse: 1.51414\tvalid_1's rmse: 1.53996\n",
      "[1200]\ttraining's rmse: 1.51045\tvalid_1's rmse: 1.53978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttraining's rmse: 1.50681\tvalid_1's rmse: 1.53971\n",
      "[1400]\ttraining's rmse: 1.50342\tvalid_1's rmse: 1.53953\n",
      "[1500]\ttraining's rmse: 1.49988\tvalid_1's rmse: 1.53939\n",
      "[1600]\ttraining's rmse: 1.49651\tvalid_1's rmse: 1.53931\n",
      "[1700]\ttraining's rmse: 1.49319\tvalid_1's rmse: 1.53935\n",
      "[1800]\ttraining's rmse: 1.4899\tvalid_1's rmse: 1.53938\n",
      "[1900]\ttraining's rmse: 1.48671\tvalid_1's rmse: 1.53935\n",
      "[2000]\ttraining's rmse: 1.48355\tvalid_1's rmse: 1.53937\n",
      "[2100]\ttraining's rmse: 1.48033\tvalid_1's rmse: 1.53935\n",
      "[2200]\ttraining's rmse: 1.47714\tvalid_1's rmse: 1.53933\n",
      "[2300]\ttraining's rmse: 1.47407\tvalid_1's rmse: 1.53931\n",
      "[2400]\ttraining's rmse: 1.47096\tvalid_1's rmse: 1.53938\n",
      "[2500]\ttraining's rmse: 1.46781\tvalid_1's rmse: 1.53941\n",
      "[2600]\ttraining's rmse: 1.46469\tvalid_1's rmse: 1.53946\n",
      "Early stopping, best iteration is:\n",
      "[2053]\ttraining's rmse: 1.48189\tvalid_1's rmse: 1.53926\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.597\tvalid_1's rmse: 1.63379\n",
      "[200]\ttraining's rmse: 1.56432\tvalid_1's rmse: 1.60506\n",
      "[300]\ttraining's rmse: 1.54922\tvalid_1's rmse: 1.59366\n",
      "[400]\ttraining's rmse: 1.53983\tvalid_1's rmse: 1.58799\n",
      "[500]\ttraining's rmse: 1.5328\tvalid_1's rmse: 1.58476\n",
      "[600]\ttraining's rmse: 1.52713\tvalid_1's rmse: 1.5828\n",
      "[700]\ttraining's rmse: 1.52221\tvalid_1's rmse: 1.58168\n",
      "[800]\ttraining's rmse: 1.51774\tvalid_1's rmse: 1.58104\n",
      "[900]\ttraining's rmse: 1.51359\tvalid_1's rmse: 1.58056\n",
      "[1000]\ttraining's rmse: 1.50969\tvalid_1's rmse: 1.58019\n",
      "[1100]\ttraining's rmse: 1.50616\tvalid_1's rmse: 1.57993\n",
      "[1200]\ttraining's rmse: 1.50249\tvalid_1's rmse: 1.57982\n",
      "[1300]\ttraining's rmse: 1.49913\tvalid_1's rmse: 1.5797\n",
      "[1400]\ttraining's rmse: 1.49554\tvalid_1's rmse: 1.5796\n",
      "[1500]\ttraining's rmse: 1.49218\tvalid_1's rmse: 1.57957\n",
      "[1600]\ttraining's rmse: 1.48897\tvalid_1's rmse: 1.57945\n",
      "[1700]\ttraining's rmse: 1.4857\tvalid_1's rmse: 1.57931\n",
      "[1800]\ttraining's rmse: 1.4825\tvalid_1's rmse: 1.57919\n",
      "[1900]\ttraining's rmse: 1.47918\tvalid_1's rmse: 1.57911\n",
      "[2000]\ttraining's rmse: 1.47606\tvalid_1's rmse: 1.57899\n",
      "[2100]\ttraining's rmse: 1.47281\tvalid_1's rmse: 1.5789\n",
      "[2200]\ttraining's rmse: 1.46962\tvalid_1's rmse: 1.57892\n",
      "[2300]\ttraining's rmse: 1.46648\tvalid_1's rmse: 1.57904\n",
      "[2400]\ttraining's rmse: 1.46341\tvalid_1's rmse: 1.57891\n",
      "[2500]\ttraining's rmse: 1.46029\tvalid_1's rmse: 1.57885\n",
      "[2600]\ttraining's rmse: 1.45734\tvalid_1's rmse: 1.57881\n",
      "[2700]\ttraining's rmse: 1.45435\tvalid_1's rmse: 1.57874\n",
      "[2800]\ttraining's rmse: 1.45137\tvalid_1's rmse: 1.57877\n",
      "[2900]\ttraining's rmse: 1.44837\tvalid_1's rmse: 1.57883\n",
      "[3000]\ttraining's rmse: 1.44545\tvalid_1's rmse: 1.5789\n",
      "[3100]\ttraining's rmse: 1.44251\tvalid_1's rmse: 1.57893\n",
      "[3200]\ttraining's rmse: 1.43969\tvalid_1's rmse: 1.57898\n",
      "[3300]\ttraining's rmse: 1.43674\tvalid_1's rmse: 1.57906\n",
      "Early stopping, best iteration is:\n",
      "[2721]\ttraining's rmse: 1.45371\tvalid_1's rmse: 1.57872\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60364\tvalid_1's rmse: 1.59812\n",
      "[200]\ttraining's rmse: 1.57065\tvalid_1's rmse: 1.56992\n",
      "[300]\ttraining's rmse: 1.55557\tvalid_1's rmse: 1.55933\n",
      "[400]\ttraining's rmse: 1.54603\tvalid_1's rmse: 1.55406\n",
      "[500]\ttraining's rmse: 1.53888\tvalid_1's rmse: 1.55122\n",
      "[600]\ttraining's rmse: 1.53316\tvalid_1's rmse: 1.54971\n",
      "[700]\ttraining's rmse: 1.52826\tvalid_1's rmse: 1.54864\n",
      "[800]\ttraining's rmse: 1.52384\tvalid_1's rmse: 1.54802\n",
      "[900]\ttraining's rmse: 1.51965\tvalid_1's rmse: 1.5478\n",
      "[1000]\ttraining's rmse: 1.51576\tvalid_1's rmse: 1.54754\n",
      "[1100]\ttraining's rmse: 1.51209\tvalid_1's rmse: 1.54736\n",
      "[1200]\ttraining's rmse: 1.50846\tvalid_1's rmse: 1.54732\n",
      "[1300]\ttraining's rmse: 1.5049\tvalid_1's rmse: 1.547\n",
      "[1400]\ttraining's rmse: 1.5015\tvalid_1's rmse: 1.5468\n",
      "[1500]\ttraining's rmse: 1.49818\tvalid_1's rmse: 1.54672\n",
      "[1600]\ttraining's rmse: 1.49482\tvalid_1's rmse: 1.54664\n",
      "[1700]\ttraining's rmse: 1.4914\tvalid_1's rmse: 1.54661\n",
      "[1800]\ttraining's rmse: 1.4882\tvalid_1's rmse: 1.54667\n",
      "[1900]\ttraining's rmse: 1.48493\tvalid_1's rmse: 1.54655\n",
      "[2000]\ttraining's rmse: 1.48171\tvalid_1's rmse: 1.54661\n",
      "[2100]\ttraining's rmse: 1.47862\tvalid_1's rmse: 1.54667\n",
      "[2200]\ttraining's rmse: 1.4755\tvalid_1's rmse: 1.54673\n",
      "[2300]\ttraining's rmse: 1.47241\tvalid_1's rmse: 1.54671\n",
      "[2400]\ttraining's rmse: 1.46933\tvalid_1's rmse: 1.54676\n",
      "Early stopping, best iteration is:\n",
      "[1896]\ttraining's rmse: 1.48506\tvalid_1's rmse: 1.54654\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60538\tvalid_1's rmse: 1.58916\n",
      "[200]\ttraining's rmse: 1.57229\tvalid_1's rmse: 1.5618\n",
      "[300]\ttraining's rmse: 1.557\tvalid_1's rmse: 1.55152\n",
      "[400]\ttraining's rmse: 1.54742\tvalid_1's rmse: 1.54711\n",
      "[500]\ttraining's rmse: 1.54036\tvalid_1's rmse: 1.545\n",
      "[600]\ttraining's rmse: 1.5346\tvalid_1's rmse: 1.54381\n",
      "[700]\ttraining's rmse: 1.52962\tvalid_1's rmse: 1.54326\n",
      "[800]\ttraining's rmse: 1.52519\tvalid_1's rmse: 1.54292\n",
      "[900]\ttraining's rmse: 1.52093\tvalid_1's rmse: 1.54267\n",
      "[1000]\ttraining's rmse: 1.517\tvalid_1's rmse: 1.54254\n",
      "[1100]\ttraining's rmse: 1.51326\tvalid_1's rmse: 1.54249\n",
      "[1200]\ttraining's rmse: 1.50969\tvalid_1's rmse: 1.54234\n",
      "[1300]\ttraining's rmse: 1.50614\tvalid_1's rmse: 1.54222\n",
      "[1400]\ttraining's rmse: 1.50264\tvalid_1's rmse: 1.54214\n",
      "[1500]\ttraining's rmse: 1.49919\tvalid_1's rmse: 1.54217\n",
      "[1600]\ttraining's rmse: 1.4958\tvalid_1's rmse: 1.54227\n",
      "[1700]\ttraining's rmse: 1.49254\tvalid_1's rmse: 1.5424\n",
      "[1800]\ttraining's rmse: 1.48921\tvalid_1's rmse: 1.54243\n",
      "[1900]\ttraining's rmse: 1.48597\tvalid_1's rmse: 1.54252\n",
      "[2000]\ttraining's rmse: 1.48269\tvalid_1's rmse: 1.5425\n",
      "[2100]\ttraining's rmse: 1.47944\tvalid_1's rmse: 1.54258\n",
      "Early stopping, best iteration is:\n",
      "[1512]\ttraining's rmse: 1.4988\tvalid_1's rmse: 1.54212\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59867\tvalid_1's rmse: 1.62463\n",
      "[200]\ttraining's rmse: 1.56571\tvalid_1's rmse: 1.59549\n",
      "[300]\ttraining's rmse: 1.55069\tvalid_1's rmse: 1.58413\n",
      "[400]\ttraining's rmse: 1.54132\tvalid_1's rmse: 1.57862\n",
      "[500]\ttraining's rmse: 1.53435\tvalid_1's rmse: 1.57551\n",
      "[600]\ttraining's rmse: 1.52877\tvalid_1's rmse: 1.57366\n",
      "[700]\ttraining's rmse: 1.52391\tvalid_1's rmse: 1.57246\n",
      "[800]\ttraining's rmse: 1.51949\tvalid_1's rmse: 1.57178\n",
      "[900]\ttraining's rmse: 1.51555\tvalid_1's rmse: 1.57127\n",
      "[1000]\ttraining's rmse: 1.51171\tvalid_1's rmse: 1.57103\n",
      "[1100]\ttraining's rmse: 1.508\tvalid_1's rmse: 1.57077\n",
      "[1200]\ttraining's rmse: 1.50443\tvalid_1's rmse: 1.57054\n",
      "[1300]\ttraining's rmse: 1.50095\tvalid_1's rmse: 1.57048\n",
      "[1400]\ttraining's rmse: 1.49741\tvalid_1's rmse: 1.57044\n",
      "[1500]\ttraining's rmse: 1.49399\tvalid_1's rmse: 1.57032\n",
      "[1600]\ttraining's rmse: 1.49077\tvalid_1's rmse: 1.57019\n",
      "[1700]\ttraining's rmse: 1.48754\tvalid_1's rmse: 1.57024\n",
      "[1800]\ttraining's rmse: 1.48424\tvalid_1's rmse: 1.57013\n",
      "[1900]\ttraining's rmse: 1.481\tvalid_1's rmse: 1.57008\n",
      "[2000]\ttraining's rmse: 1.47791\tvalid_1's rmse: 1.5701\n",
      "[2100]\ttraining's rmse: 1.47469\tvalid_1's rmse: 1.57013\n",
      "[2200]\ttraining's rmse: 1.47163\tvalid_1's rmse: 1.57009\n",
      "[2300]\ttraining's rmse: 1.46846\tvalid_1's rmse: 1.57002\n",
      "[2400]\ttraining's rmse: 1.46546\tvalid_1's rmse: 1.57002\n",
      "[2500]\ttraining's rmse: 1.46235\tvalid_1's rmse: 1.56991\n",
      "[2600]\ttraining's rmse: 1.45931\tvalid_1's rmse: 1.56986\n",
      "[2700]\ttraining's rmse: 1.45633\tvalid_1's rmse: 1.56983\n",
      "[2800]\ttraining's rmse: 1.45326\tvalid_1's rmse: 1.56991\n",
      "[2900]\ttraining's rmse: 1.45021\tvalid_1's rmse: 1.56997\n",
      "[3000]\ttraining's rmse: 1.44726\tvalid_1's rmse: 1.57003\n",
      "[3100]\ttraining's rmse: 1.4443\tvalid_1's rmse: 1.57014\n",
      "[3200]\ttraining's rmse: 1.44143\tvalid_1's rmse: 1.57014\n",
      "Early stopping, best iteration is:\n",
      "[2697]\ttraining's rmse: 1.45642\tvalid_1's rmse: 1.56982\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60145\tvalid_1's rmse: 1.60915\n",
      "[200]\ttraining's rmse: 1.56839\tvalid_1's rmse: 1.58165\n",
      "[300]\ttraining's rmse: 1.55327\tvalid_1's rmse: 1.57169\n",
      "[400]\ttraining's rmse: 1.54381\tvalid_1's rmse: 1.56704\n",
      "[500]\ttraining's rmse: 1.53679\tvalid_1's rmse: 1.56437\n",
      "[600]\ttraining's rmse: 1.53113\tvalid_1's rmse: 1.56288\n",
      "[700]\ttraining's rmse: 1.52623\tvalid_1's rmse: 1.56196\n",
      "[800]\ttraining's rmse: 1.52193\tvalid_1's rmse: 1.56141\n",
      "[900]\ttraining's rmse: 1.51777\tvalid_1's rmse: 1.56107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 1.51391\tvalid_1's rmse: 1.56081\n",
      "[1100]\ttraining's rmse: 1.51021\tvalid_1's rmse: 1.56043\n",
      "[1200]\ttraining's rmse: 1.50664\tvalid_1's rmse: 1.56034\n",
      "[1300]\ttraining's rmse: 1.50312\tvalid_1's rmse: 1.56025\n",
      "[1400]\ttraining's rmse: 1.49975\tvalid_1's rmse: 1.56019\n",
      "[1500]\ttraining's rmse: 1.49632\tvalid_1's rmse: 1.56015\n",
      "[1600]\ttraining's rmse: 1.49298\tvalid_1's rmse: 1.56004\n",
      "[1700]\ttraining's rmse: 1.4897\tvalid_1's rmse: 1.55992\n",
      "[1800]\ttraining's rmse: 1.48644\tvalid_1's rmse: 1.55989\n",
      "[1900]\ttraining's rmse: 1.48316\tvalid_1's rmse: 1.55992\n",
      "[2000]\ttraining's rmse: 1.47975\tvalid_1's rmse: 1.55993\n",
      "[2100]\ttraining's rmse: 1.47664\tvalid_1's rmse: 1.55994\n",
      "[2200]\ttraining's rmse: 1.47351\tvalid_1's rmse: 1.55994\n",
      "[2300]\ttraining's rmse: 1.47033\tvalid_1's rmse: 1.55993\n",
      "Early stopping, best iteration is:\n",
      "[1770]\ttraining's rmse: 1.48743\tvalid_1's rmse: 1.55983\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60842\tvalid_1's rmse: 1.59413\n",
      "[200]\ttraining's rmse: 1.57518\tvalid_1's rmse: 1.56716\n",
      "[300]\ttraining's rmse: 1.55893\tvalid_1's rmse: 1.55702\n",
      "[400]\ttraining's rmse: 1.54756\tvalid_1's rmse: 1.55182\n",
      "[500]\ttraining's rmse: 1.53846\tvalid_1's rmse: 1.54884\n",
      "[600]\ttraining's rmse: 1.53064\tvalid_1's rmse: 1.54683\n",
      "[700]\ttraining's rmse: 1.52377\tvalid_1's rmse: 1.54564\n",
      "[800]\ttraining's rmse: 1.51753\tvalid_1's rmse: 1.54491\n",
      "[900]\ttraining's rmse: 1.51185\tvalid_1's rmse: 1.54435\n",
      "[1000]\ttraining's rmse: 1.50618\tvalid_1's rmse: 1.54403\n",
      "[1100]\ttraining's rmse: 1.50093\tvalid_1's rmse: 1.54341\n",
      "[1200]\ttraining's rmse: 1.49595\tvalid_1's rmse: 1.54309\n",
      "[1300]\ttraining's rmse: 1.49099\tvalid_1's rmse: 1.54302\n",
      "[1400]\ttraining's rmse: 1.48612\tvalid_1's rmse: 1.54293\n",
      "[1500]\ttraining's rmse: 1.48132\tvalid_1's rmse: 1.54275\n",
      "[1600]\ttraining's rmse: 1.47658\tvalid_1's rmse: 1.54259\n",
      "[1700]\ttraining's rmse: 1.472\tvalid_1's rmse: 1.5425\n",
      "[1800]\ttraining's rmse: 1.46736\tvalid_1's rmse: 1.54242\n",
      "[1900]\ttraining's rmse: 1.46283\tvalid_1's rmse: 1.5422\n",
      "[2000]\ttraining's rmse: 1.45853\tvalid_1's rmse: 1.54208\n",
      "[2100]\ttraining's rmse: 1.45428\tvalid_1's rmse: 1.54203\n",
      "[2200]\ttraining's rmse: 1.44994\tvalid_1's rmse: 1.54195\n",
      "[2300]\ttraining's rmse: 1.44566\tvalid_1's rmse: 1.54187\n",
      "[2400]\ttraining's rmse: 1.44149\tvalid_1's rmse: 1.54185\n",
      "[2500]\ttraining's rmse: 1.43723\tvalid_1's rmse: 1.54177\n",
      "[2600]\ttraining's rmse: 1.43301\tvalid_1's rmse: 1.54156\n",
      "[2700]\ttraining's rmse: 1.42888\tvalid_1's rmse: 1.54152\n",
      "[2800]\ttraining's rmse: 1.42482\tvalid_1's rmse: 1.54149\n",
      "[2900]\ttraining's rmse: 1.42069\tvalid_1's rmse: 1.54158\n",
      "[3000]\ttraining's rmse: 1.41674\tvalid_1's rmse: 1.54152\n",
      "[3100]\ttraining's rmse: 1.41263\tvalid_1's rmse: 1.54142\n",
      "[3200]\ttraining's rmse: 1.40867\tvalid_1's rmse: 1.54149\n",
      "[3300]\ttraining's rmse: 1.40484\tvalid_1's rmse: 1.54147\n",
      "[3400]\ttraining's rmse: 1.40087\tvalid_1's rmse: 1.54149\n",
      "[3500]\ttraining's rmse: 1.39712\tvalid_1's rmse: 1.54149\n",
      "[3600]\ttraining's rmse: 1.39333\tvalid_1's rmse: 1.5415\n",
      "[3700]\ttraining's rmse: 1.38965\tvalid_1's rmse: 1.54153\n",
      "Early stopping, best iteration is:\n",
      "[3101]\ttraining's rmse: 1.41259\tvalid_1's rmse: 1.54142\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60332\tvalid_1's rmse: 1.62832\n",
      "[200]\ttraining's rmse: 1.57029\tvalid_1's rmse: 1.59927\n",
      "[300]\ttraining's rmse: 1.55415\tvalid_1's rmse: 1.58778\n",
      "[400]\ttraining's rmse: 1.54275\tvalid_1's rmse: 1.58164\n",
      "[500]\ttraining's rmse: 1.53368\tvalid_1's rmse: 1.57799\n",
      "[600]\ttraining's rmse: 1.52599\tvalid_1's rmse: 1.57576\n",
      "[700]\ttraining's rmse: 1.51902\tvalid_1's rmse: 1.57424\n",
      "[800]\ttraining's rmse: 1.51273\tvalid_1's rmse: 1.57331\n",
      "[900]\ttraining's rmse: 1.50684\tvalid_1's rmse: 1.57258\n",
      "[1000]\ttraining's rmse: 1.50127\tvalid_1's rmse: 1.57209\n",
      "[1100]\ttraining's rmse: 1.49605\tvalid_1's rmse: 1.57179\n",
      "[1200]\ttraining's rmse: 1.49099\tvalid_1's rmse: 1.57151\n",
      "[1300]\ttraining's rmse: 1.48605\tvalid_1's rmse: 1.57125\n",
      "[1400]\ttraining's rmse: 1.48121\tvalid_1's rmse: 1.57083\n",
      "[1500]\ttraining's rmse: 1.47641\tvalid_1's rmse: 1.57061\n",
      "[1600]\ttraining's rmse: 1.47186\tvalid_1's rmse: 1.5705\n",
      "[1700]\ttraining's rmse: 1.46733\tvalid_1's rmse: 1.57047\n",
      "[1800]\ttraining's rmse: 1.46301\tvalid_1's rmse: 1.5705\n",
      "[1900]\ttraining's rmse: 1.45857\tvalid_1's rmse: 1.57036\n",
      "[2000]\ttraining's rmse: 1.45419\tvalid_1's rmse: 1.57019\n",
      "[2100]\ttraining's rmse: 1.44974\tvalid_1's rmse: 1.5701\n",
      "[2200]\ttraining's rmse: 1.44545\tvalid_1's rmse: 1.56995\n",
      "[2300]\ttraining's rmse: 1.44118\tvalid_1's rmse: 1.56997\n",
      "[2400]\ttraining's rmse: 1.4371\tvalid_1's rmse: 1.57005\n",
      "[2500]\ttraining's rmse: 1.43296\tvalid_1's rmse: 1.57005\n",
      "[2600]\ttraining's rmse: 1.42884\tvalid_1's rmse: 1.56986\n",
      "[2700]\ttraining's rmse: 1.42472\tvalid_1's rmse: 1.56985\n",
      "[2800]\ttraining's rmse: 1.42058\tvalid_1's rmse: 1.56993\n",
      "[2900]\ttraining's rmse: 1.41664\tvalid_1's rmse: 1.57005\n",
      "[3000]\ttraining's rmse: 1.41272\tvalid_1's rmse: 1.56998\n",
      "[3100]\ttraining's rmse: 1.40867\tvalid_1's rmse: 1.56998\n",
      "[3200]\ttraining's rmse: 1.40485\tvalid_1's rmse: 1.5699\n",
      "Early stopping, best iteration is:\n",
      "[2699]\ttraining's rmse: 1.42476\tvalid_1's rmse: 1.56984\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60459\tvalid_1's rmse: 1.61763\n",
      "[200]\ttraining's rmse: 1.57141\tvalid_1's rmse: 1.59091\n",
      "[300]\ttraining's rmse: 1.55521\tvalid_1's rmse: 1.58059\n",
      "[400]\ttraining's rmse: 1.54388\tvalid_1's rmse: 1.57514\n",
      "[500]\ttraining's rmse: 1.53471\tvalid_1's rmse: 1.57153\n",
      "[600]\ttraining's rmse: 1.52684\tvalid_1's rmse: 1.56927\n",
      "[700]\ttraining's rmse: 1.51977\tvalid_1's rmse: 1.56774\n",
      "[800]\ttraining's rmse: 1.51354\tvalid_1's rmse: 1.56684\n",
      "[900]\ttraining's rmse: 1.50774\tvalid_1's rmse: 1.56622\n",
      "[1000]\ttraining's rmse: 1.50235\tvalid_1's rmse: 1.5657\n",
      "[1100]\ttraining's rmse: 1.49693\tvalid_1's rmse: 1.56539\n",
      "[1200]\ttraining's rmse: 1.49179\tvalid_1's rmse: 1.56501\n",
      "[1300]\ttraining's rmse: 1.48682\tvalid_1's rmse: 1.56467\n",
      "[1400]\ttraining's rmse: 1.48201\tvalid_1's rmse: 1.56459\n",
      "[1500]\ttraining's rmse: 1.4773\tvalid_1's rmse: 1.56434\n",
      "[1600]\ttraining's rmse: 1.47257\tvalid_1's rmse: 1.56413\n",
      "[1700]\ttraining's rmse: 1.46811\tvalid_1's rmse: 1.56392\n",
      "[1800]\ttraining's rmse: 1.46375\tvalid_1's rmse: 1.56377\n",
      "[1900]\ttraining's rmse: 1.45935\tvalid_1's rmse: 1.56383\n",
      "[2000]\ttraining's rmse: 1.45501\tvalid_1's rmse: 1.56382\n",
      "[2100]\ttraining's rmse: 1.45061\tvalid_1's rmse: 1.56372\n",
      "[2200]\ttraining's rmse: 1.44624\tvalid_1's rmse: 1.5637\n",
      "[2300]\ttraining's rmse: 1.44202\tvalid_1's rmse: 1.56367\n",
      "[2400]\ttraining's rmse: 1.43777\tvalid_1's rmse: 1.56354\n",
      "[2500]\ttraining's rmse: 1.43359\tvalid_1's rmse: 1.56353\n",
      "[2600]\ttraining's rmse: 1.42952\tvalid_1's rmse: 1.56345\n",
      "[2700]\ttraining's rmse: 1.42548\tvalid_1's rmse: 1.56343\n",
      "[2800]\ttraining's rmse: 1.42144\tvalid_1's rmse: 1.56345\n",
      "[2900]\ttraining's rmse: 1.41739\tvalid_1's rmse: 1.56351\n",
      "[3000]\ttraining's rmse: 1.41345\tvalid_1's rmse: 1.56351\n",
      "[3100]\ttraining's rmse: 1.40956\tvalid_1's rmse: 1.5635\n",
      "[3200]\ttraining's rmse: 1.40566\tvalid_1's rmse: 1.56351\n",
      "[3300]\ttraining's rmse: 1.40182\tvalid_1's rmse: 1.56334\n",
      "[3400]\ttraining's rmse: 1.39798\tvalid_1's rmse: 1.56333\n",
      "[3500]\ttraining's rmse: 1.39407\tvalid_1's rmse: 1.56336\n",
      "[3600]\ttraining's rmse: 1.3902\tvalid_1's rmse: 1.56326\n",
      "[3700]\ttraining's rmse: 1.38652\tvalid_1's rmse: 1.56335\n",
      "[3800]\ttraining's rmse: 1.38272\tvalid_1's rmse: 1.56329\n",
      "[3900]\ttraining's rmse: 1.37891\tvalid_1's rmse: 1.56333\n",
      "[4000]\ttraining's rmse: 1.37518\tvalid_1's rmse: 1.56336\n",
      "[4100]\ttraining's rmse: 1.37149\tvalid_1's rmse: 1.56335\n",
      "Early stopping, best iteration is:\n",
      "[3593]\ttraining's rmse: 1.39048\tvalid_1's rmse: 1.56324\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60793\tvalid_1's rmse: 1.59701\n",
      "[200]\ttraining's rmse: 1.57471\tvalid_1's rmse: 1.57019\n",
      "[300]\ttraining's rmse: 1.55835\tvalid_1's rmse: 1.55983\n",
      "[400]\ttraining's rmse: 1.54695\tvalid_1's rmse: 1.55457\n",
      "[500]\ttraining's rmse: 1.5379\tvalid_1's rmse: 1.55165\n",
      "[600]\ttraining's rmse: 1.52998\tvalid_1's rmse: 1.54969\n",
      "[700]\ttraining's rmse: 1.52295\tvalid_1's rmse: 1.54854\n",
      "[800]\ttraining's rmse: 1.51656\tvalid_1's rmse: 1.54773\n",
      "[900]\ttraining's rmse: 1.51074\tvalid_1's rmse: 1.54717\n",
      "[1000]\ttraining's rmse: 1.50527\tvalid_1's rmse: 1.54669\n",
      "[1100]\ttraining's rmse: 1.4999\tvalid_1's rmse: 1.54646\n",
      "[1200]\ttraining's rmse: 1.49464\tvalid_1's rmse: 1.5464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttraining's rmse: 1.48967\tvalid_1's rmse: 1.54634\n",
      "[1400]\ttraining's rmse: 1.48475\tvalid_1's rmse: 1.54618\n",
      "[1500]\ttraining's rmse: 1.47995\tvalid_1's rmse: 1.54606\n",
      "[1600]\ttraining's rmse: 1.47544\tvalid_1's rmse: 1.54603\n",
      "[1700]\ttraining's rmse: 1.47072\tvalid_1's rmse: 1.546\n",
      "[1800]\ttraining's rmse: 1.46621\tvalid_1's rmse: 1.54598\n",
      "[1900]\ttraining's rmse: 1.46172\tvalid_1's rmse: 1.54584\n",
      "[2000]\ttraining's rmse: 1.45742\tvalid_1's rmse: 1.54583\n",
      "[2100]\ttraining's rmse: 1.45307\tvalid_1's rmse: 1.5458\n",
      "[2200]\ttraining's rmse: 1.44877\tvalid_1's rmse: 1.54577\n",
      "[2300]\ttraining's rmse: 1.44447\tvalid_1's rmse: 1.54565\n",
      "[2400]\ttraining's rmse: 1.4402\tvalid_1's rmse: 1.54566\n",
      "[2500]\ttraining's rmse: 1.43609\tvalid_1's rmse: 1.54562\n",
      "[2600]\ttraining's rmse: 1.43201\tvalid_1's rmse: 1.54551\n",
      "[2700]\ttraining's rmse: 1.42797\tvalid_1's rmse: 1.54553\n",
      "[2800]\ttraining's rmse: 1.42395\tvalid_1's rmse: 1.54547\n",
      "[2900]\ttraining's rmse: 1.41993\tvalid_1's rmse: 1.54548\n",
      "[3000]\ttraining's rmse: 1.41586\tvalid_1's rmse: 1.54545\n",
      "[3100]\ttraining's rmse: 1.41199\tvalid_1's rmse: 1.54544\n",
      "[3200]\ttraining's rmse: 1.40795\tvalid_1's rmse: 1.54548\n",
      "[3300]\ttraining's rmse: 1.40401\tvalid_1's rmse: 1.54549\n",
      "[3400]\ttraining's rmse: 1.40025\tvalid_1's rmse: 1.54563\n",
      "[3500]\ttraining's rmse: 1.39638\tvalid_1's rmse: 1.54572\n",
      "[3600]\ttraining's rmse: 1.3925\tvalid_1's rmse: 1.54575\n",
      "Early stopping, best iteration is:\n",
      "[3024]\ttraining's rmse: 1.41494\tvalid_1's rmse: 1.5454\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60549\tvalid_1's rmse: 1.61361\n",
      "[200]\ttraining's rmse: 1.57249\tvalid_1's rmse: 1.58551\n",
      "[300]\ttraining's rmse: 1.55606\tvalid_1's rmse: 1.57457\n",
      "[400]\ttraining's rmse: 1.54477\tvalid_1's rmse: 1.56917\n",
      "[500]\ttraining's rmse: 1.53574\tvalid_1's rmse: 1.56578\n",
      "[600]\ttraining's rmse: 1.52796\tvalid_1's rmse: 1.56353\n",
      "[700]\ttraining's rmse: 1.52109\tvalid_1's rmse: 1.56219\n",
      "[800]\ttraining's rmse: 1.51472\tvalid_1's rmse: 1.5612\n",
      "[900]\ttraining's rmse: 1.50892\tvalid_1's rmse: 1.56047\n",
      "[1000]\ttraining's rmse: 1.50349\tvalid_1's rmse: 1.56008\n",
      "[1100]\ttraining's rmse: 1.49829\tvalid_1's rmse: 1.55972\n",
      "[1200]\ttraining's rmse: 1.49316\tvalid_1's rmse: 1.55949\n",
      "[1300]\ttraining's rmse: 1.48816\tvalid_1's rmse: 1.55931\n",
      "[1400]\ttraining's rmse: 1.48332\tvalid_1's rmse: 1.55914\n",
      "[1500]\ttraining's rmse: 1.47857\tvalid_1's rmse: 1.55903\n",
      "[1600]\ttraining's rmse: 1.47372\tvalid_1's rmse: 1.55886\n",
      "[1700]\ttraining's rmse: 1.46912\tvalid_1's rmse: 1.55854\n",
      "[1800]\ttraining's rmse: 1.4646\tvalid_1's rmse: 1.55836\n",
      "[1900]\ttraining's rmse: 1.46019\tvalid_1's rmse: 1.55822\n",
      "[2000]\ttraining's rmse: 1.45574\tvalid_1's rmse: 1.55811\n",
      "[2100]\ttraining's rmse: 1.4514\tvalid_1's rmse: 1.55807\n",
      "[2200]\ttraining's rmse: 1.44706\tvalid_1's rmse: 1.55796\n",
      "[2300]\ttraining's rmse: 1.44283\tvalid_1's rmse: 1.55788\n",
      "[2400]\ttraining's rmse: 1.43862\tvalid_1's rmse: 1.55786\n",
      "[2500]\ttraining's rmse: 1.43458\tvalid_1's rmse: 1.55784\n",
      "[2600]\ttraining's rmse: 1.43053\tvalid_1's rmse: 1.5578\n",
      "[2700]\ttraining's rmse: 1.42653\tvalid_1's rmse: 1.55783\n",
      "[2800]\ttraining's rmse: 1.4224\tvalid_1's rmse: 1.55791\n",
      "[2900]\ttraining's rmse: 1.4184\tvalid_1's rmse: 1.55785\n",
      "[3000]\ttraining's rmse: 1.41442\tvalid_1's rmse: 1.55776\n",
      "[3100]\ttraining's rmse: 1.41051\tvalid_1's rmse: 1.55772\n",
      "[3200]\ttraining's rmse: 1.40654\tvalid_1's rmse: 1.55778\n",
      "[3300]\ttraining's rmse: 1.40264\tvalid_1's rmse: 1.55772\n",
      "[3400]\ttraining's rmse: 1.39872\tvalid_1's rmse: 1.55773\n",
      "[3500]\ttraining's rmse: 1.39484\tvalid_1's rmse: 1.55778\n",
      "[3600]\ttraining's rmse: 1.39099\tvalid_1's rmse: 1.55772\n",
      "[3700]\ttraining's rmse: 1.38714\tvalid_1's rmse: 1.55779\n",
      "[3800]\ttraining's rmse: 1.3834\tvalid_1's rmse: 1.55776\n",
      "Early stopping, best iteration is:\n",
      "[3290]\ttraining's rmse: 1.40305\tvalid_1's rmse: 1.55767\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60503\tvalid_1's rmse: 1.61588\n",
      "[200]\ttraining's rmse: 1.57222\tvalid_1's rmse: 1.58769\n",
      "[300]\ttraining's rmse: 1.55604\tvalid_1's rmse: 1.57657\n",
      "[400]\ttraining's rmse: 1.54489\tvalid_1's rmse: 1.57069\n",
      "[500]\ttraining's rmse: 1.53596\tvalid_1's rmse: 1.56726\n",
      "[600]\ttraining's rmse: 1.5281\tvalid_1's rmse: 1.56494\n",
      "[700]\ttraining's rmse: 1.52124\tvalid_1's rmse: 1.56357\n",
      "[800]\ttraining's rmse: 1.51485\tvalid_1's rmse: 1.56265\n",
      "[900]\ttraining's rmse: 1.50904\tvalid_1's rmse: 1.56198\n",
      "[1000]\ttraining's rmse: 1.50358\tvalid_1's rmse: 1.5615\n",
      "[1100]\ttraining's rmse: 1.49829\tvalid_1's rmse: 1.56106\n",
      "[1200]\ttraining's rmse: 1.49321\tvalid_1's rmse: 1.56078\n",
      "[1300]\ttraining's rmse: 1.48831\tvalid_1's rmse: 1.56057\n",
      "[1400]\ttraining's rmse: 1.48342\tvalid_1's rmse: 1.56054\n",
      "[1500]\ttraining's rmse: 1.47859\tvalid_1's rmse: 1.56036\n",
      "[1600]\ttraining's rmse: 1.47396\tvalid_1's rmse: 1.5603\n",
      "[1700]\ttraining's rmse: 1.46937\tvalid_1's rmse: 1.56019\n",
      "[1800]\ttraining's rmse: 1.46488\tvalid_1's rmse: 1.5601\n",
      "[1900]\ttraining's rmse: 1.46042\tvalid_1's rmse: 1.56011\n",
      "[2000]\ttraining's rmse: 1.45611\tvalid_1's rmse: 1.56\n",
      "[2100]\ttraining's rmse: 1.45193\tvalid_1's rmse: 1.55996\n",
      "[2200]\ttraining's rmse: 1.44759\tvalid_1's rmse: 1.55993\n",
      "[2300]\ttraining's rmse: 1.44345\tvalid_1's rmse: 1.55998\n",
      "[2400]\ttraining's rmse: 1.43921\tvalid_1's rmse: 1.55992\n",
      "[2500]\ttraining's rmse: 1.43506\tvalid_1's rmse: 1.55996\n",
      "[2600]\ttraining's rmse: 1.43093\tvalid_1's rmse: 1.55998\n",
      "[2700]\ttraining's rmse: 1.42685\tvalid_1's rmse: 1.55996\n",
      "[2800]\ttraining's rmse: 1.42294\tvalid_1's rmse: 1.55996\n",
      "[2900]\ttraining's rmse: 1.41889\tvalid_1's rmse: 1.56008\n",
      "[3000]\ttraining's rmse: 1.41481\tvalid_1's rmse: 1.55995\n",
      "Early stopping, best iteration is:\n",
      "[2445]\ttraining's rmse: 1.43733\tvalid_1's rmse: 1.55988\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60559\tvalid_1's rmse: 1.61178\n",
      "[200]\ttraining's rmse: 1.57225\tvalid_1's rmse: 1.58512\n",
      "[300]\ttraining's rmse: 1.55597\tvalid_1's rmse: 1.57562\n",
      "[400]\ttraining's rmse: 1.54473\tvalid_1's rmse: 1.57062\n",
      "[500]\ttraining's rmse: 1.53558\tvalid_1's rmse: 1.56765\n",
      "[600]\ttraining's rmse: 1.52771\tvalid_1's rmse: 1.56592\n",
      "[700]\ttraining's rmse: 1.52053\tvalid_1's rmse: 1.56473\n",
      "[800]\ttraining's rmse: 1.51405\tvalid_1's rmse: 1.56397\n",
      "[900]\ttraining's rmse: 1.50815\tvalid_1's rmse: 1.56345\n",
      "[1000]\ttraining's rmse: 1.50265\tvalid_1's rmse: 1.56307\n",
      "[1100]\ttraining's rmse: 1.49736\tvalid_1's rmse: 1.56289\n",
      "[1200]\ttraining's rmse: 1.49223\tvalid_1's rmse: 1.56274\n",
      "[1300]\ttraining's rmse: 1.48721\tvalid_1's rmse: 1.56257\n",
      "[1400]\ttraining's rmse: 1.48241\tvalid_1's rmse: 1.56251\n",
      "[1500]\ttraining's rmse: 1.47761\tvalid_1's rmse: 1.56237\n",
      "[1600]\ttraining's rmse: 1.47278\tvalid_1's rmse: 1.56236\n",
      "[1700]\ttraining's rmse: 1.46822\tvalid_1's rmse: 1.56232\n",
      "[1800]\ttraining's rmse: 1.46368\tvalid_1's rmse: 1.56222\n",
      "[1900]\ttraining's rmse: 1.45916\tvalid_1's rmse: 1.56222\n",
      "[2000]\ttraining's rmse: 1.45481\tvalid_1's rmse: 1.56226\n",
      "[2100]\ttraining's rmse: 1.45055\tvalid_1's rmse: 1.56214\n",
      "[2200]\ttraining's rmse: 1.44624\tvalid_1's rmse: 1.56222\n",
      "[2300]\ttraining's rmse: 1.44192\tvalid_1's rmse: 1.56236\n",
      "[2400]\ttraining's rmse: 1.43759\tvalid_1's rmse: 1.56252\n",
      "[2500]\ttraining's rmse: 1.43343\tvalid_1's rmse: 1.56245\n",
      "[2600]\ttraining's rmse: 1.4293\tvalid_1's rmse: 1.56252\n",
      "Early stopping, best iteration is:\n",
      "[2060]\ttraining's rmse: 1.45227\tvalid_1's rmse: 1.56208\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60486\tvalid_1's rmse: 1.58943\n",
      "[200]\ttraining's rmse: 1.57174\tvalid_1's rmse: 1.56201\n",
      "[300]\ttraining's rmse: 1.55629\tvalid_1's rmse: 1.55188\n",
      "[400]\ttraining's rmse: 1.54629\tvalid_1's rmse: 1.5469\n",
      "[500]\ttraining's rmse: 1.53875\tvalid_1's rmse: 1.54416\n",
      "[600]\ttraining's rmse: 1.53259\tvalid_1's rmse: 1.54271\n",
      "[700]\ttraining's rmse: 1.52737\tvalid_1's rmse: 1.54194\n",
      "[800]\ttraining's rmse: 1.52264\tvalid_1's rmse: 1.54136\n",
      "[900]\ttraining's rmse: 1.5183\tvalid_1's rmse: 1.54108\n",
      "[1000]\ttraining's rmse: 1.51405\tvalid_1's rmse: 1.54076\n",
      "[1100]\ttraining's rmse: 1.51008\tvalid_1's rmse: 1.54072\n",
      "[1200]\ttraining's rmse: 1.50621\tvalid_1's rmse: 1.54059\n",
      "[1300]\ttraining's rmse: 1.50235\tvalid_1's rmse: 1.54053\n",
      "[1400]\ttraining's rmse: 1.49886\tvalid_1's rmse: 1.54039\n",
      "[1500]\ttraining's rmse: 1.49514\tvalid_1's rmse: 1.54027\n",
      "[1600]\ttraining's rmse: 1.49156\tvalid_1's rmse: 1.54015\n",
      "[1700]\ttraining's rmse: 1.48801\tvalid_1's rmse: 1.54015\n",
      "[1800]\ttraining's rmse: 1.48456\tvalid_1's rmse: 1.54014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\ttraining's rmse: 1.48101\tvalid_1's rmse: 1.54\n",
      "[2000]\ttraining's rmse: 1.4776\tvalid_1's rmse: 1.54009\n",
      "[2100]\ttraining's rmse: 1.47422\tvalid_1's rmse: 1.53996\n",
      "[2200]\ttraining's rmse: 1.47098\tvalid_1's rmse: 1.53996\n",
      "[2300]\ttraining's rmse: 1.46761\tvalid_1's rmse: 1.54001\n",
      "[2400]\ttraining's rmse: 1.46431\tvalid_1's rmse: 1.54022\n",
      "[2500]\ttraining's rmse: 1.46107\tvalid_1's rmse: 1.54026\n",
      "[2600]\ttraining's rmse: 1.45788\tvalid_1's rmse: 1.54026\n",
      "[2700]\ttraining's rmse: 1.45452\tvalid_1's rmse: 1.54023\n",
      "[2800]\ttraining's rmse: 1.45142\tvalid_1's rmse: 1.54023\n",
      "Early stopping, best iteration is:\n",
      "[2239]\ttraining's rmse: 1.46968\tvalid_1's rmse: 1.53988\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59933\tvalid_1's rmse: 1.62488\n",
      "[200]\ttraining's rmse: 1.56645\tvalid_1's rmse: 1.5954\n",
      "[300]\ttraining's rmse: 1.55118\tvalid_1's rmse: 1.58383\n",
      "[400]\ttraining's rmse: 1.54134\tvalid_1's rmse: 1.57817\n",
      "[500]\ttraining's rmse: 1.53385\tvalid_1's rmse: 1.57475\n",
      "[600]\ttraining's rmse: 1.52771\tvalid_1's rmse: 1.57286\n",
      "[700]\ttraining's rmse: 1.52236\tvalid_1's rmse: 1.57164\n",
      "[800]\ttraining's rmse: 1.51759\tvalid_1's rmse: 1.57075\n",
      "[900]\ttraining's rmse: 1.51316\tvalid_1's rmse: 1.57031\n",
      "[1000]\ttraining's rmse: 1.50905\tvalid_1's rmse: 1.57017\n",
      "[1100]\ttraining's rmse: 1.50513\tvalid_1's rmse: 1.56989\n",
      "[1200]\ttraining's rmse: 1.50127\tvalid_1's rmse: 1.56948\n",
      "[1300]\ttraining's rmse: 1.49747\tvalid_1's rmse: 1.56936\n",
      "[1400]\ttraining's rmse: 1.49382\tvalid_1's rmse: 1.56914\n",
      "[1500]\ttraining's rmse: 1.49023\tvalid_1's rmse: 1.56901\n",
      "[1600]\ttraining's rmse: 1.48671\tvalid_1's rmse: 1.56891\n",
      "[1700]\ttraining's rmse: 1.48321\tvalid_1's rmse: 1.56886\n",
      "[1800]\ttraining's rmse: 1.47979\tvalid_1's rmse: 1.5688\n",
      "[1900]\ttraining's rmse: 1.47639\tvalid_1's rmse: 1.56864\n",
      "[2000]\ttraining's rmse: 1.47312\tvalid_1's rmse: 1.56867\n",
      "[2100]\ttraining's rmse: 1.46972\tvalid_1's rmse: 1.5686\n",
      "[2200]\ttraining's rmse: 1.46634\tvalid_1's rmse: 1.56851\n",
      "[2300]\ttraining's rmse: 1.46303\tvalid_1's rmse: 1.56841\n",
      "[2400]\ttraining's rmse: 1.45983\tvalid_1's rmse: 1.56837\n",
      "[2500]\ttraining's rmse: 1.45651\tvalid_1's rmse: 1.56848\n",
      "[2600]\ttraining's rmse: 1.4533\tvalid_1's rmse: 1.56838\n",
      "[2700]\ttraining's rmse: 1.45015\tvalid_1's rmse: 1.5683\n",
      "[2800]\ttraining's rmse: 1.44681\tvalid_1's rmse: 1.56828\n",
      "[2900]\ttraining's rmse: 1.44379\tvalid_1's rmse: 1.56834\n",
      "[3000]\ttraining's rmse: 1.44078\tvalid_1's rmse: 1.56835\n",
      "[3100]\ttraining's rmse: 1.43754\tvalid_1's rmse: 1.56841\n",
      "[3200]\ttraining's rmse: 1.4346\tvalid_1's rmse: 1.56845\n",
      "[3300]\ttraining's rmse: 1.43162\tvalid_1's rmse: 1.56841\n",
      "Early stopping, best iteration is:\n",
      "[2743]\ttraining's rmse: 1.44871\tvalid_1's rmse: 1.56824\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60089\tvalid_1's rmse: 1.61326\n",
      "[200]\ttraining's rmse: 1.56788\tvalid_1's rmse: 1.58531\n",
      "[300]\ttraining's rmse: 1.55268\tvalid_1's rmse: 1.57442\n",
      "[400]\ttraining's rmse: 1.54272\tvalid_1's rmse: 1.56885\n",
      "[500]\ttraining's rmse: 1.53527\tvalid_1's rmse: 1.56557\n",
      "[600]\ttraining's rmse: 1.52905\tvalid_1's rmse: 1.56368\n",
      "[700]\ttraining's rmse: 1.52373\tvalid_1's rmse: 1.56243\n",
      "[800]\ttraining's rmse: 1.51893\tvalid_1's rmse: 1.56175\n",
      "[900]\ttraining's rmse: 1.51448\tvalid_1's rmse: 1.56133\n",
      "[1000]\ttraining's rmse: 1.51024\tvalid_1's rmse: 1.56079\n",
      "[1100]\ttraining's rmse: 1.50616\tvalid_1's rmse: 1.56053\n",
      "[1200]\ttraining's rmse: 1.50213\tvalid_1's rmse: 1.56022\n",
      "[1300]\ttraining's rmse: 1.49844\tvalid_1's rmse: 1.55992\n",
      "[1400]\ttraining's rmse: 1.49468\tvalid_1's rmse: 1.55978\n",
      "[1500]\ttraining's rmse: 1.49103\tvalid_1's rmse: 1.55963\n",
      "[1600]\ttraining's rmse: 1.48748\tvalid_1's rmse: 1.55949\n",
      "[1700]\ttraining's rmse: 1.48395\tvalid_1's rmse: 1.55936\n",
      "[1800]\ttraining's rmse: 1.48053\tvalid_1's rmse: 1.55926\n",
      "[1900]\ttraining's rmse: 1.47705\tvalid_1's rmse: 1.55926\n",
      "[2000]\ttraining's rmse: 1.47375\tvalid_1's rmse: 1.55932\n",
      "[2100]\ttraining's rmse: 1.47027\tvalid_1's rmse: 1.55917\n",
      "[2200]\ttraining's rmse: 1.46691\tvalid_1's rmse: 1.55915\n",
      "[2300]\ttraining's rmse: 1.46349\tvalid_1's rmse: 1.5591\n",
      "[2400]\ttraining's rmse: 1.46034\tvalid_1's rmse: 1.55913\n",
      "[2500]\ttraining's rmse: 1.457\tvalid_1's rmse: 1.55924\n",
      "[2600]\ttraining's rmse: 1.45383\tvalid_1's rmse: 1.55931\n",
      "[2700]\ttraining's rmse: 1.45071\tvalid_1's rmse: 1.55927\n",
      "[2800]\ttraining's rmse: 1.44758\tvalid_1's rmse: 1.55935\n",
      "[2900]\ttraining's rmse: 1.44453\tvalid_1's rmse: 1.5593\n",
      "Early stopping, best iteration is:\n",
      "[2344]\ttraining's rmse: 1.46211\tvalid_1's rmse: 1.55907\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60422\tvalid_1's rmse: 1.59338\n",
      "[200]\ttraining's rmse: 1.57115\tvalid_1's rmse: 1.56522\n",
      "[300]\ttraining's rmse: 1.55571\tvalid_1's rmse: 1.55472\n",
      "[400]\ttraining's rmse: 1.54567\tvalid_1's rmse: 1.54948\n",
      "[500]\ttraining's rmse: 1.53811\tvalid_1's rmse: 1.54672\n",
      "[600]\ttraining's rmse: 1.53179\tvalid_1's rmse: 1.54521\n",
      "[700]\ttraining's rmse: 1.52644\tvalid_1's rmse: 1.54429\n",
      "[800]\ttraining's rmse: 1.52171\tvalid_1's rmse: 1.54379\n",
      "[900]\ttraining's rmse: 1.51728\tvalid_1's rmse: 1.54359\n",
      "[1000]\ttraining's rmse: 1.51311\tvalid_1's rmse: 1.54349\n",
      "[1100]\ttraining's rmse: 1.50907\tvalid_1's rmse: 1.54336\n",
      "[1200]\ttraining's rmse: 1.505\tvalid_1's rmse: 1.54322\n",
      "[1300]\ttraining's rmse: 1.50114\tvalid_1's rmse: 1.54304\n",
      "[1400]\ttraining's rmse: 1.4974\tvalid_1's rmse: 1.543\n",
      "[1500]\ttraining's rmse: 1.49387\tvalid_1's rmse: 1.54298\n",
      "[1600]\ttraining's rmse: 1.49032\tvalid_1's rmse: 1.54301\n",
      "[1700]\ttraining's rmse: 1.48671\tvalid_1's rmse: 1.54293\n",
      "[1800]\ttraining's rmse: 1.48322\tvalid_1's rmse: 1.54293\n",
      "[1900]\ttraining's rmse: 1.47975\tvalid_1's rmse: 1.54296\n",
      "[2000]\ttraining's rmse: 1.4763\tvalid_1's rmse: 1.54293\n",
      "[2100]\ttraining's rmse: 1.47285\tvalid_1's rmse: 1.54295\n",
      "[2200]\ttraining's rmse: 1.46959\tvalid_1's rmse: 1.54297\n",
      "[2300]\ttraining's rmse: 1.46623\tvalid_1's rmse: 1.54296\n",
      "Early stopping, best iteration is:\n",
      "[1745]\ttraining's rmse: 1.48514\tvalid_1's rmse: 1.54287\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60177\tvalid_1's rmse: 1.60908\n",
      "[200]\ttraining's rmse: 1.56886\tvalid_1's rmse: 1.58016\n",
      "[300]\ttraining's rmse: 1.55359\tvalid_1's rmse: 1.56915\n",
      "[400]\ttraining's rmse: 1.54373\tvalid_1's rmse: 1.5638\n",
      "[500]\ttraining's rmse: 1.53639\tvalid_1's rmse: 1.56067\n",
      "[600]\ttraining's rmse: 1.53022\tvalid_1's rmse: 1.55889\n",
      "[700]\ttraining's rmse: 1.52494\tvalid_1's rmse: 1.55783\n",
      "[800]\ttraining's rmse: 1.52013\tvalid_1's rmse: 1.55724\n",
      "[900]\ttraining's rmse: 1.5158\tvalid_1's rmse: 1.55684\n",
      "[1000]\ttraining's rmse: 1.5116\tvalid_1's rmse: 1.55657\n",
      "[1100]\ttraining's rmse: 1.50749\tvalid_1's rmse: 1.55616\n",
      "[1200]\ttraining's rmse: 1.50366\tvalid_1's rmse: 1.55587\n",
      "[1300]\ttraining's rmse: 1.49984\tvalid_1's rmse: 1.55572\n",
      "[1400]\ttraining's rmse: 1.49605\tvalid_1's rmse: 1.55562\n",
      "[1500]\ttraining's rmse: 1.49252\tvalid_1's rmse: 1.55544\n",
      "[1600]\ttraining's rmse: 1.48885\tvalid_1's rmse: 1.55538\n",
      "[1700]\ttraining's rmse: 1.48536\tvalid_1's rmse: 1.55533\n",
      "[1800]\ttraining's rmse: 1.48182\tvalid_1's rmse: 1.55528\n",
      "[1900]\ttraining's rmse: 1.47836\tvalid_1's rmse: 1.55522\n",
      "[2000]\ttraining's rmse: 1.47502\tvalid_1's rmse: 1.55509\n",
      "[2100]\ttraining's rmse: 1.47162\tvalid_1's rmse: 1.55505\n",
      "[2200]\ttraining's rmse: 1.4683\tvalid_1's rmse: 1.55508\n",
      "[2300]\ttraining's rmse: 1.46491\tvalid_1's rmse: 1.55503\n",
      "[2400]\ttraining's rmse: 1.46164\tvalid_1's rmse: 1.55504\n",
      "[2500]\ttraining's rmse: 1.45844\tvalid_1's rmse: 1.55499\n",
      "[2600]\ttraining's rmse: 1.4553\tvalid_1's rmse: 1.55488\n",
      "[2700]\ttraining's rmse: 1.45199\tvalid_1's rmse: 1.55479\n",
      "[2800]\ttraining's rmse: 1.44876\tvalid_1's rmse: 1.55481\n",
      "[2900]\ttraining's rmse: 1.4456\tvalid_1's rmse: 1.55478\n",
      "[3000]\ttraining's rmse: 1.4424\tvalid_1's rmse: 1.55485\n",
      "[3100]\ttraining's rmse: 1.43926\tvalid_1's rmse: 1.55477\n",
      "[3200]\ttraining's rmse: 1.43618\tvalid_1's rmse: 1.55488\n",
      "[3300]\ttraining's rmse: 1.43319\tvalid_1's rmse: 1.55486\n",
      "[3400]\ttraining's rmse: 1.43011\tvalid_1's rmse: 1.55489\n",
      "Early stopping, best iteration is:\n",
      "[2855]\ttraining's rmse: 1.44699\tvalid_1's rmse: 1.55473\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60148\tvalid_1's rmse: 1.6113\n",
      "[200]\ttraining's rmse: 1.56869\tvalid_1's rmse: 1.58219\n",
      "[300]\ttraining's rmse: 1.55354\tvalid_1's rmse: 1.57082\n",
      "[400]\ttraining's rmse: 1.54371\tvalid_1's rmse: 1.5652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 1.53633\tvalid_1's rmse: 1.56192\n",
      "[600]\ttraining's rmse: 1.53025\tvalid_1's rmse: 1.56003\n",
      "[700]\ttraining's rmse: 1.52494\tvalid_1's rmse: 1.55874\n",
      "[800]\ttraining's rmse: 1.52027\tvalid_1's rmse: 1.55794\n",
      "[900]\ttraining's rmse: 1.51582\tvalid_1's rmse: 1.55731\n",
      "[1000]\ttraining's rmse: 1.51166\tvalid_1's rmse: 1.55678\n",
      "[1100]\ttraining's rmse: 1.50769\tvalid_1's rmse: 1.5564\n",
      "[1200]\ttraining's rmse: 1.50375\tvalid_1's rmse: 1.55607\n",
      "[1300]\ttraining's rmse: 1.49996\tvalid_1's rmse: 1.55576\n",
      "[1400]\ttraining's rmse: 1.4962\tvalid_1's rmse: 1.5557\n",
      "[1500]\ttraining's rmse: 1.49258\tvalid_1's rmse: 1.55552\n",
      "[1600]\ttraining's rmse: 1.48914\tvalid_1's rmse: 1.55541\n",
      "[1700]\ttraining's rmse: 1.48567\tvalid_1's rmse: 1.5554\n",
      "[1800]\ttraining's rmse: 1.48211\tvalid_1's rmse: 1.55541\n",
      "[1900]\ttraining's rmse: 1.47871\tvalid_1's rmse: 1.55545\n",
      "[2000]\ttraining's rmse: 1.47527\tvalid_1's rmse: 1.55543\n",
      "[2100]\ttraining's rmse: 1.47187\tvalid_1's rmse: 1.55545\n",
      "[2200]\ttraining's rmse: 1.4686\tvalid_1's rmse: 1.55545\n",
      "[2300]\ttraining's rmse: 1.46531\tvalid_1's rmse: 1.55538\n",
      "Early stopping, best iteration is:\n",
      "[1719]\ttraining's rmse: 1.485\tvalid_1's rmse: 1.55533\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60167\tvalid_1's rmse: 1.60867\n",
      "[200]\ttraining's rmse: 1.56826\tvalid_1's rmse: 1.5816\n",
      "[300]\ttraining's rmse: 1.55286\tvalid_1's rmse: 1.57216\n",
      "[400]\ttraining's rmse: 1.54287\tvalid_1's rmse: 1.5675\n",
      "[500]\ttraining's rmse: 1.53536\tvalid_1's rmse: 1.56491\n",
      "[600]\ttraining's rmse: 1.52908\tvalid_1's rmse: 1.56332\n",
      "[700]\ttraining's rmse: 1.52363\tvalid_1's rmse: 1.56247\n",
      "[800]\ttraining's rmse: 1.51875\tvalid_1's rmse: 1.56182\n",
      "[900]\ttraining's rmse: 1.51437\tvalid_1's rmse: 1.56145\n",
      "[1000]\ttraining's rmse: 1.51008\tvalid_1's rmse: 1.56126\n",
      "[1100]\ttraining's rmse: 1.50608\tvalid_1's rmse: 1.56105\n",
      "[1200]\ttraining's rmse: 1.50231\tvalid_1's rmse: 1.56095\n",
      "[1300]\ttraining's rmse: 1.49852\tvalid_1's rmse: 1.56081\n",
      "[1400]\ttraining's rmse: 1.4948\tvalid_1's rmse: 1.56071\n",
      "[1500]\ttraining's rmse: 1.49121\tvalid_1's rmse: 1.56062\n",
      "[1600]\ttraining's rmse: 1.4876\tvalid_1's rmse: 1.56054\n",
      "[1700]\ttraining's rmse: 1.48397\tvalid_1's rmse: 1.56053\n",
      "[1800]\ttraining's rmse: 1.48037\tvalid_1's rmse: 1.56038\n",
      "[1900]\ttraining's rmse: 1.47704\tvalid_1's rmse: 1.56036\n",
      "[2000]\ttraining's rmse: 1.47361\tvalid_1's rmse: 1.56035\n",
      "[2100]\ttraining's rmse: 1.47027\tvalid_1's rmse: 1.56033\n",
      "[2200]\ttraining's rmse: 1.46696\tvalid_1's rmse: 1.5604\n",
      "[2300]\ttraining's rmse: 1.46366\tvalid_1's rmse: 1.56056\n",
      "[2400]\ttraining's rmse: 1.46046\tvalid_1's rmse: 1.5606\n",
      "[2500]\ttraining's rmse: 1.45736\tvalid_1's rmse: 1.5607\n",
      "[2600]\ttraining's rmse: 1.45419\tvalid_1's rmse: 1.56077\n",
      "Early stopping, best iteration is:\n",
      "[2050]\ttraining's rmse: 1.47197\tvalid_1's rmse: 1.56027\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60488\tvalid_1's rmse: 1.58944\n",
      "[200]\ttraining's rmse: 1.5719\tvalid_1's rmse: 1.56194\n",
      "[300]\ttraining's rmse: 1.55673\tvalid_1's rmse: 1.55208\n",
      "[400]\ttraining's rmse: 1.54694\tvalid_1's rmse: 1.54714\n",
      "[500]\ttraining's rmse: 1.53971\tvalid_1's rmse: 1.54442\n",
      "[600]\ttraining's rmse: 1.53391\tvalid_1's rmse: 1.54284\n",
      "[700]\ttraining's rmse: 1.5289\tvalid_1's rmse: 1.54199\n",
      "[800]\ttraining's rmse: 1.52443\tvalid_1's rmse: 1.54157\n",
      "[900]\ttraining's rmse: 1.52036\tvalid_1's rmse: 1.54133\n",
      "[1000]\ttraining's rmse: 1.51643\tvalid_1's rmse: 1.5411\n",
      "[1100]\ttraining's rmse: 1.51265\tvalid_1's rmse: 1.54101\n",
      "[1200]\ttraining's rmse: 1.50902\tvalid_1's rmse: 1.54076\n",
      "[1300]\ttraining's rmse: 1.50539\tvalid_1's rmse: 1.5406\n",
      "[1400]\ttraining's rmse: 1.50202\tvalid_1's rmse: 1.54049\n",
      "[1500]\ttraining's rmse: 1.49859\tvalid_1's rmse: 1.5404\n",
      "[1600]\ttraining's rmse: 1.4952\tvalid_1's rmse: 1.54035\n",
      "[1700]\ttraining's rmse: 1.49176\tvalid_1's rmse: 1.5403\n",
      "[1800]\ttraining's rmse: 1.48841\tvalid_1's rmse: 1.5403\n",
      "[1900]\ttraining's rmse: 1.48509\tvalid_1's rmse: 1.54022\n",
      "[2000]\ttraining's rmse: 1.48194\tvalid_1's rmse: 1.54025\n",
      "[2100]\ttraining's rmse: 1.47871\tvalid_1's rmse: 1.54026\n",
      "[2200]\ttraining's rmse: 1.47552\tvalid_1's rmse: 1.54025\n",
      "[2300]\ttraining's rmse: 1.47229\tvalid_1's rmse: 1.54022\n",
      "[2400]\ttraining's rmse: 1.4692\tvalid_1's rmse: 1.54033\n",
      "[2500]\ttraining's rmse: 1.46614\tvalid_1's rmse: 1.54044\n",
      "Early stopping, best iteration is:\n",
      "[1930]\ttraining's rmse: 1.48412\tvalid_1's rmse: 1.54017\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59933\tvalid_1's rmse: 1.62483\n",
      "[200]\ttraining's rmse: 1.56666\tvalid_1's rmse: 1.59539\n",
      "[300]\ttraining's rmse: 1.55155\tvalid_1's rmse: 1.58397\n",
      "[400]\ttraining's rmse: 1.54201\tvalid_1's rmse: 1.57825\n",
      "[500]\ttraining's rmse: 1.53485\tvalid_1's rmse: 1.57491\n",
      "[600]\ttraining's rmse: 1.529\tvalid_1's rmse: 1.57301\n",
      "[700]\ttraining's rmse: 1.52402\tvalid_1's rmse: 1.57189\n",
      "[800]\ttraining's rmse: 1.51957\tvalid_1's rmse: 1.57121\n",
      "[900]\ttraining's rmse: 1.51544\tvalid_1's rmse: 1.57083\n",
      "[1000]\ttraining's rmse: 1.51149\tvalid_1's rmse: 1.5703\n",
      "[1100]\ttraining's rmse: 1.50786\tvalid_1's rmse: 1.57021\n",
      "[1200]\ttraining's rmse: 1.50422\tvalid_1's rmse: 1.56992\n",
      "[1300]\ttraining's rmse: 1.50066\tvalid_1's rmse: 1.5698\n",
      "[1400]\ttraining's rmse: 1.49721\tvalid_1's rmse: 1.56971\n",
      "[1500]\ttraining's rmse: 1.49375\tvalid_1's rmse: 1.56959\n",
      "[1600]\ttraining's rmse: 1.49038\tvalid_1's rmse: 1.5697\n",
      "[1700]\ttraining's rmse: 1.4871\tvalid_1's rmse: 1.56966\n",
      "[1800]\ttraining's rmse: 1.48378\tvalid_1's rmse: 1.56957\n",
      "[1900]\ttraining's rmse: 1.48054\tvalid_1's rmse: 1.56953\n",
      "[2000]\ttraining's rmse: 1.47726\tvalid_1's rmse: 1.56944\n",
      "[2100]\ttraining's rmse: 1.47407\tvalid_1's rmse: 1.56949\n",
      "[2200]\ttraining's rmse: 1.47095\tvalid_1's rmse: 1.56938\n",
      "[2300]\ttraining's rmse: 1.46781\tvalid_1's rmse: 1.56944\n",
      "[2400]\ttraining's rmse: 1.46476\tvalid_1's rmse: 1.56952\n",
      "[2500]\ttraining's rmse: 1.46162\tvalid_1's rmse: 1.56956\n",
      "[2600]\ttraining's rmse: 1.45862\tvalid_1's rmse: 1.56947\n",
      "[2700]\ttraining's rmse: 1.4556\tvalid_1's rmse: 1.56944\n",
      "[2800]\ttraining's rmse: 1.45253\tvalid_1's rmse: 1.56936\n",
      "[2900]\ttraining's rmse: 1.44961\tvalid_1's rmse: 1.56948\n",
      "[3000]\ttraining's rmse: 1.44665\tvalid_1's rmse: 1.56947\n",
      "[3100]\ttraining's rmse: 1.44373\tvalid_1's rmse: 1.56954\n",
      "[3200]\ttraining's rmse: 1.44099\tvalid_1's rmse: 1.56962\n",
      "[3300]\ttraining's rmse: 1.43815\tvalid_1's rmse: 1.56972\n",
      "Early stopping, best iteration is:\n",
      "[2779]\ttraining's rmse: 1.45324\tvalid_1's rmse: 1.56932\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60095\tvalid_1's rmse: 1.6133\n",
      "[200]\ttraining's rmse: 1.56812\tvalid_1's rmse: 1.58532\n",
      "[300]\ttraining's rmse: 1.55316\tvalid_1's rmse: 1.57437\n",
      "[400]\ttraining's rmse: 1.54346\tvalid_1's rmse: 1.56876\n",
      "[500]\ttraining's rmse: 1.53631\tvalid_1's rmse: 1.56543\n",
      "[600]\ttraining's rmse: 1.53041\tvalid_1's rmse: 1.56351\n",
      "[700]\ttraining's rmse: 1.52538\tvalid_1's rmse: 1.5623\n",
      "[800]\ttraining's rmse: 1.52083\tvalid_1's rmse: 1.56168\n",
      "[900]\ttraining's rmse: 1.51661\tvalid_1's rmse: 1.56116\n",
      "[1000]\ttraining's rmse: 1.51258\tvalid_1's rmse: 1.56079\n",
      "[1100]\ttraining's rmse: 1.50869\tvalid_1's rmse: 1.56057\n",
      "[1200]\ttraining's rmse: 1.50497\tvalid_1's rmse: 1.5603\n",
      "[1300]\ttraining's rmse: 1.50161\tvalid_1's rmse: 1.56012\n",
      "[1400]\ttraining's rmse: 1.498\tvalid_1's rmse: 1.55996\n",
      "[1500]\ttraining's rmse: 1.49455\tvalid_1's rmse: 1.55979\n",
      "[1600]\ttraining's rmse: 1.49115\tvalid_1's rmse: 1.55971\n",
      "[1700]\ttraining's rmse: 1.48773\tvalid_1's rmse: 1.55973\n",
      "[1800]\ttraining's rmse: 1.4844\tvalid_1's rmse: 1.55959\n",
      "[1900]\ttraining's rmse: 1.48116\tvalid_1's rmse: 1.55955\n",
      "[2000]\ttraining's rmse: 1.47796\tvalid_1's rmse: 1.55963\n",
      "[2100]\ttraining's rmse: 1.47471\tvalid_1's rmse: 1.55948\n",
      "[2200]\ttraining's rmse: 1.47157\tvalid_1's rmse: 1.55956\n",
      "[2300]\ttraining's rmse: 1.46839\tvalid_1's rmse: 1.55957\n",
      "[2400]\ttraining's rmse: 1.46544\tvalid_1's rmse: 1.55956\n",
      "[2500]\ttraining's rmse: 1.46235\tvalid_1's rmse: 1.55965\n",
      "[2600]\ttraining's rmse: 1.45929\tvalid_1's rmse: 1.55967\n",
      "Early stopping, best iteration is:\n",
      "[2098]\ttraining's rmse: 1.47478\tvalid_1's rmse: 1.55948\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60425\tvalid_1's rmse: 1.59343\n",
      "[200]\ttraining's rmse: 1.57123\tvalid_1's rmse: 1.56524\n",
      "[300]\ttraining's rmse: 1.55598\tvalid_1's rmse: 1.55469\n",
      "[400]\ttraining's rmse: 1.54618\tvalid_1's rmse: 1.54947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 1.53899\tvalid_1's rmse: 1.54684\n",
      "[600]\ttraining's rmse: 1.53296\tvalid_1's rmse: 1.54547\n",
      "[700]\ttraining's rmse: 1.52781\tvalid_1's rmse: 1.54474\n",
      "[800]\ttraining's rmse: 1.52328\tvalid_1's rmse: 1.54432\n",
      "[900]\ttraining's rmse: 1.51917\tvalid_1's rmse: 1.54416\n",
      "[1000]\ttraining's rmse: 1.51525\tvalid_1's rmse: 1.54399\n",
      "[1100]\ttraining's rmse: 1.51139\tvalid_1's rmse: 1.54394\n",
      "[1200]\ttraining's rmse: 1.50761\tvalid_1's rmse: 1.54375\n",
      "[1300]\ttraining's rmse: 1.50409\tvalid_1's rmse: 1.54375\n",
      "[1400]\ttraining's rmse: 1.50061\tvalid_1's rmse: 1.54371\n",
      "[1500]\ttraining's rmse: 1.4972\tvalid_1's rmse: 1.54378\n",
      "[1600]\ttraining's rmse: 1.49391\tvalid_1's rmse: 1.54377\n",
      "[1700]\ttraining's rmse: 1.49051\tvalid_1's rmse: 1.54377\n",
      "[1800]\ttraining's rmse: 1.48727\tvalid_1's rmse: 1.54385\n",
      "[1900]\ttraining's rmse: 1.48385\tvalid_1's rmse: 1.54388\n",
      "Early stopping, best iteration is:\n",
      "[1378]\ttraining's rmse: 1.50136\tvalid_1's rmse: 1.54369\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60186\tvalid_1's rmse: 1.60886\n",
      "[200]\ttraining's rmse: 1.56901\tvalid_1's rmse: 1.57999\n",
      "[300]\ttraining's rmse: 1.55392\tvalid_1's rmse: 1.56901\n",
      "[400]\ttraining's rmse: 1.54436\tvalid_1's rmse: 1.56372\n",
      "[500]\ttraining's rmse: 1.53721\tvalid_1's rmse: 1.56078\n",
      "[600]\ttraining's rmse: 1.53145\tvalid_1's rmse: 1.55912\n",
      "[700]\ttraining's rmse: 1.52653\tvalid_1's rmse: 1.55832\n",
      "[800]\ttraining's rmse: 1.52207\tvalid_1's rmse: 1.55768\n",
      "[900]\ttraining's rmse: 1.51794\tvalid_1's rmse: 1.55732\n",
      "[1000]\ttraining's rmse: 1.51391\tvalid_1's rmse: 1.55698\n",
      "[1100]\ttraining's rmse: 1.51004\tvalid_1's rmse: 1.55668\n",
      "[1200]\ttraining's rmse: 1.50629\tvalid_1's rmse: 1.55651\n",
      "[1300]\ttraining's rmse: 1.5027\tvalid_1's rmse: 1.5564\n",
      "[1400]\ttraining's rmse: 1.499\tvalid_1's rmse: 1.55622\n",
      "[1500]\ttraining's rmse: 1.49562\tvalid_1's rmse: 1.55613\n",
      "[1600]\ttraining's rmse: 1.49218\tvalid_1's rmse: 1.55594\n",
      "[1700]\ttraining's rmse: 1.48881\tvalid_1's rmse: 1.55581\n",
      "[1800]\ttraining's rmse: 1.48541\tvalid_1's rmse: 1.55583\n",
      "[1900]\ttraining's rmse: 1.48218\tvalid_1's rmse: 1.55575\n",
      "[2000]\ttraining's rmse: 1.47905\tvalid_1's rmse: 1.55568\n",
      "[2100]\ttraining's rmse: 1.47591\tvalid_1's rmse: 1.55556\n",
      "[2200]\ttraining's rmse: 1.47269\tvalid_1's rmse: 1.55559\n",
      "[2300]\ttraining's rmse: 1.46952\tvalid_1's rmse: 1.55567\n",
      "[2400]\ttraining's rmse: 1.46644\tvalid_1's rmse: 1.55569\n",
      "[2500]\ttraining's rmse: 1.46342\tvalid_1's rmse: 1.5557\n",
      "[2600]\ttraining's rmse: 1.46026\tvalid_1's rmse: 1.55573\n",
      "[2700]\ttraining's rmse: 1.45712\tvalid_1's rmse: 1.55564\n",
      "Early stopping, best iteration is:\n",
      "[2154]\ttraining's rmse: 1.47419\tvalid_1's rmse: 1.55552\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60156\tvalid_1's rmse: 1.6114\n",
      "[200]\ttraining's rmse: 1.56891\tvalid_1's rmse: 1.58244\n",
      "[300]\ttraining's rmse: 1.55395\tvalid_1's rmse: 1.57108\n",
      "[400]\ttraining's rmse: 1.54436\tvalid_1's rmse: 1.56539\n",
      "[500]\ttraining's rmse: 1.53728\tvalid_1's rmse: 1.56217\n",
      "[600]\ttraining's rmse: 1.53151\tvalid_1's rmse: 1.56013\n",
      "[700]\ttraining's rmse: 1.52654\tvalid_1's rmse: 1.55899\n",
      "[800]\ttraining's rmse: 1.52211\tvalid_1's rmse: 1.5582\n",
      "[900]\ttraining's rmse: 1.51791\tvalid_1's rmse: 1.55757\n",
      "[1000]\ttraining's rmse: 1.51414\tvalid_1's rmse: 1.55698\n",
      "[1100]\ttraining's rmse: 1.51044\tvalid_1's rmse: 1.55663\n",
      "[1200]\ttraining's rmse: 1.50694\tvalid_1's rmse: 1.55648\n",
      "[1300]\ttraining's rmse: 1.50338\tvalid_1's rmse: 1.55633\n",
      "[1400]\ttraining's rmse: 1.49982\tvalid_1's rmse: 1.5563\n",
      "[1500]\ttraining's rmse: 1.49642\tvalid_1's rmse: 1.55615\n",
      "[1600]\ttraining's rmse: 1.49313\tvalid_1's rmse: 1.55606\n",
      "[1700]\ttraining's rmse: 1.48975\tvalid_1's rmse: 1.55593\n",
      "[1800]\ttraining's rmse: 1.48637\tvalid_1's rmse: 1.55588\n",
      "[1900]\ttraining's rmse: 1.48322\tvalid_1's rmse: 1.55578\n",
      "[2000]\ttraining's rmse: 1.47995\tvalid_1's rmse: 1.55576\n",
      "[2100]\ttraining's rmse: 1.47681\tvalid_1's rmse: 1.55577\n",
      "[2200]\ttraining's rmse: 1.47371\tvalid_1's rmse: 1.55564\n",
      "[2300]\ttraining's rmse: 1.47056\tvalid_1's rmse: 1.55564\n",
      "[2400]\ttraining's rmse: 1.46755\tvalid_1's rmse: 1.55564\n",
      "[2500]\ttraining's rmse: 1.46453\tvalid_1's rmse: 1.55577\n",
      "[2600]\ttraining's rmse: 1.4615\tvalid_1's rmse: 1.55576\n",
      "[2700]\ttraining's rmse: 1.45845\tvalid_1's rmse: 1.5557\n",
      "[2800]\ttraining's rmse: 1.45548\tvalid_1's rmse: 1.55571\n",
      "Early stopping, best iteration is:\n",
      "[2210]\ttraining's rmse: 1.47339\tvalid_1's rmse: 1.5556\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60179\tvalid_1's rmse: 1.60846\n",
      "[200]\ttraining's rmse: 1.56849\tvalid_1's rmse: 1.58162\n",
      "[300]\ttraining's rmse: 1.5533\tvalid_1's rmse: 1.57209\n",
      "[400]\ttraining's rmse: 1.54357\tvalid_1's rmse: 1.56748\n",
      "[500]\ttraining's rmse: 1.53639\tvalid_1's rmse: 1.56478\n",
      "[600]\ttraining's rmse: 1.53047\tvalid_1's rmse: 1.56339\n",
      "[700]\ttraining's rmse: 1.5253\tvalid_1's rmse: 1.56244\n",
      "[800]\ttraining's rmse: 1.52081\tvalid_1's rmse: 1.56187\n",
      "[900]\ttraining's rmse: 1.5167\tvalid_1's rmse: 1.56153\n",
      "[1000]\ttraining's rmse: 1.5127\tvalid_1's rmse: 1.56128\n",
      "[1100]\ttraining's rmse: 1.50893\tvalid_1's rmse: 1.56116\n",
      "[1200]\ttraining's rmse: 1.50531\tvalid_1's rmse: 1.56113\n",
      "[1300]\ttraining's rmse: 1.50173\tvalid_1's rmse: 1.56102\n",
      "[1400]\ttraining's rmse: 1.49823\tvalid_1's rmse: 1.56111\n",
      "[1500]\ttraining's rmse: 1.49479\tvalid_1's rmse: 1.5611\n",
      "[1600]\ttraining's rmse: 1.4913\tvalid_1's rmse: 1.56105\n",
      "[1700]\ttraining's rmse: 1.48786\tvalid_1's rmse: 1.561\n",
      "[1800]\ttraining's rmse: 1.48449\tvalid_1's rmse: 1.561\n",
      "[1900]\ttraining's rmse: 1.48126\tvalid_1's rmse: 1.56098\n",
      "[2000]\ttraining's rmse: 1.4779\tvalid_1's rmse: 1.56106\n",
      "[2100]\ttraining's rmse: 1.47465\tvalid_1's rmse: 1.56115\n",
      "[2200]\ttraining's rmse: 1.47151\tvalid_1's rmse: 1.56115\n",
      "[2300]\ttraining's rmse: 1.46841\tvalid_1's rmse: 1.56122\n",
      "[2400]\ttraining's rmse: 1.46538\tvalid_1's rmse: 1.56134\n",
      "Early stopping, best iteration is:\n",
      "[1827]\ttraining's rmse: 1.48364\tvalid_1's rmse: 1.56094\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60495\tvalid_1's rmse: 1.5897\n",
      "[200]\ttraining's rmse: 1.57203\tvalid_1's rmse: 1.5623\n",
      "[300]\ttraining's rmse: 1.55685\tvalid_1's rmse: 1.55229\n",
      "[400]\ttraining's rmse: 1.54744\tvalid_1's rmse: 1.54721\n",
      "[500]\ttraining's rmse: 1.54052\tvalid_1's rmse: 1.54469\n",
      "[600]\ttraining's rmse: 1.53495\tvalid_1's rmse: 1.54333\n",
      "[700]\ttraining's rmse: 1.53016\tvalid_1's rmse: 1.54249\n",
      "[800]\ttraining's rmse: 1.52583\tvalid_1's rmse: 1.54192\n",
      "[900]\ttraining's rmse: 1.5219\tvalid_1's rmse: 1.54158\n",
      "[1000]\ttraining's rmse: 1.51804\tvalid_1's rmse: 1.54127\n",
      "[1100]\ttraining's rmse: 1.51434\tvalid_1's rmse: 1.54108\n",
      "[1200]\ttraining's rmse: 1.5108\tvalid_1's rmse: 1.5409\n",
      "[1300]\ttraining's rmse: 1.5073\tvalid_1's rmse: 1.54077\n",
      "[1400]\ttraining's rmse: 1.50395\tvalid_1's rmse: 1.54068\n",
      "[1500]\ttraining's rmse: 1.50059\tvalid_1's rmse: 1.54051\n",
      "[1600]\ttraining's rmse: 1.49734\tvalid_1's rmse: 1.54034\n",
      "[1700]\ttraining's rmse: 1.49412\tvalid_1's rmse: 1.54028\n",
      "[1800]\ttraining's rmse: 1.49084\tvalid_1's rmse: 1.54037\n",
      "[1900]\ttraining's rmse: 1.48763\tvalid_1's rmse: 1.54043\n",
      "[2000]\ttraining's rmse: 1.48452\tvalid_1's rmse: 1.5405\n",
      "[2100]\ttraining's rmse: 1.4814\tvalid_1's rmse: 1.54058\n",
      "[2200]\ttraining's rmse: 1.47838\tvalid_1's rmse: 1.54064\n",
      "Early stopping, best iteration is:\n",
      "[1699]\ttraining's rmse: 1.49416\tvalid_1's rmse: 1.54028\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59936\tvalid_1's rmse: 1.62495\n",
      "[200]\ttraining's rmse: 1.56673\tvalid_1's rmse: 1.59551\n",
      "[300]\ttraining's rmse: 1.55175\tvalid_1's rmse: 1.58421\n",
      "[400]\ttraining's rmse: 1.54245\tvalid_1's rmse: 1.57868\n",
      "[500]\ttraining's rmse: 1.5355\tvalid_1's rmse: 1.57554\n",
      "[600]\ttraining's rmse: 1.52988\tvalid_1's rmse: 1.5736\n",
      "[700]\ttraining's rmse: 1.52504\tvalid_1's rmse: 1.57244\n",
      "[800]\ttraining's rmse: 1.5207\tvalid_1's rmse: 1.57201\n",
      "[900]\ttraining's rmse: 1.51673\tvalid_1's rmse: 1.57148\n",
      "[1000]\ttraining's rmse: 1.51293\tvalid_1's rmse: 1.57109\n",
      "[1100]\ttraining's rmse: 1.50939\tvalid_1's rmse: 1.57081\n",
      "[1200]\ttraining's rmse: 1.50589\tvalid_1's rmse: 1.5705\n",
      "[1300]\ttraining's rmse: 1.5025\tvalid_1's rmse: 1.57033\n",
      "[1400]\ttraining's rmse: 1.49915\tvalid_1's rmse: 1.57016\n",
      "[1500]\ttraining's rmse: 1.49595\tvalid_1's rmse: 1.57008\n",
      "[1600]\ttraining's rmse: 1.49266\tvalid_1's rmse: 1.57002\n",
      "[1700]\ttraining's rmse: 1.48957\tvalid_1's rmse: 1.56995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800]\ttraining's rmse: 1.48633\tvalid_1's rmse: 1.56989\n",
      "[1900]\ttraining's rmse: 1.48329\tvalid_1's rmse: 1.56984\n",
      "[2000]\ttraining's rmse: 1.48011\tvalid_1's rmse: 1.56975\n",
      "[2100]\ttraining's rmse: 1.47686\tvalid_1's rmse: 1.56963\n",
      "[2200]\ttraining's rmse: 1.47381\tvalid_1's rmse: 1.56965\n",
      "[2300]\ttraining's rmse: 1.47067\tvalid_1's rmse: 1.56965\n",
      "[2400]\ttraining's rmse: 1.46764\tvalid_1's rmse: 1.56966\n",
      "[2500]\ttraining's rmse: 1.46459\tvalid_1's rmse: 1.56977\n",
      "[2600]\ttraining's rmse: 1.46166\tvalid_1's rmse: 1.56976\n",
      "[2700]\ttraining's rmse: 1.45879\tvalid_1's rmse: 1.56979\n",
      "[2800]\ttraining's rmse: 1.45579\tvalid_1's rmse: 1.56988\n",
      "Early stopping, best iteration is:\n",
      "[2241]\ttraining's rmse: 1.47251\tvalid_1's rmse: 1.5696\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60112\tvalid_1's rmse: 1.61341\n",
      "[200]\ttraining's rmse: 1.56839\tvalid_1's rmse: 1.58558\n",
      "[300]\ttraining's rmse: 1.55337\tvalid_1's rmse: 1.57452\n",
      "[400]\ttraining's rmse: 1.54394\tvalid_1's rmse: 1.56879\n",
      "[500]\ttraining's rmse: 1.53699\tvalid_1's rmse: 1.56563\n",
      "[600]\ttraining's rmse: 1.53136\tvalid_1's rmse: 1.5637\n",
      "[700]\ttraining's rmse: 1.52656\tvalid_1's rmse: 1.56268\n",
      "[800]\ttraining's rmse: 1.52223\tvalid_1's rmse: 1.56204\n",
      "[900]\ttraining's rmse: 1.51819\tvalid_1's rmse: 1.56158\n",
      "[1000]\ttraining's rmse: 1.51433\tvalid_1's rmse: 1.56127\n",
      "[1100]\ttraining's rmse: 1.51062\tvalid_1's rmse: 1.5611\n",
      "[1200]\ttraining's rmse: 1.50694\tvalid_1's rmse: 1.56082\n",
      "[1300]\ttraining's rmse: 1.50358\tvalid_1's rmse: 1.56057\n",
      "[1400]\ttraining's rmse: 1.50013\tvalid_1's rmse: 1.56033\n",
      "[1500]\ttraining's rmse: 1.49678\tvalid_1's rmse: 1.56021\n",
      "[1600]\ttraining's rmse: 1.49347\tvalid_1's rmse: 1.56012\n",
      "[1700]\ttraining's rmse: 1.49015\tvalid_1's rmse: 1.56007\n",
      "[1800]\ttraining's rmse: 1.4869\tvalid_1's rmse: 1.55992\n",
      "[1900]\ttraining's rmse: 1.48369\tvalid_1's rmse: 1.55996\n",
      "[2000]\ttraining's rmse: 1.48049\tvalid_1's rmse: 1.55995\n",
      "[2100]\ttraining's rmse: 1.47737\tvalid_1's rmse: 1.55992\n",
      "[2200]\ttraining's rmse: 1.47421\tvalid_1's rmse: 1.56\n",
      "[2300]\ttraining's rmse: 1.47104\tvalid_1's rmse: 1.55999\n",
      "[2400]\ttraining's rmse: 1.46807\tvalid_1's rmse: 1.56\n",
      "Early stopping, best iteration is:\n",
      "[1825]\ttraining's rmse: 1.48606\tvalid_1's rmse: 1.55989\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60439\tvalid_1's rmse: 1.59344\n",
      "[200]\ttraining's rmse: 1.57145\tvalid_1's rmse: 1.56526\n",
      "[300]\ttraining's rmse: 1.55622\tvalid_1's rmse: 1.55479\n",
      "[400]\ttraining's rmse: 1.54668\tvalid_1's rmse: 1.54978\n",
      "[500]\ttraining's rmse: 1.5396\tvalid_1's rmse: 1.54732\n",
      "[600]\ttraining's rmse: 1.53387\tvalid_1's rmse: 1.54612\n",
      "[700]\ttraining's rmse: 1.52893\tvalid_1's rmse: 1.54538\n",
      "[800]\ttraining's rmse: 1.52461\tvalid_1's rmse: 1.54498\n",
      "[900]\ttraining's rmse: 1.52068\tvalid_1's rmse: 1.54484\n",
      "[1000]\ttraining's rmse: 1.51695\tvalid_1's rmse: 1.54468\n",
      "[1100]\ttraining's rmse: 1.51322\tvalid_1's rmse: 1.54453\n",
      "[1200]\ttraining's rmse: 1.50954\tvalid_1's rmse: 1.5444\n",
      "[1300]\ttraining's rmse: 1.50606\tvalid_1's rmse: 1.54436\n",
      "[1400]\ttraining's rmse: 1.50269\tvalid_1's rmse: 1.54441\n",
      "[1500]\ttraining's rmse: 1.49938\tvalid_1's rmse: 1.54439\n",
      "[1600]\ttraining's rmse: 1.49601\tvalid_1's rmse: 1.54442\n",
      "[1700]\ttraining's rmse: 1.49274\tvalid_1's rmse: 1.5444\n",
      "[1800]\ttraining's rmse: 1.48945\tvalid_1's rmse: 1.54445\n",
      "Early stopping, best iteration is:\n",
      "[1284]\ttraining's rmse: 1.50666\tvalid_1's rmse: 1.54433\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60194\tvalid_1's rmse: 1.60901\n",
      "[200]\ttraining's rmse: 1.56916\tvalid_1's rmse: 1.58009\n",
      "[300]\ttraining's rmse: 1.5542\tvalid_1's rmse: 1.56922\n",
      "[400]\ttraining's rmse: 1.54487\tvalid_1's rmse: 1.564\n",
      "[500]\ttraining's rmse: 1.53784\tvalid_1's rmse: 1.5613\n",
      "[600]\ttraining's rmse: 1.53226\tvalid_1's rmse: 1.55979\n",
      "[700]\ttraining's rmse: 1.52748\tvalid_1's rmse: 1.55895\n",
      "[800]\ttraining's rmse: 1.52314\tvalid_1's rmse: 1.55833\n",
      "[900]\ttraining's rmse: 1.51923\tvalid_1's rmse: 1.55794\n",
      "[1000]\ttraining's rmse: 1.51549\tvalid_1's rmse: 1.55778\n",
      "[1100]\ttraining's rmse: 1.51186\tvalid_1's rmse: 1.55759\n",
      "[1200]\ttraining's rmse: 1.50839\tvalid_1's rmse: 1.55744\n",
      "[1300]\ttraining's rmse: 1.50486\tvalid_1's rmse: 1.55733\n",
      "[1400]\ttraining's rmse: 1.50136\tvalid_1's rmse: 1.55727\n",
      "[1500]\ttraining's rmse: 1.49808\tvalid_1's rmse: 1.55709\n",
      "[1600]\ttraining's rmse: 1.49476\tvalid_1's rmse: 1.557\n",
      "[1700]\ttraining's rmse: 1.49134\tvalid_1's rmse: 1.55698\n",
      "[1800]\ttraining's rmse: 1.48793\tvalid_1's rmse: 1.55695\n",
      "[1900]\ttraining's rmse: 1.48482\tvalid_1's rmse: 1.55681\n",
      "[2000]\ttraining's rmse: 1.48161\tvalid_1's rmse: 1.55675\n",
      "[2100]\ttraining's rmse: 1.47849\tvalid_1's rmse: 1.55672\n",
      "[2200]\ttraining's rmse: 1.47534\tvalid_1's rmse: 1.5567\n",
      "[2300]\ttraining's rmse: 1.4722\tvalid_1's rmse: 1.5568\n",
      "[2400]\ttraining's rmse: 1.46911\tvalid_1's rmse: 1.55682\n",
      "[2500]\ttraining's rmse: 1.46611\tvalid_1's rmse: 1.55702\n",
      "[2600]\ttraining's rmse: 1.46304\tvalid_1's rmse: 1.55706\n",
      "[2700]\ttraining's rmse: 1.46\tvalid_1's rmse: 1.55709\n",
      "Early stopping, best iteration is:\n",
      "[2167]\ttraining's rmse: 1.47641\tvalid_1's rmse: 1.55664\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60167\tvalid_1's rmse: 1.61148\n",
      "[200]\ttraining's rmse: 1.56898\tvalid_1's rmse: 1.58239\n",
      "[300]\ttraining's rmse: 1.55403\tvalid_1's rmse: 1.57105\n",
      "[400]\ttraining's rmse: 1.54473\tvalid_1's rmse: 1.56562\n",
      "[500]\ttraining's rmse: 1.5378\tvalid_1's rmse: 1.56258\n",
      "[600]\ttraining's rmse: 1.53224\tvalid_1's rmse: 1.56061\n",
      "[700]\ttraining's rmse: 1.5275\tvalid_1's rmse: 1.55952\n",
      "[800]\ttraining's rmse: 1.52333\tvalid_1's rmse: 1.55881\n",
      "[900]\ttraining's rmse: 1.51933\tvalid_1's rmse: 1.55834\n",
      "[1000]\ttraining's rmse: 1.51563\tvalid_1's rmse: 1.55802\n",
      "[1100]\ttraining's rmse: 1.51209\tvalid_1's rmse: 1.55774\n",
      "[1200]\ttraining's rmse: 1.50866\tvalid_1's rmse: 1.55741\n",
      "[1300]\ttraining's rmse: 1.50509\tvalid_1's rmse: 1.55726\n",
      "[1400]\ttraining's rmse: 1.50174\tvalid_1's rmse: 1.55719\n",
      "[1500]\ttraining's rmse: 1.49835\tvalid_1's rmse: 1.55714\n",
      "[1600]\ttraining's rmse: 1.49514\tvalid_1's rmse: 1.55708\n",
      "[1700]\ttraining's rmse: 1.49188\tvalid_1's rmse: 1.557\n",
      "[1800]\ttraining's rmse: 1.48865\tvalid_1's rmse: 1.55692\n",
      "[1900]\ttraining's rmse: 1.48546\tvalid_1's rmse: 1.55678\n",
      "[2000]\ttraining's rmse: 1.48218\tvalid_1's rmse: 1.5567\n",
      "[2100]\ttraining's rmse: 1.47916\tvalid_1's rmse: 1.55658\n",
      "[2200]\ttraining's rmse: 1.47614\tvalid_1's rmse: 1.55655\n",
      "[2300]\ttraining's rmse: 1.47308\tvalid_1's rmse: 1.55657\n",
      "[2400]\ttraining's rmse: 1.47006\tvalid_1's rmse: 1.55648\n",
      "[2500]\ttraining's rmse: 1.4672\tvalid_1's rmse: 1.55647\n",
      "[2600]\ttraining's rmse: 1.46424\tvalid_1's rmse: 1.55651\n",
      "[2700]\ttraining's rmse: 1.46123\tvalid_1's rmse: 1.55653\n",
      "[2800]\ttraining's rmse: 1.45828\tvalid_1's rmse: 1.55646\n",
      "[2900]\ttraining's rmse: 1.45538\tvalid_1's rmse: 1.55646\n",
      "[3000]\ttraining's rmse: 1.4525\tvalid_1's rmse: 1.55657\n",
      "Early stopping, best iteration is:\n",
      "[2429]\ttraining's rmse: 1.46918\tvalid_1's rmse: 1.55642\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60184\tvalid_1's rmse: 1.60858\n",
      "[200]\ttraining's rmse: 1.56867\tvalid_1's rmse: 1.58139\n",
      "[300]\ttraining's rmse: 1.55349\tvalid_1's rmse: 1.57179\n",
      "[400]\ttraining's rmse: 1.54403\tvalid_1's rmse: 1.56736\n",
      "[500]\ttraining's rmse: 1.53707\tvalid_1's rmse: 1.56485\n",
      "[600]\ttraining's rmse: 1.53142\tvalid_1's rmse: 1.56343\n",
      "[700]\ttraining's rmse: 1.52651\tvalid_1's rmse: 1.56262\n",
      "[800]\ttraining's rmse: 1.52219\tvalid_1's rmse: 1.56208\n",
      "[900]\ttraining's rmse: 1.51816\tvalid_1's rmse: 1.56179\n",
      "[1000]\ttraining's rmse: 1.51433\tvalid_1's rmse: 1.56164\n",
      "[1100]\ttraining's rmse: 1.51066\tvalid_1's rmse: 1.56166\n",
      "[1200]\ttraining's rmse: 1.5072\tvalid_1's rmse: 1.5615\n",
      "[1300]\ttraining's rmse: 1.50375\tvalid_1's rmse: 1.56142\n",
      "[1400]\ttraining's rmse: 1.50043\tvalid_1's rmse: 1.56138\n",
      "[1500]\ttraining's rmse: 1.49709\tvalid_1's rmse: 1.56131\n",
      "[1600]\ttraining's rmse: 1.49376\tvalid_1's rmse: 1.56131\n",
      "[1700]\ttraining's rmse: 1.49033\tvalid_1's rmse: 1.5613\n",
      "[1800]\ttraining's rmse: 1.48709\tvalid_1's rmse: 1.5614\n",
      "[1900]\ttraining's rmse: 1.48394\tvalid_1's rmse: 1.56139\n",
      "[2000]\ttraining's rmse: 1.48076\tvalid_1's rmse: 1.56135\n",
      "[2100]\ttraining's rmse: 1.47764\tvalid_1's rmse: 1.56123\n",
      "[2200]\ttraining's rmse: 1.47455\tvalid_1's rmse: 1.56122\n",
      "[2300]\ttraining's rmse: 1.47149\tvalid_1's rmse: 1.56132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2400]\ttraining's rmse: 1.46855\tvalid_1's rmse: 1.56134\n",
      "[2500]\ttraining's rmse: 1.46561\tvalid_1's rmse: 1.56142\n",
      "[2600]\ttraining's rmse: 1.46264\tvalid_1's rmse: 1.56156\n",
      "[2700]\ttraining's rmse: 1.45958\tvalid_1's rmse: 1.56169\n",
      "Early stopping, best iteration is:\n",
      "[2180]\ttraining's rmse: 1.47519\tvalid_1's rmse: 1.56117\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60814\tvalid_1's rmse: 1.59359\n",
      "[200]\ttraining's rmse: 1.57515\tvalid_1's rmse: 1.56711\n",
      "[300]\ttraining's rmse: 1.55886\tvalid_1's rmse: 1.55708\n",
      "[400]\ttraining's rmse: 1.54774\tvalid_1's rmse: 1.55229\n",
      "[500]\ttraining's rmse: 1.53869\tvalid_1's rmse: 1.54943\n",
      "[600]\ttraining's rmse: 1.53108\tvalid_1's rmse: 1.54752\n",
      "[700]\ttraining's rmse: 1.52423\tvalid_1's rmse: 1.54632\n",
      "[800]\ttraining's rmse: 1.51812\tvalid_1's rmse: 1.54565\n",
      "[900]\ttraining's rmse: 1.51247\tvalid_1's rmse: 1.54489\n",
      "[1000]\ttraining's rmse: 1.507\tvalid_1's rmse: 1.54439\n",
      "[1100]\ttraining's rmse: 1.50182\tvalid_1's rmse: 1.54404\n",
      "[1200]\ttraining's rmse: 1.49679\tvalid_1's rmse: 1.54379\n",
      "[1300]\ttraining's rmse: 1.49177\tvalid_1's rmse: 1.54345\n",
      "[1400]\ttraining's rmse: 1.48708\tvalid_1's rmse: 1.54319\n",
      "[1500]\ttraining's rmse: 1.48236\tvalid_1's rmse: 1.54305\n",
      "[1600]\ttraining's rmse: 1.47771\tvalid_1's rmse: 1.54297\n",
      "[1700]\ttraining's rmse: 1.47316\tvalid_1's rmse: 1.5428\n",
      "[1800]\ttraining's rmse: 1.46869\tvalid_1's rmse: 1.54266\n",
      "[1900]\ttraining's rmse: 1.46422\tvalid_1's rmse: 1.54262\n",
      "[2000]\ttraining's rmse: 1.45985\tvalid_1's rmse: 1.54241\n",
      "[2100]\ttraining's rmse: 1.45557\tvalid_1's rmse: 1.54242\n",
      "[2200]\ttraining's rmse: 1.45125\tvalid_1's rmse: 1.54235\n",
      "[2300]\ttraining's rmse: 1.447\tvalid_1's rmse: 1.54236\n",
      "[2400]\ttraining's rmse: 1.44278\tvalid_1's rmse: 1.54243\n",
      "[2500]\ttraining's rmse: 1.43873\tvalid_1's rmse: 1.54252\n",
      "[2600]\ttraining's rmse: 1.43463\tvalid_1's rmse: 1.54254\n",
      "[2700]\ttraining's rmse: 1.43065\tvalid_1's rmse: 1.54256\n",
      "[2800]\ttraining's rmse: 1.42663\tvalid_1's rmse: 1.54259\n",
      "[2900]\ttraining's rmse: 1.42275\tvalid_1's rmse: 1.54254\n",
      "Early stopping, best iteration is:\n",
      "[2329]\ttraining's rmse: 1.44577\tvalid_1's rmse: 1.5423\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60423\tvalid_1's rmse: 1.6236\n",
      "[200]\ttraining's rmse: 1.57141\tvalid_1's rmse: 1.5954\n",
      "[300]\ttraining's rmse: 1.55532\tvalid_1's rmse: 1.58405\n",
      "[400]\ttraining's rmse: 1.54415\tvalid_1's rmse: 1.57785\n",
      "[500]\ttraining's rmse: 1.53519\tvalid_1's rmse: 1.57427\n",
      "[600]\ttraining's rmse: 1.52741\tvalid_1's rmse: 1.57197\n",
      "[700]\ttraining's rmse: 1.5206\tvalid_1's rmse: 1.57036\n",
      "[800]\ttraining's rmse: 1.51435\tvalid_1's rmse: 1.56941\n",
      "[900]\ttraining's rmse: 1.50851\tvalid_1's rmse: 1.56878\n",
      "[1000]\ttraining's rmse: 1.50302\tvalid_1's rmse: 1.56831\n",
      "[1100]\ttraining's rmse: 1.49784\tvalid_1's rmse: 1.56798\n",
      "[1200]\ttraining's rmse: 1.49281\tvalid_1's rmse: 1.56755\n",
      "[1300]\ttraining's rmse: 1.48799\tvalid_1's rmse: 1.56735\n",
      "[1400]\ttraining's rmse: 1.4831\tvalid_1's rmse: 1.56729\n",
      "[1500]\ttraining's rmse: 1.47847\tvalid_1's rmse: 1.56729\n",
      "[1600]\ttraining's rmse: 1.4739\tvalid_1's rmse: 1.56728\n",
      "[1700]\ttraining's rmse: 1.46947\tvalid_1's rmse: 1.56717\n",
      "[1800]\ttraining's rmse: 1.46505\tvalid_1's rmse: 1.56696\n",
      "[1900]\ttraining's rmse: 1.4606\tvalid_1's rmse: 1.56693\n",
      "[2000]\ttraining's rmse: 1.45635\tvalid_1's rmse: 1.56695\n",
      "[2100]\ttraining's rmse: 1.45216\tvalid_1's rmse: 1.56695\n",
      "[2200]\ttraining's rmse: 1.44795\tvalid_1's rmse: 1.56681\n",
      "[2300]\ttraining's rmse: 1.44375\tvalid_1's rmse: 1.56682\n",
      "[2400]\ttraining's rmse: 1.43961\tvalid_1's rmse: 1.56691\n",
      "[2500]\ttraining's rmse: 1.43562\tvalid_1's rmse: 1.56695\n",
      "[2600]\ttraining's rmse: 1.43146\tvalid_1's rmse: 1.56699\n",
      "[2700]\ttraining's rmse: 1.42749\tvalid_1's rmse: 1.56693\n",
      "[2800]\ttraining's rmse: 1.42348\tvalid_1's rmse: 1.56702\n",
      "Early stopping, best iteration is:\n",
      "[2239]\ttraining's rmse: 1.44626\tvalid_1's rmse: 1.56678\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60338\tvalid_1's rmse: 1.6306\n",
      "[200]\ttraining's rmse: 1.57054\tvalid_1's rmse: 1.60217\n",
      "[300]\ttraining's rmse: 1.55432\tvalid_1's rmse: 1.59082\n",
      "[400]\ttraining's rmse: 1.54322\tvalid_1's rmse: 1.58485\n",
      "[500]\ttraining's rmse: 1.53431\tvalid_1's rmse: 1.58117\n",
      "[600]\ttraining's rmse: 1.5266\tvalid_1's rmse: 1.57874\n",
      "[700]\ttraining's rmse: 1.51952\tvalid_1's rmse: 1.57727\n",
      "[800]\ttraining's rmse: 1.51333\tvalid_1's rmse: 1.57634\n",
      "[900]\ttraining's rmse: 1.50758\tvalid_1's rmse: 1.57569\n",
      "[1000]\ttraining's rmse: 1.50204\tvalid_1's rmse: 1.57508\n",
      "[1100]\ttraining's rmse: 1.49685\tvalid_1's rmse: 1.57468\n",
      "[1200]\ttraining's rmse: 1.49187\tvalid_1's rmse: 1.57428\n",
      "[1300]\ttraining's rmse: 1.48694\tvalid_1's rmse: 1.57399\n",
      "[1400]\ttraining's rmse: 1.48225\tvalid_1's rmse: 1.57384\n",
      "[1500]\ttraining's rmse: 1.47751\tvalid_1's rmse: 1.57368\n",
      "[1600]\ttraining's rmse: 1.47282\tvalid_1's rmse: 1.57346\n",
      "[1700]\ttraining's rmse: 1.46833\tvalid_1's rmse: 1.57337\n",
      "[1800]\ttraining's rmse: 1.46395\tvalid_1's rmse: 1.57321\n",
      "[1900]\ttraining's rmse: 1.45961\tvalid_1's rmse: 1.57313\n",
      "[2000]\ttraining's rmse: 1.4553\tvalid_1's rmse: 1.57302\n",
      "[2100]\ttraining's rmse: 1.45083\tvalid_1's rmse: 1.57284\n",
      "[2200]\ttraining's rmse: 1.44658\tvalid_1's rmse: 1.57273\n",
      "[2300]\ttraining's rmse: 1.44238\tvalid_1's rmse: 1.57263\n",
      "[2400]\ttraining's rmse: 1.43828\tvalid_1's rmse: 1.57258\n",
      "[2500]\ttraining's rmse: 1.43415\tvalid_1's rmse: 1.5725\n",
      "[2600]\ttraining's rmse: 1.43019\tvalid_1's rmse: 1.57253\n",
      "[2700]\ttraining's rmse: 1.426\tvalid_1's rmse: 1.57248\n",
      "[2800]\ttraining's rmse: 1.42208\tvalid_1's rmse: 1.57241\n",
      "[2900]\ttraining's rmse: 1.41816\tvalid_1's rmse: 1.57238\n",
      "[3000]\ttraining's rmse: 1.41423\tvalid_1's rmse: 1.57235\n",
      "[3100]\ttraining's rmse: 1.41028\tvalid_1's rmse: 1.57235\n",
      "[3200]\ttraining's rmse: 1.40649\tvalid_1's rmse: 1.57232\n",
      "[3300]\ttraining's rmse: 1.40271\tvalid_1's rmse: 1.57226\n",
      "[3400]\ttraining's rmse: 1.39887\tvalid_1's rmse: 1.57231\n",
      "[3500]\ttraining's rmse: 1.39513\tvalid_1's rmse: 1.57239\n",
      "[3600]\ttraining's rmse: 1.39138\tvalid_1's rmse: 1.57233\n",
      "[3700]\ttraining's rmse: 1.38763\tvalid_1's rmse: 1.5723\n",
      "[3800]\ttraining's rmse: 1.38389\tvalid_1's rmse: 1.57229\n",
      "[3900]\ttraining's rmse: 1.38033\tvalid_1's rmse: 1.57238\n",
      "[4000]\ttraining's rmse: 1.37668\tvalid_1's rmse: 1.57236\n",
      "[4100]\ttraining's rmse: 1.37299\tvalid_1's rmse: 1.57227\n",
      "[4200]\ttraining's rmse: 1.3693\tvalid_1's rmse: 1.57231\n",
      "[4300]\ttraining's rmse: 1.36565\tvalid_1's rmse: 1.57242\n",
      "[4400]\ttraining's rmse: 1.36205\tvalid_1's rmse: 1.57244\n",
      "[4500]\ttraining's rmse: 1.35855\tvalid_1's rmse: 1.57249\n",
      "[4600]\ttraining's rmse: 1.35508\tvalid_1's rmse: 1.57251\n",
      "Early stopping, best iteration is:\n",
      "[4084]\ttraining's rmse: 1.37359\tvalid_1's rmse: 1.57223\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60789\tvalid_1's rmse: 1.59573\n",
      "[200]\ttraining's rmse: 1.57502\tvalid_1's rmse: 1.5682\n",
      "[300]\ttraining's rmse: 1.55884\tvalid_1's rmse: 1.55781\n",
      "[400]\ttraining's rmse: 1.54766\tvalid_1's rmse: 1.55252\n",
      "[500]\ttraining's rmse: 1.53871\tvalid_1's rmse: 1.54933\n",
      "[600]\ttraining's rmse: 1.53085\tvalid_1's rmse: 1.54722\n",
      "[700]\ttraining's rmse: 1.52377\tvalid_1's rmse: 1.5459\n",
      "[800]\ttraining's rmse: 1.51752\tvalid_1's rmse: 1.54509\n",
      "[900]\ttraining's rmse: 1.51175\tvalid_1's rmse: 1.5445\n",
      "[1000]\ttraining's rmse: 1.50645\tvalid_1's rmse: 1.54405\n",
      "[1100]\ttraining's rmse: 1.50127\tvalid_1's rmse: 1.54377\n",
      "[1200]\ttraining's rmse: 1.49632\tvalid_1's rmse: 1.54358\n",
      "[1300]\ttraining's rmse: 1.49155\tvalid_1's rmse: 1.54343\n",
      "[1400]\ttraining's rmse: 1.48682\tvalid_1's rmse: 1.54323\n",
      "[1500]\ttraining's rmse: 1.48221\tvalid_1's rmse: 1.54319\n",
      "[1600]\ttraining's rmse: 1.47775\tvalid_1's rmse: 1.54317\n",
      "[1700]\ttraining's rmse: 1.47317\tvalid_1's rmse: 1.54312\n",
      "[1800]\ttraining's rmse: 1.46863\tvalid_1's rmse: 1.54315\n",
      "[1900]\ttraining's rmse: 1.4643\tvalid_1's rmse: 1.5431\n",
      "[2000]\ttraining's rmse: 1.46001\tvalid_1's rmse: 1.54307\n",
      "[2100]\ttraining's rmse: 1.45591\tvalid_1's rmse: 1.543\n",
      "[2200]\ttraining's rmse: 1.45169\tvalid_1's rmse: 1.54296\n",
      "[2300]\ttraining's rmse: 1.44753\tvalid_1's rmse: 1.54292\n",
      "[2400]\ttraining's rmse: 1.44346\tvalid_1's rmse: 1.54287\n",
      "[2500]\ttraining's rmse: 1.43942\tvalid_1's rmse: 1.5428\n",
      "[2600]\ttraining's rmse: 1.43537\tvalid_1's rmse: 1.54275\n",
      "[2700]\ttraining's rmse: 1.43139\tvalid_1's rmse: 1.54273\n",
      "[2800]\ttraining's rmse: 1.4274\tvalid_1's rmse: 1.54274\n",
      "[2900]\ttraining's rmse: 1.42351\tvalid_1's rmse: 1.54284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttraining's rmse: 1.41966\tvalid_1's rmse: 1.54285\n",
      "[3100]\ttraining's rmse: 1.4157\tvalid_1's rmse: 1.54286\n",
      "[3200]\ttraining's rmse: 1.4118\tvalid_1's rmse: 1.54291\n",
      "[3300]\ttraining's rmse: 1.40787\tvalid_1's rmse: 1.54304\n",
      "Early stopping, best iteration is:\n",
      "[2757]\ttraining's rmse: 1.42915\tvalid_1's rmse: 1.54269\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60728\tvalid_1's rmse: 1.59993\n",
      "[200]\ttraining's rmse: 1.57417\tvalid_1's rmse: 1.57345\n",
      "[300]\ttraining's rmse: 1.55778\tvalid_1's rmse: 1.56344\n",
      "[400]\ttraining's rmse: 1.5466\tvalid_1's rmse: 1.5585\n",
      "[500]\ttraining's rmse: 1.53751\tvalid_1's rmse: 1.55552\n",
      "[600]\ttraining's rmse: 1.52976\tvalid_1's rmse: 1.55383\n",
      "[700]\ttraining's rmse: 1.52289\tvalid_1's rmse: 1.55276\n",
      "[800]\ttraining's rmse: 1.51665\tvalid_1's rmse: 1.55192\n",
      "[900]\ttraining's rmse: 1.5109\tvalid_1's rmse: 1.55156\n",
      "[1000]\ttraining's rmse: 1.50547\tvalid_1's rmse: 1.55136\n",
      "[1100]\ttraining's rmse: 1.50033\tvalid_1's rmse: 1.55108\n",
      "[1200]\ttraining's rmse: 1.49536\tvalid_1's rmse: 1.55089\n",
      "[1300]\ttraining's rmse: 1.49038\tvalid_1's rmse: 1.5507\n",
      "[1400]\ttraining's rmse: 1.48559\tvalid_1's rmse: 1.5506\n",
      "[1500]\ttraining's rmse: 1.48086\tvalid_1's rmse: 1.55045\n",
      "[1600]\ttraining's rmse: 1.47632\tvalid_1's rmse: 1.55028\n",
      "[1700]\ttraining's rmse: 1.47181\tvalid_1's rmse: 1.55017\n",
      "[1800]\ttraining's rmse: 1.46735\tvalid_1's rmse: 1.55002\n",
      "[1900]\ttraining's rmse: 1.46291\tvalid_1's rmse: 1.54999\n",
      "[2000]\ttraining's rmse: 1.45851\tvalid_1's rmse: 1.54979\n",
      "[2100]\ttraining's rmse: 1.45424\tvalid_1's rmse: 1.54964\n",
      "[2200]\ttraining's rmse: 1.44994\tvalid_1's rmse: 1.54971\n",
      "[2300]\ttraining's rmse: 1.44582\tvalid_1's rmse: 1.54979\n",
      "[2400]\ttraining's rmse: 1.44165\tvalid_1's rmse: 1.54969\n",
      "[2500]\ttraining's rmse: 1.43752\tvalid_1's rmse: 1.54975\n",
      "[2600]\ttraining's rmse: 1.43352\tvalid_1's rmse: 1.54981\n",
      "Early stopping, best iteration is:\n",
      "[2093]\ttraining's rmse: 1.45452\tvalid_1's rmse: 1.54962\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.606\tvalid_1's rmse: 1.61179\n",
      "[200]\ttraining's rmse: 1.57316\tvalid_1's rmse: 1.58253\n",
      "[300]\ttraining's rmse: 1.55696\tvalid_1's rmse: 1.57085\n",
      "[400]\ttraining's rmse: 1.54582\tvalid_1's rmse: 1.56467\n",
      "[500]\ttraining's rmse: 1.53683\tvalid_1's rmse: 1.56105\n",
      "[600]\ttraining's rmse: 1.52909\tvalid_1's rmse: 1.55859\n",
      "[700]\ttraining's rmse: 1.52221\tvalid_1's rmse: 1.55716\n",
      "[800]\ttraining's rmse: 1.51602\tvalid_1's rmse: 1.55608\n",
      "[900]\ttraining's rmse: 1.5102\tvalid_1's rmse: 1.5556\n",
      "[1000]\ttraining's rmse: 1.50477\tvalid_1's rmse: 1.55501\n",
      "[1100]\ttraining's rmse: 1.49944\tvalid_1's rmse: 1.55457\n",
      "[1200]\ttraining's rmse: 1.4944\tvalid_1's rmse: 1.55417\n",
      "[1300]\ttraining's rmse: 1.48943\tvalid_1's rmse: 1.55395\n",
      "[1400]\ttraining's rmse: 1.48468\tvalid_1's rmse: 1.55371\n",
      "[1500]\ttraining's rmse: 1.48006\tvalid_1's rmse: 1.55358\n",
      "[1600]\ttraining's rmse: 1.47561\tvalid_1's rmse: 1.5534\n",
      "[1700]\ttraining's rmse: 1.47105\tvalid_1's rmse: 1.55334\n",
      "[1800]\ttraining's rmse: 1.4667\tvalid_1's rmse: 1.55317\n",
      "[1900]\ttraining's rmse: 1.46232\tvalid_1's rmse: 1.55299\n",
      "[2000]\ttraining's rmse: 1.45792\tvalid_1's rmse: 1.55282\n",
      "[2100]\ttraining's rmse: 1.45361\tvalid_1's rmse: 1.55268\n",
      "[2200]\ttraining's rmse: 1.44945\tvalid_1's rmse: 1.5527\n",
      "[2300]\ttraining's rmse: 1.44509\tvalid_1's rmse: 1.55255\n",
      "[2400]\ttraining's rmse: 1.44102\tvalid_1's rmse: 1.5523\n",
      "[2500]\ttraining's rmse: 1.43697\tvalid_1's rmse: 1.5523\n",
      "[2600]\ttraining's rmse: 1.4329\tvalid_1's rmse: 1.55218\n",
      "[2700]\ttraining's rmse: 1.42887\tvalid_1's rmse: 1.55215\n",
      "[2800]\ttraining's rmse: 1.42479\tvalid_1's rmse: 1.55221\n",
      "[2900]\ttraining's rmse: 1.42091\tvalid_1's rmse: 1.5522\n",
      "[3000]\ttraining's rmse: 1.41682\tvalid_1's rmse: 1.55218\n",
      "[3100]\ttraining's rmse: 1.41313\tvalid_1's rmse: 1.55209\n",
      "[3200]\ttraining's rmse: 1.40922\tvalid_1's rmse: 1.5521\n",
      "[3300]\ttraining's rmse: 1.40536\tvalid_1's rmse: 1.55208\n",
      "[3400]\ttraining's rmse: 1.4014\tvalid_1's rmse: 1.55208\n",
      "[3500]\ttraining's rmse: 1.39756\tvalid_1's rmse: 1.55207\n",
      "[3600]\ttraining's rmse: 1.39364\tvalid_1's rmse: 1.55204\n",
      "[3700]\ttraining's rmse: 1.38986\tvalid_1's rmse: 1.55204\n",
      "[3800]\ttraining's rmse: 1.38606\tvalid_1's rmse: 1.55195\n",
      "[3900]\ttraining's rmse: 1.38226\tvalid_1's rmse: 1.55194\n",
      "[4000]\ttraining's rmse: 1.37845\tvalid_1's rmse: 1.55193\n",
      "[4100]\ttraining's rmse: 1.37483\tvalid_1's rmse: 1.55194\n",
      "[4200]\ttraining's rmse: 1.3711\tvalid_1's rmse: 1.55201\n",
      "[4300]\ttraining's rmse: 1.36752\tvalid_1's rmse: 1.55193\n",
      "[4400]\ttraining's rmse: 1.36395\tvalid_1's rmse: 1.55204\n",
      "Early stopping, best iteration is:\n",
      "[3815]\ttraining's rmse: 1.38544\tvalid_1's rmse: 1.55188\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60414\tvalid_1's rmse: 1.62307\n",
      "[200]\ttraining's rmse: 1.57138\tvalid_1's rmse: 1.59514\n",
      "[300]\ttraining's rmse: 1.55541\tvalid_1's rmse: 1.58411\n",
      "[400]\ttraining's rmse: 1.5445\tvalid_1's rmse: 1.57828\n",
      "[500]\ttraining's rmse: 1.5356\tvalid_1's rmse: 1.57451\n",
      "[600]\ttraining's rmse: 1.52787\tvalid_1's rmse: 1.57213\n",
      "[700]\ttraining's rmse: 1.52115\tvalid_1's rmse: 1.57084\n",
      "[800]\ttraining's rmse: 1.51486\tvalid_1's rmse: 1.56994\n",
      "[900]\ttraining's rmse: 1.50921\tvalid_1's rmse: 1.56924\n",
      "[1000]\ttraining's rmse: 1.5036\tvalid_1's rmse: 1.56888\n",
      "[1100]\ttraining's rmse: 1.49825\tvalid_1's rmse: 1.56852\n",
      "[1200]\ttraining's rmse: 1.49317\tvalid_1's rmse: 1.56837\n",
      "[1300]\ttraining's rmse: 1.48825\tvalid_1's rmse: 1.56813\n",
      "[1400]\ttraining's rmse: 1.48348\tvalid_1's rmse: 1.56785\n",
      "[1500]\ttraining's rmse: 1.47886\tvalid_1's rmse: 1.56779\n",
      "[1600]\ttraining's rmse: 1.47426\tvalid_1's rmse: 1.56768\n",
      "[1700]\ttraining's rmse: 1.46992\tvalid_1's rmse: 1.5675\n",
      "[1800]\ttraining's rmse: 1.46557\tvalid_1's rmse: 1.56735\n",
      "[1900]\ttraining's rmse: 1.46109\tvalid_1's rmse: 1.5673\n",
      "[2000]\ttraining's rmse: 1.45686\tvalid_1's rmse: 1.56728\n",
      "[2100]\ttraining's rmse: 1.45259\tvalid_1's rmse: 1.56726\n",
      "[2200]\ttraining's rmse: 1.4483\tvalid_1's rmse: 1.56728\n",
      "[2300]\ttraining's rmse: 1.44416\tvalid_1's rmse: 1.56732\n",
      "[2400]\ttraining's rmse: 1.44006\tvalid_1's rmse: 1.56724\n",
      "[2500]\ttraining's rmse: 1.43605\tvalid_1's rmse: 1.56712\n",
      "[2600]\ttraining's rmse: 1.43193\tvalid_1's rmse: 1.56716\n",
      "[2700]\ttraining's rmse: 1.42784\tvalid_1's rmse: 1.56706\n",
      "[2800]\ttraining's rmse: 1.42387\tvalid_1's rmse: 1.56714\n",
      "[2900]\ttraining's rmse: 1.41981\tvalid_1's rmse: 1.56717\n",
      "[3000]\ttraining's rmse: 1.41591\tvalid_1's rmse: 1.56731\n",
      "[3100]\ttraining's rmse: 1.41209\tvalid_1's rmse: 1.56733\n",
      "[3200]\ttraining's rmse: 1.40834\tvalid_1's rmse: 1.56723\n",
      "Early stopping, best iteration is:\n",
      "[2687]\ttraining's rmse: 1.42835\tvalid_1's rmse: 1.56701\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60559\tvalid_1's rmse: 1.61141\n",
      "[200]\ttraining's rmse: 1.57237\tvalid_1's rmse: 1.58533\n",
      "[300]\ttraining's rmse: 1.55602\tvalid_1's rmse: 1.57597\n",
      "[400]\ttraining's rmse: 1.54478\tvalid_1's rmse: 1.57119\n",
      "[500]\ttraining's rmse: 1.53576\tvalid_1's rmse: 1.56806\n",
      "[600]\ttraining's rmse: 1.52787\tvalid_1's rmse: 1.56639\n",
      "[700]\ttraining's rmse: 1.52097\tvalid_1's rmse: 1.56534\n",
      "[800]\ttraining's rmse: 1.5146\tvalid_1's rmse: 1.56476\n",
      "[900]\ttraining's rmse: 1.50894\tvalid_1's rmse: 1.56435\n",
      "[1000]\ttraining's rmse: 1.50352\tvalid_1's rmse: 1.56423\n",
      "[1100]\ttraining's rmse: 1.4982\tvalid_1's rmse: 1.56421\n",
      "[1200]\ttraining's rmse: 1.4932\tvalid_1's rmse: 1.56395\n",
      "[1300]\ttraining's rmse: 1.48839\tvalid_1's rmse: 1.56393\n",
      "[1400]\ttraining's rmse: 1.48361\tvalid_1's rmse: 1.56366\n",
      "[1500]\ttraining's rmse: 1.47891\tvalid_1's rmse: 1.56363\n",
      "[1600]\ttraining's rmse: 1.47434\tvalid_1's rmse: 1.56354\n",
      "[1700]\ttraining's rmse: 1.4697\tvalid_1's rmse: 1.56344\n",
      "[1800]\ttraining's rmse: 1.46518\tvalid_1's rmse: 1.56351\n",
      "[1900]\ttraining's rmse: 1.46078\tvalid_1's rmse: 1.56356\n",
      "[2000]\ttraining's rmse: 1.4564\tvalid_1's rmse: 1.56353\n",
      "[2100]\ttraining's rmse: 1.45214\tvalid_1's rmse: 1.56367\n",
      "[2200]\ttraining's rmse: 1.4479\tvalid_1's rmse: 1.56385\n",
      "[2300]\ttraining's rmse: 1.44372\tvalid_1's rmse: 1.56391\n",
      "Early stopping, best iteration is:\n",
      "[1774]\ttraining's rmse: 1.46635\tvalid_1's rmse: 1.56341\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60478\tvalid_1's rmse: 1.58846\n",
      "[200]\ttraining's rmse: 1.57152\tvalid_1's rmse: 1.56086\n",
      "[300]\ttraining's rmse: 1.55616\tvalid_1's rmse: 1.55084\n",
      "[400]\ttraining's rmse: 1.54627\tvalid_1's rmse: 1.54625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 1.53888\tvalid_1's rmse: 1.54392\n",
      "[600]\ttraining's rmse: 1.53279\tvalid_1's rmse: 1.5426\n",
      "[700]\ttraining's rmse: 1.5275\tvalid_1's rmse: 1.54156\n",
      "[800]\ttraining's rmse: 1.52282\tvalid_1's rmse: 1.54097\n",
      "[900]\ttraining's rmse: 1.51851\tvalid_1's rmse: 1.54074\n",
      "[1000]\ttraining's rmse: 1.5144\tvalid_1's rmse: 1.5405\n",
      "[1100]\ttraining's rmse: 1.51033\tvalid_1's rmse: 1.54041\n",
      "[1200]\ttraining's rmse: 1.50638\tvalid_1's rmse: 1.54025\n",
      "[1300]\ttraining's rmse: 1.50266\tvalid_1's rmse: 1.54016\n",
      "[1400]\ttraining's rmse: 1.49901\tvalid_1's rmse: 1.54002\n",
      "[1500]\ttraining's rmse: 1.49543\tvalid_1's rmse: 1.54001\n",
      "[1600]\ttraining's rmse: 1.49179\tvalid_1's rmse: 1.5401\n",
      "[1700]\ttraining's rmse: 1.48837\tvalid_1's rmse: 1.54006\n",
      "[1800]\ttraining's rmse: 1.48493\tvalid_1's rmse: 1.54\n",
      "[1900]\ttraining's rmse: 1.48148\tvalid_1's rmse: 1.53994\n",
      "[2000]\ttraining's rmse: 1.47821\tvalid_1's rmse: 1.53996\n",
      "[2100]\ttraining's rmse: 1.47501\tvalid_1's rmse: 1.53998\n",
      "[2200]\ttraining's rmse: 1.47175\tvalid_1's rmse: 1.54013\n",
      "[2300]\ttraining's rmse: 1.46844\tvalid_1's rmse: 1.54026\n",
      "[2400]\ttraining's rmse: 1.46519\tvalid_1's rmse: 1.54035\n",
      "[2500]\ttraining's rmse: 1.46202\tvalid_1's rmse: 1.54047\n",
      "Early stopping, best iteration is:\n",
      "[1933]\ttraining's rmse: 1.48036\tvalid_1's rmse: 1.5399\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60038\tvalid_1's rmse: 1.61987\n",
      "[200]\ttraining's rmse: 1.56762\tvalid_1's rmse: 1.59119\n",
      "[300]\ttraining's rmse: 1.55251\tvalid_1's rmse: 1.57992\n",
      "[400]\ttraining's rmse: 1.54273\tvalid_1's rmse: 1.57401\n",
      "[500]\ttraining's rmse: 1.5355\tvalid_1's rmse: 1.57066\n",
      "[600]\ttraining's rmse: 1.52939\tvalid_1's rmse: 1.56854\n",
      "[700]\ttraining's rmse: 1.52421\tvalid_1's rmse: 1.56715\n",
      "[800]\ttraining's rmse: 1.51948\tvalid_1's rmse: 1.56619\n",
      "[900]\ttraining's rmse: 1.51514\tvalid_1's rmse: 1.56549\n",
      "[1000]\ttraining's rmse: 1.51102\tvalid_1's rmse: 1.56516\n",
      "[1100]\ttraining's rmse: 1.50711\tvalid_1's rmse: 1.5648\n",
      "[1200]\ttraining's rmse: 1.5032\tvalid_1's rmse: 1.5644\n",
      "[1300]\ttraining's rmse: 1.49948\tvalid_1's rmse: 1.56427\n",
      "[1400]\ttraining's rmse: 1.49583\tvalid_1's rmse: 1.56425\n",
      "[1500]\ttraining's rmse: 1.4923\tvalid_1's rmse: 1.56409\n",
      "[1600]\ttraining's rmse: 1.48883\tvalid_1's rmse: 1.56393\n",
      "[1700]\ttraining's rmse: 1.48531\tvalid_1's rmse: 1.56394\n",
      "[1800]\ttraining's rmse: 1.48182\tvalid_1's rmse: 1.5637\n",
      "[1900]\ttraining's rmse: 1.47849\tvalid_1's rmse: 1.56367\n",
      "[2000]\ttraining's rmse: 1.47528\tvalid_1's rmse: 1.56367\n",
      "[2100]\ttraining's rmse: 1.4721\tvalid_1's rmse: 1.56376\n",
      "[2200]\ttraining's rmse: 1.4687\tvalid_1's rmse: 1.56374\n",
      "[2300]\ttraining's rmse: 1.46553\tvalid_1's rmse: 1.56361\n",
      "[2400]\ttraining's rmse: 1.46234\tvalid_1's rmse: 1.56355\n",
      "[2500]\ttraining's rmse: 1.45913\tvalid_1's rmse: 1.56362\n",
      "[2600]\ttraining's rmse: 1.45595\tvalid_1's rmse: 1.56354\n",
      "[2700]\ttraining's rmse: 1.45283\tvalid_1's rmse: 1.56358\n",
      "[2800]\ttraining's rmse: 1.44977\tvalid_1's rmse: 1.56363\n",
      "[2900]\ttraining's rmse: 1.44672\tvalid_1's rmse: 1.56358\n",
      "[3000]\ttraining's rmse: 1.4436\tvalid_1's rmse: 1.56349\n",
      "[3100]\ttraining's rmse: 1.44043\tvalid_1's rmse: 1.56342\n",
      "[3200]\ttraining's rmse: 1.43731\tvalid_1's rmse: 1.5636\n",
      "[3300]\ttraining's rmse: 1.43426\tvalid_1's rmse: 1.56359\n",
      "[3400]\ttraining's rmse: 1.43134\tvalid_1's rmse: 1.56361\n",
      "[3500]\ttraining's rmse: 1.42838\tvalid_1's rmse: 1.56369\n",
      "[3600]\ttraining's rmse: 1.42541\tvalid_1's rmse: 1.56366\n",
      "Early stopping, best iteration is:\n",
      "[3096]\ttraining's rmse: 1.44057\tvalid_1's rmse: 1.56338\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59946\tvalid_1's rmse: 1.62602\n",
      "[200]\ttraining's rmse: 1.56669\tvalid_1's rmse: 1.59677\n",
      "[300]\ttraining's rmse: 1.55155\tvalid_1's rmse: 1.58578\n",
      "[400]\ttraining's rmse: 1.54167\tvalid_1's rmse: 1.58017\n",
      "[500]\ttraining's rmse: 1.53429\tvalid_1's rmse: 1.57675\n",
      "[600]\ttraining's rmse: 1.52821\tvalid_1's rmse: 1.57475\n",
      "[700]\ttraining's rmse: 1.52288\tvalid_1's rmse: 1.57346\n",
      "[800]\ttraining's rmse: 1.51818\tvalid_1's rmse: 1.57276\n",
      "[900]\ttraining's rmse: 1.51386\tvalid_1's rmse: 1.57225\n",
      "[1000]\ttraining's rmse: 1.50976\tvalid_1's rmse: 1.57189\n",
      "[1100]\ttraining's rmse: 1.50579\tvalid_1's rmse: 1.57152\n",
      "[1200]\ttraining's rmse: 1.50203\tvalid_1's rmse: 1.57133\n",
      "[1300]\ttraining's rmse: 1.49839\tvalid_1's rmse: 1.57118\n",
      "[1400]\ttraining's rmse: 1.49479\tvalid_1's rmse: 1.57109\n",
      "[1500]\ttraining's rmse: 1.49122\tvalid_1's rmse: 1.57085\n",
      "[1600]\ttraining's rmse: 1.48774\tvalid_1's rmse: 1.57073\n",
      "[1700]\ttraining's rmse: 1.48421\tvalid_1's rmse: 1.57058\n",
      "[1800]\ttraining's rmse: 1.48083\tvalid_1's rmse: 1.57038\n",
      "[1900]\ttraining's rmse: 1.47752\tvalid_1's rmse: 1.5703\n",
      "[2000]\ttraining's rmse: 1.47417\tvalid_1's rmse: 1.57013\n",
      "[2100]\ttraining's rmse: 1.47093\tvalid_1's rmse: 1.57\n",
      "[2200]\ttraining's rmse: 1.46772\tvalid_1's rmse: 1.57001\n",
      "[2300]\ttraining's rmse: 1.46446\tvalid_1's rmse: 1.57003\n",
      "[2400]\ttraining's rmse: 1.4613\tvalid_1's rmse: 1.56998\n",
      "[2500]\ttraining's rmse: 1.45805\tvalid_1's rmse: 1.57001\n",
      "[2600]\ttraining's rmse: 1.45498\tvalid_1's rmse: 1.56989\n",
      "[2700]\ttraining's rmse: 1.45182\tvalid_1's rmse: 1.56987\n",
      "[2800]\ttraining's rmse: 1.4487\tvalid_1's rmse: 1.56977\n",
      "[2900]\ttraining's rmse: 1.44567\tvalid_1's rmse: 1.5697\n",
      "[3000]\ttraining's rmse: 1.44258\tvalid_1's rmse: 1.56959\n",
      "[3100]\ttraining's rmse: 1.43954\tvalid_1's rmse: 1.56961\n",
      "[3200]\ttraining's rmse: 1.43654\tvalid_1's rmse: 1.56963\n",
      "[3300]\ttraining's rmse: 1.43364\tvalid_1's rmse: 1.56958\n",
      "[3400]\ttraining's rmse: 1.43074\tvalid_1's rmse: 1.56948\n",
      "[3500]\ttraining's rmse: 1.42772\tvalid_1's rmse: 1.56957\n",
      "[3600]\ttraining's rmse: 1.42489\tvalid_1's rmse: 1.56965\n",
      "[3700]\ttraining's rmse: 1.422\tvalid_1's rmse: 1.56966\n",
      "[3800]\ttraining's rmse: 1.41924\tvalid_1's rmse: 1.56979\n",
      "[3900]\ttraining's rmse: 1.41651\tvalid_1's rmse: 1.56984\n",
      "[4000]\ttraining's rmse: 1.41364\tvalid_1's rmse: 1.56986\n",
      "Early stopping, best iteration is:\n",
      "[3420]\ttraining's rmse: 1.43013\tvalid_1's rmse: 1.56943\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60399\tvalid_1's rmse: 1.59267\n",
      "[200]\ttraining's rmse: 1.57106\tvalid_1's rmse: 1.56444\n",
      "[300]\ttraining's rmse: 1.55579\tvalid_1's rmse: 1.55354\n",
      "[400]\ttraining's rmse: 1.5459\tvalid_1's rmse: 1.54832\n",
      "[500]\ttraining's rmse: 1.53848\tvalid_1's rmse: 1.54511\n",
      "[600]\ttraining's rmse: 1.53239\tvalid_1's rmse: 1.54351\n",
      "[700]\ttraining's rmse: 1.52711\tvalid_1's rmse: 1.54249\n",
      "[800]\ttraining's rmse: 1.52232\tvalid_1's rmse: 1.54177\n",
      "[900]\ttraining's rmse: 1.51798\tvalid_1's rmse: 1.54125\n",
      "[1000]\ttraining's rmse: 1.51391\tvalid_1's rmse: 1.54104\n",
      "[1100]\ttraining's rmse: 1.51001\tvalid_1's rmse: 1.54084\n",
      "[1200]\ttraining's rmse: 1.50613\tvalid_1's rmse: 1.54064\n",
      "[1300]\ttraining's rmse: 1.50242\tvalid_1's rmse: 1.54038\n",
      "[1400]\ttraining's rmse: 1.49875\tvalid_1's rmse: 1.54036\n",
      "[1500]\ttraining's rmse: 1.49525\tvalid_1's rmse: 1.54029\n",
      "[1600]\ttraining's rmse: 1.49168\tvalid_1's rmse: 1.54028\n",
      "[1700]\ttraining's rmse: 1.48818\tvalid_1's rmse: 1.54026\n",
      "[1800]\ttraining's rmse: 1.48474\tvalid_1's rmse: 1.54042\n",
      "[1900]\ttraining's rmse: 1.48135\tvalid_1's rmse: 1.54036\n",
      "[2000]\ttraining's rmse: 1.47792\tvalid_1's rmse: 1.54031\n",
      "[2100]\ttraining's rmse: 1.47473\tvalid_1's rmse: 1.54044\n",
      "[2200]\ttraining's rmse: 1.47161\tvalid_1's rmse: 1.5404\n",
      "[2300]\ttraining's rmse: 1.46834\tvalid_1's rmse: 1.54039\n",
      "Early stopping, best iteration is:\n",
      "[1727]\ttraining's rmse: 1.48733\tvalid_1's rmse: 1.54024\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60356\tvalid_1's rmse: 1.59601\n",
      "[200]\ttraining's rmse: 1.57049\tvalid_1's rmse: 1.56864\n",
      "[300]\ttraining's rmse: 1.55503\tvalid_1's rmse: 1.55826\n",
      "[400]\ttraining's rmse: 1.54524\tvalid_1's rmse: 1.55362\n",
      "[500]\ttraining's rmse: 1.53786\tvalid_1's rmse: 1.55095\n",
      "[600]\ttraining's rmse: 1.53169\tvalid_1's rmse: 1.54936\n",
      "[700]\ttraining's rmse: 1.52636\tvalid_1's rmse: 1.54841\n",
      "[800]\ttraining's rmse: 1.52164\tvalid_1's rmse: 1.54794\n",
      "[900]\ttraining's rmse: 1.51727\tvalid_1's rmse: 1.54767\n",
      "[1000]\ttraining's rmse: 1.51316\tvalid_1's rmse: 1.54751\n",
      "[1100]\ttraining's rmse: 1.5091\tvalid_1's rmse: 1.54728\n",
      "[1200]\ttraining's rmse: 1.50523\tvalid_1's rmse: 1.54708\n",
      "[1300]\ttraining's rmse: 1.50139\tvalid_1's rmse: 1.54692\n",
      "[1400]\ttraining's rmse: 1.4978\tvalid_1's rmse: 1.54689\n",
      "[1500]\ttraining's rmse: 1.49419\tvalid_1's rmse: 1.54674\n",
      "[1600]\ttraining's rmse: 1.49066\tvalid_1's rmse: 1.5468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\ttraining's rmse: 1.48721\tvalid_1's rmse: 1.54676\n",
      "[1800]\ttraining's rmse: 1.48377\tvalid_1's rmse: 1.54684\n",
      "[1900]\ttraining's rmse: 1.48037\tvalid_1's rmse: 1.54689\n",
      "[2000]\ttraining's rmse: 1.47709\tvalid_1's rmse: 1.54677\n",
      "[2100]\ttraining's rmse: 1.4738\tvalid_1's rmse: 1.54675\n",
      "[2200]\ttraining's rmse: 1.47058\tvalid_1's rmse: 1.54685\n",
      "[2300]\ttraining's rmse: 1.46738\tvalid_1's rmse: 1.54689\n",
      "[2400]\ttraining's rmse: 1.46407\tvalid_1's rmse: 1.5469\n",
      "[2500]\ttraining's rmse: 1.46094\tvalid_1's rmse: 1.54699\n",
      "[2600]\ttraining's rmse: 1.45774\tvalid_1's rmse: 1.54701\n",
      "Early stopping, best iteration is:\n",
      "[2078]\ttraining's rmse: 1.47452\tvalid_1's rmse: 1.54668\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.6022\tvalid_1's rmse: 1.6075\n",
      "[200]\ttraining's rmse: 1.56949\tvalid_1's rmse: 1.57742\n",
      "[300]\ttraining's rmse: 1.55441\tvalid_1's rmse: 1.56566\n",
      "[400]\ttraining's rmse: 1.54459\tvalid_1's rmse: 1.55941\n",
      "[500]\ttraining's rmse: 1.53738\tvalid_1's rmse: 1.55575\n",
      "[600]\ttraining's rmse: 1.53133\tvalid_1's rmse: 1.55359\n",
      "[700]\ttraining's rmse: 1.5261\tvalid_1's rmse: 1.55219\n",
      "[800]\ttraining's rmse: 1.52139\tvalid_1's rmse: 1.55143\n",
      "[900]\ttraining's rmse: 1.51696\tvalid_1's rmse: 1.55098\n",
      "[1000]\ttraining's rmse: 1.51284\tvalid_1's rmse: 1.55064\n",
      "[1100]\ttraining's rmse: 1.5088\tvalid_1's rmse: 1.55023\n",
      "[1200]\ttraining's rmse: 1.50495\tvalid_1's rmse: 1.54991\n",
      "[1300]\ttraining's rmse: 1.50119\tvalid_1's rmse: 1.54955\n",
      "[1400]\ttraining's rmse: 1.49757\tvalid_1's rmse: 1.54925\n",
      "[1500]\ttraining's rmse: 1.49398\tvalid_1's rmse: 1.54911\n",
      "[1600]\ttraining's rmse: 1.4906\tvalid_1's rmse: 1.54905\n",
      "[1700]\ttraining's rmse: 1.48707\tvalid_1's rmse: 1.549\n",
      "[1800]\ttraining's rmse: 1.48364\tvalid_1's rmse: 1.54882\n",
      "[1900]\ttraining's rmse: 1.4803\tvalid_1's rmse: 1.54863\n",
      "[2000]\ttraining's rmse: 1.477\tvalid_1's rmse: 1.5487\n",
      "[2100]\ttraining's rmse: 1.47369\tvalid_1's rmse: 1.54866\n",
      "[2200]\ttraining's rmse: 1.4704\tvalid_1's rmse: 1.54862\n",
      "[2300]\ttraining's rmse: 1.46703\tvalid_1's rmse: 1.54843\n",
      "[2400]\ttraining's rmse: 1.4638\tvalid_1's rmse: 1.54833\n",
      "[2500]\ttraining's rmse: 1.4606\tvalid_1's rmse: 1.54844\n",
      "[2600]\ttraining's rmse: 1.45742\tvalid_1's rmse: 1.54842\n",
      "[2700]\ttraining's rmse: 1.45429\tvalid_1's rmse: 1.54843\n",
      "[2800]\ttraining's rmse: 1.45127\tvalid_1's rmse: 1.54845\n",
      "[2900]\ttraining's rmse: 1.44819\tvalid_1's rmse: 1.54839\n",
      "Early stopping, best iteration is:\n",
      "[2386]\ttraining's rmse: 1.46423\tvalid_1's rmse: 1.54831\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60042\tvalid_1's rmse: 1.61825\n",
      "[200]\ttraining's rmse: 1.56776\tvalid_1's rmse: 1.5895\n",
      "[300]\ttraining's rmse: 1.55263\tvalid_1's rmse: 1.57831\n",
      "[400]\ttraining's rmse: 1.54289\tvalid_1's rmse: 1.57274\n",
      "[500]\ttraining's rmse: 1.53553\tvalid_1's rmse: 1.5693\n",
      "[600]\ttraining's rmse: 1.5295\tvalid_1's rmse: 1.5675\n",
      "[700]\ttraining's rmse: 1.52432\tvalid_1's rmse: 1.56629\n",
      "[800]\ttraining's rmse: 1.51966\tvalid_1's rmse: 1.56553\n",
      "[900]\ttraining's rmse: 1.51545\tvalid_1's rmse: 1.56502\n",
      "[1000]\ttraining's rmse: 1.51137\tvalid_1's rmse: 1.56464\n",
      "[1100]\ttraining's rmse: 1.50731\tvalid_1's rmse: 1.5644\n",
      "[1200]\ttraining's rmse: 1.50355\tvalid_1's rmse: 1.56413\n",
      "[1300]\ttraining's rmse: 1.49985\tvalid_1's rmse: 1.56391\n",
      "[1400]\ttraining's rmse: 1.4961\tvalid_1's rmse: 1.56382\n",
      "[1500]\ttraining's rmse: 1.49263\tvalid_1's rmse: 1.56382\n",
      "[1600]\ttraining's rmse: 1.48908\tvalid_1's rmse: 1.5636\n",
      "[1700]\ttraining's rmse: 1.48555\tvalid_1's rmse: 1.56354\n",
      "[1800]\ttraining's rmse: 1.48206\tvalid_1's rmse: 1.5634\n",
      "[1900]\ttraining's rmse: 1.47861\tvalid_1's rmse: 1.56341\n",
      "[2000]\ttraining's rmse: 1.47532\tvalid_1's rmse: 1.56328\n",
      "[2100]\ttraining's rmse: 1.47213\tvalid_1's rmse: 1.56326\n",
      "[2200]\ttraining's rmse: 1.46882\tvalid_1's rmse: 1.56313\n",
      "[2300]\ttraining's rmse: 1.46566\tvalid_1's rmse: 1.5631\n",
      "[2400]\ttraining's rmse: 1.46257\tvalid_1's rmse: 1.56313\n",
      "[2500]\ttraining's rmse: 1.45939\tvalid_1's rmse: 1.5631\n",
      "[2600]\ttraining's rmse: 1.45621\tvalid_1's rmse: 1.56313\n",
      "[2700]\ttraining's rmse: 1.45306\tvalid_1's rmse: 1.56305\n",
      "[2800]\ttraining's rmse: 1.44998\tvalid_1's rmse: 1.56298\n",
      "[2900]\ttraining's rmse: 1.44684\tvalid_1's rmse: 1.56293\n",
      "[3000]\ttraining's rmse: 1.44383\tvalid_1's rmse: 1.56304\n",
      "[3100]\ttraining's rmse: 1.44076\tvalid_1's rmse: 1.56301\n",
      "[3200]\ttraining's rmse: 1.43776\tvalid_1's rmse: 1.56313\n",
      "[3300]\ttraining's rmse: 1.43479\tvalid_1's rmse: 1.56303\n",
      "[3400]\ttraining's rmse: 1.43176\tvalid_1's rmse: 1.56313\n",
      "Early stopping, best iteration is:\n",
      "[2884]\ttraining's rmse: 1.44737\tvalid_1's rmse: 1.56292\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60167\tvalid_1's rmse: 1.60798\n",
      "[200]\ttraining's rmse: 1.56846\tvalid_1's rmse: 1.58189\n",
      "[300]\ttraining's rmse: 1.55297\tvalid_1's rmse: 1.57265\n",
      "[400]\ttraining's rmse: 1.54298\tvalid_1's rmse: 1.5683\n",
      "[500]\ttraining's rmse: 1.53551\tvalid_1's rmse: 1.56602\n",
      "[600]\ttraining's rmse: 1.52933\tvalid_1's rmse: 1.56455\n",
      "[700]\ttraining's rmse: 1.52397\tvalid_1's rmse: 1.56367\n",
      "[800]\ttraining's rmse: 1.51921\tvalid_1's rmse: 1.56312\n",
      "[900]\ttraining's rmse: 1.51483\tvalid_1's rmse: 1.56278\n",
      "[1000]\ttraining's rmse: 1.51072\tvalid_1's rmse: 1.5626\n",
      "[1100]\ttraining's rmse: 1.50685\tvalid_1's rmse: 1.56238\n",
      "[1200]\ttraining's rmse: 1.50301\tvalid_1's rmse: 1.56212\n",
      "[1300]\ttraining's rmse: 1.49925\tvalid_1's rmse: 1.56197\n",
      "[1400]\ttraining's rmse: 1.49559\tvalid_1's rmse: 1.56205\n",
      "[1500]\ttraining's rmse: 1.49203\tvalid_1's rmse: 1.56211\n",
      "[1600]\ttraining's rmse: 1.48851\tvalid_1's rmse: 1.56215\n",
      "[1700]\ttraining's rmse: 1.485\tvalid_1's rmse: 1.56206\n",
      "[1800]\ttraining's rmse: 1.4815\tvalid_1's rmse: 1.56218\n",
      "[1900]\ttraining's rmse: 1.47819\tvalid_1's rmse: 1.56228\n",
      "Early stopping, best iteration is:\n",
      "[1313]\ttraining's rmse: 1.49876\tvalid_1's rmse: 1.56193\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60472\tvalid_1's rmse: 1.58853\n",
      "[200]\ttraining's rmse: 1.57166\tvalid_1's rmse: 1.56131\n",
      "[300]\ttraining's rmse: 1.55648\tvalid_1's rmse: 1.55153\n",
      "[400]\ttraining's rmse: 1.54685\tvalid_1's rmse: 1.54695\n",
      "[500]\ttraining's rmse: 1.53971\tvalid_1's rmse: 1.54439\n",
      "[600]\ttraining's rmse: 1.53381\tvalid_1's rmse: 1.5429\n",
      "[700]\ttraining's rmse: 1.52886\tvalid_1's rmse: 1.542\n",
      "[800]\ttraining's rmse: 1.52441\tvalid_1's rmse: 1.54152\n",
      "[900]\ttraining's rmse: 1.52033\tvalid_1's rmse: 1.5412\n",
      "[1000]\ttraining's rmse: 1.51651\tvalid_1's rmse: 1.54093\n",
      "[1100]\ttraining's rmse: 1.51266\tvalid_1's rmse: 1.54087\n",
      "[1200]\ttraining's rmse: 1.50904\tvalid_1's rmse: 1.54081\n",
      "[1300]\ttraining's rmse: 1.50551\tvalid_1's rmse: 1.5408\n",
      "[1400]\ttraining's rmse: 1.50203\tvalid_1's rmse: 1.54074\n",
      "[1500]\ttraining's rmse: 1.49858\tvalid_1's rmse: 1.54081\n",
      "[1600]\ttraining's rmse: 1.4952\tvalid_1's rmse: 1.54083\n",
      "[1700]\ttraining's rmse: 1.4919\tvalid_1's rmse: 1.54068\n",
      "[1800]\ttraining's rmse: 1.48863\tvalid_1's rmse: 1.54057\n",
      "[1900]\ttraining's rmse: 1.48535\tvalid_1's rmse: 1.54046\n",
      "[2000]\ttraining's rmse: 1.48225\tvalid_1's rmse: 1.54049\n",
      "[2100]\ttraining's rmse: 1.47919\tvalid_1's rmse: 1.54049\n",
      "[2200]\ttraining's rmse: 1.476\tvalid_1's rmse: 1.54047\n",
      "[2300]\ttraining's rmse: 1.47281\tvalid_1's rmse: 1.54061\n",
      "[2400]\ttraining's rmse: 1.46985\tvalid_1's rmse: 1.54067\n",
      "Early stopping, best iteration is:\n",
      "[1870]\ttraining's rmse: 1.48631\tvalid_1's rmse: 1.54039\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60044\tvalid_1's rmse: 1.61993\n",
      "[200]\ttraining's rmse: 1.56767\tvalid_1's rmse: 1.59131\n",
      "[300]\ttraining's rmse: 1.55277\tvalid_1's rmse: 1.58\n",
      "[400]\ttraining's rmse: 1.54321\tvalid_1's rmse: 1.57404\n",
      "[500]\ttraining's rmse: 1.5362\tvalid_1's rmse: 1.57074\n",
      "[600]\ttraining's rmse: 1.53035\tvalid_1's rmse: 1.5688\n",
      "[700]\ttraining's rmse: 1.5255\tvalid_1's rmse: 1.56768\n",
      "[800]\ttraining's rmse: 1.52106\tvalid_1's rmse: 1.56692\n",
      "[900]\ttraining's rmse: 1.51693\tvalid_1's rmse: 1.5663\n",
      "[1000]\ttraining's rmse: 1.51302\tvalid_1's rmse: 1.56587\n",
      "[1100]\ttraining's rmse: 1.50931\tvalid_1's rmse: 1.56556\n",
      "[1200]\ttraining's rmse: 1.50577\tvalid_1's rmse: 1.56536\n",
      "[1300]\ttraining's rmse: 1.5022\tvalid_1's rmse: 1.56528\n",
      "[1400]\ttraining's rmse: 1.49881\tvalid_1's rmse: 1.56512\n",
      "[1500]\ttraining's rmse: 1.49548\tvalid_1's rmse: 1.56508\n",
      "[1600]\ttraining's rmse: 1.4922\tvalid_1's rmse: 1.56496\n",
      "[1700]\ttraining's rmse: 1.48896\tvalid_1's rmse: 1.56498\n",
      "[1800]\ttraining's rmse: 1.48566\tvalid_1's rmse: 1.56472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\ttraining's rmse: 1.4824\tvalid_1's rmse: 1.56456\n",
      "[2000]\ttraining's rmse: 1.47929\tvalid_1's rmse: 1.56445\n",
      "[2100]\ttraining's rmse: 1.47624\tvalid_1's rmse: 1.56445\n",
      "[2200]\ttraining's rmse: 1.47309\tvalid_1's rmse: 1.56441\n",
      "[2300]\ttraining's rmse: 1.47005\tvalid_1's rmse: 1.56446\n",
      "[2400]\ttraining's rmse: 1.467\tvalid_1's rmse: 1.56446\n",
      "[2500]\ttraining's rmse: 1.46394\tvalid_1's rmse: 1.5644\n",
      "[2600]\ttraining's rmse: 1.46092\tvalid_1's rmse: 1.56438\n",
      "[2700]\ttraining's rmse: 1.45799\tvalid_1's rmse: 1.56448\n",
      "[2800]\ttraining's rmse: 1.4551\tvalid_1's rmse: 1.56451\n",
      "[2900]\ttraining's rmse: 1.45216\tvalid_1's rmse: 1.56453\n",
      "[3000]\ttraining's rmse: 1.44923\tvalid_1's rmse: 1.56463\n",
      "[3100]\ttraining's rmse: 1.44633\tvalid_1's rmse: 1.56454\n",
      "Early stopping, best iteration is:\n",
      "[2568]\ttraining's rmse: 1.46191\tvalid_1's rmse: 1.56436\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59959\tvalid_1's rmse: 1.62598\n",
      "[200]\ttraining's rmse: 1.56699\tvalid_1's rmse: 1.59676\n",
      "[300]\ttraining's rmse: 1.55203\tvalid_1's rmse: 1.58572\n",
      "[400]\ttraining's rmse: 1.54243\tvalid_1's rmse: 1.57984\n",
      "[500]\ttraining's rmse: 1.53539\tvalid_1's rmse: 1.57668\n",
      "[600]\ttraining's rmse: 1.52961\tvalid_1's rmse: 1.5747\n",
      "[700]\ttraining's rmse: 1.52461\tvalid_1's rmse: 1.57354\n",
      "[800]\ttraining's rmse: 1.52012\tvalid_1's rmse: 1.57291\n",
      "[900]\ttraining's rmse: 1.51601\tvalid_1's rmse: 1.57237\n",
      "[1000]\ttraining's rmse: 1.51202\tvalid_1's rmse: 1.57213\n",
      "[1100]\ttraining's rmse: 1.50838\tvalid_1's rmse: 1.57199\n",
      "[1200]\ttraining's rmse: 1.50475\tvalid_1's rmse: 1.57175\n",
      "[1300]\ttraining's rmse: 1.50129\tvalid_1's rmse: 1.57153\n",
      "[1400]\ttraining's rmse: 1.49796\tvalid_1's rmse: 1.57159\n",
      "[1500]\ttraining's rmse: 1.49458\tvalid_1's rmse: 1.57146\n",
      "[1600]\ttraining's rmse: 1.49127\tvalid_1's rmse: 1.57128\n",
      "[1700]\ttraining's rmse: 1.48795\tvalid_1's rmse: 1.5712\n",
      "[1800]\ttraining's rmse: 1.48468\tvalid_1's rmse: 1.57119\n",
      "[1900]\ttraining's rmse: 1.48155\tvalid_1's rmse: 1.57111\n",
      "[2000]\ttraining's rmse: 1.47843\tvalid_1's rmse: 1.57106\n",
      "[2100]\ttraining's rmse: 1.47531\tvalid_1's rmse: 1.57103\n",
      "[2200]\ttraining's rmse: 1.47219\tvalid_1's rmse: 1.57101\n",
      "[2300]\ttraining's rmse: 1.46908\tvalid_1's rmse: 1.57094\n",
      "[2400]\ttraining's rmse: 1.46605\tvalid_1's rmse: 1.57093\n",
      "[2500]\ttraining's rmse: 1.46298\tvalid_1's rmse: 1.57101\n",
      "[2600]\ttraining's rmse: 1.45998\tvalid_1's rmse: 1.57103\n",
      "[2700]\ttraining's rmse: 1.45687\tvalid_1's rmse: 1.57106\n",
      "[2800]\ttraining's rmse: 1.45391\tvalid_1's rmse: 1.57107\n",
      "[2900]\ttraining's rmse: 1.45103\tvalid_1's rmse: 1.57105\n",
      "[3000]\ttraining's rmse: 1.44816\tvalid_1's rmse: 1.57111\n",
      "Early stopping, best iteration is:\n",
      "[2449]\ttraining's rmse: 1.46456\tvalid_1's rmse: 1.57091\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60406\tvalid_1's rmse: 1.59302\n",
      "[200]\ttraining's rmse: 1.57131\tvalid_1's rmse: 1.56483\n",
      "[300]\ttraining's rmse: 1.55615\tvalid_1's rmse: 1.55354\n",
      "[400]\ttraining's rmse: 1.54662\tvalid_1's rmse: 1.54814\n",
      "[500]\ttraining's rmse: 1.53949\tvalid_1's rmse: 1.54509\n",
      "[600]\ttraining's rmse: 1.53366\tvalid_1's rmse: 1.54339\n",
      "[700]\ttraining's rmse: 1.52867\tvalid_1's rmse: 1.54227\n",
      "[800]\ttraining's rmse: 1.52414\tvalid_1's rmse: 1.5416\n",
      "[900]\ttraining's rmse: 1.52008\tvalid_1's rmse: 1.54126\n",
      "[1000]\ttraining's rmse: 1.51617\tvalid_1's rmse: 1.54088\n",
      "[1100]\ttraining's rmse: 1.51262\tvalid_1's rmse: 1.54081\n",
      "[1200]\ttraining's rmse: 1.50903\tvalid_1's rmse: 1.54068\n",
      "[1300]\ttraining's rmse: 1.50542\tvalid_1's rmse: 1.54049\n",
      "[1400]\ttraining's rmse: 1.5019\tvalid_1's rmse: 1.54039\n",
      "[1500]\ttraining's rmse: 1.49854\tvalid_1's rmse: 1.5403\n",
      "[1600]\ttraining's rmse: 1.49524\tvalid_1's rmse: 1.54033\n",
      "[1700]\ttraining's rmse: 1.49187\tvalid_1's rmse: 1.54035\n",
      "[1800]\ttraining's rmse: 1.48854\tvalid_1's rmse: 1.54043\n",
      "[1900]\ttraining's rmse: 1.48537\tvalid_1's rmse: 1.54045\n",
      "[2000]\ttraining's rmse: 1.4822\tvalid_1's rmse: 1.54046\n",
      "[2100]\ttraining's rmse: 1.47915\tvalid_1's rmse: 1.54053\n",
      "Early stopping, best iteration is:\n",
      "[1539]\ttraining's rmse: 1.49727\tvalid_1's rmse: 1.54024\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60362\tvalid_1's rmse: 1.59589\n",
      "[200]\ttraining's rmse: 1.57069\tvalid_1's rmse: 1.56833\n",
      "[300]\ttraining's rmse: 1.55538\tvalid_1's rmse: 1.55807\n",
      "[400]\ttraining's rmse: 1.54586\tvalid_1's rmse: 1.5533\n",
      "[500]\ttraining's rmse: 1.5387\tvalid_1's rmse: 1.55096\n",
      "[600]\ttraining's rmse: 1.5329\tvalid_1's rmse: 1.54965\n",
      "[700]\ttraining's rmse: 1.52779\tvalid_1's rmse: 1.54887\n",
      "[800]\ttraining's rmse: 1.52323\tvalid_1's rmse: 1.54856\n",
      "[900]\ttraining's rmse: 1.5191\tvalid_1's rmse: 1.54839\n",
      "[1000]\ttraining's rmse: 1.5152\tvalid_1's rmse: 1.54832\n",
      "[1100]\ttraining's rmse: 1.51139\tvalid_1's rmse: 1.54827\n",
      "[1200]\ttraining's rmse: 1.50773\tvalid_1's rmse: 1.54816\n",
      "[1300]\ttraining's rmse: 1.50412\tvalid_1's rmse: 1.54809\n",
      "[1400]\ttraining's rmse: 1.50072\tvalid_1's rmse: 1.54802\n",
      "[1500]\ttraining's rmse: 1.49729\tvalid_1's rmse: 1.54794\n",
      "[1600]\ttraining's rmse: 1.49396\tvalid_1's rmse: 1.54799\n",
      "[1700]\ttraining's rmse: 1.49059\tvalid_1's rmse: 1.54807\n",
      "[1800]\ttraining's rmse: 1.48727\tvalid_1's rmse: 1.54806\n",
      "[1900]\ttraining's rmse: 1.48403\tvalid_1's rmse: 1.54804\n",
      "[2000]\ttraining's rmse: 1.48097\tvalid_1's rmse: 1.548\n",
      "Early stopping, best iteration is:\n",
      "[1497]\ttraining's rmse: 1.49742\tvalid_1's rmse: 1.54793\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60238\tvalid_1's rmse: 1.60762\n",
      "[200]\ttraining's rmse: 1.56979\tvalid_1's rmse: 1.57761\n",
      "[300]\ttraining's rmse: 1.55479\tvalid_1's rmse: 1.56568\n",
      "[400]\ttraining's rmse: 1.54528\tvalid_1's rmse: 1.55941\n",
      "[500]\ttraining's rmse: 1.53829\tvalid_1's rmse: 1.55583\n",
      "[600]\ttraining's rmse: 1.53253\tvalid_1's rmse: 1.55386\n",
      "[700]\ttraining's rmse: 1.52757\tvalid_1's rmse: 1.55243\n",
      "[800]\ttraining's rmse: 1.52317\tvalid_1's rmse: 1.55174\n",
      "[900]\ttraining's rmse: 1.51894\tvalid_1's rmse: 1.55118\n",
      "[1000]\ttraining's rmse: 1.51512\tvalid_1's rmse: 1.55085\n",
      "[1100]\ttraining's rmse: 1.51145\tvalid_1's rmse: 1.55042\n",
      "[1200]\ttraining's rmse: 1.50783\tvalid_1's rmse: 1.55014\n",
      "[1300]\ttraining's rmse: 1.50426\tvalid_1's rmse: 1.54991\n",
      "[1400]\ttraining's rmse: 1.50081\tvalid_1's rmse: 1.54971\n",
      "[1500]\ttraining's rmse: 1.49737\tvalid_1's rmse: 1.54962\n",
      "[1600]\ttraining's rmse: 1.49403\tvalid_1's rmse: 1.54929\n",
      "[1700]\ttraining's rmse: 1.49073\tvalid_1's rmse: 1.54932\n",
      "[1800]\ttraining's rmse: 1.48755\tvalid_1's rmse: 1.54934\n",
      "[1900]\ttraining's rmse: 1.4843\tvalid_1's rmse: 1.54921\n",
      "[2000]\ttraining's rmse: 1.4811\tvalid_1's rmse: 1.54921\n",
      "[2100]\ttraining's rmse: 1.478\tvalid_1's rmse: 1.54917\n",
      "[2200]\ttraining's rmse: 1.47494\tvalid_1's rmse: 1.5491\n",
      "[2300]\ttraining's rmse: 1.47172\tvalid_1's rmse: 1.54897\n",
      "[2400]\ttraining's rmse: 1.46868\tvalid_1's rmse: 1.54883\n",
      "[2500]\ttraining's rmse: 1.46558\tvalid_1's rmse: 1.54883\n",
      "[2600]\ttraining's rmse: 1.46249\tvalid_1's rmse: 1.54886\n",
      "[2700]\ttraining's rmse: 1.45958\tvalid_1's rmse: 1.54874\n",
      "[2800]\ttraining's rmse: 1.45672\tvalid_1's rmse: 1.54875\n",
      "[2900]\ttraining's rmse: 1.45368\tvalid_1's rmse: 1.5488\n",
      "[3000]\ttraining's rmse: 1.45072\tvalid_1's rmse: 1.54875\n",
      "[3100]\ttraining's rmse: 1.44781\tvalid_1's rmse: 1.54879\n",
      "[3200]\ttraining's rmse: 1.4449\tvalid_1's rmse: 1.54899\n",
      "[3300]\ttraining's rmse: 1.44205\tvalid_1's rmse: 1.54894\n",
      "Early stopping, best iteration is:\n",
      "[2749]\ttraining's rmse: 1.45812\tvalid_1's rmse: 1.54869\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60051\tvalid_1's rmse: 1.61825\n",
      "[200]\ttraining's rmse: 1.56794\tvalid_1's rmse: 1.58967\n",
      "[300]\ttraining's rmse: 1.55297\tvalid_1's rmse: 1.57861\n",
      "[400]\ttraining's rmse: 1.54347\tvalid_1's rmse: 1.57304\n",
      "[500]\ttraining's rmse: 1.53644\tvalid_1's rmse: 1.56989\n",
      "[600]\ttraining's rmse: 1.5307\tvalid_1's rmse: 1.5681\n",
      "[700]\ttraining's rmse: 1.52578\tvalid_1's rmse: 1.56692\n",
      "[800]\ttraining's rmse: 1.52141\tvalid_1's rmse: 1.5661\n",
      "[900]\ttraining's rmse: 1.51738\tvalid_1's rmse: 1.56573\n",
      "[1000]\ttraining's rmse: 1.51358\tvalid_1's rmse: 1.56532\n",
      "[1100]\ttraining's rmse: 1.50984\tvalid_1's rmse: 1.56509\n",
      "[1200]\ttraining's rmse: 1.5063\tvalid_1's rmse: 1.56483\n",
      "[1300]\ttraining's rmse: 1.50285\tvalid_1's rmse: 1.56476\n",
      "[1400]\ttraining's rmse: 1.49939\tvalid_1's rmse: 1.56459\n",
      "[1500]\ttraining's rmse: 1.49604\tvalid_1's rmse: 1.56449\n",
      "[1600]\ttraining's rmse: 1.49275\tvalid_1's rmse: 1.56445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\ttraining's rmse: 1.48948\tvalid_1's rmse: 1.56434\n",
      "[1800]\ttraining's rmse: 1.48617\tvalid_1's rmse: 1.56421\n",
      "[1900]\ttraining's rmse: 1.4828\tvalid_1's rmse: 1.56419\n",
      "[2000]\ttraining's rmse: 1.47969\tvalid_1's rmse: 1.56404\n",
      "[2100]\ttraining's rmse: 1.47659\tvalid_1's rmse: 1.56412\n",
      "[2200]\ttraining's rmse: 1.47339\tvalid_1's rmse: 1.5641\n",
      "[2300]\ttraining's rmse: 1.47024\tvalid_1's rmse: 1.56407\n",
      "[2400]\ttraining's rmse: 1.46728\tvalid_1's rmse: 1.56422\n",
      "[2500]\ttraining's rmse: 1.4643\tvalid_1's rmse: 1.56429\n",
      "[2600]\ttraining's rmse: 1.46136\tvalid_1's rmse: 1.56427\n",
      "Early stopping, best iteration is:\n",
      "[2001]\ttraining's rmse: 1.47965\tvalid_1's rmse: 1.56403\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60182\tvalid_1's rmse: 1.60805\n",
      "[200]\ttraining's rmse: 1.56852\tvalid_1's rmse: 1.58176\n",
      "[300]\ttraining's rmse: 1.55326\tvalid_1's rmse: 1.57261\n",
      "[400]\ttraining's rmse: 1.54362\tvalid_1's rmse: 1.56818\n",
      "[500]\ttraining's rmse: 1.53639\tvalid_1's rmse: 1.56589\n",
      "[600]\ttraining's rmse: 1.53061\tvalid_1's rmse: 1.5645\n",
      "[700]\ttraining's rmse: 1.52551\tvalid_1's rmse: 1.56381\n",
      "[800]\ttraining's rmse: 1.52106\tvalid_1's rmse: 1.56336\n",
      "[900]\ttraining's rmse: 1.51695\tvalid_1's rmse: 1.56306\n",
      "[1000]\ttraining's rmse: 1.51306\tvalid_1's rmse: 1.56291\n",
      "[1100]\ttraining's rmse: 1.50942\tvalid_1's rmse: 1.56289\n",
      "[1200]\ttraining's rmse: 1.50591\tvalid_1's rmse: 1.5629\n",
      "[1300]\ttraining's rmse: 1.50234\tvalid_1's rmse: 1.56284\n",
      "[1400]\ttraining's rmse: 1.49886\tvalid_1's rmse: 1.56281\n",
      "[1500]\ttraining's rmse: 1.49554\tvalid_1's rmse: 1.56297\n",
      "[1600]\ttraining's rmse: 1.49218\tvalid_1's rmse: 1.56289\n",
      "[1700]\ttraining's rmse: 1.48886\tvalid_1's rmse: 1.5629\n",
      "[1800]\ttraining's rmse: 1.48559\tvalid_1's rmse: 1.56297\n",
      "[1900]\ttraining's rmse: 1.48241\tvalid_1's rmse: 1.56312\n",
      "[2000]\ttraining's rmse: 1.47928\tvalid_1's rmse: 1.56316\n",
      "Early stopping, best iteration is:\n",
      "[1427]\ttraining's rmse: 1.49801\tvalid_1's rmse: 1.56278\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.6048\tvalid_1's rmse: 1.5885\n",
      "[200]\ttraining's rmse: 1.57178\tvalid_1's rmse: 1.56099\n",
      "[300]\ttraining's rmse: 1.55668\tvalid_1's rmse: 1.55104\n",
      "[400]\ttraining's rmse: 1.54727\tvalid_1's rmse: 1.54658\n",
      "[500]\ttraining's rmse: 1.54043\tvalid_1's rmse: 1.54407\n",
      "[600]\ttraining's rmse: 1.53492\tvalid_1's rmse: 1.54275\n",
      "[700]\ttraining's rmse: 1.53001\tvalid_1's rmse: 1.54202\n",
      "[800]\ttraining's rmse: 1.52581\tvalid_1's rmse: 1.54166\n",
      "[900]\ttraining's rmse: 1.52189\tvalid_1's rmse: 1.54135\n",
      "[1000]\ttraining's rmse: 1.51821\tvalid_1's rmse: 1.54099\n",
      "[1100]\ttraining's rmse: 1.51451\tvalid_1's rmse: 1.54077\n",
      "[1200]\ttraining's rmse: 1.51101\tvalid_1's rmse: 1.54067\n",
      "[1300]\ttraining's rmse: 1.50762\tvalid_1's rmse: 1.54053\n",
      "[1400]\ttraining's rmse: 1.50428\tvalid_1's rmse: 1.5405\n",
      "[1500]\ttraining's rmse: 1.50107\tvalid_1's rmse: 1.54035\n",
      "[1600]\ttraining's rmse: 1.49773\tvalid_1's rmse: 1.54041\n",
      "[1700]\ttraining's rmse: 1.49459\tvalid_1's rmse: 1.54037\n",
      "[1800]\ttraining's rmse: 1.49138\tvalid_1's rmse: 1.54038\n",
      "[1900]\ttraining's rmse: 1.48817\tvalid_1's rmse: 1.54024\n",
      "[2000]\ttraining's rmse: 1.48509\tvalid_1's rmse: 1.54013\n",
      "[2100]\ttraining's rmse: 1.48216\tvalid_1's rmse: 1.54012\n",
      "[2200]\ttraining's rmse: 1.47914\tvalid_1's rmse: 1.54009\n",
      "[2300]\ttraining's rmse: 1.47609\tvalid_1's rmse: 1.54014\n",
      "[2400]\ttraining's rmse: 1.47319\tvalid_1's rmse: 1.54039\n",
      "[2500]\ttraining's rmse: 1.47028\tvalid_1's rmse: 1.54043\n",
      "[2600]\ttraining's rmse: 1.46732\tvalid_1's rmse: 1.54038\n",
      "[2700]\ttraining's rmse: 1.46433\tvalid_1's rmse: 1.5406\n",
      "Early stopping, best iteration is:\n",
      "[2152]\ttraining's rmse: 1.48058\tvalid_1's rmse: 1.54002\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60049\tvalid_1's rmse: 1.6201\n",
      "[200]\ttraining's rmse: 1.56797\tvalid_1's rmse: 1.59171\n",
      "[300]\ttraining's rmse: 1.55296\tvalid_1's rmse: 1.58032\n",
      "[400]\ttraining's rmse: 1.5438\tvalid_1's rmse: 1.57469\n",
      "[500]\ttraining's rmse: 1.53703\tvalid_1's rmse: 1.57148\n",
      "[600]\ttraining's rmse: 1.5315\tvalid_1's rmse: 1.56942\n",
      "[700]\ttraining's rmse: 1.52678\tvalid_1's rmse: 1.56833\n",
      "[800]\ttraining's rmse: 1.52249\tvalid_1's rmse: 1.56759\n",
      "[900]\ttraining's rmse: 1.51859\tvalid_1's rmse: 1.56713\n",
      "[1000]\ttraining's rmse: 1.51483\tvalid_1's rmse: 1.56684\n",
      "[1100]\ttraining's rmse: 1.51128\tvalid_1's rmse: 1.56658\n",
      "[1200]\ttraining's rmse: 1.50782\tvalid_1's rmse: 1.56634\n",
      "[1300]\ttraining's rmse: 1.5045\tvalid_1's rmse: 1.56617\n",
      "[1400]\ttraining's rmse: 1.50116\tvalid_1's rmse: 1.56599\n",
      "[1500]\ttraining's rmse: 1.49778\tvalid_1's rmse: 1.56576\n",
      "[1600]\ttraining's rmse: 1.49455\tvalid_1's rmse: 1.56566\n",
      "[1700]\ttraining's rmse: 1.49135\tvalid_1's rmse: 1.56564\n",
      "[1800]\ttraining's rmse: 1.48811\tvalid_1's rmse: 1.56543\n",
      "[1900]\ttraining's rmse: 1.48502\tvalid_1's rmse: 1.56535\n",
      "[2000]\ttraining's rmse: 1.48201\tvalid_1's rmse: 1.5652\n",
      "[2100]\ttraining's rmse: 1.479\tvalid_1's rmse: 1.56523\n",
      "[2200]\ttraining's rmse: 1.47585\tvalid_1's rmse: 1.5652\n",
      "[2300]\ttraining's rmse: 1.47279\tvalid_1's rmse: 1.56516\n",
      "[2400]\ttraining's rmse: 1.46983\tvalid_1's rmse: 1.56517\n",
      "[2500]\ttraining's rmse: 1.46695\tvalid_1's rmse: 1.56519\n",
      "[2600]\ttraining's rmse: 1.46396\tvalid_1's rmse: 1.56514\n",
      "[2700]\ttraining's rmse: 1.46102\tvalid_1's rmse: 1.56506\n",
      "[2800]\ttraining's rmse: 1.45815\tvalid_1's rmse: 1.5651\n",
      "[2900]\ttraining's rmse: 1.45532\tvalid_1's rmse: 1.5651\n",
      "[3000]\ttraining's rmse: 1.45254\tvalid_1's rmse: 1.56503\n",
      "[3100]\ttraining's rmse: 1.44966\tvalid_1's rmse: 1.56512\n",
      "[3200]\ttraining's rmse: 1.44681\tvalid_1's rmse: 1.56511\n",
      "[3300]\ttraining's rmse: 1.44398\tvalid_1's rmse: 1.56513\n",
      "[3400]\ttraining's rmse: 1.44119\tvalid_1's rmse: 1.56513\n",
      "[3500]\ttraining's rmse: 1.43837\tvalid_1's rmse: 1.56509\n",
      "[3600]\ttraining's rmse: 1.43564\tvalid_1's rmse: 1.56514\n",
      "Early stopping, best iteration is:\n",
      "[3006]\ttraining's rmse: 1.45235\tvalid_1's rmse: 1.56503\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59972\tvalid_1's rmse: 1.62612\n",
      "[200]\ttraining's rmse: 1.56704\tvalid_1's rmse: 1.59667\n",
      "[300]\ttraining's rmse: 1.55219\tvalid_1's rmse: 1.58561\n",
      "[400]\ttraining's rmse: 1.54292\tvalid_1's rmse: 1.57998\n",
      "[500]\ttraining's rmse: 1.53606\tvalid_1's rmse: 1.57666\n",
      "[600]\ttraining's rmse: 1.53054\tvalid_1's rmse: 1.57481\n",
      "[700]\ttraining's rmse: 1.52566\tvalid_1's rmse: 1.57355\n",
      "[800]\ttraining's rmse: 1.52129\tvalid_1's rmse: 1.5728\n",
      "[900]\ttraining's rmse: 1.51741\tvalid_1's rmse: 1.57221\n",
      "[1000]\ttraining's rmse: 1.51359\tvalid_1's rmse: 1.57202\n",
      "[1100]\ttraining's rmse: 1.51004\tvalid_1's rmse: 1.57177\n",
      "[1200]\ttraining's rmse: 1.5067\tvalid_1's rmse: 1.57162\n",
      "[1300]\ttraining's rmse: 1.50338\tvalid_1's rmse: 1.57142\n",
      "[1400]\ttraining's rmse: 1.50009\tvalid_1's rmse: 1.57126\n",
      "[1500]\ttraining's rmse: 1.49682\tvalid_1's rmse: 1.5712\n",
      "[1600]\ttraining's rmse: 1.49349\tvalid_1's rmse: 1.57095\n",
      "[1700]\ttraining's rmse: 1.49029\tvalid_1's rmse: 1.5708\n",
      "[1800]\ttraining's rmse: 1.48722\tvalid_1's rmse: 1.57067\n",
      "[1900]\ttraining's rmse: 1.48413\tvalid_1's rmse: 1.57065\n",
      "[2000]\ttraining's rmse: 1.4811\tvalid_1's rmse: 1.57065\n",
      "[2100]\ttraining's rmse: 1.4781\tvalid_1's rmse: 1.57059\n",
      "[2200]\ttraining's rmse: 1.47511\tvalid_1's rmse: 1.57055\n",
      "[2300]\ttraining's rmse: 1.472\tvalid_1's rmse: 1.57056\n",
      "[2400]\ttraining's rmse: 1.469\tvalid_1's rmse: 1.57064\n",
      "[2500]\ttraining's rmse: 1.46598\tvalid_1's rmse: 1.57068\n",
      "[2600]\ttraining's rmse: 1.46306\tvalid_1's rmse: 1.57064\n",
      "[2700]\ttraining's rmse: 1.4601\tvalid_1's rmse: 1.57065\n",
      "[2800]\ttraining's rmse: 1.4572\tvalid_1's rmse: 1.5707\n",
      "Early stopping, best iteration is:\n",
      "[2230]\ttraining's rmse: 1.47416\tvalid_1's rmse: 1.57049\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60421\tvalid_1's rmse: 1.59288\n",
      "[200]\ttraining's rmse: 1.57137\tvalid_1's rmse: 1.56453\n",
      "[300]\ttraining's rmse: 1.5564\tvalid_1's rmse: 1.55363\n",
      "[400]\ttraining's rmse: 1.54706\tvalid_1's rmse: 1.54831\n",
      "[500]\ttraining's rmse: 1.54013\tvalid_1's rmse: 1.54534\n",
      "[600]\ttraining's rmse: 1.53452\tvalid_1's rmse: 1.54391\n",
      "[700]\ttraining's rmse: 1.52972\tvalid_1's rmse: 1.54296\n",
      "[800]\ttraining's rmse: 1.52538\tvalid_1's rmse: 1.54237\n",
      "[900]\ttraining's rmse: 1.52146\tvalid_1's rmse: 1.54205\n",
      "[1000]\ttraining's rmse: 1.51761\tvalid_1's rmse: 1.54176\n",
      "[1100]\ttraining's rmse: 1.514\tvalid_1's rmse: 1.54162\n",
      "[1200]\ttraining's rmse: 1.51052\tvalid_1's rmse: 1.54144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttraining's rmse: 1.50699\tvalid_1's rmse: 1.54134\n",
      "[1400]\ttraining's rmse: 1.50371\tvalid_1's rmse: 1.54123\n",
      "[1500]\ttraining's rmse: 1.50038\tvalid_1's rmse: 1.54118\n",
      "[1600]\ttraining's rmse: 1.49711\tvalid_1's rmse: 1.54116\n",
      "[1700]\ttraining's rmse: 1.49387\tvalid_1's rmse: 1.54112\n",
      "[1800]\ttraining's rmse: 1.49079\tvalid_1's rmse: 1.54115\n",
      "[1900]\ttraining's rmse: 1.48773\tvalid_1's rmse: 1.5412\n",
      "[2000]\ttraining's rmse: 1.48472\tvalid_1's rmse: 1.54114\n",
      "[2100]\ttraining's rmse: 1.48163\tvalid_1's rmse: 1.54117\n",
      "[2200]\ttraining's rmse: 1.47872\tvalid_1's rmse: 1.54116\n",
      "[2300]\ttraining's rmse: 1.4758\tvalid_1's rmse: 1.54122\n",
      "Early stopping, best iteration is:\n",
      "[1703]\ttraining's rmse: 1.49379\tvalid_1's rmse: 1.54111\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60368\tvalid_1's rmse: 1.59606\n",
      "[200]\ttraining's rmse: 1.57075\tvalid_1's rmse: 1.56854\n",
      "[300]\ttraining's rmse: 1.55567\tvalid_1's rmse: 1.55829\n",
      "[400]\ttraining's rmse: 1.54627\tvalid_1's rmse: 1.55364\n",
      "[500]\ttraining's rmse: 1.53929\tvalid_1's rmse: 1.55135\n",
      "[600]\ttraining's rmse: 1.53369\tvalid_1's rmse: 1.55018\n",
      "[700]\ttraining's rmse: 1.52877\tvalid_1's rmse: 1.54945\n",
      "[800]\ttraining's rmse: 1.52446\tvalid_1's rmse: 1.54905\n",
      "[900]\ttraining's rmse: 1.5205\tvalid_1's rmse: 1.54883\n",
      "[1000]\ttraining's rmse: 1.51679\tvalid_1's rmse: 1.54868\n",
      "[1100]\ttraining's rmse: 1.51326\tvalid_1's rmse: 1.54875\n",
      "[1200]\ttraining's rmse: 1.5097\tvalid_1's rmse: 1.54868\n",
      "[1300]\ttraining's rmse: 1.50637\tvalid_1's rmse: 1.54855\n",
      "[1400]\ttraining's rmse: 1.50306\tvalid_1's rmse: 1.54858\n",
      "[1500]\ttraining's rmse: 1.49961\tvalid_1's rmse: 1.54866\n",
      "[1600]\ttraining's rmse: 1.49635\tvalid_1's rmse: 1.54865\n",
      "[1700]\ttraining's rmse: 1.49307\tvalid_1's rmse: 1.54877\n",
      "[1800]\ttraining's rmse: 1.48988\tvalid_1's rmse: 1.54879\n",
      "[1900]\ttraining's rmse: 1.48675\tvalid_1's rmse: 1.54892\n",
      "Early stopping, best iteration is:\n",
      "[1300]\ttraining's rmse: 1.50637\tvalid_1's rmse: 1.54855\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60237\tvalid_1's rmse: 1.60755\n",
      "[200]\ttraining's rmse: 1.56992\tvalid_1's rmse: 1.57752\n",
      "[300]\ttraining's rmse: 1.5551\tvalid_1's rmse: 1.56555\n",
      "[400]\ttraining's rmse: 1.54573\tvalid_1's rmse: 1.55951\n",
      "[500]\ttraining's rmse: 1.53891\tvalid_1's rmse: 1.55619\n",
      "[600]\ttraining's rmse: 1.53337\tvalid_1's rmse: 1.55419\n",
      "[700]\ttraining's rmse: 1.52869\tvalid_1's rmse: 1.55305\n",
      "[800]\ttraining's rmse: 1.52436\tvalid_1's rmse: 1.55231\n",
      "[900]\ttraining's rmse: 1.52028\tvalid_1's rmse: 1.55172\n",
      "[1000]\ttraining's rmse: 1.51659\tvalid_1's rmse: 1.55144\n",
      "[1100]\ttraining's rmse: 1.513\tvalid_1's rmse: 1.55117\n",
      "[1200]\ttraining's rmse: 1.50955\tvalid_1's rmse: 1.55093\n",
      "[1300]\ttraining's rmse: 1.50618\tvalid_1's rmse: 1.55069\n",
      "[1400]\ttraining's rmse: 1.50285\tvalid_1's rmse: 1.55048\n",
      "[1500]\ttraining's rmse: 1.49954\tvalid_1's rmse: 1.55037\n",
      "[1600]\ttraining's rmse: 1.49636\tvalid_1's rmse: 1.55023\n",
      "[1700]\ttraining's rmse: 1.49314\tvalid_1's rmse: 1.55019\n",
      "[1800]\ttraining's rmse: 1.49007\tvalid_1's rmse: 1.55012\n",
      "[1900]\ttraining's rmse: 1.48697\tvalid_1's rmse: 1.55006\n",
      "[2000]\ttraining's rmse: 1.48372\tvalid_1's rmse: 1.55009\n",
      "[2100]\ttraining's rmse: 1.48064\tvalid_1's rmse: 1.55016\n",
      "[2200]\ttraining's rmse: 1.47757\tvalid_1's rmse: 1.55018\n",
      "[2300]\ttraining's rmse: 1.47446\tvalid_1's rmse: 1.55003\n",
      "[2400]\ttraining's rmse: 1.47146\tvalid_1's rmse: 1.54993\n",
      "[2500]\ttraining's rmse: 1.46844\tvalid_1's rmse: 1.54997\n",
      "[2600]\ttraining's rmse: 1.46541\tvalid_1's rmse: 1.54995\n",
      "[2700]\ttraining's rmse: 1.46257\tvalid_1's rmse: 1.54992\n",
      "[2800]\ttraining's rmse: 1.45978\tvalid_1's rmse: 1.54991\n",
      "[2900]\ttraining's rmse: 1.45686\tvalid_1's rmse: 1.54985\n",
      "[3000]\ttraining's rmse: 1.45394\tvalid_1's rmse: 1.54998\n",
      "[3100]\ttraining's rmse: 1.45097\tvalid_1's rmse: 1.55001\n",
      "[3200]\ttraining's rmse: 1.44819\tvalid_1's rmse: 1.55008\n",
      "[3300]\ttraining's rmse: 1.44546\tvalid_1's rmse: 1.55001\n",
      "[3400]\ttraining's rmse: 1.44253\tvalid_1's rmse: 1.55006\n",
      "Early stopping, best iteration is:\n",
      "[2898]\ttraining's rmse: 1.45691\tvalid_1's rmse: 1.54985\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60048\tvalid_1's rmse: 1.61823\n",
      "[200]\ttraining's rmse: 1.56802\tvalid_1's rmse: 1.58965\n",
      "[300]\ttraining's rmse: 1.55321\tvalid_1's rmse: 1.57861\n",
      "[400]\ttraining's rmse: 1.54396\tvalid_1's rmse: 1.57326\n",
      "[500]\ttraining's rmse: 1.53713\tvalid_1's rmse: 1.57\n",
      "[600]\ttraining's rmse: 1.53158\tvalid_1's rmse: 1.56825\n",
      "[700]\ttraining's rmse: 1.52688\tvalid_1's rmse: 1.56716\n",
      "[800]\ttraining's rmse: 1.52268\tvalid_1's rmse: 1.56649\n",
      "[900]\ttraining's rmse: 1.51883\tvalid_1's rmse: 1.56599\n",
      "[1000]\ttraining's rmse: 1.51521\tvalid_1's rmse: 1.56561\n",
      "[1100]\ttraining's rmse: 1.51158\tvalid_1's rmse: 1.56528\n",
      "[1200]\ttraining's rmse: 1.50815\tvalid_1's rmse: 1.56519\n",
      "[1300]\ttraining's rmse: 1.50486\tvalid_1's rmse: 1.56507\n",
      "[1400]\ttraining's rmse: 1.50157\tvalid_1's rmse: 1.56482\n",
      "[1500]\ttraining's rmse: 1.49834\tvalid_1's rmse: 1.56482\n",
      "[1600]\ttraining's rmse: 1.49506\tvalid_1's rmse: 1.56471\n",
      "[1700]\ttraining's rmse: 1.49186\tvalid_1's rmse: 1.56457\n",
      "[1800]\ttraining's rmse: 1.48855\tvalid_1's rmse: 1.56451\n",
      "[1900]\ttraining's rmse: 1.48533\tvalid_1's rmse: 1.56442\n",
      "[2000]\ttraining's rmse: 1.48227\tvalid_1's rmse: 1.56442\n",
      "[2100]\ttraining's rmse: 1.47924\tvalid_1's rmse: 1.56454\n",
      "[2200]\ttraining's rmse: 1.47616\tvalid_1's rmse: 1.5645\n",
      "[2300]\ttraining's rmse: 1.47303\tvalid_1's rmse: 1.56449\n",
      "[2400]\ttraining's rmse: 1.47013\tvalid_1's rmse: 1.56453\n",
      "[2500]\ttraining's rmse: 1.4672\tvalid_1's rmse: 1.56455\n",
      "[2600]\ttraining's rmse: 1.46422\tvalid_1's rmse: 1.56442\n",
      "[2700]\ttraining's rmse: 1.46134\tvalid_1's rmse: 1.56454\n",
      "[2800]\ttraining's rmse: 1.45843\tvalid_1's rmse: 1.56461\n",
      "[2900]\ttraining's rmse: 1.45568\tvalid_1's rmse: 1.56467\n",
      "[3000]\ttraining's rmse: 1.45276\tvalid_1's rmse: 1.56464\n",
      "[3100]\ttraining's rmse: 1.44994\tvalid_1's rmse: 1.56462\n",
      "[3200]\ttraining's rmse: 1.44714\tvalid_1's rmse: 1.56456\n",
      "Early stopping, best iteration is:\n",
      "[2602]\ttraining's rmse: 1.46415\tvalid_1's rmse: 1.5644\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60188\tvalid_1's rmse: 1.60816\n",
      "[200]\ttraining's rmse: 1.56878\tvalid_1's rmse: 1.58179\n",
      "[300]\ttraining's rmse: 1.55353\tvalid_1's rmse: 1.57229\n",
      "[400]\ttraining's rmse: 1.54417\tvalid_1's rmse: 1.56812\n",
      "[500]\ttraining's rmse: 1.53729\tvalid_1's rmse: 1.56579\n",
      "[600]\ttraining's rmse: 1.53174\tvalid_1's rmse: 1.56462\n",
      "[700]\ttraining's rmse: 1.52693\tvalid_1's rmse: 1.56388\n",
      "[800]\ttraining's rmse: 1.52264\tvalid_1's rmse: 1.5635\n",
      "[900]\ttraining's rmse: 1.51867\tvalid_1's rmse: 1.56315\n",
      "[1000]\ttraining's rmse: 1.51494\tvalid_1's rmse: 1.56316\n",
      "[1100]\ttraining's rmse: 1.51146\tvalid_1's rmse: 1.56296\n",
      "[1200]\ttraining's rmse: 1.50807\tvalid_1's rmse: 1.56295\n",
      "[1300]\ttraining's rmse: 1.50458\tvalid_1's rmse: 1.563\n",
      "[1400]\ttraining's rmse: 1.50123\tvalid_1's rmse: 1.56293\n",
      "[1500]\ttraining's rmse: 1.49803\tvalid_1's rmse: 1.56294\n",
      "[1600]\ttraining's rmse: 1.49477\tvalid_1's rmse: 1.56285\n",
      "[1700]\ttraining's rmse: 1.49142\tvalid_1's rmse: 1.56297\n",
      "[1800]\ttraining's rmse: 1.48813\tvalid_1's rmse: 1.56302\n",
      "[1900]\ttraining's rmse: 1.485\tvalid_1's rmse: 1.56308\n",
      "[2000]\ttraining's rmse: 1.48187\tvalid_1's rmse: 1.56318\n",
      "[2100]\ttraining's rmse: 1.47876\tvalid_1's rmse: 1.56313\n",
      "[2200]\ttraining's rmse: 1.47577\tvalid_1's rmse: 1.5632\n",
      "Early stopping, best iteration is:\n",
      "[1621]\ttraining's rmse: 1.4941\tvalid_1's rmse: 1.56283\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60779\tvalid_1's rmse: 1.59385\n",
      "[200]\ttraining's rmse: 1.57474\tvalid_1's rmse: 1.56794\n",
      "[300]\ttraining's rmse: 1.55861\tvalid_1's rmse: 1.55837\n",
      "[400]\ttraining's rmse: 1.54743\tvalid_1's rmse: 1.55355\n",
      "[500]\ttraining's rmse: 1.53864\tvalid_1's rmse: 1.55079\n",
      "[600]\ttraining's rmse: 1.53101\tvalid_1's rmse: 1.54905\n",
      "[700]\ttraining's rmse: 1.52422\tvalid_1's rmse: 1.54767\n",
      "[800]\ttraining's rmse: 1.51799\tvalid_1's rmse: 1.54673\n",
      "[900]\ttraining's rmse: 1.5124\tvalid_1's rmse: 1.54599\n",
      "[1000]\ttraining's rmse: 1.50704\tvalid_1's rmse: 1.54562\n",
      "[1100]\ttraining's rmse: 1.50183\tvalid_1's rmse: 1.54535\n",
      "[1200]\ttraining's rmse: 1.49694\tvalid_1's rmse: 1.54514\n",
      "[1300]\ttraining's rmse: 1.49212\tvalid_1's rmse: 1.54494\n",
      "[1400]\ttraining's rmse: 1.4874\tvalid_1's rmse: 1.54461\n",
      "[1500]\ttraining's rmse: 1.48276\tvalid_1's rmse: 1.54433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\ttraining's rmse: 1.47823\tvalid_1's rmse: 1.54419\n",
      "[1700]\ttraining's rmse: 1.4737\tvalid_1's rmse: 1.54412\n",
      "[1800]\ttraining's rmse: 1.4692\tvalid_1's rmse: 1.54402\n",
      "[1900]\ttraining's rmse: 1.46483\tvalid_1's rmse: 1.5438\n",
      "[2000]\ttraining's rmse: 1.46059\tvalid_1's rmse: 1.54371\n",
      "[2100]\ttraining's rmse: 1.45645\tvalid_1's rmse: 1.54374\n",
      "[2200]\ttraining's rmse: 1.4524\tvalid_1's rmse: 1.54359\n",
      "[2300]\ttraining's rmse: 1.44826\tvalid_1's rmse: 1.54353\n",
      "[2400]\ttraining's rmse: 1.44439\tvalid_1's rmse: 1.54345\n",
      "[2500]\ttraining's rmse: 1.44023\tvalid_1's rmse: 1.54347\n",
      "[2600]\ttraining's rmse: 1.43625\tvalid_1's rmse: 1.54351\n",
      "[2700]\ttraining's rmse: 1.43227\tvalid_1's rmse: 1.5434\n",
      "[2800]\ttraining's rmse: 1.42829\tvalid_1's rmse: 1.54338\n",
      "[2900]\ttraining's rmse: 1.42435\tvalid_1's rmse: 1.54324\n",
      "[3000]\ttraining's rmse: 1.42045\tvalid_1's rmse: 1.54328\n",
      "[3100]\ttraining's rmse: 1.41662\tvalid_1's rmse: 1.54323\n",
      "[3200]\ttraining's rmse: 1.4128\tvalid_1's rmse: 1.54333\n",
      "[3300]\ttraining's rmse: 1.40903\tvalid_1's rmse: 1.54341\n",
      "[3400]\ttraining's rmse: 1.4055\tvalid_1's rmse: 1.54348\n",
      "[3500]\ttraining's rmse: 1.40174\tvalid_1's rmse: 1.54348\n",
      "[3600]\ttraining's rmse: 1.39809\tvalid_1's rmse: 1.54365\n",
      "Early stopping, best iteration is:\n",
      "[3054]\ttraining's rmse: 1.4184\tvalid_1's rmse: 1.54319\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60602\tvalid_1's rmse: 1.6101\n",
      "[200]\ttraining's rmse: 1.57314\tvalid_1's rmse: 1.58214\n",
      "[300]\ttraining's rmse: 1.55713\tvalid_1's rmse: 1.57123\n",
      "[400]\ttraining's rmse: 1.54593\tvalid_1's rmse: 1.56535\n",
      "[500]\ttraining's rmse: 1.53702\tvalid_1's rmse: 1.56198\n",
      "[600]\ttraining's rmse: 1.52939\tvalid_1's rmse: 1.55968\n",
      "[700]\ttraining's rmse: 1.52263\tvalid_1's rmse: 1.55826\n",
      "[800]\ttraining's rmse: 1.51641\tvalid_1's rmse: 1.55733\n",
      "[900]\ttraining's rmse: 1.51073\tvalid_1's rmse: 1.55686\n",
      "[1000]\ttraining's rmse: 1.5054\tvalid_1's rmse: 1.55651\n",
      "[1100]\ttraining's rmse: 1.50029\tvalid_1's rmse: 1.55621\n",
      "[1200]\ttraining's rmse: 1.49547\tvalid_1's rmse: 1.55604\n",
      "[1300]\ttraining's rmse: 1.49076\tvalid_1's rmse: 1.55595\n",
      "[1400]\ttraining's rmse: 1.48609\tvalid_1's rmse: 1.55601\n",
      "[1500]\ttraining's rmse: 1.4815\tvalid_1's rmse: 1.55591\n",
      "[1600]\ttraining's rmse: 1.47701\tvalid_1's rmse: 1.55595\n",
      "[1700]\ttraining's rmse: 1.47262\tvalid_1's rmse: 1.55589\n",
      "[1800]\ttraining's rmse: 1.46836\tvalid_1's rmse: 1.5559\n",
      "[1900]\ttraining's rmse: 1.46406\tvalid_1's rmse: 1.55592\n",
      "[2000]\ttraining's rmse: 1.45978\tvalid_1's rmse: 1.55601\n",
      "[2100]\ttraining's rmse: 1.45556\tvalid_1's rmse: 1.55587\n",
      "Early stopping, best iteration is:\n",
      "[1529]\ttraining's rmse: 1.48022\tvalid_1's rmse: 1.55582\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60248\tvalid_1's rmse: 1.64156\n",
      "[200]\ttraining's rmse: 1.56974\tvalid_1's rmse: 1.61228\n",
      "[300]\ttraining's rmse: 1.55376\tvalid_1's rmse: 1.60086\n",
      "[400]\ttraining's rmse: 1.54266\tvalid_1's rmse: 1.59463\n",
      "[500]\ttraining's rmse: 1.53376\tvalid_1's rmse: 1.59106\n",
      "[600]\ttraining's rmse: 1.52601\tvalid_1's rmse: 1.58872\n",
      "[700]\ttraining's rmse: 1.5193\tvalid_1's rmse: 1.58736\n",
      "[800]\ttraining's rmse: 1.51308\tvalid_1's rmse: 1.58629\n",
      "[900]\ttraining's rmse: 1.50733\tvalid_1's rmse: 1.58547\n",
      "[1000]\ttraining's rmse: 1.50193\tvalid_1's rmse: 1.5849\n",
      "[1100]\ttraining's rmse: 1.49678\tvalid_1's rmse: 1.58451\n",
      "[1200]\ttraining's rmse: 1.49176\tvalid_1's rmse: 1.58417\n",
      "[1300]\ttraining's rmse: 1.48703\tvalid_1's rmse: 1.58397\n",
      "[1400]\ttraining's rmse: 1.48241\tvalid_1's rmse: 1.58385\n",
      "[1500]\ttraining's rmse: 1.47787\tvalid_1's rmse: 1.5836\n",
      "[1600]\ttraining's rmse: 1.47335\tvalid_1's rmse: 1.58347\n",
      "[1700]\ttraining's rmse: 1.46885\tvalid_1's rmse: 1.58328\n",
      "[1800]\ttraining's rmse: 1.46429\tvalid_1's rmse: 1.58311\n",
      "[1900]\ttraining's rmse: 1.45995\tvalid_1's rmse: 1.5832\n",
      "[2000]\ttraining's rmse: 1.45565\tvalid_1's rmse: 1.58318\n",
      "[2100]\ttraining's rmse: 1.45154\tvalid_1's rmse: 1.58309\n",
      "[2200]\ttraining's rmse: 1.44745\tvalid_1's rmse: 1.5831\n",
      "[2300]\ttraining's rmse: 1.44323\tvalid_1's rmse: 1.58295\n",
      "[2400]\ttraining's rmse: 1.43922\tvalid_1's rmse: 1.58293\n",
      "[2500]\ttraining's rmse: 1.43513\tvalid_1's rmse: 1.58306\n",
      "[2600]\ttraining's rmse: 1.43112\tvalid_1's rmse: 1.58296\n",
      "[2700]\ttraining's rmse: 1.42711\tvalid_1's rmse: 1.583\n",
      "[2800]\ttraining's rmse: 1.42308\tvalid_1's rmse: 1.58296\n",
      "[2900]\ttraining's rmse: 1.41913\tvalid_1's rmse: 1.58305\n",
      "[3000]\ttraining's rmse: 1.41519\tvalid_1's rmse: 1.58309\n",
      "Early stopping, best iteration is:\n",
      "[2417]\ttraining's rmse: 1.4385\tvalid_1's rmse: 1.58288\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60664\tvalid_1's rmse: 1.60463\n",
      "[200]\ttraining's rmse: 1.57365\tvalid_1's rmse: 1.57767\n",
      "[300]\ttraining's rmse: 1.55758\tvalid_1's rmse: 1.56743\n",
      "[400]\ttraining's rmse: 1.5464\tvalid_1's rmse: 1.56204\n",
      "[500]\ttraining's rmse: 1.53732\tvalid_1's rmse: 1.55835\n",
      "[600]\ttraining's rmse: 1.52971\tvalid_1's rmse: 1.55616\n",
      "[700]\ttraining's rmse: 1.5229\tvalid_1's rmse: 1.5548\n",
      "[800]\ttraining's rmse: 1.51671\tvalid_1's rmse: 1.55391\n",
      "[900]\ttraining's rmse: 1.51108\tvalid_1's rmse: 1.55324\n",
      "[1000]\ttraining's rmse: 1.50568\tvalid_1's rmse: 1.55296\n",
      "[1100]\ttraining's rmse: 1.5006\tvalid_1's rmse: 1.55275\n",
      "[1200]\ttraining's rmse: 1.49575\tvalid_1's rmse: 1.55254\n",
      "[1300]\ttraining's rmse: 1.49102\tvalid_1's rmse: 1.55231\n",
      "[1400]\ttraining's rmse: 1.48632\tvalid_1's rmse: 1.55211\n",
      "[1500]\ttraining's rmse: 1.48161\tvalid_1's rmse: 1.55201\n",
      "[1600]\ttraining's rmse: 1.47723\tvalid_1's rmse: 1.55194\n",
      "[1700]\ttraining's rmse: 1.4727\tvalid_1's rmse: 1.55171\n",
      "[1800]\ttraining's rmse: 1.46827\tvalid_1's rmse: 1.55158\n",
      "[1900]\ttraining's rmse: 1.46401\tvalid_1's rmse: 1.55161\n",
      "[2000]\ttraining's rmse: 1.45975\tvalid_1's rmse: 1.5516\n",
      "[2100]\ttraining's rmse: 1.45545\tvalid_1's rmse: 1.55148\n",
      "[2200]\ttraining's rmse: 1.45132\tvalid_1's rmse: 1.55149\n",
      "[2300]\ttraining's rmse: 1.44726\tvalid_1's rmse: 1.55151\n",
      "[2400]\ttraining's rmse: 1.4432\tvalid_1's rmse: 1.55148\n",
      "[2500]\ttraining's rmse: 1.43913\tvalid_1's rmse: 1.55146\n",
      "[2600]\ttraining's rmse: 1.43515\tvalid_1's rmse: 1.55149\n",
      "[2700]\ttraining's rmse: 1.43123\tvalid_1's rmse: 1.55149\n",
      "[2800]\ttraining's rmse: 1.42741\tvalid_1's rmse: 1.55148\n",
      "[2900]\ttraining's rmse: 1.4235\tvalid_1's rmse: 1.55143\n",
      "[3000]\ttraining's rmse: 1.41964\tvalid_1's rmse: 1.55138\n",
      "[3100]\ttraining's rmse: 1.41573\tvalid_1's rmse: 1.55128\n",
      "[3200]\ttraining's rmse: 1.4121\tvalid_1's rmse: 1.5513\n",
      "[3300]\ttraining's rmse: 1.40839\tvalid_1's rmse: 1.55131\n",
      "[3400]\ttraining's rmse: 1.40472\tvalid_1's rmse: 1.55132\n",
      "[3500]\ttraining's rmse: 1.40108\tvalid_1's rmse: 1.55136\n",
      "[3600]\ttraining's rmse: 1.39732\tvalid_1's rmse: 1.55141\n",
      "[3700]\ttraining's rmse: 1.39363\tvalid_1's rmse: 1.55146\n",
      "Early stopping, best iteration is:\n",
      "[3149]\ttraining's rmse: 1.41396\tvalid_1's rmse: 1.5512\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60838\tvalid_1's rmse: 1.58929\n",
      "[200]\ttraining's rmse: 1.57547\tvalid_1's rmse: 1.56354\n",
      "[300]\ttraining's rmse: 1.55927\tvalid_1's rmse: 1.55356\n",
      "[400]\ttraining's rmse: 1.54817\tvalid_1's rmse: 1.54821\n",
      "[500]\ttraining's rmse: 1.53918\tvalid_1's rmse: 1.54527\n",
      "[600]\ttraining's rmse: 1.53139\tvalid_1's rmse: 1.54339\n",
      "[700]\ttraining's rmse: 1.52449\tvalid_1's rmse: 1.5421\n",
      "[800]\ttraining's rmse: 1.51821\tvalid_1's rmse: 1.54124\n",
      "[900]\ttraining's rmse: 1.51251\tvalid_1's rmse: 1.54087\n",
      "[1000]\ttraining's rmse: 1.50709\tvalid_1's rmse: 1.54045\n",
      "[1100]\ttraining's rmse: 1.50203\tvalid_1's rmse: 1.54022\n",
      "[1200]\ttraining's rmse: 1.49706\tvalid_1's rmse: 1.54012\n",
      "[1300]\ttraining's rmse: 1.49221\tvalid_1's rmse: 1.53999\n",
      "[1400]\ttraining's rmse: 1.48734\tvalid_1's rmse: 1.53995\n",
      "[1500]\ttraining's rmse: 1.4828\tvalid_1's rmse: 1.53985\n",
      "[1600]\ttraining's rmse: 1.47828\tvalid_1's rmse: 1.53976\n",
      "[1700]\ttraining's rmse: 1.47382\tvalid_1's rmse: 1.53967\n",
      "[1800]\ttraining's rmse: 1.46943\tvalid_1's rmse: 1.53957\n",
      "[1900]\ttraining's rmse: 1.46508\tvalid_1's rmse: 1.53948\n",
      "[2000]\ttraining's rmse: 1.46074\tvalid_1's rmse: 1.53962\n",
      "[2100]\ttraining's rmse: 1.4565\tvalid_1's rmse: 1.53975\n",
      "[2200]\ttraining's rmse: 1.45233\tvalid_1's rmse: 1.53981\n",
      "[2300]\ttraining's rmse: 1.44814\tvalid_1's rmse: 1.5399\n",
      "[2400]\ttraining's rmse: 1.4441\tvalid_1's rmse: 1.54003\n",
      "Early stopping, best iteration is:\n",
      "[1893]\ttraining's rmse: 1.46538\tvalid_1's rmse: 1.53946\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 1.60747\tvalid_1's rmse: 1.599\n",
      "[200]\ttraining's rmse: 1.57459\tvalid_1's rmse: 1.57105\n",
      "[300]\ttraining's rmse: 1.55848\tvalid_1's rmse: 1.56063\n",
      "[400]\ttraining's rmse: 1.54732\tvalid_1's rmse: 1.55546\n",
      "[500]\ttraining's rmse: 1.53836\tvalid_1's rmse: 1.55255\n",
      "[600]\ttraining's rmse: 1.53071\tvalid_1's rmse: 1.55069\n",
      "[700]\ttraining's rmse: 1.524\tvalid_1's rmse: 1.54955\n",
      "[800]\ttraining's rmse: 1.51784\tvalid_1's rmse: 1.54902\n",
      "[900]\ttraining's rmse: 1.5121\tvalid_1's rmse: 1.54846\n",
      "[1000]\ttraining's rmse: 1.50678\tvalid_1's rmse: 1.54802\n",
      "[1100]\ttraining's rmse: 1.50158\tvalid_1's rmse: 1.54767\n",
      "[1200]\ttraining's rmse: 1.49663\tvalid_1's rmse: 1.54738\n",
      "[1300]\ttraining's rmse: 1.49179\tvalid_1's rmse: 1.54716\n",
      "[1400]\ttraining's rmse: 1.48707\tvalid_1's rmse: 1.54704\n",
      "[1500]\ttraining's rmse: 1.48234\tvalid_1's rmse: 1.54693\n",
      "[1600]\ttraining's rmse: 1.47774\tvalid_1's rmse: 1.54687\n",
      "[1700]\ttraining's rmse: 1.47329\tvalid_1's rmse: 1.5467\n",
      "[1800]\ttraining's rmse: 1.46891\tvalid_1's rmse: 1.54661\n",
      "[1900]\ttraining's rmse: 1.46449\tvalid_1's rmse: 1.54659\n",
      "[2000]\ttraining's rmse: 1.46016\tvalid_1's rmse: 1.54655\n",
      "[2100]\ttraining's rmse: 1.4559\tvalid_1's rmse: 1.54656\n",
      "[2200]\ttraining's rmse: 1.45173\tvalid_1's rmse: 1.54647\n",
      "[2300]\ttraining's rmse: 1.44767\tvalid_1's rmse: 1.54653\n",
      "[2400]\ttraining's rmse: 1.44375\tvalid_1's rmse: 1.54647\n",
      "[2500]\ttraining's rmse: 1.43971\tvalid_1's rmse: 1.54638\n",
      "[2600]\ttraining's rmse: 1.43569\tvalid_1's rmse: 1.54645\n",
      "[2700]\ttraining's rmse: 1.43171\tvalid_1's rmse: 1.54643\n",
      "[2800]\ttraining's rmse: 1.42773\tvalid_1's rmse: 1.54642\n",
      "[2900]\ttraining's rmse: 1.42372\tvalid_1's rmse: 1.5464\n",
      "[3000]\ttraining's rmse: 1.41983\tvalid_1's rmse: 1.54627\n",
      "[3100]\ttraining's rmse: 1.41612\tvalid_1's rmse: 1.54609\n",
      "[3200]\ttraining's rmse: 1.41229\tvalid_1's rmse: 1.54607\n",
      "[3300]\ttraining's rmse: 1.40862\tvalid_1's rmse: 1.54596\n",
      "[3400]\ttraining's rmse: 1.40483\tvalid_1's rmse: 1.54586\n",
      "[3500]\ttraining's rmse: 1.40101\tvalid_1's rmse: 1.54575\n",
      "[3600]\ttraining's rmse: 1.39738\tvalid_1's rmse: 1.5458\n",
      "[3700]\ttraining's rmse: 1.39376\tvalid_1's rmse: 1.54588\n",
      "[3800]\ttraining's rmse: 1.39012\tvalid_1's rmse: 1.54585\n",
      "[3900]\ttraining's rmse: 1.38644\tvalid_1's rmse: 1.54582\n",
      "[4000]\ttraining's rmse: 1.38282\tvalid_1's rmse: 1.54581\n",
      "[4100]\ttraining's rmse: 1.3793\tvalid_1's rmse: 1.54581\n",
      "Early stopping, best iteration is:\n",
      "[3538]\ttraining's rmse: 1.39967\tvalid_1's rmse: 1.54572\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60347\tvalid_1's rmse: 1.63197\n",
      "[200]\ttraining's rmse: 1.57078\tvalid_1's rmse: 1.60228\n",
      "[300]\ttraining's rmse: 1.55481\tvalid_1's rmse: 1.59022\n",
      "[400]\ttraining's rmse: 1.5437\tvalid_1's rmse: 1.5838\n",
      "[500]\ttraining's rmse: 1.5348\tvalid_1's rmse: 1.58002\n",
      "[600]\ttraining's rmse: 1.52716\tvalid_1's rmse: 1.57757\n",
      "[700]\ttraining's rmse: 1.52022\tvalid_1's rmse: 1.5761\n",
      "[800]\ttraining's rmse: 1.514\tvalid_1's rmse: 1.57519\n",
      "[900]\ttraining's rmse: 1.50833\tvalid_1's rmse: 1.57461\n",
      "[1000]\ttraining's rmse: 1.50296\tvalid_1's rmse: 1.57403\n",
      "[1100]\ttraining's rmse: 1.49778\tvalid_1's rmse: 1.57367\n",
      "[1200]\ttraining's rmse: 1.49293\tvalid_1's rmse: 1.5734\n",
      "[1300]\ttraining's rmse: 1.48827\tvalid_1's rmse: 1.57315\n",
      "[1400]\ttraining's rmse: 1.48346\tvalid_1's rmse: 1.57314\n",
      "[1500]\ttraining's rmse: 1.47894\tvalid_1's rmse: 1.57297\n",
      "[1600]\ttraining's rmse: 1.4744\tvalid_1's rmse: 1.57287\n",
      "[1700]\ttraining's rmse: 1.47\tvalid_1's rmse: 1.57304\n",
      "[1800]\ttraining's rmse: 1.46542\tvalid_1's rmse: 1.57289\n",
      "[1900]\ttraining's rmse: 1.46093\tvalid_1's rmse: 1.57272\n",
      "[2000]\ttraining's rmse: 1.45671\tvalid_1's rmse: 1.57269\n",
      "[2100]\ttraining's rmse: 1.45252\tvalid_1's rmse: 1.5727\n",
      "[2200]\ttraining's rmse: 1.44843\tvalid_1's rmse: 1.57266\n",
      "[2300]\ttraining's rmse: 1.4443\tvalid_1's rmse: 1.57259\n",
      "[2400]\ttraining's rmse: 1.44025\tvalid_1's rmse: 1.57258\n",
      "[2500]\ttraining's rmse: 1.43621\tvalid_1's rmse: 1.57265\n",
      "[2600]\ttraining's rmse: 1.4321\tvalid_1's rmse: 1.57274\n",
      "[2700]\ttraining's rmse: 1.42807\tvalid_1's rmse: 1.57272\n",
      "[2800]\ttraining's rmse: 1.42422\tvalid_1's rmse: 1.57267\n",
      "[2900]\ttraining's rmse: 1.42034\tvalid_1's rmse: 1.57264\n",
      "Early stopping, best iteration is:\n",
      "[2334]\ttraining's rmse: 1.44294\tvalid_1's rmse: 1.57255\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60416\tvalid_1's rmse: 1.62655\n",
      "[200]\ttraining's rmse: 1.5714\tvalid_1's rmse: 1.5981\n",
      "[300]\ttraining's rmse: 1.55547\tvalid_1's rmse: 1.58721\n",
      "[400]\ttraining's rmse: 1.54452\tvalid_1's rmse: 1.58133\n",
      "[500]\ttraining's rmse: 1.53564\tvalid_1's rmse: 1.5777\n",
      "[600]\ttraining's rmse: 1.52798\tvalid_1's rmse: 1.5754\n",
      "[700]\ttraining's rmse: 1.52113\tvalid_1's rmse: 1.57403\n",
      "[800]\ttraining's rmse: 1.51507\tvalid_1's rmse: 1.57314\n",
      "[900]\ttraining's rmse: 1.50924\tvalid_1's rmse: 1.57245\n",
      "[1000]\ttraining's rmse: 1.5039\tvalid_1's rmse: 1.57206\n",
      "[1100]\ttraining's rmse: 1.49881\tvalid_1's rmse: 1.57174\n",
      "[1200]\ttraining's rmse: 1.49371\tvalid_1's rmse: 1.57149\n",
      "[1300]\ttraining's rmse: 1.48884\tvalid_1's rmse: 1.57124\n",
      "[1400]\ttraining's rmse: 1.48416\tvalid_1's rmse: 1.57106\n",
      "[1500]\ttraining's rmse: 1.47959\tvalid_1's rmse: 1.57094\n",
      "[1600]\ttraining's rmse: 1.47501\tvalid_1's rmse: 1.57081\n",
      "[1700]\ttraining's rmse: 1.47065\tvalid_1's rmse: 1.57082\n",
      "[1800]\ttraining's rmse: 1.46618\tvalid_1's rmse: 1.57088\n",
      "[1900]\ttraining's rmse: 1.46173\tvalid_1's rmse: 1.57092\n",
      "[2000]\ttraining's rmse: 1.4575\tvalid_1's rmse: 1.57086\n",
      "[2100]\ttraining's rmse: 1.4533\tvalid_1's rmse: 1.57085\n",
      "[2200]\ttraining's rmse: 1.44909\tvalid_1's rmse: 1.57074\n",
      "[2300]\ttraining's rmse: 1.44488\tvalid_1's rmse: 1.57075\n",
      "[2400]\ttraining's rmse: 1.44073\tvalid_1's rmse: 1.57069\n",
      "[2500]\ttraining's rmse: 1.43675\tvalid_1's rmse: 1.57076\n",
      "[2600]\ttraining's rmse: 1.43277\tvalid_1's rmse: 1.57084\n",
      "[2700]\ttraining's rmse: 1.42882\tvalid_1's rmse: 1.57072\n",
      "[2800]\ttraining's rmse: 1.42484\tvalid_1's rmse: 1.57069\n",
      "[2900]\ttraining's rmse: 1.42098\tvalid_1's rmse: 1.57081\n",
      "[3000]\ttraining's rmse: 1.41712\tvalid_1's rmse: 1.57082\n",
      "[3100]\ttraining's rmse: 1.41318\tvalid_1's rmse: 1.57092\n",
      "[3200]\ttraining's rmse: 1.40939\tvalid_1's rmse: 1.57099\n",
      "[3300]\ttraining's rmse: 1.40565\tvalid_1's rmse: 1.57107\n",
      "Early stopping, best iteration is:\n",
      "[2779]\ttraining's rmse: 1.42568\tvalid_1's rmse: 1.57066\n",
      "fold 8 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60671\tvalid_1's rmse: 1.60266\n",
      "[200]\ttraining's rmse: 1.57361\tvalid_1's rmse: 1.57717\n",
      "[300]\ttraining's rmse: 1.55735\tvalid_1's rmse: 1.56784\n",
      "[400]\ttraining's rmse: 1.54624\tvalid_1's rmse: 1.56296\n",
      "[500]\ttraining's rmse: 1.53726\tvalid_1's rmse: 1.56006\n",
      "[600]\ttraining's rmse: 1.52957\tvalid_1's rmse: 1.5583\n",
      "[700]\ttraining's rmse: 1.52272\tvalid_1's rmse: 1.55729\n",
      "[800]\ttraining's rmse: 1.5165\tvalid_1's rmse: 1.55669\n",
      "[900]\ttraining's rmse: 1.5108\tvalid_1's rmse: 1.55638\n",
      "[1000]\ttraining's rmse: 1.50526\tvalid_1's rmse: 1.55618\n",
      "[1100]\ttraining's rmse: 1.50018\tvalid_1's rmse: 1.55605\n",
      "[1200]\ttraining's rmse: 1.4951\tvalid_1's rmse: 1.55589\n",
      "[1300]\ttraining's rmse: 1.49021\tvalid_1's rmse: 1.55587\n",
      "[1400]\ttraining's rmse: 1.48535\tvalid_1's rmse: 1.55575\n",
      "[1500]\ttraining's rmse: 1.48077\tvalid_1's rmse: 1.55579\n",
      "[1600]\ttraining's rmse: 1.47638\tvalid_1's rmse: 1.55589\n",
      "[1700]\ttraining's rmse: 1.47192\tvalid_1's rmse: 1.55584\n",
      "[1800]\ttraining's rmse: 1.46755\tvalid_1's rmse: 1.55573\n",
      "[1900]\ttraining's rmse: 1.46316\tvalid_1's rmse: 1.55576\n",
      "[2000]\ttraining's rmse: 1.45886\tvalid_1's rmse: 1.55576\n",
      "Early stopping, best iteration is:\n",
      "[1440]\ttraining's rmse: 1.4835\tvalid_1's rmse: 1.5557\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60437\tvalid_1's rmse: 1.5888\n",
      "[200]\ttraining's rmse: 1.57115\tvalid_1's rmse: 1.56198\n",
      "[300]\ttraining's rmse: 1.55591\tvalid_1's rmse: 1.55232\n",
      "[400]\ttraining's rmse: 1.54593\tvalid_1's rmse: 1.5476\n",
      "[500]\ttraining's rmse: 1.53861\tvalid_1's rmse: 1.54515\n",
      "[600]\ttraining's rmse: 1.53261\tvalid_1's rmse: 1.54384\n",
      "[700]\ttraining's rmse: 1.5274\tvalid_1's rmse: 1.54289\n",
      "[800]\ttraining's rmse: 1.52256\tvalid_1's rmse: 1.54226\n",
      "[900]\ttraining's rmse: 1.51824\tvalid_1's rmse: 1.54198\n",
      "[1000]\ttraining's rmse: 1.51415\tvalid_1's rmse: 1.5417\n",
      "[1100]\ttraining's rmse: 1.51018\tvalid_1's rmse: 1.54149\n",
      "[1200]\ttraining's rmse: 1.50653\tvalid_1's rmse: 1.54151\n",
      "[1300]\ttraining's rmse: 1.50276\tvalid_1's rmse: 1.54151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttraining's rmse: 1.49915\tvalid_1's rmse: 1.54155\n",
      "[1500]\ttraining's rmse: 1.49558\tvalid_1's rmse: 1.54152\n",
      "[1600]\ttraining's rmse: 1.49201\tvalid_1's rmse: 1.54139\n",
      "[1700]\ttraining's rmse: 1.48853\tvalid_1's rmse: 1.54134\n",
      "[1800]\ttraining's rmse: 1.48516\tvalid_1's rmse: 1.54148\n",
      "[1900]\ttraining's rmse: 1.48188\tvalid_1's rmse: 1.54145\n",
      "[2000]\ttraining's rmse: 1.47851\tvalid_1's rmse: 1.54137\n",
      "[2100]\ttraining's rmse: 1.47526\tvalid_1's rmse: 1.54147\n",
      "[2200]\ttraining's rmse: 1.47198\tvalid_1's rmse: 1.54151\n",
      "[2300]\ttraining's rmse: 1.46869\tvalid_1's rmse: 1.54151\n",
      "[2400]\ttraining's rmse: 1.46559\tvalid_1's rmse: 1.54161\n",
      "[2500]\ttraining's rmse: 1.46253\tvalid_1's rmse: 1.54167\n",
      "[2600]\ttraining's rmse: 1.45953\tvalid_1's rmse: 1.54174\n",
      "Early stopping, best iteration is:\n",
      "[2042]\ttraining's rmse: 1.4772\tvalid_1's rmse: 1.54131\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60237\tvalid_1's rmse: 1.60666\n",
      "[200]\ttraining's rmse: 1.56955\tvalid_1's rmse: 1.57831\n",
      "[300]\ttraining's rmse: 1.5544\tvalid_1's rmse: 1.56711\n",
      "[400]\ttraining's rmse: 1.5446\tvalid_1's rmse: 1.56148\n",
      "[500]\ttraining's rmse: 1.53723\tvalid_1's rmse: 1.55861\n",
      "[600]\ttraining's rmse: 1.53107\tvalid_1's rmse: 1.55674\n",
      "[700]\ttraining's rmse: 1.52586\tvalid_1's rmse: 1.55566\n",
      "[800]\ttraining's rmse: 1.52133\tvalid_1's rmse: 1.555\n",
      "[900]\ttraining's rmse: 1.51697\tvalid_1's rmse: 1.55445\n",
      "[1000]\ttraining's rmse: 1.51286\tvalid_1's rmse: 1.55407\n",
      "[1100]\ttraining's rmse: 1.50902\tvalid_1's rmse: 1.55382\n",
      "[1200]\ttraining's rmse: 1.5053\tvalid_1's rmse: 1.55368\n",
      "[1300]\ttraining's rmse: 1.50154\tvalid_1's rmse: 1.55356\n",
      "[1400]\ttraining's rmse: 1.49792\tvalid_1's rmse: 1.55351\n",
      "[1500]\ttraining's rmse: 1.49433\tvalid_1's rmse: 1.55339\n",
      "[1600]\ttraining's rmse: 1.49078\tvalid_1's rmse: 1.55322\n",
      "[1700]\ttraining's rmse: 1.48744\tvalid_1's rmse: 1.55325\n",
      "[1800]\ttraining's rmse: 1.48413\tvalid_1's rmse: 1.55337\n",
      "[1900]\ttraining's rmse: 1.48072\tvalid_1's rmse: 1.5534\n",
      "[2000]\ttraining's rmse: 1.47741\tvalid_1's rmse: 1.55323\n",
      "[2100]\ttraining's rmse: 1.47414\tvalid_1's rmse: 1.55325\n",
      "[2200]\ttraining's rmse: 1.47087\tvalid_1's rmse: 1.55325\n",
      "[2300]\ttraining's rmse: 1.4675\tvalid_1's rmse: 1.55322\n",
      "[2400]\ttraining's rmse: 1.46433\tvalid_1's rmse: 1.55322\n",
      "[2500]\ttraining's rmse: 1.46117\tvalid_1's rmse: 1.55336\n",
      "[2600]\ttraining's rmse: 1.45806\tvalid_1's rmse: 1.5534\n",
      "Early stopping, best iteration is:\n",
      "[2058]\ttraining's rmse: 1.47559\tvalid_1's rmse: 1.55315\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59869\tvalid_1's rmse: 1.63804\n",
      "[200]\ttraining's rmse: 1.56596\tvalid_1's rmse: 1.60809\n",
      "[300]\ttraining's rmse: 1.55091\tvalid_1's rmse: 1.59627\n",
      "[400]\ttraining's rmse: 1.5412\tvalid_1's rmse: 1.59014\n",
      "[500]\ttraining's rmse: 1.53387\tvalid_1's rmse: 1.58644\n",
      "[600]\ttraining's rmse: 1.5278\tvalid_1's rmse: 1.58433\n",
      "[700]\ttraining's rmse: 1.52258\tvalid_1's rmse: 1.58285\n",
      "[800]\ttraining's rmse: 1.51782\tvalid_1's rmse: 1.58184\n",
      "[900]\ttraining's rmse: 1.51359\tvalid_1's rmse: 1.58133\n",
      "[1000]\ttraining's rmse: 1.50943\tvalid_1's rmse: 1.58075\n",
      "[1100]\ttraining's rmse: 1.50554\tvalid_1's rmse: 1.58022\n",
      "[1200]\ttraining's rmse: 1.50176\tvalid_1's rmse: 1.57978\n",
      "[1300]\ttraining's rmse: 1.49808\tvalid_1's rmse: 1.57966\n",
      "[1400]\ttraining's rmse: 1.49452\tvalid_1's rmse: 1.57943\n",
      "[1500]\ttraining's rmse: 1.49094\tvalid_1's rmse: 1.57935\n",
      "[1600]\ttraining's rmse: 1.4875\tvalid_1's rmse: 1.57914\n",
      "[1700]\ttraining's rmse: 1.48397\tvalid_1's rmse: 1.57898\n",
      "[1800]\ttraining's rmse: 1.48055\tvalid_1's rmse: 1.57885\n",
      "[1900]\ttraining's rmse: 1.4772\tvalid_1's rmse: 1.57857\n",
      "[2000]\ttraining's rmse: 1.47401\tvalid_1's rmse: 1.57844\n",
      "[2100]\ttraining's rmse: 1.47079\tvalid_1's rmse: 1.57844\n",
      "[2200]\ttraining's rmse: 1.4675\tvalid_1's rmse: 1.57836\n",
      "[2300]\ttraining's rmse: 1.46435\tvalid_1's rmse: 1.57836\n",
      "[2400]\ttraining's rmse: 1.46123\tvalid_1's rmse: 1.57829\n",
      "[2500]\ttraining's rmse: 1.45809\tvalid_1's rmse: 1.57836\n",
      "[2600]\ttraining's rmse: 1.45508\tvalid_1's rmse: 1.57834\n",
      "[2700]\ttraining's rmse: 1.45202\tvalid_1's rmse: 1.57831\n",
      "[2800]\ttraining's rmse: 1.44896\tvalid_1's rmse: 1.57836\n",
      "[2900]\ttraining's rmse: 1.44592\tvalid_1's rmse: 1.57824\n",
      "[3000]\ttraining's rmse: 1.44279\tvalid_1's rmse: 1.5782\n",
      "[3100]\ttraining's rmse: 1.43981\tvalid_1's rmse: 1.57824\n",
      "[3200]\ttraining's rmse: 1.43681\tvalid_1's rmse: 1.57831\n",
      "[3300]\ttraining's rmse: 1.43386\tvalid_1's rmse: 1.57824\n",
      "[3400]\ttraining's rmse: 1.43096\tvalid_1's rmse: 1.57832\n",
      "[3500]\ttraining's rmse: 1.42804\tvalid_1's rmse: 1.57853\n",
      "[3600]\ttraining's rmse: 1.42515\tvalid_1's rmse: 1.57858\n",
      "Early stopping, best iteration is:\n",
      "[3065]\ttraining's rmse: 1.44085\tvalid_1's rmse: 1.57816\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60285\tvalid_1's rmse: 1.60045\n",
      "[200]\ttraining's rmse: 1.56986\tvalid_1's rmse: 1.57263\n",
      "[300]\ttraining's rmse: 1.55472\tvalid_1's rmse: 1.56227\n",
      "[400]\ttraining's rmse: 1.54492\tvalid_1's rmse: 1.55685\n",
      "[500]\ttraining's rmse: 1.53751\tvalid_1's rmse: 1.55362\n",
      "[600]\ttraining's rmse: 1.53153\tvalid_1's rmse: 1.55169\n",
      "[700]\ttraining's rmse: 1.52622\tvalid_1's rmse: 1.5504\n",
      "[800]\ttraining's rmse: 1.52149\tvalid_1's rmse: 1.54963\n",
      "[900]\ttraining's rmse: 1.51724\tvalid_1's rmse: 1.5492\n",
      "[1000]\ttraining's rmse: 1.51302\tvalid_1's rmse: 1.54867\n",
      "[1100]\ttraining's rmse: 1.50912\tvalid_1's rmse: 1.54835\n",
      "[1200]\ttraining's rmse: 1.50534\tvalid_1's rmse: 1.54803\n",
      "[1300]\ttraining's rmse: 1.50164\tvalid_1's rmse: 1.5479\n",
      "[1400]\ttraining's rmse: 1.498\tvalid_1's rmse: 1.54781\n",
      "[1500]\ttraining's rmse: 1.49453\tvalid_1's rmse: 1.54765\n",
      "[1600]\ttraining's rmse: 1.49126\tvalid_1's rmse: 1.54753\n",
      "[1700]\ttraining's rmse: 1.48794\tvalid_1's rmse: 1.54746\n",
      "[1800]\ttraining's rmse: 1.48444\tvalid_1's rmse: 1.54744\n",
      "[1900]\ttraining's rmse: 1.48114\tvalid_1's rmse: 1.54749\n",
      "[2000]\ttraining's rmse: 1.47784\tvalid_1's rmse: 1.5475\n",
      "[2100]\ttraining's rmse: 1.47466\tvalid_1's rmse: 1.54761\n",
      "[2200]\ttraining's rmse: 1.47142\tvalid_1's rmse: 1.54767\n",
      "[2300]\ttraining's rmse: 1.46825\tvalid_1's rmse: 1.54746\n",
      "[2400]\ttraining's rmse: 1.46519\tvalid_1's rmse: 1.54747\n",
      "Early stopping, best iteration is:\n",
      "[1833]\ttraining's rmse: 1.48336\tvalid_1's rmse: 1.54739\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60449\tvalid_1's rmse: 1.58548\n",
      "[200]\ttraining's rmse: 1.57159\tvalid_1's rmse: 1.5587\n",
      "[300]\ttraining's rmse: 1.55636\tvalid_1's rmse: 1.54845\n",
      "[400]\ttraining's rmse: 1.5465\tvalid_1's rmse: 1.54326\n",
      "[500]\ttraining's rmse: 1.53915\tvalid_1's rmse: 1.54044\n",
      "[600]\ttraining's rmse: 1.53293\tvalid_1's rmse: 1.53906\n",
      "[700]\ttraining's rmse: 1.52775\tvalid_1's rmse: 1.53819\n",
      "[800]\ttraining's rmse: 1.52306\tvalid_1's rmse: 1.53799\n",
      "[900]\ttraining's rmse: 1.51878\tvalid_1's rmse: 1.53771\n",
      "[1000]\ttraining's rmse: 1.51474\tvalid_1's rmse: 1.53739\n",
      "[1100]\ttraining's rmse: 1.51074\tvalid_1's rmse: 1.53712\n",
      "[1200]\ttraining's rmse: 1.50687\tvalid_1's rmse: 1.53701\n",
      "[1300]\ttraining's rmse: 1.50316\tvalid_1's rmse: 1.53694\n",
      "[1400]\ttraining's rmse: 1.4996\tvalid_1's rmse: 1.53699\n",
      "[1500]\ttraining's rmse: 1.49602\tvalid_1's rmse: 1.53703\n",
      "[1600]\ttraining's rmse: 1.49242\tvalid_1's rmse: 1.5369\n",
      "[1700]\ttraining's rmse: 1.48901\tvalid_1's rmse: 1.53686\n",
      "[1800]\ttraining's rmse: 1.48563\tvalid_1's rmse: 1.53682\n",
      "[1900]\ttraining's rmse: 1.4823\tvalid_1's rmse: 1.53685\n",
      "[2000]\ttraining's rmse: 1.47891\tvalid_1's rmse: 1.53697\n",
      "[2100]\ttraining's rmse: 1.47559\tvalid_1's rmse: 1.537\n",
      "[2200]\ttraining's rmse: 1.47246\tvalid_1's rmse: 1.53702\n",
      "[2300]\ttraining's rmse: 1.46918\tvalid_1's rmse: 1.53709\n",
      "Early stopping, best iteration is:\n",
      "[1769]\ttraining's rmse: 1.48661\tvalid_1's rmse: 1.53681\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60379\tvalid_1's rmse: 1.59459\n",
      "[200]\ttraining's rmse: 1.57084\tvalid_1's rmse: 1.56572\n",
      "[300]\ttraining's rmse: 1.55574\tvalid_1's rmse: 1.55488\n",
      "[400]\ttraining's rmse: 1.54607\tvalid_1's rmse: 1.54978\n",
      "[500]\ttraining's rmse: 1.5388\tvalid_1's rmse: 1.54695\n",
      "[600]\ttraining's rmse: 1.53278\tvalid_1's rmse: 1.54519\n",
      "[700]\ttraining's rmse: 1.52756\tvalid_1's rmse: 1.54399\n",
      "[800]\ttraining's rmse: 1.52283\tvalid_1's rmse: 1.54327\n",
      "[900]\ttraining's rmse: 1.51847\tvalid_1's rmse: 1.54291\n",
      "[1000]\ttraining's rmse: 1.51449\tvalid_1's rmse: 1.54262\n",
      "[1100]\ttraining's rmse: 1.51051\tvalid_1's rmse: 1.54223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 1.50661\tvalid_1's rmse: 1.54205\n",
      "[1300]\ttraining's rmse: 1.503\tvalid_1's rmse: 1.54203\n",
      "[1400]\ttraining's rmse: 1.49944\tvalid_1's rmse: 1.54182\n",
      "[1500]\ttraining's rmse: 1.49594\tvalid_1's rmse: 1.54164\n",
      "[1600]\ttraining's rmse: 1.4923\tvalid_1's rmse: 1.54159\n",
      "[1700]\ttraining's rmse: 1.48891\tvalid_1's rmse: 1.54154\n",
      "[1800]\ttraining's rmse: 1.48551\tvalid_1's rmse: 1.54155\n",
      "[1900]\ttraining's rmse: 1.48223\tvalid_1's rmse: 1.54144\n",
      "[2000]\ttraining's rmse: 1.47883\tvalid_1's rmse: 1.54155\n",
      "[2100]\ttraining's rmse: 1.47545\tvalid_1's rmse: 1.54127\n",
      "[2200]\ttraining's rmse: 1.4721\tvalid_1's rmse: 1.54142\n",
      "[2300]\ttraining's rmse: 1.46898\tvalid_1's rmse: 1.54143\n",
      "[2400]\ttraining's rmse: 1.46592\tvalid_1's rmse: 1.54141\n",
      "[2500]\ttraining's rmse: 1.46283\tvalid_1's rmse: 1.54131\n",
      "[2600]\ttraining's rmse: 1.45968\tvalid_1's rmse: 1.54139\n",
      "[2700]\ttraining's rmse: 1.45651\tvalid_1's rmse: 1.54142\n",
      "Early stopping, best iteration is:\n",
      "[2117]\ttraining's rmse: 1.47487\tvalid_1's rmse: 1.54123\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59995\tvalid_1's rmse: 1.62787\n",
      "[200]\ttraining's rmse: 1.56726\tvalid_1's rmse: 1.5975\n",
      "[300]\ttraining's rmse: 1.55216\tvalid_1's rmse: 1.58538\n",
      "[400]\ttraining's rmse: 1.54238\tvalid_1's rmse: 1.57884\n",
      "[500]\ttraining's rmse: 1.53507\tvalid_1's rmse: 1.57544\n",
      "[600]\ttraining's rmse: 1.52908\tvalid_1's rmse: 1.57332\n",
      "[700]\ttraining's rmse: 1.52385\tvalid_1's rmse: 1.57204\n",
      "[800]\ttraining's rmse: 1.51925\tvalid_1's rmse: 1.57115\n",
      "[900]\ttraining's rmse: 1.51501\tvalid_1's rmse: 1.57062\n",
      "[1000]\ttraining's rmse: 1.511\tvalid_1's rmse: 1.57025\n",
      "[1100]\ttraining's rmse: 1.50705\tvalid_1's rmse: 1.56995\n",
      "[1200]\ttraining's rmse: 1.50326\tvalid_1's rmse: 1.56958\n",
      "[1300]\ttraining's rmse: 1.49957\tvalid_1's rmse: 1.56931\n",
      "[1400]\ttraining's rmse: 1.49596\tvalid_1's rmse: 1.56912\n",
      "[1500]\ttraining's rmse: 1.49251\tvalid_1's rmse: 1.56903\n",
      "[1600]\ttraining's rmse: 1.489\tvalid_1's rmse: 1.56894\n",
      "[1700]\ttraining's rmse: 1.48565\tvalid_1's rmse: 1.56874\n",
      "[1800]\ttraining's rmse: 1.48227\tvalid_1's rmse: 1.56869\n",
      "[1900]\ttraining's rmse: 1.47895\tvalid_1's rmse: 1.56863\n",
      "[2000]\ttraining's rmse: 1.47569\tvalid_1's rmse: 1.56853\n",
      "[2100]\ttraining's rmse: 1.47254\tvalid_1's rmse: 1.56861\n",
      "[2200]\ttraining's rmse: 1.4693\tvalid_1's rmse: 1.56853\n",
      "[2300]\ttraining's rmse: 1.46606\tvalid_1's rmse: 1.56844\n",
      "[2400]\ttraining's rmse: 1.46297\tvalid_1's rmse: 1.56844\n",
      "[2500]\ttraining's rmse: 1.4597\tvalid_1's rmse: 1.56841\n",
      "[2600]\ttraining's rmse: 1.45661\tvalid_1's rmse: 1.56837\n",
      "[2700]\ttraining's rmse: 1.45351\tvalid_1's rmse: 1.56825\n",
      "[2800]\ttraining's rmse: 1.45041\tvalid_1's rmse: 1.56819\n",
      "[2900]\ttraining's rmse: 1.44739\tvalid_1's rmse: 1.56821\n",
      "[3000]\ttraining's rmse: 1.44429\tvalid_1's rmse: 1.5682\n",
      "[3100]\ttraining's rmse: 1.44124\tvalid_1's rmse: 1.56827\n",
      "[3200]\ttraining's rmse: 1.43824\tvalid_1's rmse: 1.5682\n",
      "[3300]\ttraining's rmse: 1.43524\tvalid_1's rmse: 1.56828\n",
      "[3400]\ttraining's rmse: 1.43228\tvalid_1's rmse: 1.56836\n",
      "Early stopping, best iteration is:\n",
      "[2842]\ttraining's rmse: 1.44915\tvalid_1's rmse: 1.56812\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60027\tvalid_1's rmse: 1.62268\n",
      "[200]\ttraining's rmse: 1.56771\tvalid_1's rmse: 1.59367\n",
      "[300]\ttraining's rmse: 1.55271\tvalid_1's rmse: 1.58255\n",
      "[400]\ttraining's rmse: 1.54296\tvalid_1's rmse: 1.57697\n",
      "[500]\ttraining's rmse: 1.5357\tvalid_1's rmse: 1.57365\n",
      "[600]\ttraining's rmse: 1.52957\tvalid_1's rmse: 1.5716\n",
      "[700]\ttraining's rmse: 1.5244\tvalid_1's rmse: 1.57034\n",
      "[800]\ttraining's rmse: 1.51976\tvalid_1's rmse: 1.56933\n",
      "[900]\ttraining's rmse: 1.51545\tvalid_1's rmse: 1.56868\n",
      "[1000]\ttraining's rmse: 1.51131\tvalid_1's rmse: 1.56804\n",
      "[1100]\ttraining's rmse: 1.50747\tvalid_1's rmse: 1.56762\n",
      "[1200]\ttraining's rmse: 1.50373\tvalid_1's rmse: 1.56743\n",
      "[1300]\ttraining's rmse: 1.50004\tvalid_1's rmse: 1.56719\n",
      "[1400]\ttraining's rmse: 1.49638\tvalid_1's rmse: 1.56699\n",
      "[1500]\ttraining's rmse: 1.49288\tvalid_1's rmse: 1.56691\n",
      "[1600]\ttraining's rmse: 1.48929\tvalid_1's rmse: 1.56668\n",
      "[1700]\ttraining's rmse: 1.48583\tvalid_1's rmse: 1.56636\n",
      "[1800]\ttraining's rmse: 1.4826\tvalid_1's rmse: 1.56641\n",
      "[1900]\ttraining's rmse: 1.47914\tvalid_1's rmse: 1.56635\n",
      "[2000]\ttraining's rmse: 1.47583\tvalid_1's rmse: 1.5663\n",
      "[2100]\ttraining's rmse: 1.47258\tvalid_1's rmse: 1.56629\n",
      "[2200]\ttraining's rmse: 1.46925\tvalid_1's rmse: 1.56622\n",
      "[2300]\ttraining's rmse: 1.46609\tvalid_1's rmse: 1.56616\n",
      "[2400]\ttraining's rmse: 1.46295\tvalid_1's rmse: 1.56618\n",
      "[2500]\ttraining's rmse: 1.4599\tvalid_1's rmse: 1.5663\n",
      "[2600]\ttraining's rmse: 1.45688\tvalid_1's rmse: 1.56635\n",
      "[2700]\ttraining's rmse: 1.45378\tvalid_1's rmse: 1.56642\n",
      "[2800]\ttraining's rmse: 1.45068\tvalid_1's rmse: 1.56639\n",
      "[2900]\ttraining's rmse: 1.44768\tvalid_1's rmse: 1.56639\n",
      "Early stopping, best iteration is:\n",
      "[2328]\ttraining's rmse: 1.46519\tvalid_1's rmse: 1.56612\n",
      "fold 8 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60293\tvalid_1's rmse: 1.59912\n",
      "[200]\ttraining's rmse: 1.56971\tvalid_1's rmse: 1.57309\n",
      "[300]\ttraining's rmse: 1.5543\tvalid_1's rmse: 1.56429\n",
      "[400]\ttraining's rmse: 1.54442\tvalid_1's rmse: 1.55981\n",
      "[500]\ttraining's rmse: 1.53706\tvalid_1's rmse: 1.55756\n",
      "[600]\ttraining's rmse: 1.53104\tvalid_1's rmse: 1.55619\n",
      "[700]\ttraining's rmse: 1.52579\tvalid_1's rmse: 1.55553\n",
      "[800]\ttraining's rmse: 1.52105\tvalid_1's rmse: 1.55512\n",
      "[900]\ttraining's rmse: 1.51676\tvalid_1's rmse: 1.55474\n",
      "[1000]\ttraining's rmse: 1.51263\tvalid_1's rmse: 1.55455\n",
      "[1100]\ttraining's rmse: 1.50863\tvalid_1's rmse: 1.55443\n",
      "[1200]\ttraining's rmse: 1.50484\tvalid_1's rmse: 1.5542\n",
      "[1300]\ttraining's rmse: 1.50113\tvalid_1's rmse: 1.55416\n",
      "[1400]\ttraining's rmse: 1.4974\tvalid_1's rmse: 1.55406\n",
      "[1500]\ttraining's rmse: 1.49385\tvalid_1's rmse: 1.55399\n",
      "[1600]\ttraining's rmse: 1.49029\tvalid_1's rmse: 1.55402\n",
      "[1700]\ttraining's rmse: 1.48682\tvalid_1's rmse: 1.55389\n",
      "[1800]\ttraining's rmse: 1.48349\tvalid_1's rmse: 1.55406\n",
      "[1900]\ttraining's rmse: 1.48\tvalid_1's rmse: 1.55402\n",
      "[2000]\ttraining's rmse: 1.47674\tvalid_1's rmse: 1.55395\n",
      "[2100]\ttraining's rmse: 1.47346\tvalid_1's rmse: 1.55389\n",
      "[2200]\ttraining's rmse: 1.47026\tvalid_1's rmse: 1.55394\n",
      "[2300]\ttraining's rmse: 1.46698\tvalid_1's rmse: 1.5539\n",
      "[2400]\ttraining's rmse: 1.46385\tvalid_1's rmse: 1.554\n",
      "[2500]\ttraining's rmse: 1.46075\tvalid_1's rmse: 1.55397\n",
      "[2600]\ttraining's rmse: 1.45773\tvalid_1's rmse: 1.55392\n",
      "[2700]\ttraining's rmse: 1.45465\tvalid_1's rmse: 1.55398\n",
      "[2800]\ttraining's rmse: 1.45166\tvalid_1's rmse: 1.554\n",
      "Early stopping, best iteration is:\n",
      "[2233]\ttraining's rmse: 1.4692\tvalid_1's rmse: 1.55384\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.6045\tvalid_1's rmse: 1.5889\n",
      "[200]\ttraining's rmse: 1.57141\tvalid_1's rmse: 1.56197\n",
      "[300]\ttraining's rmse: 1.55625\tvalid_1's rmse: 1.55228\n",
      "[400]\ttraining's rmse: 1.54666\tvalid_1's rmse: 1.54768\n",
      "[500]\ttraining's rmse: 1.53958\tvalid_1's rmse: 1.54563\n",
      "[600]\ttraining's rmse: 1.53389\tvalid_1's rmse: 1.54437\n",
      "[700]\ttraining's rmse: 1.5289\tvalid_1's rmse: 1.54371\n",
      "[800]\ttraining's rmse: 1.5244\tvalid_1's rmse: 1.5433\n",
      "[900]\ttraining's rmse: 1.52039\tvalid_1's rmse: 1.54304\n",
      "[1000]\ttraining's rmse: 1.51651\tvalid_1's rmse: 1.54278\n",
      "[1100]\ttraining's rmse: 1.51277\tvalid_1's rmse: 1.54271\n",
      "[1200]\ttraining's rmse: 1.50928\tvalid_1's rmse: 1.54258\n",
      "[1300]\ttraining's rmse: 1.50571\tvalid_1's rmse: 1.54243\n",
      "[1400]\ttraining's rmse: 1.50226\tvalid_1's rmse: 1.54226\n",
      "[1500]\ttraining's rmse: 1.49897\tvalid_1's rmse: 1.54221\n",
      "[1600]\ttraining's rmse: 1.49567\tvalid_1's rmse: 1.54219\n",
      "[1700]\ttraining's rmse: 1.49237\tvalid_1's rmse: 1.54227\n",
      "[1800]\ttraining's rmse: 1.48912\tvalid_1's rmse: 1.54216\n",
      "[1900]\ttraining's rmse: 1.48593\tvalid_1's rmse: 1.54208\n",
      "[2000]\ttraining's rmse: 1.4827\tvalid_1's rmse: 1.54209\n",
      "[2100]\ttraining's rmse: 1.47961\tvalid_1's rmse: 1.54216\n",
      "[2200]\ttraining's rmse: 1.47646\tvalid_1's rmse: 1.54217\n",
      "[2300]\ttraining's rmse: 1.47334\tvalid_1's rmse: 1.54216\n",
      "[2400]\ttraining's rmse: 1.47047\tvalid_1's rmse: 1.54228\n",
      "[2500]\ttraining's rmse: 1.46745\tvalid_1's rmse: 1.54226\n",
      "Early stopping, best iteration is:\n",
      "[1943]\ttraining's rmse: 1.48453\tvalid_1's rmse: 1.54201\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60231\tvalid_1's rmse: 1.60652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 1.56962\tvalid_1's rmse: 1.57799\n",
      "[300]\ttraining's rmse: 1.55463\tvalid_1's rmse: 1.56676\n",
      "[400]\ttraining's rmse: 1.54513\tvalid_1's rmse: 1.56108\n",
      "[500]\ttraining's rmse: 1.53808\tvalid_1's rmse: 1.55803\n",
      "[600]\ttraining's rmse: 1.53235\tvalid_1's rmse: 1.55613\n",
      "[700]\ttraining's rmse: 1.5274\tvalid_1's rmse: 1.55506\n",
      "[800]\ttraining's rmse: 1.52301\tvalid_1's rmse: 1.55433\n",
      "[900]\ttraining's rmse: 1.51895\tvalid_1's rmse: 1.5538\n",
      "[1000]\ttraining's rmse: 1.51516\tvalid_1's rmse: 1.55357\n",
      "[1100]\ttraining's rmse: 1.51147\tvalid_1's rmse: 1.55324\n",
      "[1200]\ttraining's rmse: 1.50799\tvalid_1's rmse: 1.55309\n",
      "[1300]\ttraining's rmse: 1.50454\tvalid_1's rmse: 1.55294\n",
      "[1400]\ttraining's rmse: 1.50115\tvalid_1's rmse: 1.55286\n",
      "[1500]\ttraining's rmse: 1.49781\tvalid_1's rmse: 1.55275\n",
      "[1600]\ttraining's rmse: 1.49451\tvalid_1's rmse: 1.55273\n",
      "[1700]\ttraining's rmse: 1.49126\tvalid_1's rmse: 1.5526\n",
      "[1800]\ttraining's rmse: 1.48804\tvalid_1's rmse: 1.55262\n",
      "[1900]\ttraining's rmse: 1.4848\tvalid_1's rmse: 1.55253\n",
      "[2000]\ttraining's rmse: 1.48161\tvalid_1's rmse: 1.55251\n",
      "[2100]\ttraining's rmse: 1.47838\tvalid_1's rmse: 1.55255\n",
      "[2200]\ttraining's rmse: 1.47524\tvalid_1's rmse: 1.55259\n",
      "[2300]\ttraining's rmse: 1.4722\tvalid_1's rmse: 1.55247\n",
      "[2400]\ttraining's rmse: 1.46921\tvalid_1's rmse: 1.55266\n",
      "[2500]\ttraining's rmse: 1.46617\tvalid_1's rmse: 1.5527\n",
      "Early stopping, best iteration is:\n",
      "[1989]\ttraining's rmse: 1.48197\tvalid_1's rmse: 1.55246\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59854\tvalid_1's rmse: 1.63768\n",
      "[200]\ttraining's rmse: 1.56613\tvalid_1's rmse: 1.6081\n",
      "[300]\ttraining's rmse: 1.55121\tvalid_1's rmse: 1.59637\n",
      "[400]\ttraining's rmse: 1.54179\tvalid_1's rmse: 1.5902\n",
      "[500]\ttraining's rmse: 1.53478\tvalid_1's rmse: 1.5868\n",
      "[600]\ttraining's rmse: 1.52911\tvalid_1's rmse: 1.58467\n",
      "[700]\ttraining's rmse: 1.52414\tvalid_1's rmse: 1.5833\n",
      "[800]\ttraining's rmse: 1.51983\tvalid_1's rmse: 1.58242\n",
      "[900]\ttraining's rmse: 1.51581\tvalid_1's rmse: 1.58205\n",
      "[1000]\ttraining's rmse: 1.51185\tvalid_1's rmse: 1.58171\n",
      "[1100]\ttraining's rmse: 1.50819\tvalid_1's rmse: 1.58122\n",
      "[1200]\ttraining's rmse: 1.50469\tvalid_1's rmse: 1.58097\n",
      "[1300]\ttraining's rmse: 1.50117\tvalid_1's rmse: 1.58068\n",
      "[1400]\ttraining's rmse: 1.49785\tvalid_1's rmse: 1.58055\n",
      "[1500]\ttraining's rmse: 1.49446\tvalid_1's rmse: 1.5803\n",
      "[1600]\ttraining's rmse: 1.49119\tvalid_1's rmse: 1.58028\n",
      "[1700]\ttraining's rmse: 1.48792\tvalid_1's rmse: 1.58016\n",
      "[1800]\ttraining's rmse: 1.48469\tvalid_1's rmse: 1.58003\n",
      "[1900]\ttraining's rmse: 1.48138\tvalid_1's rmse: 1.57993\n",
      "[2000]\ttraining's rmse: 1.47831\tvalid_1's rmse: 1.57988\n",
      "[2100]\ttraining's rmse: 1.47518\tvalid_1's rmse: 1.57986\n",
      "[2200]\ttraining's rmse: 1.47202\tvalid_1's rmse: 1.57987\n",
      "[2300]\ttraining's rmse: 1.46915\tvalid_1's rmse: 1.57973\n",
      "[2400]\ttraining's rmse: 1.46609\tvalid_1's rmse: 1.57958\n",
      "[2500]\ttraining's rmse: 1.46317\tvalid_1's rmse: 1.57955\n",
      "[2600]\ttraining's rmse: 1.46034\tvalid_1's rmse: 1.57949\n",
      "[2700]\ttraining's rmse: 1.45742\tvalid_1's rmse: 1.57938\n",
      "[2800]\ttraining's rmse: 1.45447\tvalid_1's rmse: 1.57938\n",
      "[2900]\ttraining's rmse: 1.45148\tvalid_1's rmse: 1.57932\n",
      "[3000]\ttraining's rmse: 1.44854\tvalid_1's rmse: 1.57945\n",
      "[3100]\ttraining's rmse: 1.44568\tvalid_1's rmse: 1.57946\n",
      "[3200]\ttraining's rmse: 1.44284\tvalid_1's rmse: 1.57959\n",
      "[3300]\ttraining's rmse: 1.44012\tvalid_1's rmse: 1.57967\n",
      "[3400]\ttraining's rmse: 1.43729\tvalid_1's rmse: 1.57977\n",
      "[3500]\ttraining's rmse: 1.43458\tvalid_1's rmse: 1.57979\n",
      "Early stopping, best iteration is:\n",
      "[2925]\ttraining's rmse: 1.4508\tvalid_1's rmse: 1.57929\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60293\tvalid_1's rmse: 1.6005\n",
      "[200]\ttraining's rmse: 1.57004\tvalid_1's rmse: 1.57289\n",
      "[300]\ttraining's rmse: 1.55506\tvalid_1's rmse: 1.56223\n",
      "[400]\ttraining's rmse: 1.54561\tvalid_1's rmse: 1.55687\n",
      "[500]\ttraining's rmse: 1.53855\tvalid_1's rmse: 1.55372\n",
      "[600]\ttraining's rmse: 1.53281\tvalid_1's rmse: 1.55176\n",
      "[700]\ttraining's rmse: 1.52791\tvalid_1's rmse: 1.55065\n",
      "[800]\ttraining's rmse: 1.52349\tvalid_1's rmse: 1.54988\n",
      "[900]\ttraining's rmse: 1.51935\tvalid_1's rmse: 1.54939\n",
      "[1000]\ttraining's rmse: 1.51555\tvalid_1's rmse: 1.54905\n",
      "[1100]\ttraining's rmse: 1.51187\tvalid_1's rmse: 1.54876\n",
      "[1200]\ttraining's rmse: 1.50843\tvalid_1's rmse: 1.54848\n",
      "[1300]\ttraining's rmse: 1.50493\tvalid_1's rmse: 1.54828\n",
      "[1400]\ttraining's rmse: 1.50139\tvalid_1's rmse: 1.54825\n",
      "[1500]\ttraining's rmse: 1.49811\tvalid_1's rmse: 1.54808\n",
      "[1600]\ttraining's rmse: 1.49487\tvalid_1's rmse: 1.54796\n",
      "[1700]\ttraining's rmse: 1.49171\tvalid_1's rmse: 1.54782\n",
      "[1800]\ttraining's rmse: 1.48847\tvalid_1's rmse: 1.54796\n",
      "[1900]\ttraining's rmse: 1.48532\tvalid_1's rmse: 1.54801\n",
      "[2000]\ttraining's rmse: 1.48211\tvalid_1's rmse: 1.54795\n",
      "[2100]\ttraining's rmse: 1.47903\tvalid_1's rmse: 1.54792\n",
      "[2200]\ttraining's rmse: 1.47584\tvalid_1's rmse: 1.54789\n",
      "Early stopping, best iteration is:\n",
      "[1691]\ttraining's rmse: 1.492\tvalid_1's rmse: 1.54782\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60457\tvalid_1's rmse: 1.58546\n",
      "[200]\ttraining's rmse: 1.5717\tvalid_1's rmse: 1.55858\n",
      "[300]\ttraining's rmse: 1.55671\tvalid_1's rmse: 1.54829\n",
      "[400]\ttraining's rmse: 1.54703\tvalid_1's rmse: 1.54302\n",
      "[500]\ttraining's rmse: 1.53989\tvalid_1's rmse: 1.54039\n",
      "[600]\ttraining's rmse: 1.53415\tvalid_1's rmse: 1.53912\n",
      "[700]\ttraining's rmse: 1.52922\tvalid_1's rmse: 1.53833\n",
      "[800]\ttraining's rmse: 1.52469\tvalid_1's rmse: 1.53776\n",
      "[900]\ttraining's rmse: 1.52072\tvalid_1's rmse: 1.53761\n",
      "[1000]\ttraining's rmse: 1.51687\tvalid_1's rmse: 1.53741\n",
      "[1100]\ttraining's rmse: 1.51318\tvalid_1's rmse: 1.53728\n",
      "[1200]\ttraining's rmse: 1.50963\tvalid_1's rmse: 1.53716\n",
      "[1300]\ttraining's rmse: 1.50617\tvalid_1's rmse: 1.53709\n",
      "[1400]\ttraining's rmse: 1.50278\tvalid_1's rmse: 1.53706\n",
      "[1500]\ttraining's rmse: 1.49942\tvalid_1's rmse: 1.53705\n",
      "[1600]\ttraining's rmse: 1.49606\tvalid_1's rmse: 1.53708\n",
      "[1700]\ttraining's rmse: 1.49279\tvalid_1's rmse: 1.53691\n",
      "[1800]\ttraining's rmse: 1.48956\tvalid_1's rmse: 1.53687\n",
      "[1900]\ttraining's rmse: 1.48632\tvalid_1's rmse: 1.53688\n",
      "[2000]\ttraining's rmse: 1.48318\tvalid_1's rmse: 1.53697\n",
      "[2100]\ttraining's rmse: 1.48\tvalid_1's rmse: 1.53693\n",
      "[2200]\ttraining's rmse: 1.47702\tvalid_1's rmse: 1.53698\n",
      "[2300]\ttraining's rmse: 1.47394\tvalid_1's rmse: 1.53699\n",
      "[2400]\ttraining's rmse: 1.471\tvalid_1's rmse: 1.53708\n",
      "[2500]\ttraining's rmse: 1.468\tvalid_1's rmse: 1.53714\n",
      "Early stopping, best iteration is:\n",
      "[1903]\ttraining's rmse: 1.48622\tvalid_1's rmse: 1.53686\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60383\tvalid_1's rmse: 1.59461\n",
      "[200]\ttraining's rmse: 1.57101\tvalid_1's rmse: 1.56567\n",
      "[300]\ttraining's rmse: 1.55607\tvalid_1's rmse: 1.55471\n",
      "[400]\ttraining's rmse: 1.54662\tvalid_1's rmse: 1.54951\n",
      "[500]\ttraining's rmse: 1.53962\tvalid_1's rmse: 1.54686\n",
      "[600]\ttraining's rmse: 1.53394\tvalid_1's rmse: 1.54538\n",
      "[700]\ttraining's rmse: 1.529\tvalid_1's rmse: 1.54451\n",
      "[800]\ttraining's rmse: 1.52455\tvalid_1's rmse: 1.54408\n",
      "[900]\ttraining's rmse: 1.52046\tvalid_1's rmse: 1.54377\n",
      "[1000]\ttraining's rmse: 1.51666\tvalid_1's rmse: 1.54347\n",
      "[1100]\ttraining's rmse: 1.51284\tvalid_1's rmse: 1.54324\n",
      "[1200]\ttraining's rmse: 1.50933\tvalid_1's rmse: 1.54306\n",
      "[1300]\ttraining's rmse: 1.50593\tvalid_1's rmse: 1.54296\n",
      "[1400]\ttraining's rmse: 1.50261\tvalid_1's rmse: 1.54297\n",
      "[1500]\ttraining's rmse: 1.4993\tvalid_1's rmse: 1.54285\n",
      "[1600]\ttraining's rmse: 1.49589\tvalid_1's rmse: 1.54279\n",
      "[1700]\ttraining's rmse: 1.49257\tvalid_1's rmse: 1.54275\n",
      "[1800]\ttraining's rmse: 1.48925\tvalid_1's rmse: 1.54277\n",
      "[1900]\ttraining's rmse: 1.4861\tvalid_1's rmse: 1.5427\n",
      "[2000]\ttraining's rmse: 1.48288\tvalid_1's rmse: 1.54272\n",
      "[2100]\ttraining's rmse: 1.47965\tvalid_1's rmse: 1.54282\n",
      "[2200]\ttraining's rmse: 1.47649\tvalid_1's rmse: 1.54297\n",
      "[2300]\ttraining's rmse: 1.4735\tvalid_1's rmse: 1.54298\n",
      "[2400]\ttraining's rmse: 1.47056\tvalid_1's rmse: 1.54311\n",
      "Early stopping, best iteration is:\n",
      "[1830]\ttraining's rmse: 1.48827\tvalid_1's rmse: 1.54267\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60001\tvalid_1's rmse: 1.62796\n",
      "[200]\ttraining's rmse: 1.56745\tvalid_1's rmse: 1.59733\n",
      "[300]\ttraining's rmse: 1.55257\tvalid_1's rmse: 1.5852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 1.54319\tvalid_1's rmse: 1.57876\n",
      "[500]\ttraining's rmse: 1.53614\tvalid_1's rmse: 1.57518\n",
      "[600]\ttraining's rmse: 1.53042\tvalid_1's rmse: 1.57299\n",
      "[700]\ttraining's rmse: 1.52547\tvalid_1's rmse: 1.57165\n",
      "[800]\ttraining's rmse: 1.52109\tvalid_1's rmse: 1.57097\n",
      "[900]\ttraining's rmse: 1.51695\tvalid_1's rmse: 1.57047\n",
      "[1000]\ttraining's rmse: 1.51314\tvalid_1's rmse: 1.57006\n",
      "[1100]\ttraining's rmse: 1.50957\tvalid_1's rmse: 1.56968\n",
      "[1200]\ttraining's rmse: 1.50601\tvalid_1's rmse: 1.56954\n",
      "[1300]\ttraining's rmse: 1.50252\tvalid_1's rmse: 1.56925\n",
      "[1400]\ttraining's rmse: 1.49917\tvalid_1's rmse: 1.56909\n",
      "[1500]\ttraining's rmse: 1.49589\tvalid_1's rmse: 1.56888\n",
      "[1600]\ttraining's rmse: 1.49256\tvalid_1's rmse: 1.56868\n",
      "[1700]\ttraining's rmse: 1.48938\tvalid_1's rmse: 1.56874\n",
      "[1800]\ttraining's rmse: 1.48604\tvalid_1's rmse: 1.56859\n",
      "[1900]\ttraining's rmse: 1.48285\tvalid_1's rmse: 1.56851\n",
      "[2000]\ttraining's rmse: 1.47978\tvalid_1's rmse: 1.56853\n",
      "[2100]\ttraining's rmse: 1.47661\tvalid_1's rmse: 1.56862\n",
      "[2200]\ttraining's rmse: 1.47355\tvalid_1's rmse: 1.56851\n",
      "[2300]\ttraining's rmse: 1.47048\tvalid_1's rmse: 1.5684\n",
      "[2400]\ttraining's rmse: 1.46749\tvalid_1's rmse: 1.56837\n",
      "[2500]\ttraining's rmse: 1.46438\tvalid_1's rmse: 1.56829\n",
      "[2600]\ttraining's rmse: 1.46135\tvalid_1's rmse: 1.56838\n",
      "[2700]\ttraining's rmse: 1.45836\tvalid_1's rmse: 1.56828\n",
      "[2800]\ttraining's rmse: 1.45534\tvalid_1's rmse: 1.56834\n",
      "[2900]\ttraining's rmse: 1.45244\tvalid_1's rmse: 1.56831\n",
      "[3000]\ttraining's rmse: 1.44952\tvalid_1's rmse: 1.5681\n",
      "[3100]\ttraining's rmse: 1.44662\tvalid_1's rmse: 1.5681\n",
      "[3200]\ttraining's rmse: 1.44386\tvalid_1's rmse: 1.56818\n",
      "[3300]\ttraining's rmse: 1.441\tvalid_1's rmse: 1.56816\n",
      "[3400]\ttraining's rmse: 1.43823\tvalid_1's rmse: 1.56828\n",
      "[3500]\ttraining's rmse: 1.43539\tvalid_1's rmse: 1.56834\n",
      "[3600]\ttraining's rmse: 1.43259\tvalid_1's rmse: 1.56846\n",
      "Early stopping, best iteration is:\n",
      "[3060]\ttraining's rmse: 1.44782\tvalid_1's rmse: 1.56803\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60036\tvalid_1's rmse: 1.62284\n",
      "[200]\ttraining's rmse: 1.5677\tvalid_1's rmse: 1.59369\n",
      "[300]\ttraining's rmse: 1.55283\tvalid_1's rmse: 1.58272\n",
      "[400]\ttraining's rmse: 1.54328\tvalid_1's rmse: 1.57715\n",
      "[500]\ttraining's rmse: 1.53636\tvalid_1's rmse: 1.57411\n",
      "[600]\ttraining's rmse: 1.53065\tvalid_1's rmse: 1.57198\n",
      "[700]\ttraining's rmse: 1.52581\tvalid_1's rmse: 1.57073\n",
      "[800]\ttraining's rmse: 1.52148\tvalid_1's rmse: 1.5699\n",
      "[900]\ttraining's rmse: 1.5174\tvalid_1's rmse: 1.56944\n",
      "[1000]\ttraining's rmse: 1.51355\tvalid_1's rmse: 1.56893\n",
      "[1100]\ttraining's rmse: 1.50997\tvalid_1's rmse: 1.56846\n",
      "[1200]\ttraining's rmse: 1.50634\tvalid_1's rmse: 1.56825\n",
      "[1300]\ttraining's rmse: 1.50287\tvalid_1's rmse: 1.56808\n",
      "[1400]\ttraining's rmse: 1.49943\tvalid_1's rmse: 1.56794\n",
      "[1500]\ttraining's rmse: 1.49616\tvalid_1's rmse: 1.56778\n",
      "[1600]\ttraining's rmse: 1.49282\tvalid_1's rmse: 1.5678\n",
      "[1700]\ttraining's rmse: 1.48956\tvalid_1's rmse: 1.56775\n",
      "[1800]\ttraining's rmse: 1.48647\tvalid_1's rmse: 1.56764\n",
      "[1900]\ttraining's rmse: 1.48325\tvalid_1's rmse: 1.56756\n",
      "[2000]\ttraining's rmse: 1.48005\tvalid_1's rmse: 1.56753\n",
      "[2100]\ttraining's rmse: 1.47692\tvalid_1's rmse: 1.56752\n",
      "[2200]\ttraining's rmse: 1.47387\tvalid_1's rmse: 1.56757\n",
      "[2300]\ttraining's rmse: 1.47076\tvalid_1's rmse: 1.56749\n",
      "[2400]\ttraining's rmse: 1.46779\tvalid_1's rmse: 1.56747\n",
      "[2500]\ttraining's rmse: 1.46481\tvalid_1's rmse: 1.56756\n",
      "[2600]\ttraining's rmse: 1.46187\tvalid_1's rmse: 1.56768\n",
      "[2700]\ttraining's rmse: 1.45891\tvalid_1's rmse: 1.56757\n",
      "[2800]\ttraining's rmse: 1.45603\tvalid_1's rmse: 1.56763\n",
      "[2900]\ttraining's rmse: 1.45311\tvalid_1's rmse: 1.5676\n",
      "Early stopping, best iteration is:\n",
      "[2347]\ttraining's rmse: 1.4694\tvalid_1's rmse: 1.56742\n",
      "fold 8 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60296\tvalid_1's rmse: 1.59907\n",
      "[200]\ttraining's rmse: 1.56986\tvalid_1's rmse: 1.57319\n",
      "[300]\ttraining's rmse: 1.55467\tvalid_1's rmse: 1.56439\n",
      "[400]\ttraining's rmse: 1.54509\tvalid_1's rmse: 1.5602\n",
      "[500]\ttraining's rmse: 1.53804\tvalid_1's rmse: 1.55786\n",
      "[600]\ttraining's rmse: 1.53232\tvalid_1's rmse: 1.55662\n",
      "[700]\ttraining's rmse: 1.52729\tvalid_1's rmse: 1.55579\n",
      "[800]\ttraining's rmse: 1.52268\tvalid_1's rmse: 1.55544\n",
      "[900]\ttraining's rmse: 1.51874\tvalid_1's rmse: 1.55514\n",
      "[1000]\ttraining's rmse: 1.51485\tvalid_1's rmse: 1.55497\n",
      "[1100]\ttraining's rmse: 1.51111\tvalid_1's rmse: 1.555\n",
      "[1200]\ttraining's rmse: 1.50758\tvalid_1's rmse: 1.55509\n",
      "[1300]\ttraining's rmse: 1.50405\tvalid_1's rmse: 1.5552\n",
      "[1400]\ttraining's rmse: 1.50046\tvalid_1's rmse: 1.55522\n",
      "[1500]\ttraining's rmse: 1.49715\tvalid_1's rmse: 1.55526\n",
      "Early stopping, best iteration is:\n",
      "[996]\ttraining's rmse: 1.51502\tvalid_1's rmse: 1.55495\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60454\tvalid_1's rmse: 1.58888\n",
      "[200]\ttraining's rmse: 1.57148\tvalid_1's rmse: 1.56217\n",
      "[300]\ttraining's rmse: 1.55643\tvalid_1's rmse: 1.55265\n",
      "[400]\ttraining's rmse: 1.54703\tvalid_1's rmse: 1.54818\n",
      "[500]\ttraining's rmse: 1.5402\tvalid_1's rmse: 1.54595\n",
      "[600]\ttraining's rmse: 1.5347\tvalid_1's rmse: 1.54472\n",
      "[700]\ttraining's rmse: 1.52997\tvalid_1's rmse: 1.54366\n",
      "[800]\ttraining's rmse: 1.52575\tvalid_1's rmse: 1.54313\n",
      "[900]\ttraining's rmse: 1.52183\tvalid_1's rmse: 1.54292\n",
      "[1000]\ttraining's rmse: 1.51804\tvalid_1's rmse: 1.54295\n",
      "[1100]\ttraining's rmse: 1.51453\tvalid_1's rmse: 1.54287\n",
      "[1200]\ttraining's rmse: 1.51118\tvalid_1's rmse: 1.54263\n",
      "[1300]\ttraining's rmse: 1.50771\tvalid_1's rmse: 1.54237\n",
      "[1400]\ttraining's rmse: 1.50428\tvalid_1's rmse: 1.54233\n",
      "[1500]\ttraining's rmse: 1.50108\tvalid_1's rmse: 1.54223\n",
      "[1600]\ttraining's rmse: 1.4978\tvalid_1's rmse: 1.54201\n",
      "[1700]\ttraining's rmse: 1.49458\tvalid_1's rmse: 1.54195\n",
      "[1800]\ttraining's rmse: 1.49154\tvalid_1's rmse: 1.54195\n",
      "[1900]\ttraining's rmse: 1.48839\tvalid_1's rmse: 1.54203\n",
      "[2000]\ttraining's rmse: 1.48525\tvalid_1's rmse: 1.54196\n",
      "[2100]\ttraining's rmse: 1.48223\tvalid_1's rmse: 1.54203\n",
      "[2200]\ttraining's rmse: 1.47924\tvalid_1's rmse: 1.54209\n",
      "[2300]\ttraining's rmse: 1.47625\tvalid_1's rmse: 1.542\n",
      "Early stopping, best iteration is:\n",
      "[1785]\ttraining's rmse: 1.492\tvalid_1's rmse: 1.54188\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60239\tvalid_1's rmse: 1.60681\n",
      "[200]\ttraining's rmse: 1.56979\tvalid_1's rmse: 1.57831\n",
      "[300]\ttraining's rmse: 1.55492\tvalid_1's rmse: 1.56703\n",
      "[400]\ttraining's rmse: 1.54568\tvalid_1's rmse: 1.5615\n",
      "[500]\ttraining's rmse: 1.53882\tvalid_1's rmse: 1.55845\n",
      "[600]\ttraining's rmse: 1.53327\tvalid_1's rmse: 1.55667\n",
      "[700]\ttraining's rmse: 1.52854\tvalid_1's rmse: 1.55558\n",
      "[800]\ttraining's rmse: 1.52441\tvalid_1's rmse: 1.55509\n",
      "[900]\ttraining's rmse: 1.52045\tvalid_1's rmse: 1.55466\n",
      "[1000]\ttraining's rmse: 1.51672\tvalid_1's rmse: 1.55437\n",
      "[1100]\ttraining's rmse: 1.51327\tvalid_1's rmse: 1.55416\n",
      "[1200]\ttraining's rmse: 1.50995\tvalid_1's rmse: 1.55415\n",
      "[1300]\ttraining's rmse: 1.50673\tvalid_1's rmse: 1.55418\n",
      "[1400]\ttraining's rmse: 1.50359\tvalid_1's rmse: 1.55413\n",
      "[1500]\ttraining's rmse: 1.50024\tvalid_1's rmse: 1.55404\n",
      "[1600]\ttraining's rmse: 1.49706\tvalid_1's rmse: 1.55411\n",
      "[1700]\ttraining's rmse: 1.49381\tvalid_1's rmse: 1.55407\n",
      "[1800]\ttraining's rmse: 1.49062\tvalid_1's rmse: 1.55407\n",
      "[1900]\ttraining's rmse: 1.48751\tvalid_1's rmse: 1.55402\n",
      "[2000]\ttraining's rmse: 1.48456\tvalid_1's rmse: 1.55398\n",
      "[2100]\ttraining's rmse: 1.48145\tvalid_1's rmse: 1.5541\n",
      "[2200]\ttraining's rmse: 1.47841\tvalid_1's rmse: 1.55417\n",
      "[2300]\ttraining's rmse: 1.47543\tvalid_1's rmse: 1.55411\n",
      "[2400]\ttraining's rmse: 1.47245\tvalid_1's rmse: 1.55411\n",
      "[2500]\ttraining's rmse: 1.46952\tvalid_1's rmse: 1.55425\n",
      "Early stopping, best iteration is:\n",
      "[1921]\ttraining's rmse: 1.48687\tvalid_1's rmse: 1.55397\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59875\tvalid_1's rmse: 1.63772\n",
      "[200]\ttraining's rmse: 1.56632\tvalid_1's rmse: 1.60821\n",
      "[300]\ttraining's rmse: 1.55161\tvalid_1's rmse: 1.59661\n",
      "[400]\ttraining's rmse: 1.54237\tvalid_1's rmse: 1.59048\n",
      "[500]\ttraining's rmse: 1.53561\tvalid_1's rmse: 1.58685\n",
      "[600]\ttraining's rmse: 1.53016\tvalid_1's rmse: 1.58465\n",
      "[700]\ttraining's rmse: 1.52546\tvalid_1's rmse: 1.58326\n",
      "[800]\ttraining's rmse: 1.52118\tvalid_1's rmse: 1.58242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttraining's rmse: 1.51724\tvalid_1's rmse: 1.58183\n",
      "[1000]\ttraining's rmse: 1.51342\tvalid_1's rmse: 1.58135\n",
      "[1100]\ttraining's rmse: 1.5099\tvalid_1's rmse: 1.58102\n",
      "[1200]\ttraining's rmse: 1.50645\tvalid_1's rmse: 1.58064\n",
      "[1300]\ttraining's rmse: 1.50317\tvalid_1's rmse: 1.58043\n",
      "[1400]\ttraining's rmse: 1.49988\tvalid_1's rmse: 1.58024\n",
      "[1500]\ttraining's rmse: 1.49673\tvalid_1's rmse: 1.58008\n",
      "[1600]\ttraining's rmse: 1.49348\tvalid_1's rmse: 1.57996\n",
      "[1700]\ttraining's rmse: 1.49033\tvalid_1's rmse: 1.57979\n",
      "[1800]\ttraining's rmse: 1.48705\tvalid_1's rmse: 1.57966\n",
      "[1900]\ttraining's rmse: 1.48387\tvalid_1's rmse: 1.57958\n",
      "[2000]\ttraining's rmse: 1.48095\tvalid_1's rmse: 1.57945\n",
      "[2100]\ttraining's rmse: 1.47784\tvalid_1's rmse: 1.57955\n",
      "[2200]\ttraining's rmse: 1.47473\tvalid_1's rmse: 1.57953\n",
      "[2300]\ttraining's rmse: 1.47183\tvalid_1's rmse: 1.57951\n",
      "[2400]\ttraining's rmse: 1.46886\tvalid_1's rmse: 1.57949\n",
      "[2500]\ttraining's rmse: 1.46593\tvalid_1's rmse: 1.57941\n",
      "[2600]\ttraining's rmse: 1.46319\tvalid_1's rmse: 1.57941\n",
      "[2700]\ttraining's rmse: 1.46028\tvalid_1's rmse: 1.57945\n",
      "[2800]\ttraining's rmse: 1.45747\tvalid_1's rmse: 1.57951\n",
      "[2900]\ttraining's rmse: 1.45463\tvalid_1's rmse: 1.57946\n",
      "[3000]\ttraining's rmse: 1.45176\tvalid_1's rmse: 1.57942\n",
      "[3100]\ttraining's rmse: 1.44904\tvalid_1's rmse: 1.5795\n",
      "Early stopping, best iteration is:\n",
      "[2537]\ttraining's rmse: 1.46488\tvalid_1's rmse: 1.57935\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.603\tvalid_1's rmse: 1.60043\n",
      "[200]\ttraining's rmse: 1.57032\tvalid_1's rmse: 1.57268\n",
      "[300]\ttraining's rmse: 1.55537\tvalid_1's rmse: 1.56211\n",
      "[400]\ttraining's rmse: 1.54608\tvalid_1's rmse: 1.55677\n",
      "[500]\ttraining's rmse: 1.53922\tvalid_1's rmse: 1.5538\n",
      "[600]\ttraining's rmse: 1.53373\tvalid_1's rmse: 1.55233\n",
      "[700]\ttraining's rmse: 1.52907\tvalid_1's rmse: 1.55145\n",
      "[800]\ttraining's rmse: 1.52482\tvalid_1's rmse: 1.55077\n",
      "[900]\ttraining's rmse: 1.52092\tvalid_1's rmse: 1.55035\n",
      "[1000]\ttraining's rmse: 1.51711\tvalid_1's rmse: 1.54999\n",
      "[1100]\ttraining's rmse: 1.51347\tvalid_1's rmse: 1.54977\n",
      "[1200]\ttraining's rmse: 1.51007\tvalid_1's rmse: 1.54957\n",
      "[1300]\ttraining's rmse: 1.50678\tvalid_1's rmse: 1.54928\n",
      "[1400]\ttraining's rmse: 1.50337\tvalid_1's rmse: 1.54919\n",
      "[1500]\ttraining's rmse: 1.50019\tvalid_1's rmse: 1.54915\n",
      "[1600]\ttraining's rmse: 1.49711\tvalid_1's rmse: 1.54906\n",
      "[1700]\ttraining's rmse: 1.49404\tvalid_1's rmse: 1.54901\n",
      "[1800]\ttraining's rmse: 1.49085\tvalid_1's rmse: 1.54916\n",
      "[1900]\ttraining's rmse: 1.48779\tvalid_1's rmse: 1.54919\n",
      "[2000]\ttraining's rmse: 1.48474\tvalid_1's rmse: 1.54914\n",
      "[2100]\ttraining's rmse: 1.48165\tvalid_1's rmse: 1.54923\n",
      "[2200]\ttraining's rmse: 1.4786\tvalid_1's rmse: 1.5492\n",
      "[2300]\ttraining's rmse: 1.47564\tvalid_1's rmse: 1.54919\n",
      "Early stopping, best iteration is:\n",
      "[1704]\ttraining's rmse: 1.49394\tvalid_1's rmse: 1.549\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60476\tvalid_1's rmse: 1.58563\n",
      "[200]\ttraining's rmse: 1.57194\tvalid_1's rmse: 1.5586\n",
      "[300]\ttraining's rmse: 1.55703\tvalid_1's rmse: 1.5486\n",
      "[400]\ttraining's rmse: 1.54757\tvalid_1's rmse: 1.5436\n",
      "[500]\ttraining's rmse: 1.54068\tvalid_1's rmse: 1.54109\n",
      "[600]\ttraining's rmse: 1.53508\tvalid_1's rmse: 1.53975\n",
      "[700]\ttraining's rmse: 1.53028\tvalid_1's rmse: 1.5391\n",
      "[800]\ttraining's rmse: 1.52592\tvalid_1's rmse: 1.5387\n",
      "[900]\ttraining's rmse: 1.52195\tvalid_1's rmse: 1.53859\n",
      "[1000]\ttraining's rmse: 1.51826\tvalid_1's rmse: 1.53833\n",
      "[1100]\ttraining's rmse: 1.51474\tvalid_1's rmse: 1.53816\n",
      "[1200]\ttraining's rmse: 1.51132\tvalid_1's rmse: 1.53796\n",
      "[1300]\ttraining's rmse: 1.50804\tvalid_1's rmse: 1.53791\n",
      "[1400]\ttraining's rmse: 1.50475\tvalid_1's rmse: 1.53786\n",
      "[1500]\ttraining's rmse: 1.50141\tvalid_1's rmse: 1.53782\n",
      "[1600]\ttraining's rmse: 1.49815\tvalid_1's rmse: 1.53779\n",
      "[1700]\ttraining's rmse: 1.49498\tvalid_1's rmse: 1.53784\n",
      "[1800]\ttraining's rmse: 1.49173\tvalid_1's rmse: 1.53793\n",
      "[1900]\ttraining's rmse: 1.48857\tvalid_1's rmse: 1.53772\n",
      "[2000]\ttraining's rmse: 1.48544\tvalid_1's rmse: 1.53776\n",
      "[2100]\ttraining's rmse: 1.48234\tvalid_1's rmse: 1.5378\n",
      "[2200]\ttraining's rmse: 1.47933\tvalid_1's rmse: 1.53794\n",
      "[2300]\ttraining's rmse: 1.47642\tvalid_1's rmse: 1.53798\n",
      "[2400]\ttraining's rmse: 1.47358\tvalid_1's rmse: 1.53793\n",
      "[2500]\ttraining's rmse: 1.47062\tvalid_1's rmse: 1.53794\n",
      "Early stopping, best iteration is:\n",
      "[1911]\ttraining's rmse: 1.48825\tvalid_1's rmse: 1.5377\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60387\tvalid_1's rmse: 1.59465\n",
      "[200]\ttraining's rmse: 1.57116\tvalid_1's rmse: 1.56571\n",
      "[300]\ttraining's rmse: 1.55624\tvalid_1's rmse: 1.55483\n",
      "[400]\ttraining's rmse: 1.54699\tvalid_1's rmse: 1.54987\n",
      "[500]\ttraining's rmse: 1.54023\tvalid_1's rmse: 1.54744\n",
      "[600]\ttraining's rmse: 1.53467\tvalid_1's rmse: 1.54614\n",
      "[700]\ttraining's rmse: 1.52989\tvalid_1's rmse: 1.54532\n",
      "[800]\ttraining's rmse: 1.52565\tvalid_1's rmse: 1.5447\n",
      "[900]\ttraining's rmse: 1.52172\tvalid_1's rmse: 1.54442\n",
      "[1000]\ttraining's rmse: 1.51812\tvalid_1's rmse: 1.54419\n",
      "[1100]\ttraining's rmse: 1.51448\tvalid_1's rmse: 1.54413\n",
      "[1200]\ttraining's rmse: 1.5111\tvalid_1's rmse: 1.544\n",
      "[1300]\ttraining's rmse: 1.50786\tvalid_1's rmse: 1.54394\n",
      "[1400]\ttraining's rmse: 1.50455\tvalid_1's rmse: 1.54386\n",
      "[1500]\ttraining's rmse: 1.50123\tvalid_1's rmse: 1.54375\n",
      "[1600]\ttraining's rmse: 1.49787\tvalid_1's rmse: 1.5437\n",
      "[1700]\ttraining's rmse: 1.49469\tvalid_1's rmse: 1.54364\n",
      "[1800]\ttraining's rmse: 1.4915\tvalid_1's rmse: 1.54366\n",
      "[1900]\ttraining's rmse: 1.48838\tvalid_1's rmse: 1.54364\n",
      "[2000]\ttraining's rmse: 1.48525\tvalid_1's rmse: 1.54351\n",
      "[2100]\ttraining's rmse: 1.48216\tvalid_1's rmse: 1.54356\n",
      "[2200]\ttraining's rmse: 1.47907\tvalid_1's rmse: 1.54366\n",
      "[2300]\ttraining's rmse: 1.47616\tvalid_1's rmse: 1.54377\n",
      "[2400]\ttraining's rmse: 1.47325\tvalid_1's rmse: 1.54389\n",
      "[2500]\ttraining's rmse: 1.47039\tvalid_1's rmse: 1.54391\n",
      "[2600]\ttraining's rmse: 1.46751\tvalid_1's rmse: 1.54403\n",
      "Early stopping, best iteration is:\n",
      "[2004]\ttraining's rmse: 1.48514\tvalid_1's rmse: 1.54349\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59998\tvalid_1's rmse: 1.62785\n",
      "[200]\ttraining's rmse: 1.56752\tvalid_1's rmse: 1.59744\n",
      "[300]\ttraining's rmse: 1.55276\tvalid_1's rmse: 1.58522\n",
      "[400]\ttraining's rmse: 1.54356\tvalid_1's rmse: 1.57915\n",
      "[500]\ttraining's rmse: 1.53671\tvalid_1's rmse: 1.57576\n",
      "[600]\ttraining's rmse: 1.53124\tvalid_1's rmse: 1.5738\n",
      "[700]\ttraining's rmse: 1.52645\tvalid_1's rmse: 1.57258\n",
      "[800]\ttraining's rmse: 1.52216\tvalid_1's rmse: 1.57205\n",
      "[900]\ttraining's rmse: 1.51826\tvalid_1's rmse: 1.57167\n",
      "[1000]\ttraining's rmse: 1.51453\tvalid_1's rmse: 1.57129\n",
      "[1100]\ttraining's rmse: 1.51096\tvalid_1's rmse: 1.57102\n",
      "[1200]\ttraining's rmse: 1.50748\tvalid_1's rmse: 1.57083\n",
      "[1300]\ttraining's rmse: 1.50419\tvalid_1's rmse: 1.57075\n",
      "[1400]\ttraining's rmse: 1.50085\tvalid_1's rmse: 1.57059\n",
      "[1500]\ttraining's rmse: 1.49765\tvalid_1's rmse: 1.5704\n",
      "[1600]\ttraining's rmse: 1.4945\tvalid_1's rmse: 1.5703\n",
      "[1700]\ttraining's rmse: 1.49133\tvalid_1's rmse: 1.57027\n",
      "[1800]\ttraining's rmse: 1.48823\tvalid_1's rmse: 1.57018\n",
      "[1900]\ttraining's rmse: 1.48523\tvalid_1's rmse: 1.57024\n",
      "[2000]\ttraining's rmse: 1.48226\tvalid_1's rmse: 1.57018\n",
      "[2100]\ttraining's rmse: 1.47925\tvalid_1's rmse: 1.57002\n",
      "[2200]\ttraining's rmse: 1.4762\tvalid_1's rmse: 1.56988\n",
      "[2300]\ttraining's rmse: 1.4732\tvalid_1's rmse: 1.56995\n",
      "[2400]\ttraining's rmse: 1.47024\tvalid_1's rmse: 1.56988\n",
      "[2500]\ttraining's rmse: 1.46725\tvalid_1's rmse: 1.56981\n",
      "[2600]\ttraining's rmse: 1.46432\tvalid_1's rmse: 1.56984\n",
      "[2700]\ttraining's rmse: 1.46139\tvalid_1's rmse: 1.56979\n",
      "[2800]\ttraining's rmse: 1.45852\tvalid_1's rmse: 1.56975\n",
      "[2900]\ttraining's rmse: 1.45569\tvalid_1's rmse: 1.56977\n",
      "[3000]\ttraining's rmse: 1.45283\tvalid_1's rmse: 1.56975\n",
      "[3100]\ttraining's rmse: 1.45008\tvalid_1's rmse: 1.56988\n",
      "[3200]\ttraining's rmse: 1.44737\tvalid_1's rmse: 1.56989\n",
      "[3300]\ttraining's rmse: 1.44452\tvalid_1's rmse: 1.56986\n",
      "[3400]\ttraining's rmse: 1.44182\tvalid_1's rmse: 1.56984\n",
      "Early stopping, best iteration is:\n",
      "[2834]\ttraining's rmse: 1.45761\tvalid_1's rmse: 1.56968\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60039\tvalid_1's rmse: 1.62278\n",
      "[200]\ttraining's rmse: 1.56791\tvalid_1's rmse: 1.59366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's rmse: 1.55319\tvalid_1's rmse: 1.58245\n",
      "[400]\ttraining's rmse: 1.54386\tvalid_1's rmse: 1.57679\n",
      "[500]\ttraining's rmse: 1.53714\tvalid_1's rmse: 1.5736\n",
      "[600]\ttraining's rmse: 1.53166\tvalid_1's rmse: 1.57167\n",
      "[700]\ttraining's rmse: 1.52689\tvalid_1's rmse: 1.57046\n",
      "[800]\ttraining's rmse: 1.52278\tvalid_1's rmse: 1.56956\n",
      "[900]\ttraining's rmse: 1.51886\tvalid_1's rmse: 1.56902\n",
      "[1000]\ttraining's rmse: 1.51514\tvalid_1's rmse: 1.56872\n",
      "[1100]\ttraining's rmse: 1.51168\tvalid_1's rmse: 1.56834\n",
      "[1200]\ttraining's rmse: 1.50812\tvalid_1's rmse: 1.56816\n",
      "[1300]\ttraining's rmse: 1.50476\tvalid_1's rmse: 1.56791\n",
      "[1400]\ttraining's rmse: 1.50145\tvalid_1's rmse: 1.56785\n",
      "[1500]\ttraining's rmse: 1.49838\tvalid_1's rmse: 1.56772\n",
      "[1600]\ttraining's rmse: 1.49508\tvalid_1's rmse: 1.56759\n",
      "[1700]\ttraining's rmse: 1.49194\tvalid_1's rmse: 1.56754\n",
      "[1800]\ttraining's rmse: 1.48893\tvalid_1's rmse: 1.56746\n",
      "[1900]\ttraining's rmse: 1.48579\tvalid_1's rmse: 1.56739\n",
      "[2000]\ttraining's rmse: 1.48263\tvalid_1's rmse: 1.56734\n",
      "[2100]\ttraining's rmse: 1.47965\tvalid_1's rmse: 1.56717\n",
      "[2200]\ttraining's rmse: 1.4765\tvalid_1's rmse: 1.56708\n",
      "[2300]\ttraining's rmse: 1.47351\tvalid_1's rmse: 1.56702\n",
      "[2400]\ttraining's rmse: 1.47056\tvalid_1's rmse: 1.56704\n",
      "[2500]\ttraining's rmse: 1.46765\tvalid_1's rmse: 1.56703\n",
      "[2600]\ttraining's rmse: 1.46483\tvalid_1's rmse: 1.56703\n",
      "[2700]\ttraining's rmse: 1.46178\tvalid_1's rmse: 1.56695\n",
      "[2800]\ttraining's rmse: 1.45891\tvalid_1's rmse: 1.56697\n",
      "[2900]\ttraining's rmse: 1.45608\tvalid_1's rmse: 1.56699\n",
      "[3000]\ttraining's rmse: 1.45325\tvalid_1's rmse: 1.56704\n",
      "[3100]\ttraining's rmse: 1.45041\tvalid_1's rmse: 1.56702\n",
      "[3200]\ttraining's rmse: 1.44757\tvalid_1's rmse: 1.56698\n",
      "[3300]\ttraining's rmse: 1.4449\tvalid_1's rmse: 1.5671\n",
      "Early stopping, best iteration is:\n",
      "[2783]\ttraining's rmse: 1.45937\tvalid_1's rmse: 1.56692\n",
      "fold 8 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60301\tvalid_1's rmse: 1.59909\n",
      "[200]\ttraining's rmse: 1.57\tvalid_1's rmse: 1.57312\n",
      "[300]\ttraining's rmse: 1.55486\tvalid_1's rmse: 1.56404\n",
      "[400]\ttraining's rmse: 1.54555\tvalid_1's rmse: 1.55999\n",
      "[500]\ttraining's rmse: 1.53877\tvalid_1's rmse: 1.55772\n",
      "[600]\ttraining's rmse: 1.53322\tvalid_1's rmse: 1.55661\n",
      "[700]\ttraining's rmse: 1.52838\tvalid_1's rmse: 1.55594\n",
      "[800]\ttraining's rmse: 1.52402\tvalid_1's rmse: 1.55558\n",
      "[900]\ttraining's rmse: 1.52016\tvalid_1's rmse: 1.55546\n",
      "[1000]\ttraining's rmse: 1.51644\tvalid_1's rmse: 1.55543\n",
      "[1100]\ttraining's rmse: 1.51286\tvalid_1's rmse: 1.55539\n",
      "[1200]\ttraining's rmse: 1.50943\tvalid_1's rmse: 1.55529\n",
      "[1300]\ttraining's rmse: 1.50597\tvalid_1's rmse: 1.55529\n",
      "[1400]\ttraining's rmse: 1.50256\tvalid_1's rmse: 1.55528\n",
      "[1500]\ttraining's rmse: 1.49946\tvalid_1's rmse: 1.55522\n",
      "[1600]\ttraining's rmse: 1.49625\tvalid_1's rmse: 1.55521\n",
      "[1700]\ttraining's rmse: 1.49303\tvalid_1's rmse: 1.5554\n",
      "[1800]\ttraining's rmse: 1.4899\tvalid_1's rmse: 1.5555\n",
      "[1900]\ttraining's rmse: 1.48675\tvalid_1's rmse: 1.55563\n",
      "[2000]\ttraining's rmse: 1.48363\tvalid_1's rmse: 1.55573\n",
      "[2100]\ttraining's rmse: 1.48051\tvalid_1's rmse: 1.55575\n",
      "Early stopping, best iteration is:\n",
      "[1596]\ttraining's rmse: 1.49638\tvalid_1's rmse: 1.55518\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60716\tvalid_1's rmse: 1.59805\n",
      "[200]\ttraining's rmse: 1.57413\tvalid_1's rmse: 1.57266\n",
      "[300]\ttraining's rmse: 1.55796\tvalid_1's rmse: 1.56319\n",
      "[400]\ttraining's rmse: 1.54697\tvalid_1's rmse: 1.5586\n",
      "[500]\ttraining's rmse: 1.53806\tvalid_1's rmse: 1.55598\n",
      "[600]\ttraining's rmse: 1.53051\tvalid_1's rmse: 1.55425\n",
      "[700]\ttraining's rmse: 1.52371\tvalid_1's rmse: 1.55304\n",
      "[800]\ttraining's rmse: 1.51769\tvalid_1's rmse: 1.55218\n",
      "[900]\ttraining's rmse: 1.51205\tvalid_1's rmse: 1.55144\n",
      "[1000]\ttraining's rmse: 1.50664\tvalid_1's rmse: 1.55099\n",
      "[1100]\ttraining's rmse: 1.50168\tvalid_1's rmse: 1.55065\n",
      "[1200]\ttraining's rmse: 1.49675\tvalid_1's rmse: 1.55044\n",
      "[1300]\ttraining's rmse: 1.49184\tvalid_1's rmse: 1.55023\n",
      "[1400]\ttraining's rmse: 1.48725\tvalid_1's rmse: 1.55021\n",
      "[1500]\ttraining's rmse: 1.48263\tvalid_1's rmse: 1.55001\n",
      "[1600]\ttraining's rmse: 1.47812\tvalid_1's rmse: 1.54988\n",
      "[1700]\ttraining's rmse: 1.47371\tvalid_1's rmse: 1.54978\n",
      "[1800]\ttraining's rmse: 1.46941\tvalid_1's rmse: 1.54956\n",
      "[1900]\ttraining's rmse: 1.46509\tvalid_1's rmse: 1.54953\n",
      "[2000]\ttraining's rmse: 1.46079\tvalid_1's rmse: 1.54931\n",
      "[2100]\ttraining's rmse: 1.45667\tvalid_1's rmse: 1.54934\n",
      "[2200]\ttraining's rmse: 1.4526\tvalid_1's rmse: 1.54941\n",
      "[2300]\ttraining's rmse: 1.44847\tvalid_1's rmse: 1.54929\n",
      "[2400]\ttraining's rmse: 1.44436\tvalid_1's rmse: 1.54926\n",
      "[2500]\ttraining's rmse: 1.44041\tvalid_1's rmse: 1.54917\n",
      "[2600]\ttraining's rmse: 1.43646\tvalid_1's rmse: 1.54915\n",
      "[2700]\ttraining's rmse: 1.43247\tvalid_1's rmse: 1.54923\n",
      "[2800]\ttraining's rmse: 1.42858\tvalid_1's rmse: 1.54919\n",
      "[2900]\ttraining's rmse: 1.42474\tvalid_1's rmse: 1.54916\n",
      "[3000]\ttraining's rmse: 1.42092\tvalid_1's rmse: 1.54903\n",
      "[3100]\ttraining's rmse: 1.41706\tvalid_1's rmse: 1.54892\n",
      "[3200]\ttraining's rmse: 1.41322\tvalid_1's rmse: 1.54902\n",
      "[3300]\ttraining's rmse: 1.40945\tvalid_1's rmse: 1.54903\n",
      "[3400]\ttraining's rmse: 1.40575\tvalid_1's rmse: 1.549\n",
      "[3500]\ttraining's rmse: 1.40208\tvalid_1's rmse: 1.54899\n",
      "[3600]\ttraining's rmse: 1.3983\tvalid_1's rmse: 1.54906\n",
      "[3700]\ttraining's rmse: 1.39474\tvalid_1's rmse: 1.54897\n",
      "Early stopping, best iteration is:\n",
      "[3111]\ttraining's rmse: 1.41665\tvalid_1's rmse: 1.54891\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60588\tvalid_1's rmse: 1.6112\n",
      "[200]\ttraining's rmse: 1.57331\tvalid_1's rmse: 1.5827\n",
      "[300]\ttraining's rmse: 1.55748\tvalid_1's rmse: 1.57122\n",
      "[400]\ttraining's rmse: 1.54641\tvalid_1's rmse: 1.56468\n",
      "[500]\ttraining's rmse: 1.5376\tvalid_1's rmse: 1.56103\n",
      "[600]\ttraining's rmse: 1.53004\tvalid_1's rmse: 1.55886\n",
      "[700]\ttraining's rmse: 1.52335\tvalid_1's rmse: 1.55726\n",
      "[800]\ttraining's rmse: 1.51722\tvalid_1's rmse: 1.55635\n",
      "[900]\ttraining's rmse: 1.51152\tvalid_1's rmse: 1.55579\n",
      "[1000]\ttraining's rmse: 1.50614\tvalid_1's rmse: 1.55529\n",
      "[1100]\ttraining's rmse: 1.50112\tvalid_1's rmse: 1.55504\n",
      "[1200]\ttraining's rmse: 1.49624\tvalid_1's rmse: 1.55469\n",
      "[1300]\ttraining's rmse: 1.49146\tvalid_1's rmse: 1.5545\n",
      "[1400]\ttraining's rmse: 1.48675\tvalid_1's rmse: 1.55416\n",
      "[1500]\ttraining's rmse: 1.48214\tvalid_1's rmse: 1.55395\n",
      "[1600]\ttraining's rmse: 1.47777\tvalid_1's rmse: 1.55385\n",
      "[1700]\ttraining's rmse: 1.4734\tvalid_1's rmse: 1.55381\n",
      "[1800]\ttraining's rmse: 1.46904\tvalid_1's rmse: 1.55359\n",
      "[1900]\ttraining's rmse: 1.46479\tvalid_1's rmse: 1.55341\n",
      "[2000]\ttraining's rmse: 1.46053\tvalid_1's rmse: 1.55334\n",
      "[2100]\ttraining's rmse: 1.45628\tvalid_1's rmse: 1.55335\n",
      "[2200]\ttraining's rmse: 1.45211\tvalid_1's rmse: 1.55326\n",
      "[2300]\ttraining's rmse: 1.44805\tvalid_1's rmse: 1.55318\n",
      "[2400]\ttraining's rmse: 1.44394\tvalid_1's rmse: 1.55325\n",
      "[2500]\ttraining's rmse: 1.43997\tvalid_1's rmse: 1.55327\n",
      "[2600]\ttraining's rmse: 1.43597\tvalid_1's rmse: 1.55334\n",
      "[2700]\ttraining's rmse: 1.4319\tvalid_1's rmse: 1.5533\n",
      "[2800]\ttraining's rmse: 1.42796\tvalid_1's rmse: 1.55315\n",
      "[2900]\ttraining's rmse: 1.424\tvalid_1's rmse: 1.55305\n",
      "[3000]\ttraining's rmse: 1.42019\tvalid_1's rmse: 1.55316\n",
      "[3100]\ttraining's rmse: 1.41634\tvalid_1's rmse: 1.55313\n",
      "[3200]\ttraining's rmse: 1.41256\tvalid_1's rmse: 1.55318\n",
      "[3300]\ttraining's rmse: 1.40882\tvalid_1's rmse: 1.55312\n",
      "[3400]\ttraining's rmse: 1.4051\tvalid_1's rmse: 1.55322\n",
      "[3500]\ttraining's rmse: 1.40141\tvalid_1's rmse: 1.55333\n",
      "Early stopping, best iteration is:\n",
      "[2906]\ttraining's rmse: 1.42376\tvalid_1's rmse: 1.553\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60448\tvalid_1's rmse: 1.62695\n",
      "[200]\ttraining's rmse: 1.57182\tvalid_1's rmse: 1.59818\n",
      "[300]\ttraining's rmse: 1.55569\tvalid_1's rmse: 1.58703\n",
      "[400]\ttraining's rmse: 1.54465\tvalid_1's rmse: 1.58099\n",
      "[500]\ttraining's rmse: 1.53572\tvalid_1's rmse: 1.57738\n",
      "[600]\ttraining's rmse: 1.52819\tvalid_1's rmse: 1.57506\n",
      "[700]\ttraining's rmse: 1.52136\tvalid_1's rmse: 1.57369\n",
      "[800]\ttraining's rmse: 1.51532\tvalid_1's rmse: 1.57264\n",
      "[900]\ttraining's rmse: 1.50969\tvalid_1's rmse: 1.57186\n",
      "[1000]\ttraining's rmse: 1.50432\tvalid_1's rmse: 1.57129\n",
      "[1100]\ttraining's rmse: 1.49932\tvalid_1's rmse: 1.57094\n",
      "[1200]\ttraining's rmse: 1.49447\tvalid_1's rmse: 1.57075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttraining's rmse: 1.48959\tvalid_1's rmse: 1.57044\n",
      "[1400]\ttraining's rmse: 1.48498\tvalid_1's rmse: 1.57031\n",
      "[1500]\ttraining's rmse: 1.4804\tvalid_1's rmse: 1.57011\n",
      "[1600]\ttraining's rmse: 1.47592\tvalid_1's rmse: 1.56992\n",
      "[1700]\ttraining's rmse: 1.4715\tvalid_1's rmse: 1.56984\n",
      "[1800]\ttraining's rmse: 1.4673\tvalid_1's rmse: 1.5696\n",
      "[1900]\ttraining's rmse: 1.46299\tvalid_1's rmse: 1.56957\n",
      "[2000]\ttraining's rmse: 1.45873\tvalid_1's rmse: 1.56958\n",
      "[2100]\ttraining's rmse: 1.45449\tvalid_1's rmse: 1.56945\n",
      "[2200]\ttraining's rmse: 1.45035\tvalid_1's rmse: 1.5695\n",
      "[2300]\ttraining's rmse: 1.44628\tvalid_1's rmse: 1.56947\n",
      "[2400]\ttraining's rmse: 1.44236\tvalid_1's rmse: 1.56945\n",
      "[2500]\ttraining's rmse: 1.43833\tvalid_1's rmse: 1.56943\n",
      "[2600]\ttraining's rmse: 1.43438\tvalid_1's rmse: 1.56933\n",
      "[2700]\ttraining's rmse: 1.43036\tvalid_1's rmse: 1.5692\n",
      "[2800]\ttraining's rmse: 1.42635\tvalid_1's rmse: 1.56921\n",
      "[2900]\ttraining's rmse: 1.42255\tvalid_1's rmse: 1.56916\n",
      "[3000]\ttraining's rmse: 1.41881\tvalid_1's rmse: 1.56914\n",
      "[3100]\ttraining's rmse: 1.41514\tvalid_1's rmse: 1.56917\n",
      "[3200]\ttraining's rmse: 1.41142\tvalid_1's rmse: 1.56925\n",
      "[3300]\ttraining's rmse: 1.40769\tvalid_1's rmse: 1.56933\n",
      "[3400]\ttraining's rmse: 1.40397\tvalid_1's rmse: 1.56939\n",
      "[3500]\ttraining's rmse: 1.40038\tvalid_1's rmse: 1.56931\n",
      "Early stopping, best iteration is:\n",
      "[2972]\ttraining's rmse: 1.41983\tvalid_1's rmse: 1.56908\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60445\tvalid_1's rmse: 1.62463\n",
      "[200]\ttraining's rmse: 1.57164\tvalid_1's rmse: 1.59854\n",
      "[300]\ttraining's rmse: 1.5558\tvalid_1's rmse: 1.58831\n",
      "[400]\ttraining's rmse: 1.54463\tvalid_1's rmse: 1.58297\n",
      "[500]\ttraining's rmse: 1.53572\tvalid_1's rmse: 1.57944\n",
      "[600]\ttraining's rmse: 1.52808\tvalid_1's rmse: 1.57708\n",
      "[700]\ttraining's rmse: 1.52126\tvalid_1's rmse: 1.57567\n",
      "[800]\ttraining's rmse: 1.515\tvalid_1's rmse: 1.57468\n",
      "[900]\ttraining's rmse: 1.50931\tvalid_1's rmse: 1.574\n",
      "[1000]\ttraining's rmse: 1.50406\tvalid_1's rmse: 1.57361\n",
      "[1100]\ttraining's rmse: 1.49904\tvalid_1's rmse: 1.57319\n",
      "[1200]\ttraining's rmse: 1.49412\tvalid_1's rmse: 1.57271\n",
      "[1300]\ttraining's rmse: 1.48923\tvalid_1's rmse: 1.57249\n",
      "[1400]\ttraining's rmse: 1.48451\tvalid_1's rmse: 1.57219\n",
      "[1500]\ttraining's rmse: 1.47988\tvalid_1's rmse: 1.57227\n",
      "[1600]\ttraining's rmse: 1.4754\tvalid_1's rmse: 1.57206\n",
      "[1700]\ttraining's rmse: 1.47101\tvalid_1's rmse: 1.57179\n",
      "[1800]\ttraining's rmse: 1.4669\tvalid_1's rmse: 1.57173\n",
      "[1900]\ttraining's rmse: 1.46254\tvalid_1's rmse: 1.57163\n",
      "[2000]\ttraining's rmse: 1.4584\tvalid_1's rmse: 1.57165\n",
      "[2100]\ttraining's rmse: 1.45412\tvalid_1's rmse: 1.5714\n",
      "[2200]\ttraining's rmse: 1.44996\tvalid_1's rmse: 1.57115\n",
      "[2300]\ttraining's rmse: 1.44592\tvalid_1's rmse: 1.57111\n",
      "[2400]\ttraining's rmse: 1.4419\tvalid_1's rmse: 1.57102\n",
      "[2500]\ttraining's rmse: 1.43785\tvalid_1's rmse: 1.57097\n",
      "[2600]\ttraining's rmse: 1.43378\tvalid_1's rmse: 1.57083\n",
      "[2700]\ttraining's rmse: 1.42998\tvalid_1's rmse: 1.57077\n",
      "[2800]\ttraining's rmse: 1.42605\tvalid_1's rmse: 1.57084\n",
      "[2900]\ttraining's rmse: 1.42216\tvalid_1's rmse: 1.57084\n",
      "[3000]\ttraining's rmse: 1.41834\tvalid_1's rmse: 1.57077\n",
      "[3100]\ttraining's rmse: 1.41444\tvalid_1's rmse: 1.57059\n",
      "[3200]\ttraining's rmse: 1.41057\tvalid_1's rmse: 1.57067\n",
      "[3300]\ttraining's rmse: 1.40673\tvalid_1's rmse: 1.57058\n",
      "[3400]\ttraining's rmse: 1.40314\tvalid_1's rmse: 1.57052\n",
      "[3500]\ttraining's rmse: 1.39946\tvalid_1's rmse: 1.5705\n",
      "[3600]\ttraining's rmse: 1.39569\tvalid_1's rmse: 1.57049\n",
      "[3700]\ttraining's rmse: 1.39213\tvalid_1's rmse: 1.57043\n",
      "[3800]\ttraining's rmse: 1.38848\tvalid_1's rmse: 1.57049\n",
      "[3900]\ttraining's rmse: 1.38473\tvalid_1's rmse: 1.57062\n",
      "[4000]\ttraining's rmse: 1.3811\tvalid_1's rmse: 1.57067\n",
      "[4100]\ttraining's rmse: 1.37762\tvalid_1's rmse: 1.57068\n",
      "[4200]\ttraining's rmse: 1.37415\tvalid_1's rmse: 1.57067\n",
      "Early stopping, best iteration is:\n",
      "[3668]\ttraining's rmse: 1.39327\tvalid_1's rmse: 1.57038\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60807\tvalid_1's rmse: 1.59369\n",
      "[200]\ttraining's rmse: 1.57538\tvalid_1's rmse: 1.5653\n",
      "[300]\ttraining's rmse: 1.55911\tvalid_1's rmse: 1.55411\n",
      "[400]\ttraining's rmse: 1.54805\tvalid_1's rmse: 1.54857\n",
      "[500]\ttraining's rmse: 1.53909\tvalid_1's rmse: 1.54506\n",
      "[600]\ttraining's rmse: 1.5315\tvalid_1's rmse: 1.54304\n",
      "[700]\ttraining's rmse: 1.52471\tvalid_1's rmse: 1.54156\n",
      "[800]\ttraining's rmse: 1.51861\tvalid_1's rmse: 1.54062\n",
      "[900]\ttraining's rmse: 1.51295\tvalid_1's rmse: 1.54032\n",
      "[1000]\ttraining's rmse: 1.50756\tvalid_1's rmse: 1.53982\n",
      "[1100]\ttraining's rmse: 1.50241\tvalid_1's rmse: 1.53934\n",
      "[1200]\ttraining's rmse: 1.49752\tvalid_1's rmse: 1.53909\n",
      "[1300]\ttraining's rmse: 1.49282\tvalid_1's rmse: 1.53895\n",
      "[1400]\ttraining's rmse: 1.48815\tvalid_1's rmse: 1.53894\n",
      "[1500]\ttraining's rmse: 1.48359\tvalid_1's rmse: 1.53878\n",
      "[1600]\ttraining's rmse: 1.47913\tvalid_1's rmse: 1.53872\n",
      "[1700]\ttraining's rmse: 1.47478\tvalid_1's rmse: 1.53863\n",
      "[1800]\ttraining's rmse: 1.47041\tvalid_1's rmse: 1.53843\n",
      "[1900]\ttraining's rmse: 1.4661\tvalid_1's rmse: 1.5384\n",
      "[2000]\ttraining's rmse: 1.46194\tvalid_1's rmse: 1.53846\n",
      "[2100]\ttraining's rmse: 1.45781\tvalid_1's rmse: 1.53847\n",
      "[2200]\ttraining's rmse: 1.4536\tvalid_1's rmse: 1.53854\n",
      "[2300]\ttraining's rmse: 1.44954\tvalid_1's rmse: 1.53862\n",
      "[2400]\ttraining's rmse: 1.44549\tvalid_1's rmse: 1.53853\n",
      "Early stopping, best iteration is:\n",
      "[1835]\ttraining's rmse: 1.4689\tvalid_1's rmse: 1.53838\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60706\tvalid_1's rmse: 1.60046\n",
      "[200]\ttraining's rmse: 1.57393\tvalid_1's rmse: 1.57468\n",
      "[300]\ttraining's rmse: 1.55775\tvalid_1's rmse: 1.56538\n",
      "[400]\ttraining's rmse: 1.54665\tvalid_1's rmse: 1.56055\n",
      "[500]\ttraining's rmse: 1.53778\tvalid_1's rmse: 1.55778\n",
      "[600]\ttraining's rmse: 1.5302\tvalid_1's rmse: 1.55604\n",
      "[700]\ttraining's rmse: 1.52349\tvalid_1's rmse: 1.55489\n",
      "[800]\ttraining's rmse: 1.51731\tvalid_1's rmse: 1.55436\n",
      "[900]\ttraining's rmse: 1.51162\tvalid_1's rmse: 1.55379\n",
      "[1000]\ttraining's rmse: 1.50632\tvalid_1's rmse: 1.55347\n",
      "[1100]\ttraining's rmse: 1.50117\tvalid_1's rmse: 1.55323\n",
      "[1200]\ttraining's rmse: 1.49621\tvalid_1's rmse: 1.55295\n",
      "[1300]\ttraining's rmse: 1.49145\tvalid_1's rmse: 1.55265\n",
      "[1400]\ttraining's rmse: 1.48679\tvalid_1's rmse: 1.55259\n",
      "[1500]\ttraining's rmse: 1.4822\tvalid_1's rmse: 1.55248\n",
      "[1600]\ttraining's rmse: 1.47767\tvalid_1's rmse: 1.55242\n",
      "[1700]\ttraining's rmse: 1.47327\tvalid_1's rmse: 1.55219\n",
      "[1800]\ttraining's rmse: 1.46888\tvalid_1's rmse: 1.55201\n",
      "[1900]\ttraining's rmse: 1.46466\tvalid_1's rmse: 1.55203\n",
      "[2000]\ttraining's rmse: 1.46039\tvalid_1's rmse: 1.55191\n",
      "[2100]\ttraining's rmse: 1.45628\tvalid_1's rmse: 1.55191\n",
      "[2200]\ttraining's rmse: 1.45217\tvalid_1's rmse: 1.55197\n",
      "[2300]\ttraining's rmse: 1.44819\tvalid_1's rmse: 1.55195\n",
      "[2400]\ttraining's rmse: 1.4442\tvalid_1's rmse: 1.55205\n",
      "[2500]\ttraining's rmse: 1.4401\tvalid_1's rmse: 1.55196\n",
      "[2600]\ttraining's rmse: 1.43609\tvalid_1's rmse: 1.55199\n",
      "Early stopping, best iteration is:\n",
      "[2061]\ttraining's rmse: 1.45788\tvalid_1's rmse: 1.55182\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60625\tvalid_1's rmse: 1.61081\n",
      "[200]\ttraining's rmse: 1.57341\tvalid_1's rmse: 1.58308\n",
      "[300]\ttraining's rmse: 1.55739\tvalid_1's rmse: 1.5721\n",
      "[400]\ttraining's rmse: 1.54623\tvalid_1's rmse: 1.56624\n",
      "[500]\ttraining's rmse: 1.53728\tvalid_1's rmse: 1.56272\n",
      "[600]\ttraining's rmse: 1.52971\tvalid_1's rmse: 1.56043\n",
      "[700]\ttraining's rmse: 1.52292\tvalid_1's rmse: 1.55905\n",
      "[800]\ttraining's rmse: 1.51668\tvalid_1's rmse: 1.55816\n",
      "[900]\ttraining's rmse: 1.51094\tvalid_1's rmse: 1.5575\n",
      "[1000]\ttraining's rmse: 1.50564\tvalid_1's rmse: 1.55674\n",
      "[1100]\ttraining's rmse: 1.5006\tvalid_1's rmse: 1.55637\n",
      "[1200]\ttraining's rmse: 1.49576\tvalid_1's rmse: 1.55617\n",
      "[1300]\ttraining's rmse: 1.49092\tvalid_1's rmse: 1.55597\n",
      "[1400]\ttraining's rmse: 1.48627\tvalid_1's rmse: 1.55573\n",
      "[1500]\ttraining's rmse: 1.48155\tvalid_1's rmse: 1.55561\n",
      "[1600]\ttraining's rmse: 1.47701\tvalid_1's rmse: 1.55547\n",
      "[1700]\ttraining's rmse: 1.4727\tvalid_1's rmse: 1.55528\n",
      "[1800]\ttraining's rmse: 1.46828\tvalid_1's rmse: 1.55522\n",
      "[1900]\ttraining's rmse: 1.464\tvalid_1's rmse: 1.55514\n",
      "[2000]\ttraining's rmse: 1.45993\tvalid_1's rmse: 1.55514\n",
      "[2100]\ttraining's rmse: 1.45565\tvalid_1's rmse: 1.5551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2200]\ttraining's rmse: 1.45144\tvalid_1's rmse: 1.55504\n",
      "[2300]\ttraining's rmse: 1.4474\tvalid_1's rmse: 1.55493\n",
      "[2400]\ttraining's rmse: 1.44327\tvalid_1's rmse: 1.55492\n",
      "[2500]\ttraining's rmse: 1.43933\tvalid_1's rmse: 1.55489\n",
      "[2600]\ttraining's rmse: 1.43533\tvalid_1's rmse: 1.55491\n",
      "[2700]\ttraining's rmse: 1.43142\tvalid_1's rmse: 1.55484\n",
      "[2800]\ttraining's rmse: 1.42745\tvalid_1's rmse: 1.55489\n",
      "[2900]\ttraining's rmse: 1.42352\tvalid_1's rmse: 1.55481\n",
      "[3000]\ttraining's rmse: 1.41958\tvalid_1's rmse: 1.55487\n",
      "[3100]\ttraining's rmse: 1.41577\tvalid_1's rmse: 1.55483\n",
      "[3200]\ttraining's rmse: 1.41189\tvalid_1's rmse: 1.55499\n",
      "[3300]\ttraining's rmse: 1.40816\tvalid_1's rmse: 1.55504\n",
      "[3400]\ttraining's rmse: 1.40437\tvalid_1's rmse: 1.55498\n",
      "[3500]\ttraining's rmse: 1.40064\tvalid_1's rmse: 1.55513\n",
      "Early stopping, best iteration is:\n",
      "[2938]\ttraining's rmse: 1.42197\tvalid_1's rmse: 1.55479\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60606\tvalid_1's rmse: 1.61258\n",
      "[200]\ttraining's rmse: 1.57357\tvalid_1's rmse: 1.58303\n",
      "[300]\ttraining's rmse: 1.55762\tvalid_1's rmse: 1.571\n",
      "[400]\ttraining's rmse: 1.54682\tvalid_1's rmse: 1.56483\n",
      "[500]\ttraining's rmse: 1.53785\tvalid_1's rmse: 1.56106\n",
      "[600]\ttraining's rmse: 1.53024\tvalid_1's rmse: 1.55859\n",
      "[700]\ttraining's rmse: 1.52347\tvalid_1's rmse: 1.55702\n",
      "[800]\ttraining's rmse: 1.51729\tvalid_1's rmse: 1.55579\n",
      "[900]\ttraining's rmse: 1.5117\tvalid_1's rmse: 1.55508\n",
      "[1000]\ttraining's rmse: 1.5064\tvalid_1's rmse: 1.55452\n",
      "[1100]\ttraining's rmse: 1.50136\tvalid_1's rmse: 1.55411\n",
      "[1200]\ttraining's rmse: 1.49649\tvalid_1's rmse: 1.5538\n",
      "[1300]\ttraining's rmse: 1.49171\tvalid_1's rmse: 1.55366\n",
      "[1400]\ttraining's rmse: 1.4871\tvalid_1's rmse: 1.55334\n",
      "[1500]\ttraining's rmse: 1.48261\tvalid_1's rmse: 1.55329\n",
      "[1600]\ttraining's rmse: 1.47801\tvalid_1's rmse: 1.55301\n",
      "[1700]\ttraining's rmse: 1.47365\tvalid_1's rmse: 1.55299\n",
      "[1800]\ttraining's rmse: 1.46924\tvalid_1's rmse: 1.55277\n",
      "[1900]\ttraining's rmse: 1.46495\tvalid_1's rmse: 1.55275\n",
      "[2000]\ttraining's rmse: 1.46073\tvalid_1's rmse: 1.55243\n",
      "[2100]\ttraining's rmse: 1.45661\tvalid_1's rmse: 1.55226\n",
      "[2200]\ttraining's rmse: 1.45247\tvalid_1's rmse: 1.55231\n",
      "[2300]\ttraining's rmse: 1.44838\tvalid_1's rmse: 1.55227\n",
      "[2400]\ttraining's rmse: 1.44437\tvalid_1's rmse: 1.5522\n",
      "[2500]\ttraining's rmse: 1.44035\tvalid_1's rmse: 1.55206\n",
      "[2600]\ttraining's rmse: 1.43632\tvalid_1's rmse: 1.55197\n",
      "[2700]\ttraining's rmse: 1.43238\tvalid_1's rmse: 1.55184\n",
      "[2800]\ttraining's rmse: 1.42844\tvalid_1's rmse: 1.55184\n",
      "[2900]\ttraining's rmse: 1.42456\tvalid_1's rmse: 1.55188\n",
      "[3000]\ttraining's rmse: 1.42071\tvalid_1's rmse: 1.55177\n",
      "[3100]\ttraining's rmse: 1.41682\tvalid_1's rmse: 1.55171\n",
      "[3200]\ttraining's rmse: 1.41305\tvalid_1's rmse: 1.55167\n",
      "[3300]\ttraining's rmse: 1.40924\tvalid_1's rmse: 1.5516\n",
      "[3400]\ttraining's rmse: 1.40558\tvalid_1's rmse: 1.55174\n",
      "[3500]\ttraining's rmse: 1.40192\tvalid_1's rmse: 1.55187\n",
      "[3600]\ttraining's rmse: 1.3983\tvalid_1's rmse: 1.55181\n",
      "[3700]\ttraining's rmse: 1.39465\tvalid_1's rmse: 1.55183\n",
      "[3800]\ttraining's rmse: 1.39099\tvalid_1's rmse: 1.55184\n",
      "[3900]\ttraining's rmse: 1.38734\tvalid_1's rmse: 1.55183\n",
      "Early stopping, best iteration is:\n",
      "[3325]\ttraining's rmse: 1.40831\tvalid_1's rmse: 1.55156\n",
      "fold 8 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60271\tvalid_1's rmse: 1.64176\n",
      "[200]\ttraining's rmse: 1.56988\tvalid_1's rmse: 1.61389\n",
      "[300]\ttraining's rmse: 1.55386\tvalid_1's rmse: 1.60346\n",
      "[400]\ttraining's rmse: 1.54292\tvalid_1's rmse: 1.59798\n",
      "[500]\ttraining's rmse: 1.53402\tvalid_1's rmse: 1.59453\n",
      "[600]\ttraining's rmse: 1.52646\tvalid_1's rmse: 1.59249\n",
      "[700]\ttraining's rmse: 1.51981\tvalid_1's rmse: 1.59102\n",
      "[800]\ttraining's rmse: 1.51376\tvalid_1's rmse: 1.59003\n",
      "[900]\ttraining's rmse: 1.5081\tvalid_1's rmse: 1.58943\n",
      "[1000]\ttraining's rmse: 1.50266\tvalid_1's rmse: 1.58886\n",
      "[1100]\ttraining's rmse: 1.49763\tvalid_1's rmse: 1.58856\n",
      "[1200]\ttraining's rmse: 1.49266\tvalid_1's rmse: 1.58848\n",
      "[1300]\ttraining's rmse: 1.48787\tvalid_1's rmse: 1.58824\n",
      "[1400]\ttraining's rmse: 1.48321\tvalid_1's rmse: 1.58811\n",
      "[1500]\ttraining's rmse: 1.47855\tvalid_1's rmse: 1.58782\n",
      "[1600]\ttraining's rmse: 1.474\tvalid_1's rmse: 1.58764\n",
      "[1700]\ttraining's rmse: 1.46958\tvalid_1's rmse: 1.5876\n",
      "[1800]\ttraining's rmse: 1.4653\tvalid_1's rmse: 1.58742\n",
      "[1900]\ttraining's rmse: 1.46096\tvalid_1's rmse: 1.58732\n",
      "[2000]\ttraining's rmse: 1.45666\tvalid_1's rmse: 1.58746\n",
      "[2100]\ttraining's rmse: 1.45253\tvalid_1's rmse: 1.58751\n",
      "[2200]\ttraining's rmse: 1.44844\tvalid_1's rmse: 1.58752\n",
      "[2300]\ttraining's rmse: 1.44443\tvalid_1's rmse: 1.58737\n",
      "[2400]\ttraining's rmse: 1.44033\tvalid_1's rmse: 1.5875\n",
      "Early stopping, best iteration is:\n",
      "[1894]\ttraining's rmse: 1.46121\tvalid_1's rmse: 1.58731\n",
      "fold 9 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60787\tvalid_1's rmse: 1.59153\n",
      "[200]\ttraining's rmse: 1.57479\tvalid_1's rmse: 1.56615\n",
      "[300]\ttraining's rmse: 1.55861\tvalid_1's rmse: 1.55661\n",
      "[400]\ttraining's rmse: 1.54763\tvalid_1's rmse: 1.55166\n",
      "[500]\ttraining's rmse: 1.5388\tvalid_1's rmse: 1.54857\n",
      "[600]\ttraining's rmse: 1.53117\tvalid_1's rmse: 1.54697\n",
      "[700]\ttraining's rmse: 1.52439\tvalid_1's rmse: 1.54583\n",
      "[800]\ttraining's rmse: 1.51825\tvalid_1's rmse: 1.54522\n",
      "[900]\ttraining's rmse: 1.51256\tvalid_1's rmse: 1.54481\n",
      "[1000]\ttraining's rmse: 1.5072\tvalid_1's rmse: 1.54457\n",
      "[1100]\ttraining's rmse: 1.5021\tvalid_1's rmse: 1.54442\n",
      "[1200]\ttraining's rmse: 1.49713\tvalid_1's rmse: 1.54431\n",
      "[1300]\ttraining's rmse: 1.49222\tvalid_1's rmse: 1.5443\n",
      "[1400]\ttraining's rmse: 1.48755\tvalid_1's rmse: 1.54419\n",
      "[1500]\ttraining's rmse: 1.48294\tvalid_1's rmse: 1.54411\n",
      "[1600]\ttraining's rmse: 1.4785\tvalid_1's rmse: 1.54408\n",
      "[1700]\ttraining's rmse: 1.47413\tvalid_1's rmse: 1.54413\n",
      "[1800]\ttraining's rmse: 1.46988\tvalid_1's rmse: 1.54421\n",
      "[1900]\ttraining's rmse: 1.46558\tvalid_1's rmse: 1.54425\n",
      "[2000]\ttraining's rmse: 1.46144\tvalid_1's rmse: 1.54427\n",
      "[2100]\ttraining's rmse: 1.45724\tvalid_1's rmse: 1.54432\n",
      "[2200]\ttraining's rmse: 1.45306\tvalid_1's rmse: 1.54442\n",
      "Early stopping, best iteration is:\n",
      "[1607]\ttraining's rmse: 1.47818\tvalid_1's rmse: 1.54407\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60366\tvalid_1's rmse: 1.59233\n",
      "[200]\ttraining's rmse: 1.5705\tvalid_1's rmse: 1.56599\n",
      "[300]\ttraining's rmse: 1.55531\tvalid_1's rmse: 1.55664\n",
      "[400]\ttraining's rmse: 1.54544\tvalid_1's rmse: 1.55226\n",
      "[500]\ttraining's rmse: 1.53809\tvalid_1's rmse: 1.54993\n",
      "[600]\ttraining's rmse: 1.53207\tvalid_1's rmse: 1.54842\n",
      "[700]\ttraining's rmse: 1.52699\tvalid_1's rmse: 1.54765\n",
      "[800]\ttraining's rmse: 1.52232\tvalid_1's rmse: 1.54715\n",
      "[900]\ttraining's rmse: 1.51797\tvalid_1's rmse: 1.54694\n",
      "[1000]\ttraining's rmse: 1.5139\tvalid_1's rmse: 1.54663\n",
      "[1100]\ttraining's rmse: 1.50993\tvalid_1's rmse: 1.5465\n",
      "[1200]\ttraining's rmse: 1.50616\tvalid_1's rmse: 1.54628\n",
      "[1300]\ttraining's rmse: 1.50247\tvalid_1's rmse: 1.54613\n",
      "[1400]\ttraining's rmse: 1.49895\tvalid_1's rmse: 1.54607\n",
      "[1500]\ttraining's rmse: 1.49549\tvalid_1's rmse: 1.54588\n",
      "[1600]\ttraining's rmse: 1.49203\tvalid_1's rmse: 1.54598\n",
      "[1700]\ttraining's rmse: 1.48858\tvalid_1's rmse: 1.54601\n",
      "[1800]\ttraining's rmse: 1.48533\tvalid_1's rmse: 1.54599\n",
      "[1900]\ttraining's rmse: 1.48204\tvalid_1's rmse: 1.54598\n",
      "[2000]\ttraining's rmse: 1.4788\tvalid_1's rmse: 1.54602\n",
      "[2100]\ttraining's rmse: 1.47554\tvalid_1's rmse: 1.546\n",
      "Early stopping, best iteration is:\n",
      "[1515]\ttraining's rmse: 1.49502\tvalid_1's rmse: 1.54583\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60213\tvalid_1's rmse: 1.60822\n",
      "[200]\ttraining's rmse: 1.56955\tvalid_1's rmse: 1.57887\n",
      "[300]\ttraining's rmse: 1.55457\tvalid_1's rmse: 1.56704\n",
      "[400]\ttraining's rmse: 1.5449\tvalid_1's rmse: 1.56131\n",
      "[500]\ttraining's rmse: 1.53762\tvalid_1's rmse: 1.5581\n",
      "[600]\ttraining's rmse: 1.53159\tvalid_1's rmse: 1.55621\n",
      "[700]\ttraining's rmse: 1.52648\tvalid_1's rmse: 1.55525\n",
      "[800]\ttraining's rmse: 1.52187\tvalid_1's rmse: 1.55459\n",
      "[900]\ttraining's rmse: 1.51764\tvalid_1's rmse: 1.55411\n",
      "[1000]\ttraining's rmse: 1.51364\tvalid_1's rmse: 1.55383\n",
      "[1100]\ttraining's rmse: 1.50981\tvalid_1's rmse: 1.55361\n",
      "[1200]\ttraining's rmse: 1.50613\tvalid_1's rmse: 1.55358\n",
      "[1300]\ttraining's rmse: 1.50249\tvalid_1's rmse: 1.55342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttraining's rmse: 1.4988\tvalid_1's rmse: 1.55335\n",
      "[1500]\ttraining's rmse: 1.49528\tvalid_1's rmse: 1.55325\n",
      "[1600]\ttraining's rmse: 1.49178\tvalid_1's rmse: 1.55319\n",
      "[1700]\ttraining's rmse: 1.48835\tvalid_1's rmse: 1.55319\n",
      "[1800]\ttraining's rmse: 1.48485\tvalid_1's rmse: 1.55318\n",
      "[1900]\ttraining's rmse: 1.48151\tvalid_1's rmse: 1.55312\n",
      "[2000]\ttraining's rmse: 1.47817\tvalid_1's rmse: 1.55312\n",
      "[2100]\ttraining's rmse: 1.47483\tvalid_1's rmse: 1.55295\n",
      "[2200]\ttraining's rmse: 1.47164\tvalid_1's rmse: 1.55293\n",
      "[2300]\ttraining's rmse: 1.46849\tvalid_1's rmse: 1.5529\n",
      "[2400]\ttraining's rmse: 1.46532\tvalid_1's rmse: 1.55305\n",
      "[2500]\ttraining's rmse: 1.46219\tvalid_1's rmse: 1.55302\n",
      "[2600]\ttraining's rmse: 1.45907\tvalid_1's rmse: 1.55297\n",
      "[2700]\ttraining's rmse: 1.45606\tvalid_1's rmse: 1.55303\n",
      "[2800]\ttraining's rmse: 1.45291\tvalid_1's rmse: 1.55306\n",
      "Early stopping, best iteration is:\n",
      "[2250]\ttraining's rmse: 1.47003\tvalid_1's rmse: 1.55283\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60057\tvalid_1's rmse: 1.6232\n",
      "[200]\ttraining's rmse: 1.56779\tvalid_1's rmse: 1.59402\n",
      "[300]\ttraining's rmse: 1.55272\tvalid_1's rmse: 1.58293\n",
      "[400]\ttraining's rmse: 1.54298\tvalid_1's rmse: 1.5773\n",
      "[500]\ttraining's rmse: 1.53562\tvalid_1's rmse: 1.57378\n",
      "[600]\ttraining's rmse: 1.5296\tvalid_1's rmse: 1.57197\n",
      "[700]\ttraining's rmse: 1.52435\tvalid_1's rmse: 1.57072\n",
      "[800]\ttraining's rmse: 1.51969\tvalid_1's rmse: 1.56981\n",
      "[900]\ttraining's rmse: 1.5154\tvalid_1's rmse: 1.56941\n",
      "[1000]\ttraining's rmse: 1.51131\tvalid_1's rmse: 1.56897\n",
      "[1100]\ttraining's rmse: 1.50752\tvalid_1's rmse: 1.5686\n",
      "[1200]\ttraining's rmse: 1.50381\tvalid_1's rmse: 1.56855\n",
      "[1300]\ttraining's rmse: 1.50016\tvalid_1's rmse: 1.56836\n",
      "[1400]\ttraining's rmse: 1.49659\tvalid_1's rmse: 1.56815\n",
      "[1500]\ttraining's rmse: 1.4932\tvalid_1's rmse: 1.56801\n",
      "[1600]\ttraining's rmse: 1.48985\tvalid_1's rmse: 1.56789\n",
      "[1700]\ttraining's rmse: 1.48657\tvalid_1's rmse: 1.56775\n",
      "[1800]\ttraining's rmse: 1.48329\tvalid_1's rmse: 1.56777\n",
      "[1900]\ttraining's rmse: 1.48011\tvalid_1's rmse: 1.56767\n",
      "[2000]\ttraining's rmse: 1.47682\tvalid_1's rmse: 1.56764\n",
      "[2100]\ttraining's rmse: 1.47364\tvalid_1's rmse: 1.56762\n",
      "[2200]\ttraining's rmse: 1.47053\tvalid_1's rmse: 1.56763\n",
      "[2300]\ttraining's rmse: 1.46741\tvalid_1's rmse: 1.56764\n",
      "[2400]\ttraining's rmse: 1.46429\tvalid_1's rmse: 1.56753\n",
      "[2500]\ttraining's rmse: 1.46119\tvalid_1's rmse: 1.56752\n",
      "[2600]\ttraining's rmse: 1.45819\tvalid_1's rmse: 1.56753\n",
      "[2700]\ttraining's rmse: 1.45514\tvalid_1's rmse: 1.56745\n",
      "[2800]\ttraining's rmse: 1.45216\tvalid_1's rmse: 1.56733\n",
      "[2900]\ttraining's rmse: 1.44909\tvalid_1's rmse: 1.56727\n",
      "[3000]\ttraining's rmse: 1.44622\tvalid_1's rmse: 1.56723\n",
      "[3100]\ttraining's rmse: 1.44325\tvalid_1's rmse: 1.56721\n",
      "[3200]\ttraining's rmse: 1.44028\tvalid_1's rmse: 1.56725\n",
      "[3300]\ttraining's rmse: 1.43724\tvalid_1's rmse: 1.5672\n",
      "[3400]\ttraining's rmse: 1.43434\tvalid_1's rmse: 1.56711\n",
      "[3500]\ttraining's rmse: 1.43135\tvalid_1's rmse: 1.56706\n",
      "[3600]\ttraining's rmse: 1.42856\tvalid_1's rmse: 1.56704\n",
      "[3700]\ttraining's rmse: 1.42568\tvalid_1's rmse: 1.56709\n",
      "[3800]\ttraining's rmse: 1.42287\tvalid_1's rmse: 1.56706\n",
      "[3900]\ttraining's rmse: 1.41993\tvalid_1's rmse: 1.56718\n",
      "[4000]\ttraining's rmse: 1.41711\tvalid_1's rmse: 1.56725\n",
      "[4100]\ttraining's rmse: 1.41427\tvalid_1's rmse: 1.56727\n",
      "Early stopping, best iteration is:\n",
      "[3568]\ttraining's rmse: 1.42946\tvalid_1's rmse: 1.567\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60078\tvalid_1's rmse: 1.61965\n",
      "[200]\ttraining's rmse: 1.56792\tvalid_1's rmse: 1.59228\n",
      "[300]\ttraining's rmse: 1.55291\tvalid_1's rmse: 1.58157\n",
      "[400]\ttraining's rmse: 1.54311\tvalid_1's rmse: 1.57612\n",
      "[500]\ttraining's rmse: 1.53579\tvalid_1's rmse: 1.57274\n",
      "[600]\ttraining's rmse: 1.52976\tvalid_1's rmse: 1.57081\n",
      "[700]\ttraining's rmse: 1.5246\tvalid_1's rmse: 1.56971\n",
      "[800]\ttraining's rmse: 1.5199\tvalid_1's rmse: 1.56894\n",
      "[900]\ttraining's rmse: 1.51554\tvalid_1's rmse: 1.56835\n",
      "[1000]\ttraining's rmse: 1.51142\tvalid_1's rmse: 1.56799\n",
      "[1100]\ttraining's rmse: 1.50749\tvalid_1's rmse: 1.56764\n",
      "[1200]\ttraining's rmse: 1.50374\tvalid_1's rmse: 1.56748\n",
      "[1300]\ttraining's rmse: 1.5001\tvalid_1's rmse: 1.5672\n",
      "[1400]\ttraining's rmse: 1.4965\tvalid_1's rmse: 1.56707\n",
      "[1500]\ttraining's rmse: 1.49307\tvalid_1's rmse: 1.56685\n",
      "[1600]\ttraining's rmse: 1.48962\tvalid_1's rmse: 1.56682\n",
      "[1700]\ttraining's rmse: 1.48629\tvalid_1's rmse: 1.56665\n",
      "[1800]\ttraining's rmse: 1.48305\tvalid_1's rmse: 1.5667\n",
      "[1900]\ttraining's rmse: 1.47982\tvalid_1's rmse: 1.56654\n",
      "[2000]\ttraining's rmse: 1.47648\tvalid_1's rmse: 1.56658\n",
      "[2100]\ttraining's rmse: 1.47329\tvalid_1's rmse: 1.56653\n",
      "[2200]\ttraining's rmse: 1.46999\tvalid_1's rmse: 1.56651\n",
      "[2300]\ttraining's rmse: 1.46686\tvalid_1's rmse: 1.56634\n",
      "[2400]\ttraining's rmse: 1.46374\tvalid_1's rmse: 1.56619\n",
      "[2500]\ttraining's rmse: 1.46061\tvalid_1's rmse: 1.56613\n",
      "[2600]\ttraining's rmse: 1.45748\tvalid_1's rmse: 1.56619\n",
      "[2700]\ttraining's rmse: 1.45442\tvalid_1's rmse: 1.56622\n",
      "[2800]\ttraining's rmse: 1.4514\tvalid_1's rmse: 1.56617\n",
      "[2900]\ttraining's rmse: 1.44846\tvalid_1's rmse: 1.56612\n",
      "[3000]\ttraining's rmse: 1.44541\tvalid_1's rmse: 1.56603\n",
      "[3100]\ttraining's rmse: 1.44241\tvalid_1's rmse: 1.56608\n",
      "[3200]\ttraining's rmse: 1.43938\tvalid_1's rmse: 1.56604\n",
      "[3300]\ttraining's rmse: 1.43644\tvalid_1's rmse: 1.56615\n",
      "[3400]\ttraining's rmse: 1.43359\tvalid_1's rmse: 1.56613\n",
      "[3500]\ttraining's rmse: 1.43061\tvalid_1's rmse: 1.56617\n",
      "Early stopping, best iteration is:\n",
      "[2977]\ttraining's rmse: 1.44613\tvalid_1's rmse: 1.56599\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.6042\tvalid_1's rmse: 1.59079\n",
      "[200]\ttraining's rmse: 1.57151\tvalid_1's rmse: 1.56196\n",
      "[300]\ttraining's rmse: 1.55626\tvalid_1's rmse: 1.55076\n",
      "[400]\ttraining's rmse: 1.54642\tvalid_1's rmse: 1.54516\n",
      "[500]\ttraining's rmse: 1.53909\tvalid_1's rmse: 1.5423\n",
      "[600]\ttraining's rmse: 1.53312\tvalid_1's rmse: 1.5405\n",
      "[700]\ttraining's rmse: 1.52785\tvalid_1's rmse: 1.53935\n",
      "[800]\ttraining's rmse: 1.52312\tvalid_1's rmse: 1.5387\n",
      "[900]\ttraining's rmse: 1.51892\tvalid_1's rmse: 1.53837\n",
      "[1000]\ttraining's rmse: 1.51486\tvalid_1's rmse: 1.53802\n",
      "[1100]\ttraining's rmse: 1.5109\tvalid_1's rmse: 1.53796\n",
      "[1200]\ttraining's rmse: 1.50718\tvalid_1's rmse: 1.53777\n",
      "[1300]\ttraining's rmse: 1.50366\tvalid_1's rmse: 1.53772\n",
      "[1400]\ttraining's rmse: 1.50012\tvalid_1's rmse: 1.53762\n",
      "[1500]\ttraining's rmse: 1.49657\tvalid_1's rmse: 1.53752\n",
      "[1600]\ttraining's rmse: 1.49308\tvalid_1's rmse: 1.53744\n",
      "[1700]\ttraining's rmse: 1.48986\tvalid_1's rmse: 1.53739\n",
      "[1800]\ttraining's rmse: 1.4865\tvalid_1's rmse: 1.53727\n",
      "[1900]\ttraining's rmse: 1.4832\tvalid_1's rmse: 1.53724\n",
      "[2000]\ttraining's rmse: 1.47997\tvalid_1's rmse: 1.53714\n",
      "[2100]\ttraining's rmse: 1.47666\tvalid_1's rmse: 1.53722\n",
      "[2200]\ttraining's rmse: 1.47351\tvalid_1's rmse: 1.53727\n",
      "[2300]\ttraining's rmse: 1.47043\tvalid_1's rmse: 1.5373\n",
      "[2400]\ttraining's rmse: 1.4672\tvalid_1's rmse: 1.5372\n",
      "[2500]\ttraining's rmse: 1.46402\tvalid_1's rmse: 1.53711\n",
      "[2600]\ttraining's rmse: 1.46083\tvalid_1's rmse: 1.53715\n",
      "[2700]\ttraining's rmse: 1.45777\tvalid_1's rmse: 1.53704\n",
      "[2800]\ttraining's rmse: 1.45475\tvalid_1's rmse: 1.53704\n",
      "[2900]\ttraining's rmse: 1.45183\tvalid_1's rmse: 1.53719\n",
      "[3000]\ttraining's rmse: 1.4488\tvalid_1's rmse: 1.53727\n",
      "[3100]\ttraining's rmse: 1.44589\tvalid_1's rmse: 1.53734\n",
      "[3200]\ttraining's rmse: 1.44292\tvalid_1's rmse: 1.5373\n",
      "[3300]\ttraining's rmse: 1.44007\tvalid_1's rmse: 1.53736\n",
      "Early stopping, best iteration is:\n",
      "[2785]\ttraining's rmse: 1.4552\tvalid_1's rmse: 1.537\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60316\tvalid_1's rmse: 1.59693\n",
      "[200]\ttraining's rmse: 1.57017\tvalid_1's rmse: 1.57041\n",
      "[300]\ttraining's rmse: 1.55483\tvalid_1's rmse: 1.56056\n",
      "[400]\ttraining's rmse: 1.54503\tvalid_1's rmse: 1.55596\n",
      "[500]\ttraining's rmse: 1.53775\tvalid_1's rmse: 1.55357\n",
      "[600]\ttraining's rmse: 1.5317\tvalid_1's rmse: 1.55221\n",
      "[700]\ttraining's rmse: 1.5264\tvalid_1's rmse: 1.55139\n",
      "[800]\ttraining's rmse: 1.52178\tvalid_1's rmse: 1.55084\n",
      "[900]\ttraining's rmse: 1.51747\tvalid_1's rmse: 1.55051\n",
      "[1000]\ttraining's rmse: 1.51338\tvalid_1's rmse: 1.55031\n",
      "[1100]\ttraining's rmse: 1.50943\tvalid_1's rmse: 1.55016\n",
      "[1200]\ttraining's rmse: 1.50567\tvalid_1's rmse: 1.55005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttraining's rmse: 1.50191\tvalid_1's rmse: 1.55002\n",
      "[1400]\ttraining's rmse: 1.49832\tvalid_1's rmse: 1.55003\n",
      "[1500]\ttraining's rmse: 1.49488\tvalid_1's rmse: 1.55011\n",
      "[1600]\ttraining's rmse: 1.4914\tvalid_1's rmse: 1.54998\n",
      "[1700]\ttraining's rmse: 1.48809\tvalid_1's rmse: 1.5501\n",
      "[1800]\ttraining's rmse: 1.4846\tvalid_1's rmse: 1.55016\n",
      "[1900]\ttraining's rmse: 1.48129\tvalid_1's rmse: 1.55009\n",
      "[2000]\ttraining's rmse: 1.47799\tvalid_1's rmse: 1.55011\n",
      "[2100]\ttraining's rmse: 1.47473\tvalid_1's rmse: 1.55018\n",
      "[2200]\ttraining's rmse: 1.4715\tvalid_1's rmse: 1.55024\n",
      "Early stopping, best iteration is:\n",
      "[1618]\ttraining's rmse: 1.49083\tvalid_1's rmse: 1.54992\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60255\tvalid_1's rmse: 1.60618\n",
      "[200]\ttraining's rmse: 1.56964\tvalid_1's rmse: 1.57733\n",
      "[300]\ttraining's rmse: 1.55454\tvalid_1's rmse: 1.56615\n",
      "[400]\ttraining's rmse: 1.54477\tvalid_1's rmse: 1.56074\n",
      "[500]\ttraining's rmse: 1.53753\tvalid_1's rmse: 1.55735\n",
      "[600]\ttraining's rmse: 1.53154\tvalid_1's rmse: 1.55546\n",
      "[700]\ttraining's rmse: 1.52634\tvalid_1's rmse: 1.55428\n",
      "[800]\ttraining's rmse: 1.52168\tvalid_1's rmse: 1.55344\n",
      "[900]\ttraining's rmse: 1.51745\tvalid_1's rmse: 1.55294\n",
      "[1000]\ttraining's rmse: 1.51341\tvalid_1's rmse: 1.55243\n",
      "[1100]\ttraining's rmse: 1.50951\tvalid_1's rmse: 1.55208\n",
      "[1200]\ttraining's rmse: 1.50575\tvalid_1's rmse: 1.55195\n",
      "[1300]\ttraining's rmse: 1.502\tvalid_1's rmse: 1.55172\n",
      "[1400]\ttraining's rmse: 1.49847\tvalid_1's rmse: 1.55158\n",
      "[1500]\ttraining's rmse: 1.49485\tvalid_1's rmse: 1.55131\n",
      "[1600]\ttraining's rmse: 1.49141\tvalid_1's rmse: 1.55117\n",
      "[1700]\ttraining's rmse: 1.48794\tvalid_1's rmse: 1.55107\n",
      "[1800]\ttraining's rmse: 1.48458\tvalid_1's rmse: 1.55104\n",
      "[1900]\ttraining's rmse: 1.48125\tvalid_1's rmse: 1.551\n",
      "[2000]\ttraining's rmse: 1.47791\tvalid_1's rmse: 1.55084\n",
      "[2100]\ttraining's rmse: 1.47457\tvalid_1's rmse: 1.55083\n",
      "[2200]\ttraining's rmse: 1.47136\tvalid_1's rmse: 1.55079\n",
      "[2300]\ttraining's rmse: 1.46807\tvalid_1's rmse: 1.5509\n",
      "[2400]\ttraining's rmse: 1.46498\tvalid_1's rmse: 1.55092\n",
      "[2500]\ttraining's rmse: 1.46188\tvalid_1's rmse: 1.55087\n",
      "[2600]\ttraining's rmse: 1.45877\tvalid_1's rmse: 1.55085\n",
      "[2700]\ttraining's rmse: 1.45572\tvalid_1's rmse: 1.5509\n",
      "Early stopping, best iteration is:\n",
      "[2167]\ttraining's rmse: 1.47242\tvalid_1's rmse: 1.55074\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60244\tvalid_1's rmse: 1.60775\n",
      "[200]\ttraining's rmse: 1.5699\tvalid_1's rmse: 1.57677\n",
      "[300]\ttraining's rmse: 1.55488\tvalid_1's rmse: 1.56469\n",
      "[400]\ttraining's rmse: 1.54527\tvalid_1's rmse: 1.55828\n",
      "[500]\ttraining's rmse: 1.53793\tvalid_1's rmse: 1.55467\n",
      "[600]\ttraining's rmse: 1.53192\tvalid_1's rmse: 1.55248\n",
      "[700]\ttraining's rmse: 1.52676\tvalid_1's rmse: 1.55113\n",
      "[800]\ttraining's rmse: 1.52212\tvalid_1's rmse: 1.55025\n",
      "[900]\ttraining's rmse: 1.51785\tvalid_1's rmse: 1.5496\n",
      "[1000]\ttraining's rmse: 1.51378\tvalid_1's rmse: 1.54913\n",
      "[1100]\ttraining's rmse: 1.50996\tvalid_1's rmse: 1.54878\n",
      "[1200]\ttraining's rmse: 1.50632\tvalid_1's rmse: 1.54851\n",
      "[1300]\ttraining's rmse: 1.50266\tvalid_1's rmse: 1.54833\n",
      "[1400]\ttraining's rmse: 1.49914\tvalid_1's rmse: 1.54803\n",
      "[1500]\ttraining's rmse: 1.49572\tvalid_1's rmse: 1.54767\n",
      "[1600]\ttraining's rmse: 1.4923\tvalid_1's rmse: 1.5475\n",
      "[1700]\ttraining's rmse: 1.48898\tvalid_1's rmse: 1.54733\n",
      "[1800]\ttraining's rmse: 1.48557\tvalid_1's rmse: 1.54716\n",
      "[1900]\ttraining's rmse: 1.48223\tvalid_1's rmse: 1.5471\n",
      "[2000]\ttraining's rmse: 1.47895\tvalid_1's rmse: 1.54697\n",
      "[2100]\ttraining's rmse: 1.47567\tvalid_1's rmse: 1.54688\n",
      "[2200]\ttraining's rmse: 1.47253\tvalid_1's rmse: 1.54684\n",
      "[2300]\ttraining's rmse: 1.4692\tvalid_1's rmse: 1.54687\n",
      "[2400]\ttraining's rmse: 1.46613\tvalid_1's rmse: 1.54693\n",
      "[2500]\ttraining's rmse: 1.46306\tvalid_1's rmse: 1.5469\n",
      "[2600]\ttraining's rmse: 1.46008\tvalid_1's rmse: 1.54687\n",
      "[2700]\ttraining's rmse: 1.45709\tvalid_1's rmse: 1.54691\n",
      "[2800]\ttraining's rmse: 1.45409\tvalid_1's rmse: 1.54678\n",
      "[2900]\ttraining's rmse: 1.45105\tvalid_1's rmse: 1.54677\n",
      "[3000]\ttraining's rmse: 1.44805\tvalid_1's rmse: 1.54685\n",
      "[3100]\ttraining's rmse: 1.44509\tvalid_1's rmse: 1.54671\n",
      "[3200]\ttraining's rmse: 1.44225\tvalid_1's rmse: 1.54681\n",
      "[3300]\ttraining's rmse: 1.43925\tvalid_1's rmse: 1.54683\n",
      "[3400]\ttraining's rmse: 1.43646\tvalid_1's rmse: 1.54689\n",
      "[3500]\ttraining's rmse: 1.43351\tvalid_1's rmse: 1.5469\n",
      "[3600]\ttraining's rmse: 1.43069\tvalid_1's rmse: 1.54696\n",
      "[3700]\ttraining's rmse: 1.42782\tvalid_1's rmse: 1.54686\n",
      "Early stopping, best iteration is:\n",
      "[3116]\ttraining's rmse: 1.44466\tvalid_1's rmse: 1.54671\n",
      "fold 8 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59881\tvalid_1's rmse: 1.63815\n",
      "[200]\ttraining's rmse: 1.56603\tvalid_1's rmse: 1.60941\n",
      "[300]\ttraining's rmse: 1.55096\tvalid_1's rmse: 1.59859\n",
      "[400]\ttraining's rmse: 1.54129\tvalid_1's rmse: 1.5933\n",
      "[500]\ttraining's rmse: 1.534\tvalid_1's rmse: 1.59007\n",
      "[600]\ttraining's rmse: 1.52806\tvalid_1's rmse: 1.5882\n",
      "[700]\ttraining's rmse: 1.52293\tvalid_1's rmse: 1.58693\n",
      "[800]\ttraining's rmse: 1.5184\tvalid_1's rmse: 1.58607\n",
      "[900]\ttraining's rmse: 1.51414\tvalid_1's rmse: 1.5853\n",
      "[1000]\ttraining's rmse: 1.51012\tvalid_1's rmse: 1.58473\n",
      "[1100]\ttraining's rmse: 1.50629\tvalid_1's rmse: 1.58436\n",
      "[1200]\ttraining's rmse: 1.50256\tvalid_1's rmse: 1.58416\n",
      "[1300]\ttraining's rmse: 1.49904\tvalid_1's rmse: 1.58388\n",
      "[1400]\ttraining's rmse: 1.49536\tvalid_1's rmse: 1.58368\n",
      "[1500]\ttraining's rmse: 1.49191\tvalid_1's rmse: 1.58354\n",
      "[1600]\ttraining's rmse: 1.48845\tvalid_1's rmse: 1.58338\n",
      "[1700]\ttraining's rmse: 1.48502\tvalid_1's rmse: 1.58315\n",
      "[1800]\ttraining's rmse: 1.4816\tvalid_1's rmse: 1.58298\n",
      "[1900]\ttraining's rmse: 1.47822\tvalid_1's rmse: 1.58288\n",
      "[2000]\ttraining's rmse: 1.47502\tvalid_1's rmse: 1.58291\n",
      "[2100]\ttraining's rmse: 1.47173\tvalid_1's rmse: 1.58292\n",
      "[2200]\ttraining's rmse: 1.4685\tvalid_1's rmse: 1.58287\n",
      "[2300]\ttraining's rmse: 1.46536\tvalid_1's rmse: 1.58298\n",
      "[2400]\ttraining's rmse: 1.46224\tvalid_1's rmse: 1.58294\n",
      "[2500]\ttraining's rmse: 1.45914\tvalid_1's rmse: 1.58299\n",
      "Early stopping, best iteration is:\n",
      "[1923]\ttraining's rmse: 1.47751\tvalid_1's rmse: 1.58285\n",
      "fold 9 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60399\tvalid_1's rmse: 1.58813\n",
      "[200]\ttraining's rmse: 1.57089\tvalid_1's rmse: 1.56259\n",
      "[300]\ttraining's rmse: 1.55563\tvalid_1's rmse: 1.55355\n",
      "[400]\ttraining's rmse: 1.54592\tvalid_1's rmse: 1.54906\n",
      "[500]\ttraining's rmse: 1.53863\tvalid_1's rmse: 1.5467\n",
      "[600]\ttraining's rmse: 1.53247\tvalid_1's rmse: 1.54525\n",
      "[700]\ttraining's rmse: 1.52722\tvalid_1's rmse: 1.54438\n",
      "[800]\ttraining's rmse: 1.5226\tvalid_1's rmse: 1.5439\n",
      "[900]\ttraining's rmse: 1.5183\tvalid_1's rmse: 1.54359\n",
      "[1000]\ttraining's rmse: 1.51428\tvalid_1's rmse: 1.54344\n",
      "[1100]\ttraining's rmse: 1.51041\tvalid_1's rmse: 1.54332\n",
      "[1200]\ttraining's rmse: 1.50669\tvalid_1's rmse: 1.54326\n",
      "[1300]\ttraining's rmse: 1.50295\tvalid_1's rmse: 1.54308\n",
      "[1400]\ttraining's rmse: 1.49925\tvalid_1's rmse: 1.5431\n",
      "[1500]\ttraining's rmse: 1.49582\tvalid_1's rmse: 1.54299\n",
      "[1600]\ttraining's rmse: 1.4924\tvalid_1's rmse: 1.54294\n",
      "[1700]\ttraining's rmse: 1.48908\tvalid_1's rmse: 1.5429\n",
      "[1800]\ttraining's rmse: 1.48578\tvalid_1's rmse: 1.54298\n",
      "[1900]\ttraining's rmse: 1.4825\tvalid_1's rmse: 1.54302\n",
      "[2000]\ttraining's rmse: 1.47915\tvalid_1's rmse: 1.54298\n",
      "[2100]\ttraining's rmse: 1.47587\tvalid_1's rmse: 1.54298\n",
      "[2200]\ttraining's rmse: 1.47265\tvalid_1's rmse: 1.54303\n",
      "[2300]\ttraining's rmse: 1.46945\tvalid_1's rmse: 1.54302\n",
      "Early stopping, best iteration is:\n",
      "[1715]\ttraining's rmse: 1.48854\tvalid_1's rmse: 1.54288\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60362\tvalid_1's rmse: 1.59221\n",
      "[200]\ttraining's rmse: 1.57067\tvalid_1's rmse: 1.56585\n",
      "[300]\ttraining's rmse: 1.55557\tvalid_1's rmse: 1.55644\n",
      "[400]\ttraining's rmse: 1.54604\tvalid_1's rmse: 1.55203\n",
      "[500]\ttraining's rmse: 1.539\tvalid_1's rmse: 1.54965\n",
      "[600]\ttraining's rmse: 1.53323\tvalid_1's rmse: 1.54833\n",
      "[700]\ttraining's rmse: 1.52835\tvalid_1's rmse: 1.54747\n",
      "[800]\ttraining's rmse: 1.52392\tvalid_1's rmse: 1.54714\n",
      "[900]\ttraining's rmse: 1.5198\tvalid_1's rmse: 1.54694\n",
      "[1000]\ttraining's rmse: 1.51603\tvalid_1's rmse: 1.54673\n",
      "[1100]\ttraining's rmse: 1.51235\tvalid_1's rmse: 1.54671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's rmse: 1.50884\tvalid_1's rmse: 1.54662\n",
      "[1300]\ttraining's rmse: 1.50534\tvalid_1's rmse: 1.5466\n",
      "[1400]\ttraining's rmse: 1.50197\tvalid_1's rmse: 1.54649\n",
      "[1500]\ttraining's rmse: 1.49868\tvalid_1's rmse: 1.54625\n",
      "[1600]\ttraining's rmse: 1.49547\tvalid_1's rmse: 1.54608\n",
      "[1700]\ttraining's rmse: 1.49221\tvalid_1's rmse: 1.54591\n",
      "[1800]\ttraining's rmse: 1.48899\tvalid_1's rmse: 1.5458\n",
      "[1900]\ttraining's rmse: 1.48584\tvalid_1's rmse: 1.54572\n",
      "[2000]\ttraining's rmse: 1.48282\tvalid_1's rmse: 1.5456\n",
      "[2100]\ttraining's rmse: 1.4798\tvalid_1's rmse: 1.54561\n",
      "[2200]\ttraining's rmse: 1.47671\tvalid_1's rmse: 1.54573\n",
      "[2300]\ttraining's rmse: 1.47367\tvalid_1's rmse: 1.54584\n",
      "[2400]\ttraining's rmse: 1.47067\tvalid_1's rmse: 1.54569\n",
      "[2500]\ttraining's rmse: 1.46772\tvalid_1's rmse: 1.5457\n",
      "[2600]\ttraining's rmse: 1.4648\tvalid_1's rmse: 1.54568\n",
      "Early stopping, best iteration is:\n",
      "[2051]\ttraining's rmse: 1.48126\tvalid_1's rmse: 1.54556\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60226\tvalid_1's rmse: 1.60837\n",
      "[200]\ttraining's rmse: 1.56976\tvalid_1's rmse: 1.57876\n",
      "[300]\ttraining's rmse: 1.55508\tvalid_1's rmse: 1.56733\n",
      "[400]\ttraining's rmse: 1.54568\tvalid_1's rmse: 1.56132\n",
      "[500]\ttraining's rmse: 1.53871\tvalid_1's rmse: 1.55817\n",
      "[600]\ttraining's rmse: 1.53302\tvalid_1's rmse: 1.55637\n",
      "[700]\ttraining's rmse: 1.52813\tvalid_1's rmse: 1.55506\n",
      "[800]\ttraining's rmse: 1.52377\tvalid_1's rmse: 1.55439\n",
      "[900]\ttraining's rmse: 1.51985\tvalid_1's rmse: 1.55387\n",
      "[1000]\ttraining's rmse: 1.51608\tvalid_1's rmse: 1.55338\n",
      "[1100]\ttraining's rmse: 1.51247\tvalid_1's rmse: 1.5532\n",
      "[1200]\ttraining's rmse: 1.50901\tvalid_1's rmse: 1.55321\n",
      "[1300]\ttraining's rmse: 1.50565\tvalid_1's rmse: 1.55308\n",
      "[1400]\ttraining's rmse: 1.50223\tvalid_1's rmse: 1.55302\n",
      "[1500]\ttraining's rmse: 1.499\tvalid_1's rmse: 1.55302\n",
      "[1600]\ttraining's rmse: 1.49578\tvalid_1's rmse: 1.55284\n",
      "[1700]\ttraining's rmse: 1.49253\tvalid_1's rmse: 1.55292\n",
      "[1800]\ttraining's rmse: 1.48919\tvalid_1's rmse: 1.55276\n",
      "[1900]\ttraining's rmse: 1.48607\tvalid_1's rmse: 1.55275\n",
      "[2000]\ttraining's rmse: 1.48288\tvalid_1's rmse: 1.5528\n",
      "[2100]\ttraining's rmse: 1.47979\tvalid_1's rmse: 1.5527\n",
      "[2200]\ttraining's rmse: 1.47671\tvalid_1's rmse: 1.55281\n",
      "[2300]\ttraining's rmse: 1.47371\tvalid_1's rmse: 1.55288\n",
      "[2400]\ttraining's rmse: 1.47069\tvalid_1's rmse: 1.55297\n",
      "[2500]\ttraining's rmse: 1.46769\tvalid_1's rmse: 1.55308\n",
      "[2600]\ttraining's rmse: 1.46473\tvalid_1's rmse: 1.55312\n",
      "Early stopping, best iteration is:\n",
      "[2094]\ttraining's rmse: 1.47997\tvalid_1's rmse: 1.55267\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60062\tvalid_1's rmse: 1.62324\n",
      "[200]\ttraining's rmse: 1.56796\tvalid_1's rmse: 1.59416\n",
      "[300]\ttraining's rmse: 1.553\tvalid_1's rmse: 1.58298\n",
      "[400]\ttraining's rmse: 1.54348\tvalid_1's rmse: 1.57714\n",
      "[500]\ttraining's rmse: 1.53644\tvalid_1's rmse: 1.57382\n",
      "[600]\ttraining's rmse: 1.53076\tvalid_1's rmse: 1.5721\n",
      "[700]\ttraining's rmse: 1.52578\tvalid_1's rmse: 1.57102\n",
      "[800]\ttraining's rmse: 1.52139\tvalid_1's rmse: 1.57037\n",
      "[900]\ttraining's rmse: 1.51727\tvalid_1's rmse: 1.56997\n",
      "[1000]\ttraining's rmse: 1.51348\tvalid_1's rmse: 1.56966\n",
      "[1100]\ttraining's rmse: 1.50998\tvalid_1's rmse: 1.56949\n",
      "[1200]\ttraining's rmse: 1.50654\tvalid_1's rmse: 1.5692\n",
      "[1300]\ttraining's rmse: 1.50309\tvalid_1's rmse: 1.56909\n",
      "[1400]\ttraining's rmse: 1.49973\tvalid_1's rmse: 1.56895\n",
      "[1500]\ttraining's rmse: 1.49649\tvalid_1's rmse: 1.56871\n",
      "[1600]\ttraining's rmse: 1.49329\tvalid_1's rmse: 1.56859\n",
      "[1700]\ttraining's rmse: 1.49023\tvalid_1's rmse: 1.56849\n",
      "[1800]\ttraining's rmse: 1.48701\tvalid_1's rmse: 1.56853\n",
      "[1900]\ttraining's rmse: 1.4838\tvalid_1's rmse: 1.56842\n",
      "[2000]\ttraining's rmse: 1.48064\tvalid_1's rmse: 1.56826\n",
      "[2100]\ttraining's rmse: 1.47763\tvalid_1's rmse: 1.56818\n",
      "[2200]\ttraining's rmse: 1.47465\tvalid_1's rmse: 1.56826\n",
      "[2300]\ttraining's rmse: 1.47165\tvalid_1's rmse: 1.56809\n",
      "[2400]\ttraining's rmse: 1.46865\tvalid_1's rmse: 1.56791\n",
      "[2500]\ttraining's rmse: 1.46575\tvalid_1's rmse: 1.56785\n",
      "[2600]\ttraining's rmse: 1.46282\tvalid_1's rmse: 1.56774\n",
      "[2700]\ttraining's rmse: 1.4599\tvalid_1's rmse: 1.56774\n",
      "[2800]\ttraining's rmse: 1.45708\tvalid_1's rmse: 1.56755\n",
      "[2900]\ttraining's rmse: 1.45418\tvalid_1's rmse: 1.56747\n",
      "[3000]\ttraining's rmse: 1.45138\tvalid_1's rmse: 1.56752\n",
      "[3100]\ttraining's rmse: 1.44858\tvalid_1's rmse: 1.56757\n",
      "[3200]\ttraining's rmse: 1.44573\tvalid_1's rmse: 1.56758\n",
      "[3300]\ttraining's rmse: 1.44298\tvalid_1's rmse: 1.56761\n",
      "[3400]\ttraining's rmse: 1.44028\tvalid_1's rmse: 1.56771\n",
      "[3500]\ttraining's rmse: 1.43755\tvalid_1's rmse: 1.56767\n",
      "Early stopping, best iteration is:\n",
      "[2944]\ttraining's rmse: 1.4529\tvalid_1's rmse: 1.56745\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60082\tvalid_1's rmse: 1.61939\n",
      "[200]\ttraining's rmse: 1.56802\tvalid_1's rmse: 1.59184\n",
      "[300]\ttraining's rmse: 1.55316\tvalid_1's rmse: 1.58125\n",
      "[400]\ttraining's rmse: 1.54363\tvalid_1's rmse: 1.57567\n",
      "[500]\ttraining's rmse: 1.53662\tvalid_1's rmse: 1.57245\n",
      "[600]\ttraining's rmse: 1.53098\tvalid_1's rmse: 1.57062\n",
      "[700]\ttraining's rmse: 1.52609\tvalid_1's rmse: 1.56948\n",
      "[800]\ttraining's rmse: 1.52167\tvalid_1's rmse: 1.56881\n",
      "[900]\ttraining's rmse: 1.51756\tvalid_1's rmse: 1.56829\n",
      "[1000]\ttraining's rmse: 1.5137\tvalid_1's rmse: 1.56788\n",
      "[1100]\ttraining's rmse: 1.51001\tvalid_1's rmse: 1.56763\n",
      "[1200]\ttraining's rmse: 1.50651\tvalid_1's rmse: 1.56737\n",
      "[1300]\ttraining's rmse: 1.50302\tvalid_1's rmse: 1.56724\n",
      "[1400]\ttraining's rmse: 1.49977\tvalid_1's rmse: 1.56718\n",
      "[1500]\ttraining's rmse: 1.49647\tvalid_1's rmse: 1.56705\n",
      "[1600]\ttraining's rmse: 1.49318\tvalid_1's rmse: 1.5669\n",
      "[1700]\ttraining's rmse: 1.48993\tvalid_1's rmse: 1.56682\n",
      "[1800]\ttraining's rmse: 1.48681\tvalid_1's rmse: 1.56682\n",
      "[1900]\ttraining's rmse: 1.48368\tvalid_1's rmse: 1.56691\n",
      "[2000]\ttraining's rmse: 1.48055\tvalid_1's rmse: 1.56691\n",
      "[2100]\ttraining's rmse: 1.4775\tvalid_1's rmse: 1.56696\n",
      "[2200]\ttraining's rmse: 1.47443\tvalid_1's rmse: 1.56701\n",
      "[2300]\ttraining's rmse: 1.47147\tvalid_1's rmse: 1.56696\n",
      "Early stopping, best iteration is:\n",
      "[1767]\ttraining's rmse: 1.48781\tvalid_1's rmse: 1.56677\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60419\tvalid_1's rmse: 1.59098\n",
      "[200]\ttraining's rmse: 1.57152\tvalid_1's rmse: 1.56175\n",
      "[300]\ttraining's rmse: 1.55652\tvalid_1's rmse: 1.55065\n",
      "[400]\ttraining's rmse: 1.54697\tvalid_1's rmse: 1.54495\n",
      "[500]\ttraining's rmse: 1.53993\tvalid_1's rmse: 1.54199\n",
      "[600]\ttraining's rmse: 1.53428\tvalid_1's rmse: 1.54028\n",
      "[700]\ttraining's rmse: 1.52928\tvalid_1's rmse: 1.5395\n",
      "[800]\ttraining's rmse: 1.52482\tvalid_1's rmse: 1.53878\n",
      "[900]\ttraining's rmse: 1.52089\tvalid_1's rmse: 1.53851\n",
      "[1000]\ttraining's rmse: 1.51701\tvalid_1's rmse: 1.53837\n",
      "[1100]\ttraining's rmse: 1.51344\tvalid_1's rmse: 1.53818\n",
      "[1200]\ttraining's rmse: 1.50993\tvalid_1's rmse: 1.53818\n",
      "[1300]\ttraining's rmse: 1.50653\tvalid_1's rmse: 1.53801\n",
      "[1400]\ttraining's rmse: 1.50315\tvalid_1's rmse: 1.538\n",
      "[1500]\ttraining's rmse: 1.49983\tvalid_1's rmse: 1.53793\n",
      "[1600]\ttraining's rmse: 1.49654\tvalid_1's rmse: 1.53791\n",
      "[1700]\ttraining's rmse: 1.49337\tvalid_1's rmse: 1.5378\n",
      "[1800]\ttraining's rmse: 1.49024\tvalid_1's rmse: 1.53773\n",
      "[1900]\ttraining's rmse: 1.48721\tvalid_1's rmse: 1.53776\n",
      "[2000]\ttraining's rmse: 1.48417\tvalid_1's rmse: 1.53766\n",
      "[2100]\ttraining's rmse: 1.48099\tvalid_1's rmse: 1.53751\n",
      "[2200]\ttraining's rmse: 1.47797\tvalid_1's rmse: 1.5375\n",
      "[2300]\ttraining's rmse: 1.47498\tvalid_1's rmse: 1.53757\n",
      "[2400]\ttraining's rmse: 1.47187\tvalid_1's rmse: 1.53756\n",
      "[2500]\ttraining's rmse: 1.46889\tvalid_1's rmse: 1.53748\n",
      "[2600]\ttraining's rmse: 1.46598\tvalid_1's rmse: 1.53747\n",
      "[2700]\ttraining's rmse: 1.46306\tvalid_1's rmse: 1.5374\n",
      "[2800]\ttraining's rmse: 1.46018\tvalid_1's rmse: 1.53753\n",
      "[2900]\ttraining's rmse: 1.45731\tvalid_1's rmse: 1.53747\n",
      "[3000]\ttraining's rmse: 1.45443\tvalid_1's rmse: 1.53747\n",
      "[3100]\ttraining's rmse: 1.45169\tvalid_1's rmse: 1.53749\n",
      "[3200]\ttraining's rmse: 1.44885\tvalid_1's rmse: 1.53751\n",
      "[3300]\ttraining's rmse: 1.44614\tvalid_1's rmse: 1.53744\n",
      "Early stopping, best iteration is:\n",
      "[2742]\ttraining's rmse: 1.4619\tvalid_1's rmse: 1.53738\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60319\tvalid_1's rmse: 1.59679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 1.57036\tvalid_1's rmse: 1.5703\n",
      "[300]\ttraining's rmse: 1.55533\tvalid_1's rmse: 1.56044\n",
      "[400]\ttraining's rmse: 1.54574\tvalid_1's rmse: 1.55585\n",
      "[500]\ttraining's rmse: 1.53864\tvalid_1's rmse: 1.55356\n",
      "[600]\ttraining's rmse: 1.53296\tvalid_1's rmse: 1.55254\n",
      "[700]\ttraining's rmse: 1.52801\tvalid_1's rmse: 1.55191\n",
      "[800]\ttraining's rmse: 1.52365\tvalid_1's rmse: 1.55153\n",
      "[900]\ttraining's rmse: 1.51952\tvalid_1's rmse: 1.55144\n",
      "[1000]\ttraining's rmse: 1.51563\tvalid_1's rmse: 1.55146\n",
      "[1100]\ttraining's rmse: 1.51188\tvalid_1's rmse: 1.55129\n",
      "[1200]\ttraining's rmse: 1.50831\tvalid_1's rmse: 1.55121\n",
      "[1300]\ttraining's rmse: 1.50483\tvalid_1's rmse: 1.55123\n",
      "[1400]\ttraining's rmse: 1.5013\tvalid_1's rmse: 1.55138\n",
      "[1500]\ttraining's rmse: 1.49802\tvalid_1's rmse: 1.5513\n",
      "[1600]\ttraining's rmse: 1.49484\tvalid_1's rmse: 1.55128\n",
      "[1700]\ttraining's rmse: 1.49162\tvalid_1's rmse: 1.55132\n",
      "[1800]\ttraining's rmse: 1.48827\tvalid_1's rmse: 1.55139\n",
      "Early stopping, best iteration is:\n",
      "[1216]\ttraining's rmse: 1.50776\tvalid_1's rmse: 1.55114\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60254\tvalid_1's rmse: 1.60618\n",
      "[200]\ttraining's rmse: 1.56983\tvalid_1's rmse: 1.57732\n",
      "[300]\ttraining's rmse: 1.5548\tvalid_1's rmse: 1.56589\n",
      "[400]\ttraining's rmse: 1.54537\tvalid_1's rmse: 1.56051\n",
      "[500]\ttraining's rmse: 1.53834\tvalid_1's rmse: 1.55739\n",
      "[600]\ttraining's rmse: 1.5326\tvalid_1's rmse: 1.5556\n",
      "[700]\ttraining's rmse: 1.52767\tvalid_1's rmse: 1.55453\n",
      "[800]\ttraining's rmse: 1.52333\tvalid_1's rmse: 1.55385\n",
      "[900]\ttraining's rmse: 1.51938\tvalid_1's rmse: 1.5533\n",
      "[1000]\ttraining's rmse: 1.51565\tvalid_1's rmse: 1.55292\n",
      "[1100]\ttraining's rmse: 1.512\tvalid_1's rmse: 1.55273\n",
      "[1200]\ttraining's rmse: 1.50846\tvalid_1's rmse: 1.55263\n",
      "[1300]\ttraining's rmse: 1.50496\tvalid_1's rmse: 1.55266\n",
      "[1400]\ttraining's rmse: 1.50165\tvalid_1's rmse: 1.55252\n",
      "[1500]\ttraining's rmse: 1.49825\tvalid_1's rmse: 1.55242\n",
      "[1600]\ttraining's rmse: 1.49493\tvalid_1's rmse: 1.55222\n",
      "[1700]\ttraining's rmse: 1.49167\tvalid_1's rmse: 1.55224\n",
      "[1800]\ttraining's rmse: 1.48849\tvalid_1's rmse: 1.55216\n",
      "[1900]\ttraining's rmse: 1.48528\tvalid_1's rmse: 1.55205\n",
      "[2000]\ttraining's rmse: 1.48223\tvalid_1's rmse: 1.55207\n",
      "[2100]\ttraining's rmse: 1.47913\tvalid_1's rmse: 1.55208\n",
      "[2200]\ttraining's rmse: 1.47606\tvalid_1's rmse: 1.55204\n",
      "[2300]\ttraining's rmse: 1.4731\tvalid_1's rmse: 1.55217\n",
      "[2400]\ttraining's rmse: 1.47006\tvalid_1's rmse: 1.55215\n",
      "[2500]\ttraining's rmse: 1.46699\tvalid_1's rmse: 1.55221\n",
      "[2600]\ttraining's rmse: 1.46392\tvalid_1's rmse: 1.55237\n",
      "Early stopping, best iteration is:\n",
      "[2055]\ttraining's rmse: 1.48047\tvalid_1's rmse: 1.552\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60246\tvalid_1's rmse: 1.60754\n",
      "[200]\ttraining's rmse: 1.56995\tvalid_1's rmse: 1.57667\n",
      "[300]\ttraining's rmse: 1.55514\tvalid_1's rmse: 1.56476\n",
      "[400]\ttraining's rmse: 1.54576\tvalid_1's rmse: 1.5584\n",
      "[500]\ttraining's rmse: 1.5388\tvalid_1's rmse: 1.55476\n",
      "[600]\ttraining's rmse: 1.53313\tvalid_1's rmse: 1.55257\n",
      "[700]\ttraining's rmse: 1.52822\tvalid_1's rmse: 1.55131\n",
      "[800]\ttraining's rmse: 1.52374\tvalid_1's rmse: 1.55041\n",
      "[900]\ttraining's rmse: 1.51975\tvalid_1's rmse: 1.55009\n",
      "[1000]\ttraining's rmse: 1.51594\tvalid_1's rmse: 1.54986\n",
      "[1100]\ttraining's rmse: 1.51236\tvalid_1's rmse: 1.54959\n",
      "[1200]\ttraining's rmse: 1.50894\tvalid_1's rmse: 1.54924\n",
      "[1300]\ttraining's rmse: 1.50558\tvalid_1's rmse: 1.54913\n",
      "[1400]\ttraining's rmse: 1.50217\tvalid_1's rmse: 1.54894\n",
      "[1500]\ttraining's rmse: 1.49888\tvalid_1's rmse: 1.54882\n",
      "[1600]\ttraining's rmse: 1.49569\tvalid_1's rmse: 1.54879\n",
      "[1700]\ttraining's rmse: 1.49254\tvalid_1's rmse: 1.5488\n",
      "[1800]\ttraining's rmse: 1.48934\tvalid_1's rmse: 1.54879\n",
      "[1900]\ttraining's rmse: 1.48628\tvalid_1's rmse: 1.54881\n",
      "[2000]\ttraining's rmse: 1.48321\tvalid_1's rmse: 1.5487\n",
      "[2100]\ttraining's rmse: 1.48012\tvalid_1's rmse: 1.54858\n",
      "[2200]\ttraining's rmse: 1.47711\tvalid_1's rmse: 1.54854\n",
      "[2300]\ttraining's rmse: 1.47398\tvalid_1's rmse: 1.54837\n",
      "[2400]\ttraining's rmse: 1.47091\tvalid_1's rmse: 1.5484\n",
      "[2500]\ttraining's rmse: 1.46791\tvalid_1's rmse: 1.54834\n",
      "[2600]\ttraining's rmse: 1.46493\tvalid_1's rmse: 1.54829\n",
      "[2700]\ttraining's rmse: 1.46203\tvalid_1's rmse: 1.54823\n",
      "[2800]\ttraining's rmse: 1.4591\tvalid_1's rmse: 1.54816\n",
      "[2900]\ttraining's rmse: 1.45629\tvalid_1's rmse: 1.5482\n",
      "[3000]\ttraining's rmse: 1.45345\tvalid_1's rmse: 1.54815\n",
      "[3100]\ttraining's rmse: 1.45057\tvalid_1's rmse: 1.54813\n",
      "[3200]\ttraining's rmse: 1.44775\tvalid_1's rmse: 1.54817\n",
      "[3300]\ttraining's rmse: 1.44498\tvalid_1's rmse: 1.54808\n",
      "[3400]\ttraining's rmse: 1.44222\tvalid_1's rmse: 1.5481\n",
      "[3500]\ttraining's rmse: 1.43938\tvalid_1's rmse: 1.54811\n",
      "[3600]\ttraining's rmse: 1.43667\tvalid_1's rmse: 1.54819\n",
      "[3700]\ttraining's rmse: 1.43393\tvalid_1's rmse: 1.54828\n",
      "[3800]\ttraining's rmse: 1.43131\tvalid_1's rmse: 1.54834\n",
      "[3900]\ttraining's rmse: 1.42862\tvalid_1's rmse: 1.54835\n",
      "Early stopping, best iteration is:\n",
      "[3357]\ttraining's rmse: 1.44342\tvalid_1's rmse: 1.54806\n",
      "fold 8 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59885\tvalid_1's rmse: 1.63827\n",
      "[200]\ttraining's rmse: 1.56616\tvalid_1's rmse: 1.60942\n",
      "[300]\ttraining's rmse: 1.55134\tvalid_1's rmse: 1.59887\n",
      "[400]\ttraining's rmse: 1.54193\tvalid_1's rmse: 1.59366\n",
      "[500]\ttraining's rmse: 1.53497\tvalid_1's rmse: 1.59043\n",
      "[600]\ttraining's rmse: 1.52929\tvalid_1's rmse: 1.58835\n",
      "[700]\ttraining's rmse: 1.52454\tvalid_1's rmse: 1.58722\n",
      "[800]\ttraining's rmse: 1.52023\tvalid_1's rmse: 1.5863\n",
      "[900]\ttraining's rmse: 1.51625\tvalid_1's rmse: 1.58581\n",
      "[1000]\ttraining's rmse: 1.51246\tvalid_1's rmse: 1.58539\n",
      "[1100]\ttraining's rmse: 1.50881\tvalid_1's rmse: 1.58491\n",
      "[1200]\ttraining's rmse: 1.50529\tvalid_1's rmse: 1.58479\n",
      "[1300]\ttraining's rmse: 1.50191\tvalid_1's rmse: 1.58449\n",
      "[1400]\ttraining's rmse: 1.49842\tvalid_1's rmse: 1.58437\n",
      "[1500]\ttraining's rmse: 1.4951\tvalid_1's rmse: 1.58427\n",
      "[1600]\ttraining's rmse: 1.4919\tvalid_1's rmse: 1.58422\n",
      "[1700]\ttraining's rmse: 1.48864\tvalid_1's rmse: 1.58413\n",
      "[1800]\ttraining's rmse: 1.48554\tvalid_1's rmse: 1.58397\n",
      "[1900]\ttraining's rmse: 1.48242\tvalid_1's rmse: 1.58385\n",
      "[2000]\ttraining's rmse: 1.47938\tvalid_1's rmse: 1.58379\n",
      "[2100]\ttraining's rmse: 1.4763\tvalid_1's rmse: 1.58383\n",
      "[2200]\ttraining's rmse: 1.4732\tvalid_1's rmse: 1.58382\n",
      "[2300]\ttraining's rmse: 1.47024\tvalid_1's rmse: 1.58385\n",
      "[2400]\ttraining's rmse: 1.46721\tvalid_1's rmse: 1.5838\n",
      "[2500]\ttraining's rmse: 1.46424\tvalid_1's rmse: 1.58377\n",
      "[2600]\ttraining's rmse: 1.46124\tvalid_1's rmse: 1.58363\n",
      "[2700]\ttraining's rmse: 1.45829\tvalid_1's rmse: 1.58372\n",
      "[2800]\ttraining's rmse: 1.45534\tvalid_1's rmse: 1.58381\n",
      "[2900]\ttraining's rmse: 1.45252\tvalid_1's rmse: 1.58385\n",
      "[3000]\ttraining's rmse: 1.44964\tvalid_1's rmse: 1.58392\n",
      "[3100]\ttraining's rmse: 1.44678\tvalid_1's rmse: 1.58397\n",
      "[3200]\ttraining's rmse: 1.44407\tvalid_1's rmse: 1.58395\n",
      "Early stopping, best iteration is:\n",
      "[2603]\ttraining's rmse: 1.46115\tvalid_1's rmse: 1.58362\n",
      "fold 9 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60402\tvalid_1's rmse: 1.58788\n",
      "[200]\ttraining's rmse: 1.57109\tvalid_1's rmse: 1.56235\n",
      "[300]\ttraining's rmse: 1.55599\tvalid_1's rmse: 1.55326\n",
      "[400]\ttraining's rmse: 1.54652\tvalid_1's rmse: 1.54901\n",
      "[500]\ttraining's rmse: 1.53954\tvalid_1's rmse: 1.54662\n",
      "[600]\ttraining's rmse: 1.53369\tvalid_1's rmse: 1.54521\n",
      "[700]\ttraining's rmse: 1.52879\tvalid_1's rmse: 1.5446\n",
      "[800]\ttraining's rmse: 1.52449\tvalid_1's rmse: 1.54423\n",
      "[900]\ttraining's rmse: 1.52043\tvalid_1's rmse: 1.54393\n",
      "[1000]\ttraining's rmse: 1.51657\tvalid_1's rmse: 1.54387\n",
      "[1100]\ttraining's rmse: 1.5129\tvalid_1's rmse: 1.54375\n",
      "[1200]\ttraining's rmse: 1.50929\tvalid_1's rmse: 1.54374\n",
      "[1300]\ttraining's rmse: 1.50585\tvalid_1's rmse: 1.54369\n",
      "[1400]\ttraining's rmse: 1.5025\tvalid_1's rmse: 1.54368\n",
      "[1500]\ttraining's rmse: 1.49921\tvalid_1's rmse: 1.54372\n",
      "[1600]\ttraining's rmse: 1.49604\tvalid_1's rmse: 1.54371\n",
      "[1700]\ttraining's rmse: 1.49272\tvalid_1's rmse: 1.54368\n",
      "[1800]\ttraining's rmse: 1.48954\tvalid_1's rmse: 1.54393\n",
      "[1900]\ttraining's rmse: 1.4864\tvalid_1's rmse: 1.54401\n",
      "Early stopping, best iteration is:\n",
      "[1355]\ttraining's rmse: 1.50396\tvalid_1's rmse: 1.54361\n",
      "fold 0 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 1.60383\tvalid_1's rmse: 1.59234\n",
      "[200]\ttraining's rmse: 1.57089\tvalid_1's rmse: 1.56588\n",
      "[300]\ttraining's rmse: 1.55585\tvalid_1's rmse: 1.55644\n",
      "[400]\ttraining's rmse: 1.54661\tvalid_1's rmse: 1.55226\n",
      "[500]\ttraining's rmse: 1.5398\tvalid_1's rmse: 1.54998\n",
      "[600]\ttraining's rmse: 1.53439\tvalid_1's rmse: 1.54861\n",
      "[700]\ttraining's rmse: 1.52967\tvalid_1's rmse: 1.54788\n",
      "[800]\ttraining's rmse: 1.52542\tvalid_1's rmse: 1.5475\n",
      "[900]\ttraining's rmse: 1.52152\tvalid_1's rmse: 1.54711\n",
      "[1000]\ttraining's rmse: 1.51768\tvalid_1's rmse: 1.54688\n",
      "[1100]\ttraining's rmse: 1.5141\tvalid_1's rmse: 1.54688\n",
      "[1200]\ttraining's rmse: 1.51078\tvalid_1's rmse: 1.54683\n",
      "[1300]\ttraining's rmse: 1.50745\tvalid_1's rmse: 1.54672\n",
      "[1400]\ttraining's rmse: 1.50414\tvalid_1's rmse: 1.54681\n",
      "[1500]\ttraining's rmse: 1.50098\tvalid_1's rmse: 1.54666\n",
      "[1600]\ttraining's rmse: 1.49786\tvalid_1's rmse: 1.54671\n",
      "[1700]\ttraining's rmse: 1.49473\tvalid_1's rmse: 1.54675\n",
      "[1800]\ttraining's rmse: 1.49157\tvalid_1's rmse: 1.54688\n",
      "[1900]\ttraining's rmse: 1.48845\tvalid_1's rmse: 1.54693\n",
      "[2000]\ttraining's rmse: 1.48547\tvalid_1's rmse: 1.54687\n",
      "[2100]\ttraining's rmse: 1.48253\tvalid_1's rmse: 1.54692\n",
      "Early stopping, best iteration is:\n",
      "[1524]\ttraining's rmse: 1.50027\tvalid_1's rmse: 1.54664\n",
      "fold 1 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60231\tvalid_1's rmse: 1.60846\n",
      "[200]\ttraining's rmse: 1.56985\tvalid_1's rmse: 1.57873\n",
      "[300]\ttraining's rmse: 1.55513\tvalid_1's rmse: 1.56705\n",
      "[400]\ttraining's rmse: 1.54598\tvalid_1's rmse: 1.56124\n",
      "[500]\ttraining's rmse: 1.53923\tvalid_1's rmse: 1.55808\n",
      "[600]\ttraining's rmse: 1.53381\tvalid_1's rmse: 1.55629\n",
      "[700]\ttraining's rmse: 1.52907\tvalid_1's rmse: 1.55532\n",
      "[800]\ttraining's rmse: 1.52488\tvalid_1's rmse: 1.55458\n",
      "[900]\ttraining's rmse: 1.52108\tvalid_1's rmse: 1.55429\n",
      "[1000]\ttraining's rmse: 1.51743\tvalid_1's rmse: 1.5541\n",
      "[1100]\ttraining's rmse: 1.51401\tvalid_1's rmse: 1.55401\n",
      "[1200]\ttraining's rmse: 1.51067\tvalid_1's rmse: 1.55379\n",
      "[1300]\ttraining's rmse: 1.50736\tvalid_1's rmse: 1.55366\n",
      "[1400]\ttraining's rmse: 1.50419\tvalid_1's rmse: 1.55368\n",
      "[1500]\ttraining's rmse: 1.50103\tvalid_1's rmse: 1.55373\n",
      "[1600]\ttraining's rmse: 1.49779\tvalid_1's rmse: 1.55364\n",
      "[1700]\ttraining's rmse: 1.49469\tvalid_1's rmse: 1.55356\n",
      "[1800]\ttraining's rmse: 1.49145\tvalid_1's rmse: 1.5536\n",
      "[1900]\ttraining's rmse: 1.48839\tvalid_1's rmse: 1.55364\n",
      "[2000]\ttraining's rmse: 1.48531\tvalid_1's rmse: 1.55359\n",
      "[2100]\ttraining's rmse: 1.48222\tvalid_1's rmse: 1.55363\n",
      "[2200]\ttraining's rmse: 1.47913\tvalid_1's rmse: 1.55356\n",
      "[2300]\ttraining's rmse: 1.47615\tvalid_1's rmse: 1.55363\n",
      "[2400]\ttraining's rmse: 1.47327\tvalid_1's rmse: 1.55373\n",
      "[2500]\ttraining's rmse: 1.47042\tvalid_1's rmse: 1.55387\n",
      "[2600]\ttraining's rmse: 1.46751\tvalid_1's rmse: 1.55386\n",
      "[2700]\ttraining's rmse: 1.46465\tvalid_1's rmse: 1.55387\n",
      "[2800]\ttraining's rmse: 1.46176\tvalid_1's rmse: 1.55392\n",
      "Early stopping, best iteration is:\n",
      "[2213]\ttraining's rmse: 1.47878\tvalid_1's rmse: 1.55351\n",
      "fold 2 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60082\tvalid_1's rmse: 1.62338\n",
      "[200]\ttraining's rmse: 1.56821\tvalid_1's rmse: 1.59404\n",
      "[300]\ttraining's rmse: 1.55327\tvalid_1's rmse: 1.58282\n",
      "[400]\ttraining's rmse: 1.54404\tvalid_1's rmse: 1.57735\n",
      "[500]\ttraining's rmse: 1.53718\tvalid_1's rmse: 1.57424\n",
      "[600]\ttraining's rmse: 1.53167\tvalid_1's rmse: 1.57223\n",
      "[700]\ttraining's rmse: 1.52686\tvalid_1's rmse: 1.571\n",
      "[800]\ttraining's rmse: 1.52269\tvalid_1's rmse: 1.57013\n",
      "[900]\ttraining's rmse: 1.51877\tvalid_1's rmse: 1.56973\n",
      "[1000]\ttraining's rmse: 1.51507\tvalid_1's rmse: 1.56936\n",
      "[1100]\ttraining's rmse: 1.51162\tvalid_1's rmse: 1.56915\n",
      "[1200]\ttraining's rmse: 1.50817\tvalid_1's rmse: 1.56886\n",
      "[1300]\ttraining's rmse: 1.50476\tvalid_1's rmse: 1.56857\n",
      "[1400]\ttraining's rmse: 1.50149\tvalid_1's rmse: 1.56847\n",
      "[1500]\ttraining's rmse: 1.49841\tvalid_1's rmse: 1.56844\n",
      "[1600]\ttraining's rmse: 1.49522\tvalid_1's rmse: 1.56833\n",
      "[1700]\ttraining's rmse: 1.49218\tvalid_1's rmse: 1.56811\n",
      "[1800]\ttraining's rmse: 1.4892\tvalid_1's rmse: 1.56806\n",
      "[1900]\ttraining's rmse: 1.48609\tvalid_1's rmse: 1.5679\n",
      "[2000]\ttraining's rmse: 1.48303\tvalid_1's rmse: 1.56774\n",
      "[2100]\ttraining's rmse: 1.48006\tvalid_1's rmse: 1.56765\n",
      "[2200]\ttraining's rmse: 1.47722\tvalid_1's rmse: 1.56762\n",
      "[2300]\ttraining's rmse: 1.4743\tvalid_1's rmse: 1.56758\n",
      "[2400]\ttraining's rmse: 1.47134\tvalid_1's rmse: 1.56756\n",
      "[2500]\ttraining's rmse: 1.46845\tvalid_1's rmse: 1.56747\n",
      "[2600]\ttraining's rmse: 1.46552\tvalid_1's rmse: 1.56744\n",
      "[2700]\ttraining's rmse: 1.46267\tvalid_1's rmse: 1.56739\n",
      "[2800]\ttraining's rmse: 1.45991\tvalid_1's rmse: 1.56744\n",
      "[2900]\ttraining's rmse: 1.45704\tvalid_1's rmse: 1.56738\n",
      "[3000]\ttraining's rmse: 1.45423\tvalid_1's rmse: 1.56736\n",
      "[3100]\ttraining's rmse: 1.4515\tvalid_1's rmse: 1.56738\n",
      "[3200]\ttraining's rmse: 1.44876\tvalid_1's rmse: 1.5675\n",
      "[3300]\ttraining's rmse: 1.44604\tvalid_1's rmse: 1.56756\n",
      "[3400]\ttraining's rmse: 1.44344\tvalid_1's rmse: 1.56754\n",
      "[3500]\ttraining's rmse: 1.44077\tvalid_1's rmse: 1.56765\n",
      "Early stopping, best iteration is:\n",
      "[2944]\ttraining's rmse: 1.45574\tvalid_1's rmse: 1.56733\n",
      "fold 3 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60082\tvalid_1's rmse: 1.61964\n",
      "[200]\ttraining's rmse: 1.56814\tvalid_1's rmse: 1.59226\n",
      "[300]\ttraining's rmse: 1.55342\tvalid_1's rmse: 1.58181\n",
      "[400]\ttraining's rmse: 1.54415\tvalid_1's rmse: 1.57625\n",
      "[500]\ttraining's rmse: 1.53732\tvalid_1's rmse: 1.57314\n",
      "[600]\ttraining's rmse: 1.53177\tvalid_1's rmse: 1.57127\n",
      "[700]\ttraining's rmse: 1.52704\tvalid_1's rmse: 1.57013\n",
      "[800]\ttraining's rmse: 1.52292\tvalid_1's rmse: 1.56945\n",
      "[900]\ttraining's rmse: 1.51896\tvalid_1's rmse: 1.56895\n",
      "[1000]\ttraining's rmse: 1.51516\tvalid_1's rmse: 1.56859\n",
      "[1100]\ttraining's rmse: 1.51161\tvalid_1's rmse: 1.56823\n",
      "[1200]\ttraining's rmse: 1.50823\tvalid_1's rmse: 1.56803\n",
      "[1300]\ttraining's rmse: 1.50489\tvalid_1's rmse: 1.56775\n",
      "[1400]\ttraining's rmse: 1.50165\tvalid_1's rmse: 1.56767\n",
      "[1500]\ttraining's rmse: 1.49845\tvalid_1's rmse: 1.56779\n",
      "[1600]\ttraining's rmse: 1.49526\tvalid_1's rmse: 1.56776\n",
      "[1700]\ttraining's rmse: 1.49213\tvalid_1's rmse: 1.56776\n",
      "[1800]\ttraining's rmse: 1.48902\tvalid_1's rmse: 1.56764\n",
      "[1900]\ttraining's rmse: 1.48595\tvalid_1's rmse: 1.56763\n",
      "[2000]\ttraining's rmse: 1.48289\tvalid_1's rmse: 1.56761\n",
      "[2100]\ttraining's rmse: 1.47995\tvalid_1's rmse: 1.56766\n",
      "[2200]\ttraining's rmse: 1.47694\tvalid_1's rmse: 1.56784\n",
      "[2300]\ttraining's rmse: 1.47398\tvalid_1's rmse: 1.56787\n",
      "[2400]\ttraining's rmse: 1.47111\tvalid_1's rmse: 1.56794\n",
      "[2500]\ttraining's rmse: 1.46822\tvalid_1's rmse: 1.568\n",
      "Early stopping, best iteration is:\n",
      "[1946]\ttraining's rmse: 1.48451\tvalid_1's rmse: 1.56752\n",
      "fold 4 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60426\tvalid_1's rmse: 1.591\n",
      "[200]\ttraining's rmse: 1.57167\tvalid_1's rmse: 1.56184\n",
      "[300]\ttraining's rmse: 1.55682\tvalid_1's rmse: 1.55055\n",
      "[400]\ttraining's rmse: 1.54743\tvalid_1's rmse: 1.54512\n",
      "[500]\ttraining's rmse: 1.54065\tvalid_1's rmse: 1.54248\n",
      "[600]\ttraining's rmse: 1.53515\tvalid_1's rmse: 1.54102\n",
      "[700]\ttraining's rmse: 1.53044\tvalid_1's rmse: 1.54018\n",
      "[800]\ttraining's rmse: 1.5261\tvalid_1's rmse: 1.53971\n",
      "[900]\ttraining's rmse: 1.52221\tvalid_1's rmse: 1.53943\n",
      "[1000]\ttraining's rmse: 1.51845\tvalid_1's rmse: 1.53937\n",
      "[1100]\ttraining's rmse: 1.5149\tvalid_1's rmse: 1.53912\n",
      "[1200]\ttraining's rmse: 1.51151\tvalid_1's rmse: 1.53899\n",
      "[1300]\ttraining's rmse: 1.50836\tvalid_1's rmse: 1.5389\n",
      "[1400]\ttraining's rmse: 1.5052\tvalid_1's rmse: 1.53888\n",
      "[1500]\ttraining's rmse: 1.50197\tvalid_1's rmse: 1.53882\n",
      "[1600]\ttraining's rmse: 1.49878\tvalid_1's rmse: 1.53874\n",
      "[1700]\ttraining's rmse: 1.49573\tvalid_1's rmse: 1.53879\n",
      "[1800]\ttraining's rmse: 1.49263\tvalid_1's rmse: 1.53866\n",
      "[1900]\ttraining's rmse: 1.48956\tvalid_1's rmse: 1.53851\n",
      "[2000]\ttraining's rmse: 1.48655\tvalid_1's rmse: 1.53834\n",
      "[2100]\ttraining's rmse: 1.48339\tvalid_1's rmse: 1.53816\n",
      "[2200]\ttraining's rmse: 1.48032\tvalid_1's rmse: 1.53802\n",
      "[2300]\ttraining's rmse: 1.47744\tvalid_1's rmse: 1.53803\n",
      "[2400]\ttraining's rmse: 1.47441\tvalid_1's rmse: 1.53806\n",
      "[2500]\ttraining's rmse: 1.47154\tvalid_1's rmse: 1.53802\n",
      "[2600]\ttraining's rmse: 1.46873\tvalid_1's rmse: 1.53786\n",
      "[2700]\ttraining's rmse: 1.46591\tvalid_1's rmse: 1.5379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2800]\ttraining's rmse: 1.46302\tvalid_1's rmse: 1.53793\n",
      "[2900]\ttraining's rmse: 1.46025\tvalid_1's rmse: 1.53795\n",
      "[3000]\ttraining's rmse: 1.45739\tvalid_1's rmse: 1.53793\n",
      "[3100]\ttraining's rmse: 1.45451\tvalid_1's rmse: 1.53786\n",
      "[3200]\ttraining's rmse: 1.45178\tvalid_1's rmse: 1.53794\n",
      "Early stopping, best iteration is:\n",
      "[2651]\ttraining's rmse: 1.46729\tvalid_1's rmse: 1.53783\n",
      "fold 5 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60327\tvalid_1's rmse: 1.59674\n",
      "[200]\ttraining's rmse: 1.57042\tvalid_1's rmse: 1.57\n",
      "[300]\ttraining's rmse: 1.55534\tvalid_1's rmse: 1.56047\n",
      "[400]\ttraining's rmse: 1.54604\tvalid_1's rmse: 1.55619\n",
      "[500]\ttraining's rmse: 1.53922\tvalid_1's rmse: 1.55404\n",
      "[600]\ttraining's rmse: 1.53367\tvalid_1's rmse: 1.55301\n",
      "[700]\ttraining's rmse: 1.52896\tvalid_1's rmse: 1.55252\n",
      "[800]\ttraining's rmse: 1.52471\tvalid_1's rmse: 1.55204\n",
      "[900]\ttraining's rmse: 1.52077\tvalid_1's rmse: 1.55184\n",
      "[1000]\ttraining's rmse: 1.51708\tvalid_1's rmse: 1.55183\n",
      "[1100]\ttraining's rmse: 1.51346\tvalid_1's rmse: 1.55173\n",
      "[1200]\ttraining's rmse: 1.51012\tvalid_1's rmse: 1.55169\n",
      "[1300]\ttraining's rmse: 1.50686\tvalid_1's rmse: 1.55167\n",
      "[1400]\ttraining's rmse: 1.50341\tvalid_1's rmse: 1.55174\n",
      "[1500]\ttraining's rmse: 1.50016\tvalid_1's rmse: 1.55178\n",
      "[1600]\ttraining's rmse: 1.49701\tvalid_1's rmse: 1.55187\n",
      "[1700]\ttraining's rmse: 1.49385\tvalid_1's rmse: 1.5518\n",
      "[1800]\ttraining's rmse: 1.4906\tvalid_1's rmse: 1.55202\n",
      "[1900]\ttraining's rmse: 1.48751\tvalid_1's rmse: 1.55211\n",
      "Early stopping, best iteration is:\n",
      "[1317]\ttraining's rmse: 1.50626\tvalid_1's rmse: 1.55162\n",
      "fold 6 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60259\tvalid_1's rmse: 1.60608\n",
      "[200]\ttraining's rmse: 1.56994\tvalid_1's rmse: 1.57725\n",
      "[300]\ttraining's rmse: 1.5551\tvalid_1's rmse: 1.56612\n",
      "[400]\ttraining's rmse: 1.54587\tvalid_1's rmse: 1.56069\n",
      "[500]\ttraining's rmse: 1.53902\tvalid_1's rmse: 1.55775\n",
      "[600]\ttraining's rmse: 1.53359\tvalid_1's rmse: 1.55601\n",
      "[700]\ttraining's rmse: 1.52882\tvalid_1's rmse: 1.55494\n",
      "[800]\ttraining's rmse: 1.5246\tvalid_1's rmse: 1.55421\n",
      "[900]\ttraining's rmse: 1.5208\tvalid_1's rmse: 1.55373\n",
      "[1000]\ttraining's rmse: 1.5172\tvalid_1's rmse: 1.55344\n",
      "[1100]\ttraining's rmse: 1.51367\tvalid_1's rmse: 1.55328\n",
      "[1200]\ttraining's rmse: 1.51019\tvalid_1's rmse: 1.55321\n",
      "[1300]\ttraining's rmse: 1.50688\tvalid_1's rmse: 1.55303\n",
      "[1400]\ttraining's rmse: 1.50363\tvalid_1's rmse: 1.55289\n",
      "[1500]\ttraining's rmse: 1.50036\tvalid_1's rmse: 1.55278\n",
      "[1600]\ttraining's rmse: 1.49712\tvalid_1's rmse: 1.55272\n",
      "[1700]\ttraining's rmse: 1.49387\tvalid_1's rmse: 1.55283\n",
      "[1800]\ttraining's rmse: 1.49073\tvalid_1's rmse: 1.55264\n",
      "[1900]\ttraining's rmse: 1.4875\tvalid_1's rmse: 1.55264\n",
      "[2000]\ttraining's rmse: 1.48446\tvalid_1's rmse: 1.5527\n",
      "[2100]\ttraining's rmse: 1.4814\tvalid_1's rmse: 1.55284\n",
      "[2200]\ttraining's rmse: 1.47843\tvalid_1's rmse: 1.55278\n",
      "[2300]\ttraining's rmse: 1.47546\tvalid_1's rmse: 1.55276\n",
      "[2400]\ttraining's rmse: 1.47253\tvalid_1's rmse: 1.55292\n",
      "Early stopping, best iteration is:\n",
      "[1854]\ttraining's rmse: 1.48901\tvalid_1's rmse: 1.55257\n",
      "fold 7 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60253\tvalid_1's rmse: 1.60772\n",
      "[200]\ttraining's rmse: 1.57013\tvalid_1's rmse: 1.57671\n",
      "[300]\ttraining's rmse: 1.55539\tvalid_1's rmse: 1.56452\n",
      "[400]\ttraining's rmse: 1.54622\tvalid_1's rmse: 1.5584\n",
      "[500]\ttraining's rmse: 1.53949\tvalid_1's rmse: 1.55492\n",
      "[600]\ttraining's rmse: 1.53403\tvalid_1's rmse: 1.5528\n",
      "[700]\ttraining's rmse: 1.52935\tvalid_1's rmse: 1.5516\n",
      "[800]\ttraining's rmse: 1.52517\tvalid_1's rmse: 1.55078\n",
      "[900]\ttraining's rmse: 1.52126\tvalid_1's rmse: 1.55024\n",
      "[1000]\ttraining's rmse: 1.51771\tvalid_1's rmse: 1.54992\n",
      "[1100]\ttraining's rmse: 1.51431\tvalid_1's rmse: 1.54966\n",
      "[1200]\ttraining's rmse: 1.51095\tvalid_1's rmse: 1.54938\n",
      "[1300]\ttraining's rmse: 1.50769\tvalid_1's rmse: 1.54915\n",
      "[1400]\ttraining's rmse: 1.50448\tvalid_1's rmse: 1.54905\n",
      "[1500]\ttraining's rmse: 1.50131\tvalid_1's rmse: 1.54891\n",
      "[1600]\ttraining's rmse: 1.49811\tvalid_1's rmse: 1.54889\n",
      "[1700]\ttraining's rmse: 1.49505\tvalid_1's rmse: 1.54888\n",
      "[1800]\ttraining's rmse: 1.49186\tvalid_1's rmse: 1.54879\n",
      "[1900]\ttraining's rmse: 1.48885\tvalid_1's rmse: 1.5487\n",
      "[2000]\ttraining's rmse: 1.48581\tvalid_1's rmse: 1.54856\n",
      "[2100]\ttraining's rmse: 1.48291\tvalid_1's rmse: 1.5483\n",
      "[2200]\ttraining's rmse: 1.47999\tvalid_1's rmse: 1.54838\n",
      "[2300]\ttraining's rmse: 1.47694\tvalid_1's rmse: 1.54825\n",
      "[2400]\ttraining's rmse: 1.47393\tvalid_1's rmse: 1.54817\n",
      "[2500]\ttraining's rmse: 1.47105\tvalid_1's rmse: 1.5482\n",
      "[2600]\ttraining's rmse: 1.46818\tvalid_1's rmse: 1.54821\n",
      "[2700]\ttraining's rmse: 1.4654\tvalid_1's rmse: 1.54815\n",
      "[2800]\ttraining's rmse: 1.4625\tvalid_1's rmse: 1.5482\n",
      "[2900]\ttraining's rmse: 1.45972\tvalid_1's rmse: 1.54819\n",
      "[3000]\ttraining's rmse: 1.45701\tvalid_1's rmse: 1.54824\n",
      "Early stopping, best iteration is:\n",
      "[2439]\ttraining's rmse: 1.47283\tvalid_1's rmse: 1.54812\n",
      "fold 8 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.59897\tvalid_1's rmse: 1.63805\n",
      "[200]\ttraining's rmse: 1.56636\tvalid_1's rmse: 1.60924\n",
      "[300]\ttraining's rmse: 1.55164\tvalid_1's rmse: 1.59853\n",
      "[400]\ttraining's rmse: 1.54244\tvalid_1's rmse: 1.59338\n",
      "[500]\ttraining's rmse: 1.53569\tvalid_1's rmse: 1.5903\n",
      "[600]\ttraining's rmse: 1.53028\tvalid_1's rmse: 1.5884\n",
      "[700]\ttraining's rmse: 1.52571\tvalid_1's rmse: 1.58721\n",
      "[800]\ttraining's rmse: 1.52152\tvalid_1's rmse: 1.58624\n",
      "[900]\ttraining's rmse: 1.51768\tvalid_1's rmse: 1.58569\n",
      "[1000]\ttraining's rmse: 1.51409\tvalid_1's rmse: 1.5852\n",
      "[1100]\ttraining's rmse: 1.51064\tvalid_1's rmse: 1.58487\n",
      "[1200]\ttraining's rmse: 1.50726\tvalid_1's rmse: 1.58455\n",
      "[1300]\ttraining's rmse: 1.504\tvalid_1's rmse: 1.58431\n",
      "[1400]\ttraining's rmse: 1.50064\tvalid_1's rmse: 1.58413\n",
      "[1500]\ttraining's rmse: 1.4975\tvalid_1's rmse: 1.58395\n",
      "[1600]\ttraining's rmse: 1.49425\tvalid_1's rmse: 1.58381\n",
      "[1700]\ttraining's rmse: 1.49116\tvalid_1's rmse: 1.58381\n",
      "[1800]\ttraining's rmse: 1.48815\tvalid_1's rmse: 1.58379\n",
      "[1900]\ttraining's rmse: 1.4851\tvalid_1's rmse: 1.58373\n",
      "[2000]\ttraining's rmse: 1.48201\tvalid_1's rmse: 1.58378\n",
      "[2100]\ttraining's rmse: 1.479\tvalid_1's rmse: 1.58368\n",
      "[2200]\ttraining's rmse: 1.47603\tvalid_1's rmse: 1.58356\n",
      "[2300]\ttraining's rmse: 1.47305\tvalid_1's rmse: 1.58359\n",
      "[2400]\ttraining's rmse: 1.47005\tvalid_1's rmse: 1.58356\n",
      "[2500]\ttraining's rmse: 1.46702\tvalid_1's rmse: 1.58353\n",
      "[2600]\ttraining's rmse: 1.46415\tvalid_1's rmse: 1.58341\n",
      "[2700]\ttraining's rmse: 1.46121\tvalid_1's rmse: 1.5834\n",
      "[2800]\ttraining's rmse: 1.45826\tvalid_1's rmse: 1.58348\n",
      "[2900]\ttraining's rmse: 1.45549\tvalid_1's rmse: 1.5836\n",
      "[3000]\ttraining's rmse: 1.45278\tvalid_1's rmse: 1.58363\n",
      "[3100]\ttraining's rmse: 1.45006\tvalid_1's rmse: 1.5837\n",
      "[3200]\ttraining's rmse: 1.44725\tvalid_1's rmse: 1.58358\n",
      "Early stopping, best iteration is:\n",
      "[2677]\ttraining's rmse: 1.46179\tvalid_1's rmse: 1.58335\n",
      "fold 9 0 0.0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60409\tvalid_1's rmse: 1.58812\n",
      "[200]\ttraining's rmse: 1.57121\tvalid_1's rmse: 1.56249\n",
      "[300]\ttraining's rmse: 1.55625\tvalid_1's rmse: 1.55342\n",
      "[400]\ttraining's rmse: 1.54692\tvalid_1's rmse: 1.549\n",
      "[500]\ttraining's rmse: 1.54016\tvalid_1's rmse: 1.54692\n",
      "[600]\ttraining's rmse: 1.53468\tvalid_1's rmse: 1.54555\n",
      "[700]\ttraining's rmse: 1.52995\tvalid_1's rmse: 1.54492\n",
      "[800]\ttraining's rmse: 1.52588\tvalid_1's rmse: 1.5447\n",
      "[900]\ttraining's rmse: 1.52198\tvalid_1's rmse: 1.54461\n",
      "[1000]\ttraining's rmse: 1.51836\tvalid_1's rmse: 1.54461\n",
      "[1100]\ttraining's rmse: 1.5148\tvalid_1's rmse: 1.54458\n",
      "[1200]\ttraining's rmse: 1.51129\tvalid_1's rmse: 1.54463\n",
      "[1300]\ttraining's rmse: 1.50797\tvalid_1's rmse: 1.54462\n",
      "[1400]\ttraining's rmse: 1.50467\tvalid_1's rmse: 1.54466\n",
      "[1500]\ttraining's rmse: 1.50141\tvalid_1's rmse: 1.54469\n",
      "[1600]\ttraining's rmse: 1.4983\tvalid_1's rmse: 1.54473\n",
      "[1700]\ttraining's rmse: 1.49519\tvalid_1's rmse: 1.54482\n",
      "[1800]\ttraining's rmse: 1.49206\tvalid_1's rmse: 1.54491\n",
      "Early stopping, best iteration is:\n",
      "[1258]\ttraining's rmse: 1.50933\tvalid_1's rmse: 1.54452\n"
     ]
    }
   ],
   "source": [
    "feat_names=['feats','feats1','feats2','feats3']\n",
    "df_all=pd.DataFrame()\n",
    "for fold in [5,6,7,8,9,10]:\n",
    "    df_total=pd.DataFrame()\n",
    "    for feat in [feats,feats1,feats2,feats3]:\n",
    "        df=regression(df_train[df_train.outliers==0],df_test[df_test.outliers==0],fold,feat)\n",
    "        df['feats']=feat_names[[feats,feats1,feats2,feats3].index(feat)] # indicate feat\n",
    "        df_total=pd.concat([df_total,df],axis=0) # data frame for each feat\n",
    "    df_total['num_folds']=fold # indicate fold number\n",
    "    df_all=pd.concat([df_all,df_total],axis=0) # data frame for each fold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all2=df_all.groupby(['num_folds','feats']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2875fd79828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(5,11):\n",
    "    df=df_all2.loc[i]\n",
    "    #df_err=df_all3.loc[i]\n",
    "    plt.scatter(df.cv_error,df.test_error+(i-5)*0.001,linestyle='-',marker='o',label=i)\n",
    "    #plt.errorbar(df.ave_cv_error,df.ave_test_error,xerr=df_err.cv_error)\n",
    "    plt.ylabel('Test rmse')\n",
    "    plt.xlabel('CV rmse')\n",
    "    plt.legend()\n",
    "    plt.xlim([1.550,1.560])\n",
    "    plt.ylim([1.542,1.554])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEKCAYAAADJvIhZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3X10VfWd7/H31yQQBAzlyQSiIlQelIIiI2UsilDRFiNq0capS/s03Hrba3RGbJk7UmRuZ5xhZgCla7y09YGlhfE6CI1owSIdMkpxeBDBIlJRa0gwEEp4SoDA9/5xdiAJSTgn55x9kpPPa62snPPbe//Od5PAh733b/+2uTsiIiJhOC/VBYiISMeh0BERkdAodEREJDQKHRERCY1CR0REQqPQERGR0CQtdMzsaTOrMLNtzSwfb2ZVZvZO8DWz0fIMM9tsZq/Ua5tgZpvMbJuZPWdmmcmqX0REEi+ZRzrPAjefY50Sd78y+JrdaFkRsL3ujZmdBzwHFLr7cOAT4L4E1isiIkmWtNBx97XA/tZsa2b5wGTg5/WaewHH3P2D4P3rwNfiKlJEREKV6tNTY81sC1AGPOzu7wXt84BHgO711t0HZJnZaHffAEwFLmquYzObBkwD6Nq169VDhw5NRv0iImlr48aN+9y9TyL7TGXobAIucffDZvZVYBlwmZndAlS4+0YzG1+3sru7mRUCc82sM7AKqG2uc3dfCCwEGD16tG/YsCGJuyIikn7M7JNE95my0WvuftDdDwevXyVyFNMbuBa41cw+BpYAE8zs+WC9de4+zt2vAdYCO1NTvYiItEbKQsfMcs3MgtfXBLVUuvsMd8939wFAIfCGu98TrNc3+N4Z+CHwVEqKFxGRVkna6TUzWwyMB3qbWSnwYyALwN2fInJN5n4zqwWqiYxKO9eU19OD02/nAf/m7m8kq34REUk86wiPNtA1HRFJphMnTlBaWkpNTU2qS2mV7Oxs8vPzycrKatBuZhvdfXQiPyvVo9dERNq90tJSunfvzoABAwiuGrQb7k5lZSWlpaVceumlSf88TYMjIhKnmpoaevXq1e4CB8DM6NWrV2hHaQodEZEEaI+BUyfM2hU6IiISGl3TERFJEwMGDKB79+5kZGSQmZlJWxxApdAREUkja9asoXfv3qkuo1kKHRGRkC3bvJs5K3dQdqCafj26MP2mIdx2Vf9UlxUKXdMREQnRss27mbF0K7sPVOPA7gPVzFi6lWWbd8fdt5kxadIkrr76ahYuXBh/sUmgIx0RkRDNWbmD6hMnG7RVnzjJnJU74j7aefPNN+nXrx8VFRXceOONDB06lOuuuy6uPhNNRzoiIiEqO1AdU3ss+vXrB0Dfvn25/fbbefvtt+PuM9EUOiIiIerXo0tM7dE6cuQIhw4dOv161apVDB8+PK4+k0GhIyISouk3DaFLVkaDti5ZGUy/aUhc/X722Wd86UtfYuTIkVxzzTVMnjyZm2++Oa4+k0HXdEREQlR33SbRo9cGDhzIli1bElFiUil0RERCdttV/TvMEOnGdHpNRERCo9AREZHQKHRERCQ0Ch0REQmNQkdEREKj0BERSRMHDhxg6tSpDB06lGHDhrFu3bpUl3QWDZkWEUkTRUVF3Hzzzbz00kscP36co0ePprqksyh0RETC9u6LsHo2VJVCTj5MnAkj7oqry4MHD7J27VqeffZZADp16kSnTp0SUGxi6fSaiEiY3n0Rih+Aqk8Bj3wvfiDSHoddu3bRp08fvvWtb3HVVVfx3e9+lyNHjiSm5gRS6IiIhGn1bDjRaEbpE9WR9jjU1tayadMm7r//fjZv3kzXrl15/PHH4+ozGRQ6IiJhqiqNrT1K+fn55OfnM2bMGACmTp3Kpk2b4uozGRQ6IiJhysmPrT1Kubm5XHTRRezYsQOA1atXc/nll8fVZzJoIIGISJgmzoxcw6l/ii2rS6Q9Tk8++STf+MY3OH78OAMHDuSZZ56Ju89ES1romNnTwC1Ahbuf9SQhMxsPLAc+CpqWuvvsesszgA3Abne/JWibCMwhcoR2GPimu/8hWfsgIpJwdaPUEjx6DeDKK69kw4YNcfeTTMk80nkWWAAsamGdkrpAaUIRsB24oF7bvwFT3H27mf1P4G+Bb8ZfqohIiEbclZCQaY+Sdk3H3dcC+1uzrZnlA5OBnzfuljMhlAOUtbpAEREJXaqv6Yw1sy1EwuNhd38vaJ8HPAJ0b7T+d4FXzawaOAh8MbRKRUQkbqkcvbYJuMTdRwJPAssAzKzuOtDGJrZ5CPiqu+cDzwD/2lznZjbNzDaY2Ya9e/cmvnoREYlZykLH3Q+6++Hg9atAlpn1Bq4FbjWzj4ElwAQze97M+gAj3X190MW/A3/eQv8L3X20u4/u06dPUvdFRESik7LQMbNcM7Pg9TVBLZXuPsPd8919AFAIvOHu9wB/AnLMbHDQxY1EBhqIiEg7kcwh04uB8UBvMysFfgxkAbj7U8BU4H4zqwWqgUJ39+b6c/daM/tL4D/M7BSREPp2suoXEWlPduzYwde//vXT73ft2sXs2bN58MEHU1jV2ZIWOu5+9zmWLyAypLqldX4L/Lbe+5eBlxNQnohIWhkyZAjvvPMOACdPnqR///7cfvvtKa7qbJoGR0QkZCt2rWDSS5MY8dwIJr00iRW7ViS0/9WrVzNo0CAuueSShPabCKkeMi0i0qGs2LWCWW/NouZkDQDlR8qZ9dYsACYPnJyQz1iyZAl3393iyaaU0ZGOiEiI5m+afzpw6tScrGH+pvkJ6f/48eP86le/4s4770xIf4mm0BERCdGeI3tiao/Va6+9xqhRo7jwwgsT0l+iKXREREKU2zU3pvZYLV68uM2eWgOFjohIqIpGFZGdkd2gLTsjm6JRRXH3ffToUV5//XXuuOOOuPtKFg0kEBEJUd1ggfmb5rPnyB5yu+ZSNKooIYMIzj//fCorK+PuJ5kUOiIiIZs8cHLCRqq1Nzq9JiIioVHoiIhIaBQ6IiISGoWOiIiERqEjIiKhUeiIiKSJuXPncsUVVzB8+HDuvvtuampqzr1RyBQ6IiJpYPfu3TzxxBNs2LCBbdu2cfLkSZYsWZLqss6i0BERCVlVcTE7J0xk+7DL2TlhIlXFxQnpt7a2lurqamprazl69Cj9+vVLSL+JpNAREQlRVXEx5Y/OpLasDNypLSuj/NGZcQdP//79efjhh7n44ovJy8sjJyeHSZMmJajqxFHoiIiEqGLuPLzRtRavqaFi7ry4+v3Tn/7E8uXL+eijjygrK+PIkSM8//zzcfWZDAodEZEQ1ZaXx9Qerd/85jdceuml9OnTh6ysLO644w7eeuutuPpMBoWOiEiIMvPyYmqP1sUXX8zvfvc7jh49iruzevVqhg0bFlefyaDQEREJUd+HHsSyGz7awLKz6fvQg3H1O2bMGKZOncqoUaP4whe+wKlTp5g2bVpcfSaDZpkWEQlRTkEBELm2U1teTmZeHn0fevB0ezwee+wxHnvssbj7SSaFjohIyHIKChISMu2RTq+JiEhoFDoiIhIahY6IiIRGoSMiIqFR6IiISGiSFjpm9rSZVZjZtmaWjzezKjN7J/ia2Wh5hpltNrNX6rWV1Fu/zMyWJat+EZH2Zv78+QwfPpwrrriCefPim1YnWZJ5pPMscPM51ilx9yuDr9mNlhUB2+s3uPu4uvWBdcDShFUrItKObdu2jZ/97Ge8/fbbbNmyhVdeeYWdO3emuqyzJC103H0tsL8125pZPjAZ+Hkzy7sDEwAd6YhIu/PB+j089zdv8tPvvcFzf/MmH6zfE3ef27dv54tf/CLnn38+mZmZXH/99bz88ssJqDaxUn1NZ6yZbTGz18zsinrt84BHgFPNbHc7sNrdDzbXsZlNM7MNZrZh7969CSxZRKT1Pli/hzUvvM/h/ccAOLz/GGteeD/u4Bk+fDhr166lsrKSo0eP8uqrr/Lpp58mouSESmXobAIucfeRwJMERy1mdgtQ4e4bW9j2bmBxS527+0J3H+3uo/v06ZOomkVE4rJu+YfUHm/4/+na46dYt/zDuPodNmwYP/zhD7nxxhu5+eabGTlyJJmZbW/SmZSFjrsfdPfDwetXgSwz6w1cC9xqZh8DS4AJZnb6oRBm1gu4BlgRftUiIvGpO8KJtj0W3/nOd9i0aRNr166lZ8+eXHbZZXH3mWgpCx0zyzUzC15fE9RS6e4z3D3f3QcAhcAb7n5PvU3vBF5x95qzOhURaeO69ewcU3ssKioqAPjjH//I0qVLufvuu+PuM9GSduxlZouB8UBvMysFfgxkAbj7U8BU4H4zqwWqgUJ39yi6LgQeT0rRIiJJNnbKINa88H6DU2yZnc5j7JRBcff9ta99jcrKSrKysvjpT3/K5z73ubj7TLSkhY67txix7r4AWHCOdX4L/LZR2/g4SxMRSZnBY3KByLWdw/uP0a1nZ8ZOGXS6PR4lJSVx95Fsbe8qk4hImhs8JjchIdMepXrItIiIdCAKHRERCY1Or4lIWlm2eTdzVu6g7EA1/Xp0YfpNQ7jtqv6pLksCCh0RSRvLNu9mxtKtVJ84CcDuA9XMWLoVQMHTRuj0moikjTkrd5wOnDrVJ04yZ+WOFFUkjSl0RCRtlB2ojqk9nXz729+mb9++DB8+/HTb/v37ufHGG7nsssu48cYb+dOf/pTCCiMUOiKSNvr16BJTezr55je/ya9//esGbY8//jgTJ05k586dTJw4kccfT/199ecMHTP7vJmtNLMtwfsRZjYj+aWJiMRm+k1D6JKV0aCtS1YG028akqKKmra9ZA0Lv/8t/qWwgIXf/xbbS9bE3ed1111Hz549G7QtX76c++67D4D77ruPZctS/zSYaI50fg48xpnHDGwF7ml+dRGR1Ljtqv78wx1foH+PLhjQv0cX/uGOL0Q/iODdF2HucJjVI/L93RcTXuP2kjWsWriAQ/v2gjuH9u1l1cIFCQmexj777DPy8vIAyMvLOz03WypFM3qtq7u/FczNibu7mZ1IblkiIq1z21X9WzdS7d0XofgBOBFc/6n6NPIeYMRdCauvZMkiao83nFG69vgxSpYsYti4GxL2OW1VNEc6lWZ2KeAAZnYbEP9j7kRE2pLVs88ETp0T1ZH2BDpUuS+m9nhceOGFlJeXA1BeXk7fvn0T/hmxiiZ0fgD8AhhqZp8APwLuT2pVIiJhqyqNrb2VuvfqHVN7PG699Vaee+45AJ577jmmTJmS8M+I1TlDx93/4O4TgDxgpLt/0d0/Sn5pIiIhysmPrb2VxhXeS2anhs/OyezUmXGF98bV7913383YsWPZsWMH+fn5/OIXv+BHP/oRr7/+Opdddhmvv/46P/rRj+L6jEQ45zUdM/sBsMjdq8zsKTMbBcxw99XJL09EJCQTZza8pgOQ1SXSnkB1121KliziUOU+uvfqzbjCe+O+nrN48eIm21evblv/VEczkGCauy8ws0lAPpFTawuBq5NamYhImOoGC6yeHTmllpMfCZwEDiKoM2zcDR1i0EBTogmduqd5fgV4xt03mpluKhWR9DPirqSEjJwRTXhsMbNXgQLgNTPrxpkgEhERwL39/rMYZu3RHOl8i8iptD+4+1Ez6w18J7lliYi0H9nZ2VRWVtKrVy/q7mlsL9ydyspKsrOzQ/m8c4aOu580s8PAF82s/vqbk1eWiEj7kZ+fT2lpKXv37k11Ka2SnZ1Nfn5iR+k1J5rRaz8DRgO/58xUOA78Kol1iYi0G1lZWVx66aWpLqNdiOb02peAy709n7AUEZE2IZrQWQ8MBvQUJBFpUz5Yv4d1yz/k8P5jdOvZmbFTBjF4TG6qy5IWRBM6vwDWm9lu4BhgROb9HJXUykREWvDB+j2seeF9ao9Hzvof3n+MNS+8D6DgacOiCZ2ngW8TeaTBqXOsKyISinXLPzwdOHVqj59i3fIPFTptWDSh86m7L016JSIiMTi8/1hM7dI2RBM6vzezRUAxkdNrALi7Rq+JSMp069m5yYDp1rNzE2tLWxHNjAQ5RK7j3ArcGXxNPddGZva0mVWY2bZmlo83syozeyf4mtloeYaZbTazV+q1mZn9xMw+MLPtZvZAFPWLSIiqiovZOWEi24ddzs4JE6kqLk7K54ydMojMTg3/CcvsdB5jpwxKyudJYrR4pGNmGcB/u/sTrej7WWABsKiFdUrc/ZZmlhUB24EL6rV9E7gIGOrup8ws9U8kEpHTqoqLKX90Jl5TA0BtWRnlj0b+P5lTUJDQz6q7bqPRa+1Li6ETzEZwBxBz6Lj7WjMb0JqizCwfmAz8BPireovuB/7C3U8Fn5H6B36LyGkVc+edDpw6XlPDJ3P+noePPcmeI3vI7ZpL0agiJg+cHPfnDR6Tq5BpZ6I5vfZfZjbfzMaa2Yi6rwR9/lgz22Jmr5nZFfXa5wGPcPZouUHA181sQ7DNZc11bGbTgvU2tNepKUTam9rg0ciNZVYcoPxIOY5TfqScWW/NYsWuFSFXJ21BNKFzPTAK+Cfgp8HXggR89ibgEncfCTwJLAMws1uACnff2MQ2nYEadx8N/IzIcO4muftCdx/t7qP79OmTgHJF5Fwy8/KabN93QcP3NSdrmL9pfggVSVsTzeOqxzXxdV28H+zuB939cPD6VSArmMH6WuBWM/sYWAJMMLPng81Kgf8IXr8MJOqIS0QSoO9DD2KNZiuuyYRfjj975uU9R/aEVZa0ISl7GJuZ5VowB7iZXRPUUunuM9w9390HAIXAG+5+T7DZMmBC8Pp64IOQyxaRFuQUFJD3d7PJ7NcPzMjs148Xb+vJm1dknLVublddi+mIorlPp1XMbDEwHuhtZqXAj4EsAHd/isiw6/vNrBaoBgqjmFT0ceAFM3sIOAx8N0nli0gr5RQUNBip9qVdK/jNW7OoOXlmgEF2RjZFo4pSUZ6kmJ3r33kzy3T32nO1tWWjR4/2DRs2pLoMkQ5rxa4VzN80P+Gj1yS5zGxjcA09YaI50nmbyECCc7WJiDRp8sDJChkBWgid4MbLPKCLmX2ByKwEELlZ8/wQahORdmJ7yRpKliziUOU+uvfqzbjCexk27oZUlyVtUEtHOpOJzC6dT2SYdF3oHAIeTXJdItJObC9Zw6qFC6g9HpkH7dC+vaxaGLmrQsEjjTUbOu7+DPCMmd3l7i+GWJOItCMlSxadDpw6tcePUbJkkUJHzhLNkOm+ZnYBgJk9ZWZvm9nEJNclIu3Eocp9MbVLxxZN6Exz94NmNonIqbb7icxOICJC9169Y2qXji2a0KkbU/0V4JlgepqU3VQqIm3LuMJ7yezU8Bk2mZ06M67w3hRVJG1ZNEOmt5jZq8Bg4H+bWTfOBJGIdHB11200ek2iEc3NoRnA1cAf3H1/MD/aRe6+OYwCE0E3h0p7sGzzbuas3EHZgWr69ejC9JuGcNtV/VNdlnRgybg5NJoJP08CA4lcywHoEs12IhK9ZZt3M2PpVnYfqMaB3QeqmbF0K8s27051aSIJdc7wMLMFwA1A3aSbR4CnklmUSEczZ+UOqk+cbNBWfeIkc1buSFFFIskRzTWdP3f3UWa2GSA4xdYpyXWJdChlB6pjahdpr6I5TXbCzM4jGDxgZr04+4meIhKHfj26xNQu0l41GzpmVncU9FMiD07rY2aPAf8F/GMItYl0GNNvGkKXrIbPnOmSlcH0m4akqCKR5Gjp9NrbwCh3X2RmG4EvE5l/7U533xZKdSIdRN0oNY1ek3TXUuicfr6su78HvJf8ckQ6rtuu6q+QkbTXUuj0MbO/am6hu/9rEuoR6XjefRFWz4aqUsjJh4kzYcRdqa5KJClaCp0MoBv1jnhE0lFKn2r57otQ/ACcCEapVX0aeQ8KHklLLYVOubvPDq0SkRRYsWsFs96aRc3JGgDKj5Qz661ZAOEEz+rZZwKnzonqSLtCR9JQS0OmdYQjaW/+pvmnA6dOzcka5m+aH04BVaWxtYu0cy2Fjp6ZI2lvz5E9MbUnXE5+bO0i7VyzoePu+8MsRCQVcrvmxtSecBNnQlajG0CzukTaRdKQJu6UDq1oVBHZGdkN2rIzsikaVRROASPugoInIOciwCLfC57Q9RxJW9HMvSbS7lQVF1Mxdx615eVk5uXR96EHySkoOGu9usECKRu9BpGAUchIB6HQkbRTVVxM+aMz8ZrIAIHasjLKH42crmoueEINGZEOTKfXJK18sH4PLy07weox/8ybX5zNnr6R5095TQ0Vc+eluDoR0ZGOpI0P1u9hzQvvU5vVA4Bj2b14f8hfAJBbsYHa8vJUliciJPFIx8yeNrMKM2tyclAzG29mVWb2TvA1s9HyDDPbbGav1Gt71sw+qrfNlcmqX9qfdcs/pPZ4w6dunMrozIcDbwUgMy8vFWWJSD3JPNJ5FlgALGphnRJ3v6WZZUXAduCCRu3T3f2l+MuTdHN4/7Em24917ollZ9P3oQdDrkhEGkta6Lj7WjMb0JptzSwfmAz8BGh20lGR+rr17NwgeGqPbae25r/g1CH+c9QQruvRjZxW9Lts8249ckAkQVI9kGCsmW0xs9fM7Ip67fOAR2j6CaU/MbN3zWyumXVurmMzm2ZmG8xsw969exNdt7RBY6cMIrNT5Fe69th2ao++DqcOAXD4yGFWLVzA9pI1MfW5bPNuZizdyu4D1Tiw+0A1M5ZuZdnm3YkuX6RDSGXobAIucfeRwJPAMgAzuwWocPeNTWwzAxgK/BnQE/hhc527+0J3H+3uo/v06ZPw4qXtGTwmlxu+MZRuPTtHjnCobbC89vgxSpa0dLb3bHNW7qD6xMkGbdUnTjJn5Y54yxXpkFIWOu5+0N0PB69fBbLMrDdwLXCrmX0MLAEmmNnzwXrlHnEMeAa4JjXVS1s1eEwu9/39tRD51TrLocp9MfVXdqA6pnYRaVnKQsfMcs3MgtfXBLVUuvsMd8939wFAIfCGu98TrJcXfDfgNkCPzZYmde/VO6b25vTr0SWmdhFpWTKHTC8G1gFDzKzUzL5jZt8zs+8Fq0wFtpnZFuAJoNDd/RzdvmBmW4GtQG/g/ySrfmnfxhXeS2anhpf8Mjt1ZlzhvTH1M/2mIXTJymjQ1iUrg+k3DYm7RpGOyM7973z7N3r0aN+wYUOqy5CQbS9ZQ8mSRRyq3Ef3Xr0ZV3gvw8bdEHM/Gr0mHZWZbXT30QntU6Ej0oJ3X4w8xbOqNPKMm4kzNTmndBjJCB1NgyPSnHdfhOIHzjxOuurTyHtQ8Ii0Uqrv0xFpu1bPPhM4dU5UR9pFpFUUOiLNqSqNrV1EzkmhI9KcnPzY2kXknBQ6Is2ZOBOyGt2Pk9Ul0i4iraLQEWnOiLug4AnIuQiwyPeCJzSIQCQOGr0mcftg/R7WLf+Qw/uP0a1nZ8ZOGcTgMbmpLisxRtylkBFJIB3pSFzqntZZ90iBw/uPseaF9/lg/Z6Y+qkqLmbnhIlsH3Y5OydMpKq4OBnlikiKKXQkLk09rbP2+CnWLf8w6j6qiospf3QmtWVl4E5tWRm7ZjzCjL+9lhW7ViS6ZBFJIZ1ek7g097TO5tqbUjF3Hl5T06Atuxa+smo/fz10FgCTB05udY0i0nboSEfi0q1n08/Ra669KbXl5U229zoINSdrmL9pfqtqE5G2R6Ejcan/tM46mZ3OY+yUQVH3kZmX12R75QWR73uOxHZ9SETaLoWOxKX+0zohcoRzwzeGxjR6re9DD2LZ2Q3aajLhl+MNgNyuaTISTkR0TUfiN3hMblxDpHMKCgD4ZM7fk1lxgH0XRALnzSsyyM7IpmhUUaJKFZEUU+hIm5BTUMCIggJW7FrB/E3z2XNkD3ldcykaVaRBBCJpRKEjbcrkgZMVMiJpTNd0REQkNDrSkdAl6jHSItL+KHQkVNtL1rBq4QJqj0duHj20by+rFi4AUPCIdAA6vSahKlmy6HTg1Kk9foySJYtSVJGIhEmhI6E6VLkvpnYRSS8KHQlV9169Y2oXkfSi0JFQjSu8l8xODedly+zUmXGF96aoIhEJkwYSSKjqBgto9JpIx6TQkdANG3eDQkakg9LpNRERCU3SQsfMnjazCjPb1szy8WZWZWbvBF8zGy3PMLPNZvZKE9s+aWaHk1W7iIgkRzJPrz0LLABaugGjxN1vaWZZEbAduKB+o5mNBnokokAREQlX0o503H0tsL8125pZPjAZ+Hmj9gxgDvBI3AWKiEjoUj2QYKyZbQHKgIfd/b2gfR6RYOneaP0fAL9y93IzC7FMiceyzbuZs3IHZQeq6dejC9NvGsJtV/VPdVkikgKpDJ1NwCXuftjMvgosAy4zs1uACnffaGbj61Y2s37AncD4pjprzMymAdMALr744gSXLtFatnk3M5ZupfrESQB2H6hmxtKtAAoekQ4oZaPX3P2gux8OXr8KZJlZb+Ba4FYz+xhYAkwws+eBq4DPA38Ilp1vZn9oof+F7j7a3Uf36dMnyXsjzZmzcsfpwKlTfeIkc1buSFFFIpJKKTvSMbNc4DN3dzO7hkgAVrr7DGBGsM54Iqfd7gk2y623/WF3/3zIZUuMyg5Ux9QuIuktaaFjZouJnArrbWalwI+BLAB3fwqYCtxvZrVANVDo7p6seiQ1+vXowu4mAqZfjy4pqEZEUi1poePud59j+QIiQ6pbWue3wG+bWdattbVJeKbfNKTBNR2ALlkZTL9pSAqrEpFUSfXoNUlzdYMFNHpNREChI/F690VYPRuqSiEnHybOhBF3NVjltqv6K2REBFDoSDzefRGKH4ATwTWbqk8j7+Gs4BERAU34KfFYPftM4NQ5UR1pFxFpgkJHWq+qNLZ2EenwFDoCwIpdK5j00iRGPDeCSS9NYsWuFefeKCc/tnYR6fAUOsKKXSuY9dYsyo+U4zjlR8qZ9dascwfPxJmQ1eh+m6wukXYRkSYodIT5m+ZTc7KmQVvNyRrmb5rf8oYj7oKCJyDnIsAi3wue0CACEWmWRq+lmariYirmzqO2vJzMvDz6PvQgOQUFLW6z58iemNobGHGXQkZEoqYjnTRSVVxM+aMzqS0rA3dqy8oof3QmVcXFLW6X2zU3pnYRkdZS6KSRirnz8JqGp8m8poYzZwSCAAAJUklEQVSKufNa3K5oVBHZGdkN2rIzsikaVZTwGkWkY9PptTRSW14eU3udyQMnA5FrO3uO7CG3ay5Fo4pOt4uIJIpCJ41k5uVFTq010X4ukwdOVsiISNLp9Foa6fvQg1h2w9Nklp1N34ceTFFFIiIN6UgnjdSNUot19JqISFgUOmkmp6BAISMibZZCJ81tL1lDyZJFHKrcR/devRlXeC/Dxt2Q6rJEpINS6KSx7SVrWLVwAbXHjwFwaN9eVi2MPKxVwSMiqaDQacc+WL+Hdcs/5PD+Y3Tr2ZmxUwYxeMyZGzpLliw6HTh1ao8fo2TJIoWOiKSEQqed+mD9Hta88D61x08BcHj/Mda88D7A6eA5VLmvyW2baxcRSTYNmW6n1i3/8HTg1Kk9fop1yz88/b57r95Nbttcu4hIsil02qnD+4+ds31c4b1kdurcYHlmp86MK7w3qbWJiDRHp9faqW49OzcZPN16ngmZuus2Gr0mIm2FQqedGjtlUINrOgCZnc5j7JRBDdYbNu4GhYyItBkKnXaqbrBAS6PXRETaGoVOOzZ4TK5CRkTaFQ0kEBGR0Ch0REQkNEkLHTN72swqzGxbM8vHm1mVmb0TfM1stDzDzDab2Sv12n5hZlvM7F0ze8nMuiWrfhERSbxkHuk8C9x8jnVK3P3K4Gt2o2VFwPZGbQ+5+0h3HwH8EfhBYkoVEZEwJC103H0tsL8125pZPjAZ+HmjPg8Gyw3oAnicZYqISIhSPXptrJltAcqAh939vaB9HvAI0L3xBmb2DPBV4PfAXzfXsZlNA6YFb481d5ovTfQG0nVCtXTeN9D+tXfpvn9DEt1hKkNnE3CJux82s68Cy4DLzOwWoMLdN5rZ+MYbufu3zCwDeBL4OvBMU527+0JgIYCZbXD30Unaj5RL5/1L530D7V971xH2L9F9pmz0mrsfdPfDwetXgSwz6w1cC9xqZh8DS4AJZvZ8o21PAv8OfC3cqkVEJB4pCx0zyw2uzWBm1wS1VLr7DHfPd/cBQCHwhrvfYxGfD9Y3oAB4P0Xli4hIKyTt9JqZLQbGA73NrBT4MZAF4O5PAVOB+82sFqgGCt29pYEBBjxnZhcEr7cA90dZzsJW7UT7kc77l877Btq/9k77FyNr+d95ERGRxNGMBCIiEhqFjoiIhKbdhU480+uY2cdmtjVo31Cv/e+CqXXeMbNVZtYvjH1povaE71u95Q+bmQcjBFMiST+7WWa2u942Xw1jX5qSrJ+fmf0vM9thZu+Z2T8lez+ak6Sf37/XW/9jM3snjH1pSpL270oz+11dezBoKnRJ2reRZrYuWFYcXG8/N3dvV1/AdcAoYFszy8cDrzSz7GOgdxPtF9R7/QDwVLrsW7DsImAl8Elz67TX/QNmEbmxOF1/N28AfgN0Dt73Taf9a7TOvwAz02n/gFXAV4LXXwV+m0b79t/A9cHrbwN/F00t7e5Ix+OYXqeFPg/We9uVFE2vk4x9C8wlMsNDSkeNJHH/2oQk7d/9wOPufiz4jIoE9x+1ZP78gtsg7gIWJ6P/aCRp/xyoOwLIITL7SuiStG9DgLXB69eJ8r7Jdhc6URprkdmoXzOzK+q1O7DKzDZaZJqc08zsJ2b2KfANoMGM121MTPtmZrcCu919S+iVtk7MPzvgB8Hp0afN7HMh1toase7fYGCcma03s/80sz8Lt9yYtebnBzAO+Mzdd4ZTZqvFun8PAnOCf1v+GZgRZrExinXftgG3Bq/vJHJG5dxSdSgb56HiAJo/TLwA6FbvcHZnvWX9gu99idznc10T288AHkuHfQPOB9YDOS0dJrfX/QveXwhkEPkP1E+Ap9Ns/7YBTxC5N+0a4COCWx3SYf/qLf834K9T+bNL0s/vCeBrweu7gN+k0b4NJXL6cCOR+zAro6kj7Y50vPnpdXD3suB7BfAykb/Ejf2SNjq9Tiv2bRBwKbDFItMK5QObzKxNPuO6NT87d//M3U+6+yngZzT9M20TWvm7WQos9Yi3gVNEJplsc1r7d8/MMoE7iExt1Wa1cv/uA5YGr/8fbfT3s5V/995390nufjWR06IfRvNZaRc61sz0OmbW1cy6B+1dgUlE/heJmV1Wr4tbaaPT68S6b+6+1d37uvsAj0wrVAqMcvc9KdqFFrXyZ5dXr4vb69rbotbsH5GJcCcEywYDnWijsxq3cv8Avgy87+6lYdcci1buXxlwffB6AtAmTx+28u9e3+D7ecDfAk9F81mpfrRBzKyV0+uY2YXAy8GfaybwS3f/ddDt42Y2hMj/Ij8BvhfiLp2WpH1rM5K0f/9kZlcSOe/8MfA/wtujhpK0f08DT1tkqOtx4D4Pzm2ELYm/n4WkcABBnSTt318C84OjuRrOPG4lVEnat7vN7PvB66U0M+P/WbWk6PdXREQ6oLQ7vSYiIm2XQkdEREKj0BERkdAodEREJDQKHRERCY1CRyQGwf0MS8zsQzP7vZm9amaDzeyjYNh9/XXnmdkjqapVpC3SkGmRKAU3z70FPBfc20Bwj1B3IlOH1Lj7Y0H7ecAfgWvd/ZNm+stw95OhFC/SRuhIRyR6NwAn6gIHwN3fcfcSIjc3FtZb9zrg48aBY5Hnlqwxs18CW81sgJm9b2Y/N7NtZvaCmX3ZzN40s53B3eGY2fV25lknm+vdJT7dzP7bIhOePpbsPwCReCl0RKI3nMjkhmdx93eBU2Y2Mmhq6S77a4D/7e6XB+8/D8wHRhCZRPEvgC8BDwN/E6zzMPB9d7+SyIzM1WY2Cbgs6O9K4Gozu671uyeSfAodkcRZDBQGU55MITLBY1PedveP6r3/KJgn7xTwHrA6mOpmK5GZgQHeBP7VzB4Aerh7LZF5sCYBm4FNRAKr/jyCIm1Ou5t7TSSF3iMyR1VzFhOZ6v0/gXe9+QeuHWn0/li916fqvT9F8HfU3R83sxVErh39zsy+TORxB//g7v83pr0QSSEd6YhE7w2gs5n9ZV2Dmf2ZmV0P4O4fApXA4yR4AkszGxQcDf0jsIHIUc1K4Ntm1i1Yp3/dzL8ibZVCRyRKwSmv24EbgyHT7wGzaPgI4sVEAuHlBH/8g8FAgy1EZgF+zd1XEXn+0zoz2wq8RGQknUibpSHTIiISGh3piIhIaBQ6IiISGoWOiIiERqEjIiKhUeiIiEhoFDoiIhIahY6IiITm/wNzOqhyEYOlYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2876125cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(5,11):\n",
    "    df=df_all2.loc[i]\n",
    "    #df_err=df_all3.loc[i]\n",
    "    plt.scatter(df.cv_error,df.test_error,linestyle='-',marker='o',label=i)\n",
    "    #plt.errorbar(df.ave_cv_error,df.ave_test_error,xerr=df_err.cv_error)\n",
    "    plt.ylabel('Test rmse')\n",
    "    plt.xlabel('CV rmse')\n",
    "    plt.legend()\n",
    "    plt.xlim([1.553,1.559])\n",
    "    plt.ylim([1.543,1.549])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, CV rmse is linear to Test rmse for model without outliers. For the model without outliers CV is not reliable probably due to outliers. Outliers affect rmse hugely. So we can focus on the model without outliers and improve our base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will do feature reduction for threshold 10 and replace values from my previous results. And see if we can observe improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats10=pd.read_csv('threshold_feature_elimination10_8extra_test10_without_outliers.csv',squeeze=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data=lgb.Dataset(train[train.outliers==0][feats10],label=train[train.outliers==0]['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's rmse: 1.60547 + 0.00964734\n",
      "[200]\tcv_agg's rmse: 1.57754 + 0.00878048\n",
      "[300]\tcv_agg's rmse: 1.56693 + 0.00814712\n",
      "[400]\tcv_agg's rmse: 1.56138 + 0.00770528\n",
      "[500]\tcv_agg's rmse: 1.55811 + 0.0074054\n",
      "[600]\tcv_agg's rmse: 1.55617 + 0.00721443\n",
      "[700]\tcv_agg's rmse: 1.55489 + 0.00711153\n",
      "[800]\tcv_agg's rmse: 1.55404 + 0.00699729\n",
      "[900]\tcv_agg's rmse: 1.55353 + 0.00695016\n",
      "[1000]\tcv_agg's rmse: 1.55317 + 0.00690121\n",
      "[1100]\tcv_agg's rmse: 1.5529 + 0.00685212\n",
      "[1200]\tcv_agg's rmse: 1.55266 + 0.00681777\n",
      "[1300]\tcv_agg's rmse: 1.55248 + 0.00674346\n",
      "[1400]\tcv_agg's rmse: 1.55233 + 0.00671699\n",
      "[1500]\tcv_agg's rmse: 1.55218 + 0.00667979\n",
      "[1600]\tcv_agg's rmse: 1.55209 + 0.0066453\n",
      "[1700]\tcv_agg's rmse: 1.552 + 0.00663538\n",
      "[1800]\tcv_agg's rmse: 1.55192 + 0.00661082\n",
      "[1900]\tcv_agg's rmse: 1.55184 + 0.00659594\n",
      "[2000]\tcv_agg's rmse: 1.55174 + 0.00660216\n",
      "[2100]\tcv_agg's rmse: 1.55171 + 0.00656293\n",
      "[2200]\tcv_agg's rmse: 1.55167 + 0.00653245\n",
      "[2300]\tcv_agg's rmse: 1.55168 + 0.00654575\n",
      "[2400]\tcv_agg's rmse: 1.55163 + 0.00655089\n",
      "[2500]\tcv_agg's rmse: 1.55162 + 0.00652699\n",
      "[2600]\tcv_agg's rmse: 1.55161 + 0.00650645\n",
      "[2700]\tcv_agg's rmse: 1.5516 + 0.00644588\n",
      "[2800]\tcv_agg's rmse: 1.55161 + 0.00642542\n",
      "[2900]\tcv_agg's rmse: 1.55162 + 0.00640759\n",
      "[3000]\tcv_agg's rmse: 1.55159 + 0.00639742\n",
      "[3100]\tcv_agg's rmse: 1.55158 + 0.00640563\n",
      "[3200]\tcv_agg's rmse: 1.55158 + 0.00638596\n",
      "[3300]\tcv_agg's rmse: 1.55159 + 0.00638968\n",
      "[3400]\tcv_agg's rmse: 1.55161 + 0.00634895\n",
      "[3500]\tcv_agg's rmse: 1.55162 + 0.00630202\n",
      "[3600]\tcv_agg's rmse: 1.55163 + 0.00627621\n",
      "[3700]\tcv_agg's rmse: 1.55165 + 0.00626132\n",
      "[3800]\tcv_agg's rmse: 1.55165 + 0.00626549\n"
     ]
    }
   ],
   "source": [
    "cv_score=lgb.cv(param,train_data,10000, verbose_eval=100, early_stopping_rounds = 600,stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3235"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_score['rmse-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60184\n",
      "[200]\ttraining's rmse: 1.56997\n",
      "[300]\ttraining's rmse: 1.55583\n",
      "[400]\ttraining's rmse: 1.54695\n",
      "[500]\ttraining's rmse: 1.54033\n",
      "[600]\ttraining's rmse: 1.53503\n",
      "[700]\ttraining's rmse: 1.5305\n",
      "[800]\ttraining's rmse: 1.52646\n",
      "[900]\ttraining's rmse: 1.52282\n",
      "[1000]\ttraining's rmse: 1.51956\n",
      "[1100]\ttraining's rmse: 1.51638\n",
      "[1200]\ttraining's rmse: 1.51333\n",
      "[1300]\ttraining's rmse: 1.51044\n",
      "[1400]\ttraining's rmse: 1.50753\n",
      "[1500]\ttraining's rmse: 1.5048\n",
      "[1600]\ttraining's rmse: 1.50207\n",
      "[1700]\ttraining's rmse: 1.49935\n",
      "[1800]\ttraining's rmse: 1.49672\n",
      "[1900]\ttraining's rmse: 1.49412\n",
      "[2000]\ttraining's rmse: 1.49144\n",
      "[2100]\ttraining's rmse: 1.48891\n",
      "[2200]\ttraining's rmse: 1.48639\n",
      "[2300]\ttraining's rmse: 1.48389\n",
      "[2400]\ttraining's rmse: 1.4814\n",
      "[2500]\ttraining's rmse: 1.47887\n",
      "[2600]\ttraining's rmse: 1.47643\n",
      "[2700]\ttraining's rmse: 1.47385\n",
      "[2800]\ttraining's rmse: 1.47146\n",
      "[2900]\ttraining's rmse: 1.469\n",
      "[3000]\ttraining's rmse: 1.46664\n",
      "[3100]\ttraining's rmse: 1.46418\n",
      "[3200]\ttraining's rmse: 1.46183\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3235]\ttraining's rmse: 1.46102\n"
     ]
    }
   ],
   "source": [
    "clf=lgb.train(param,train_data,len(cv_score['rmse-mean']),valid_sets=[train_data],verbose_eval=100, early_stopping_rounds = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=clf.predict(test[feats10],clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats10_updated=feats10[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers data\n",
    "for i in range(len(feats10)):\n",
    "    if 'outlier' in feats10[i]:\n",
    "        feats10_updated.remove(feats10[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 86)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats10_updated),len(feats10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's rmse: 1.60559 + 0.00973126\n",
      "[200]\tcv_agg's rmse: 1.57763 + 0.00875306\n",
      "[300]\tcv_agg's rmse: 1.56703 + 0.0080872\n",
      "[400]\tcv_agg's rmse: 1.56149 + 0.00770222\n",
      "[500]\tcv_agg's rmse: 1.55822 + 0.00736148\n",
      "[600]\tcv_agg's rmse: 1.55625 + 0.0071866\n",
      "[700]\tcv_agg's rmse: 1.55498 + 0.00710701\n",
      "[800]\tcv_agg's rmse: 1.55419 + 0.00699939\n",
      "[900]\tcv_agg's rmse: 1.55369 + 0.00690339\n",
      "[1000]\tcv_agg's rmse: 1.5533 + 0.00683223\n",
      "[1100]\tcv_agg's rmse: 1.55299 + 0.00677273\n",
      "[1200]\tcv_agg's rmse: 1.55276 + 0.00673547\n",
      "[1300]\tcv_agg's rmse: 1.55256 + 0.00670601\n",
      "[1400]\tcv_agg's rmse: 1.55238 + 0.00670275\n",
      "[1500]\tcv_agg's rmse: 1.55222 + 0.0066688\n",
      "[1600]\tcv_agg's rmse: 1.55211 + 0.00666149\n",
      "[1700]\tcv_agg's rmse: 1.55198 + 0.0066344\n",
      "[1800]\tcv_agg's rmse: 1.55193 + 0.00661063\n",
      "[1900]\tcv_agg's rmse: 1.55189 + 0.0065954\n",
      "[2000]\tcv_agg's rmse: 1.55181 + 0.00654826\n",
      "[2100]\tcv_agg's rmse: 1.55172 + 0.00654137\n",
      "[2200]\tcv_agg's rmse: 1.55167 + 0.00653846\n",
      "[2300]\tcv_agg's rmse: 1.55167 + 0.00655412\n",
      "[2400]\tcv_agg's rmse: 1.55165 + 0.00656308\n",
      "[2500]\tcv_agg's rmse: 1.55163 + 0.0065412\n",
      "[2600]\tcv_agg's rmse: 1.55161 + 0.00653996\n",
      "[2700]\tcv_agg's rmse: 1.55161 + 0.0064958\n",
      "[2800]\tcv_agg's rmse: 1.55162 + 0.00646692\n",
      "[2900]\tcv_agg's rmse: 1.55166 + 0.00640906\n",
      "[3000]\tcv_agg's rmse: 1.55165 + 0.00640355\n",
      "[3100]\tcv_agg's rmse: 1.55168 + 0.00636389\n",
      "[3200]\tcv_agg's rmse: 1.55169 + 0.00636493\n"
     ]
    }
   ],
   "source": [
    "train_data=lgb.Dataset(train[train.outliers==0][feats10_updated],label=train[train.outliers==0]['target'])\n",
    "cv_score=lgb.cv(param,train_data,10000, verbose_eval=100, early_stopping_rounds = 600,stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 600 rounds.\n",
      "[100]\ttraining's rmse: 1.60193\n",
      "[200]\ttraining's rmse: 1.57019\n",
      "[300]\ttraining's rmse: 1.55608\n",
      "[400]\ttraining's rmse: 1.54719\n",
      "[500]\ttraining's rmse: 1.54064\n",
      "[600]\ttraining's rmse: 1.53533\n",
      "[700]\ttraining's rmse: 1.53084\n",
      "[800]\ttraining's rmse: 1.52681\n",
      "[900]\ttraining's rmse: 1.52326\n",
      "[1000]\ttraining's rmse: 1.51993\n",
      "[1100]\ttraining's rmse: 1.51672\n",
      "[1200]\ttraining's rmse: 1.51364\n",
      "[1300]\ttraining's rmse: 1.51074\n",
      "[1400]\ttraining's rmse: 1.50787\n",
      "[1500]\ttraining's rmse: 1.50506\n",
      "[1600]\ttraining's rmse: 1.50234\n",
      "[1700]\ttraining's rmse: 1.49961\n",
      "[1800]\ttraining's rmse: 1.49693\n",
      "[1900]\ttraining's rmse: 1.49432\n",
      "[2000]\ttraining's rmse: 1.49168\n",
      "[2100]\ttraining's rmse: 1.48913\n",
      "[2200]\ttraining's rmse: 1.48662\n",
      "[2300]\ttraining's rmse: 1.4841\n",
      "[2400]\ttraining's rmse: 1.48165\n",
      "[2500]\ttraining's rmse: 1.47914\n",
      "[2600]\ttraining's rmse: 1.47671\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2656]\ttraining's rmse: 1.47526\n"
     ]
    }
   ],
   "source": [
    "clf2=lgb.train(param,train_data,len(cv_score['rmse-mean']),valid_sets=[train_data],verbose_eval=100, early_stopping_rounds = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2=clf2.predict(test[feats10_updated],clf2.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623,)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission2=pd.DataFrame({'card_id':test['card_id'].values,'target':predictions2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission2.to_csv('prediction_without_outliers_feature_reduction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed with threshould value of 18000\n",
    "best_submission=pd.read_csv(\"wang_lgb_cv_pur_date_1_updated_mixed_top20_top20_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need outliers predictions\n",
    "outliers=pd.read_csv('wang_lgb_cv_pur_date_1_updated_outliers_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=outliers.sort_values('probability',ascending=False).head(18000).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission=pd.read_csv('submission.csv')\n",
    "df_submission.target=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.loc[idx,'target']=best_submission.loc[idx,'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(\"wang_lgb_cv_pur_date_1_updated_mixed_top20_top20_50_updated_1.csv\",index=False)\n",
    "# LB:3.664 which is worser than previous 3.663\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1766"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.outliers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['first_active_month', 'card_id', 'feature_3', 'target',\n",
       "       'auth_flag_purchase_amount_sum', 'auth_flag_authorized_flag_sum',\n",
       "       'auth_flag_authorized_flag_mean', 'auth_flag_authorized_flag_std',\n",
       "       'auth_flag_card_id_size', 'auth_encoder_category_2_auth_mean_mean',\n",
       "       ...\n",
       "       'feature_1_5', 'feature_2_1', 'feature_2_2', 'feature_2_3',\n",
       "       'pur_freq_unique', 'pur_freq_unique_month', 'auth_pur_freq_unique',\n",
       "       'auth_pur_freq_unique_month', 'nonauth_pur_freq_unique',\n",
       "       'nonauth_freq_unique_month'],\n",
       "      dtype='object', length=263)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results are slightly worser than before which is probably due to threshould value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3=pd.concat([df2,df],join='outer',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['total_fold']=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['features']='feats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.concat([df4,df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.concat([df4,df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_error</th>\n",
       "      <th>test_error</th>\n",
       "      <th>fold</th>\n",
       "      <th>ave_cv_error</th>\n",
       "      <th>ave_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.658294</td>\n",
       "      <td>3.650502</td>\n",
       "      <td>1</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.650528</td>\n",
       "      <td>3.655088</td>\n",
       "      <td>2</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.650849</td>\n",
       "      <td>3.656602</td>\n",
       "      <td>3</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.607118</td>\n",
       "      <td>3.645048</td>\n",
       "      <td>4</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.651150</td>\n",
       "      <td>3.651565</td>\n",
       "      <td>5</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.675512</td>\n",
       "      <td>3.649566</td>\n",
       "      <td>6</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.606465</td>\n",
       "      <td>3.657148</td>\n",
       "      <td>7</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.623117</td>\n",
       "      <td>3.657314</td>\n",
       "      <td>8</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.683562</td>\n",
       "      <td>3.647405</td>\n",
       "      <td>9</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.680909</td>\n",
       "      <td>3.652111</td>\n",
       "      <td>10</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.658294</td>\n",
       "      <td>3.650502</td>\n",
       "      <td>1</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.650528</td>\n",
       "      <td>3.655088</td>\n",
       "      <td>2</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.650849</td>\n",
       "      <td>3.656602</td>\n",
       "      <td>3</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.607118</td>\n",
       "      <td>3.645048</td>\n",
       "      <td>4</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.651150</td>\n",
       "      <td>3.651565</td>\n",
       "      <td>5</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.675512</td>\n",
       "      <td>3.649566</td>\n",
       "      <td>6</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.606465</td>\n",
       "      <td>3.657148</td>\n",
       "      <td>7</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.623117</td>\n",
       "      <td>3.657314</td>\n",
       "      <td>8</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.683562</td>\n",
       "      <td>3.647405</td>\n",
       "      <td>9</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.680909</td>\n",
       "      <td>3.652111</td>\n",
       "      <td>10</td>\n",
       "      <td>3.648849</td>\n",
       "      <td>3.647493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_error  test_error  fold  ave_cv_error  ave_test_error\n",
       "0  3.658294    3.650502     1      3.648849        3.647493\n",
       "1  3.650528    3.655088     2      3.648849        3.647493\n",
       "2  3.650849    3.656602     3      3.648849        3.647493\n",
       "3  3.607118    3.645048     4      3.648849        3.647493\n",
       "4  3.651150    3.651565     5      3.648849        3.647493\n",
       "5  3.675512    3.649566     6      3.648849        3.647493\n",
       "6  3.606465    3.657148     7      3.648849        3.647493\n",
       "7  3.623117    3.657314     8      3.648849        3.647493\n",
       "8  3.683562    3.647405     9      3.648849        3.647493\n",
       "9  3.680909    3.652111    10      3.648849        3.647493\n",
       "0  3.658294    3.650502     1      3.648849        3.647493\n",
       "1  3.650528    3.655088     2      3.648849        3.647493\n",
       "2  3.650849    3.656602     3      3.648849        3.647493\n",
       "3  3.607118    3.645048     4      3.648849        3.647493\n",
       "4  3.651150    3.651565     5      3.648849        3.647493\n",
       "5  3.675512    3.649566     6      3.648849        3.647493\n",
       "6  3.606465    3.657148     7      3.648849        3.647493\n",
       "7  3.623117    3.657314     8      3.648849        3.647493\n",
       "8  3.683562    3.647405     9      3.648849        3.647493\n",
       "9  3.680909    3.652111    10      3.648849        3.647493"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2872a3bf780>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28712ebc550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df['cv_error'],df['test_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in [5,6,7,8,9,10]:\n",
    "    for feat in [feats,feats1,feats2,feats3]:\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_param = {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9, #\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9, #\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 48,\n",
    "         \"scale_pos_weight\": 15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = lgb.Dataset(X_tr, label=y_tr.outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's auc: 0.902398 + 0.00697561\n",
      "[200]\tcv_agg's auc: 0.903697 + 0.00662913\n",
      "[300]\tcv_agg's auc: 0.903734 + 0.00670821\n",
      "[400]\tcv_agg's auc: 0.903137 + 0.00668533\n",
      "[500]\tcv_agg's auc: 0.902398 + 0.00650716\n",
      "[600]\tcv_agg's auc: 0.901779 + 0.00654513\n",
      "[700]\tcv_agg's auc: 0.901337 + 0.006394\n",
      "[800]\tcv_agg's auc: 0.900654 + 0.00646067\n"
     ]
    }
   ],
   "source": [
    "cv_score = lgb.cv(cl_param, tr_data, 10000, early_stopping_rounds=600, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best num:  232 \n",
      "best score: 0.9038768908290219\n"
     ]
    }
   ],
   "source": [
    "print('best num: ', len(cv_score['auc-mean']), '\\nbest score:', cv_score['auc-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.966905\n",
      "[200]\ttraining's auc: 0.974608\n",
      "[300]\ttraining's auc: 0.980398\n",
      "[400]\ttraining's auc: 0.984885\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(cl_param, tr_data, 400, valid_sets=(tr_data), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code\n",
    "[100]\ttraining's auc: 0.966946\n",
    "[200]\ttraining's auc: 0.974508\n",
    "[300]\ttraining's auc: 0.980274\n",
    "[400]\ttraining's auc: 0.984884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = clf.predict(X_va, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902935029308729"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_va.outlier, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(y_va.outlier, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b3833eb400>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b3eb9a9550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier: 869 \n",
      "not outlier: 75860\n"
     ]
    }
   ],
   "source": [
    "print('outlier:', y_va.outlier.sum(), '\\nnot outlier:', y_va.shape[0] - y_va.outlier.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 0:  \toutlier 0 \t not outlier 0\n",
      "top 1:  \toutlier 1 \t not outlier 0\n",
      "top 5:  \toutlier 1 \t not outlier 4\n",
      "top 8:  \toutlier 4 \t not outlier 4\n",
      "top 10:  \toutlier 4 \t not outlier 6\n",
      "top 12:  \toutlier 6 \t not outlier 6\n",
      "top 14:  \toutlier 6 \t not outlier 8\n",
      "top 17:  \toutlier 9 \t not outlier 8\n",
      "top 18:  \toutlier 9 \t not outlier 9\n",
      "top 19:  \toutlier 10 \t not outlier 9\n",
      "top 26:  \toutlier 10 \t not outlier 16\n",
      "top 28:  \toutlier 12 \t not outlier 16\n",
      "top 29:  \toutlier 12 \t not outlier 17\n",
      "top 30:  \toutlier 13 \t not outlier 17\n",
      "top 35:  \toutlier 13 \t not outlier 22\n",
      "top 42:  \toutlier 20 \t not outlier 22\n",
      "top 63:  \toutlier 20 \t not outlier 43\n",
      "top 64:  \toutlier 21 \t not outlier 43\n",
      "top 72:  \toutlier 21 \t not outlier 51\n",
      "top 77:  \toutlier 26 \t not outlier 51\n",
      "top 80:  \toutlier 26 \t not outlier 54\n",
      "top 81:  \toutlier 27 \t not outlier 54\n",
      "top 83:  \toutlier 27 \t not outlier 56\n",
      "top 87:  \toutlier 31 \t not outlier 56\n",
      "top 89:  \toutlier 31 \t not outlier 58\n",
      "top 93:  \toutlier 35 \t not outlier 58\n",
      "top 105:  \toutlier 35 \t not outlier 70\n",
      "top 107:  \toutlier 37 \t not outlier 70\n",
      "top 109:  \toutlier 37 \t not outlier 72\n",
      "top 112:  \toutlier 40 \t not outlier 72\n",
      "top 118:  \toutlier 40 \t not outlier 78\n",
      "top 119:  \toutlier 41 \t not outlier 78\n",
      "top 126:  \toutlier 41 \t not outlier 85\n",
      "top 130:  \toutlier 45 \t not outlier 85\n",
      "top 132:  \toutlier 45 \t not outlier 87\n",
      "top 133:  \toutlier 46 \t not outlier 87\n",
      "top 144:  \toutlier 46 \t not outlier 98\n",
      "top 147:  \toutlier 49 \t not outlier 98\n",
      "top 148:  \toutlier 49 \t not outlier 99\n",
      "top 150:  \toutlier 51 \t not outlier 99\n",
      "top 158:  \toutlier 51 \t not outlier 107\n",
      "top 159:  \toutlier 52 \t not outlier 107\n",
      "top 163:  \toutlier 52 \t not outlier 111\n",
      "top 166:  \toutlier 55 \t not outlier 111\n",
      "top 171:  \toutlier 55 \t not outlier 116\n",
      "top 173:  \toutlier 57 \t not outlier 116\n",
      "top 177:  \toutlier 57 \t not outlier 120\n",
      "top 179:  \toutlier 59 \t not outlier 120\n",
      "top 186:  \toutlier 59 \t not outlier 127\n",
      "top 189:  \toutlier 62 \t not outlier 127\n",
      "top 194:  \toutlier 62 \t not outlier 132\n",
      "top 197:  \toutlier 65 \t not outlier 132\n",
      "top 208:  \toutlier 65 \t not outlier 143\n",
      "top 209:  \toutlier 66 \t not outlier 143\n",
      "top 222:  \toutlier 66 \t not outlier 156\n",
      "top 224:  \toutlier 68 \t not outlier 156\n",
      "top 225:  \toutlier 68 \t not outlier 157\n",
      "top 226:  \toutlier 69 \t not outlier 157\n",
      "top 231:  \toutlier 69 \t not outlier 162\n",
      "top 233:  \toutlier 71 \t not outlier 162\n",
      "top 235:  \toutlier 71 \t not outlier 164\n",
      "top 237:  \toutlier 73 \t not outlier 164\n",
      "top 248:  \toutlier 73 \t not outlier 175\n",
      "top 251:  \toutlier 76 \t not outlier 175\n",
      "top 261:  \toutlier 76 \t not outlier 185\n",
      "top 262:  \toutlier 77 \t not outlier 185\n",
      "top 267:  \toutlier 77 \t not outlier 190\n",
      "top 269:  \toutlier 79 \t not outlier 190\n",
      "top 274:  \toutlier 79 \t not outlier 195\n",
      "top 275:  \toutlier 80 \t not outlier 195\n",
      "top 276:  \toutlier 80 \t not outlier 196\n",
      "top 278:  \toutlier 82 \t not outlier 196\n",
      "top 281:  \toutlier 82 \t not outlier 199\n",
      "top 282:  \toutlier 83 \t not outlier 199\n",
      "top 284:  \toutlier 83 \t not outlier 201\n",
      "top 288:  \toutlier 87 \t not outlier 201\n",
      "top 298:  \toutlier 87 \t not outlier 211\n",
      "top 301:  \toutlier 90 \t not outlier 211\n",
      "top 305:  \toutlier 90 \t not outlier 215\n",
      "top 306:  \toutlier 91 \t not outlier 215\n",
      "top 318:  \toutlier 91 \t not outlier 227\n",
      "top 320:  \toutlier 93 \t not outlier 227\n",
      "top 321:  \toutlier 93 \t not outlier 228\n",
      "top 322:  \toutlier 94 \t not outlier 228\n",
      "top 329:  \toutlier 94 \t not outlier 235\n",
      "top 334:  \toutlier 99 \t not outlier 235\n",
      "top 343:  \toutlier 99 \t not outlier 244\n",
      "top 346:  \toutlier 102 \t not outlier 244\n",
      "top 350:  \toutlier 102 \t not outlier 248\n",
      "top 352:  \toutlier 104 \t not outlier 248\n",
      "top 353:  \toutlier 104 \t not outlier 249\n",
      "top 357:  \toutlier 108 \t not outlier 249\n",
      "top 364:  \toutlier 108 \t not outlier 256\n",
      "top 366:  \toutlier 110 \t not outlier 256\n",
      "top 367:  \toutlier 110 \t not outlier 257\n",
      "top 368:  \toutlier 111 \t not outlier 257\n",
      "top 373:  \toutlier 111 \t not outlier 262\n",
      "top 377:  \toutlier 115 \t not outlier 262\n",
      "top 384:  \toutlier 115 \t not outlier 269\n",
      "top 387:  \toutlier 118 \t not outlier 269\n",
      "top 388:  \toutlier 118 \t not outlier 270\n",
      "top 391:  \toutlier 121 \t not outlier 270\n",
      "top 393:  \toutlier 121 \t not outlier 272\n",
      "top 394:  \toutlier 122 \t not outlier 272\n",
      "top 402:  \toutlier 122 \t not outlier 280\n",
      "top 404:  \toutlier 124 \t not outlier 280\n",
      "top 406:  \toutlier 124 \t not outlier 282\n",
      "top 407:  \toutlier 125 \t not outlier 282\n",
      "top 408:  \toutlier 125 \t not outlier 283\n",
      "top 410:  \toutlier 127 \t not outlier 283\n",
      "top 415:  \toutlier 127 \t not outlier 288\n",
      "top 417:  \toutlier 129 \t not outlier 288\n",
      "top 422:  \toutlier 129 \t not outlier 293\n",
      "top 423:  \toutlier 130 \t not outlier 293\n",
      "top 424:  \toutlier 130 \t not outlier 294\n",
      "top 429:  \toutlier 135 \t not outlier 294\n",
      "top 436:  \toutlier 135 \t not outlier 301\n",
      "top 437:  \toutlier 136 \t not outlier 301\n",
      "top 443:  \toutlier 136 \t not outlier 307\n",
      "top 445:  \toutlier 138 \t not outlier 307\n",
      "top 455:  \toutlier 138 \t not outlier 317\n",
      "top 456:  \toutlier 139 \t not outlier 317\n",
      "top 471:  \toutlier 139 \t not outlier 332\n",
      "top 475:  \toutlier 143 \t not outlier 332\n",
      "top 478:  \toutlier 143 \t not outlier 335\n",
      "top 479:  \toutlier 144 \t not outlier 335\n",
      "top 503:  \toutlier 144 \t not outlier 359\n",
      "top 505:  \toutlier 146 \t not outlier 359\n",
      "top 508:  \toutlier 146 \t not outlier 362\n",
      "top 514:  \toutlier 152 \t not outlier 362\n",
      "top 517:  \toutlier 152 \t not outlier 365\n",
      "top 518:  \toutlier 153 \t not outlier 365\n",
      "top 536:  \toutlier 153 \t not outlier 383\n",
      "top 538:  \toutlier 155 \t not outlier 383\n",
      "top 541:  \toutlier 155 \t not outlier 386\n",
      "top 543:  \toutlier 157 \t not outlier 386\n",
      "top 553:  \toutlier 157 \t not outlier 396\n",
      "top 554:  \toutlier 158 \t not outlier 396\n",
      "top 564:  \toutlier 158 \t not outlier 406\n",
      "top 566:  \toutlier 160 \t not outlier 406\n",
      "top 575:  \toutlier 160 \t not outlier 415\n",
      "top 576:  \toutlier 161 \t not outlier 415\n",
      "top 583:  \toutlier 161 \t not outlier 422\n",
      "top 585:  \toutlier 163 \t not outlier 422\n",
      "top 588:  \toutlier 163 \t not outlier 425\n",
      "top 591:  \toutlier 166 \t not outlier 425\n",
      "top 594:  \toutlier 166 \t not outlier 428\n",
      "top 595:  \toutlier 167 \t not outlier 428\n",
      "top 619:  \toutlier 167 \t not outlier 452\n",
      "top 621:  \toutlier 169 \t not outlier 452\n",
      "top 625:  \toutlier 169 \t not outlier 456\n",
      "top 627:  \toutlier 171 \t not outlier 456\n",
      "top 633:  \toutlier 171 \t not outlier 462\n",
      "top 636:  \toutlier 174 \t not outlier 462\n",
      "top 638:  \toutlier 174 \t not outlier 464\n",
      "top 641:  \toutlier 177 \t not outlier 464\n",
      "top 644:  \toutlier 177 \t not outlier 467\n",
      "top 645:  \toutlier 178 \t not outlier 467\n",
      "top 647:  \toutlier 178 \t not outlier 469\n",
      "top 650:  \toutlier 181 \t not outlier 469\n",
      "top 672:  \toutlier 181 \t not outlier 491\n",
      "top 674:  \toutlier 183 \t not outlier 491\n",
      "top 676:  \toutlier 183 \t not outlier 493\n",
      "top 678:  \toutlier 185 \t not outlier 493\n",
      "top 679:  \toutlier 185 \t not outlier 494\n",
      "top 680:  \toutlier 186 \t not outlier 494\n",
      "top 687:  \toutlier 186 \t not outlier 501\n",
      "top 689:  \toutlier 188 \t not outlier 501\n",
      "top 690:  \toutlier 188 \t not outlier 502\n",
      "top 691:  \toutlier 189 \t not outlier 502\n",
      "top 698:  \toutlier 189 \t not outlier 509\n",
      "top 700:  \toutlier 191 \t not outlier 509\n",
      "top 706:  \toutlier 191 \t not outlier 515\n",
      "top 707:  \toutlier 192 \t not outlier 515\n",
      "top 712:  \toutlier 192 \t not outlier 520\n",
      "top 714:  \toutlier 194 \t not outlier 520\n",
      "top 722:  \toutlier 194 \t not outlier 528\n",
      "top 728:  \toutlier 200 \t not outlier 528\n",
      "top 730:  \toutlier 200 \t not outlier 530\n",
      "top 732:  \toutlier 202 \t not outlier 530\n",
      "top 758:  \toutlier 202 \t not outlier 556\n",
      "top 759:  \toutlier 203 \t not outlier 556\n",
      "top 760:  \toutlier 203 \t not outlier 557\n",
      "top 762:  \toutlier 205 \t not outlier 557\n",
      "top 767:  \toutlier 205 \t not outlier 562\n",
      "top 768:  \toutlier 206 \t not outlier 562\n",
      "top 773:  \toutlier 206 \t not outlier 567\n",
      "top 775:  \toutlier 208 \t not outlier 567\n",
      "top 791:  \toutlier 208 \t not outlier 583\n",
      "top 792:  \toutlier 209 \t not outlier 583\n",
      "top 795:  \toutlier 209 \t not outlier 586\n",
      "top 797:  \toutlier 211 \t not outlier 586\n",
      "top 808:  \toutlier 211 \t not outlier 597\n",
      "top 809:  \toutlier 212 \t not outlier 597\n",
      "top 814:  \toutlier 212 \t not outlier 602\n",
      "top 816:  \toutlier 214 \t not outlier 602\n",
      "top 823:  \toutlier 214 \t not outlier 609\n",
      "top 825:  \toutlier 216 \t not outlier 609\n",
      "top 830:  \toutlier 216 \t not outlier 614\n",
      "top 831:  \toutlier 217 \t not outlier 614\n",
      "top 852:  \toutlier 217 \t not outlier 635\n",
      "top 854:  \toutlier 219 \t not outlier 635\n",
      "top 857:  \toutlier 219 \t not outlier 638\n",
      "top 860:  \toutlier 222 \t not outlier 638\n",
      "top 866:  \toutlier 222 \t not outlier 644\n",
      "top 869:  \toutlier 225 \t not outlier 644\n",
      "top 881:  \toutlier 225 \t not outlier 656\n",
      "top 884:  \toutlier 228 \t not outlier 656\n",
      "top 892:  \toutlier 228 \t not outlier 664\n",
      "top 894:  \toutlier 230 \t not outlier 664\n",
      "top 903:  \toutlier 230 \t not outlier 673\n",
      "top 904:  \toutlier 231 \t not outlier 673\n",
      "top 927:  \toutlier 231 \t not outlier 696\n",
      "top 929:  \toutlier 233 \t not outlier 696\n",
      "top 937:  \toutlier 233 \t not outlier 704\n",
      "top 938:  \toutlier 234 \t not outlier 704\n",
      "top 951:  \toutlier 234 \t not outlier 717\n",
      "top 954:  \toutlier 237 \t not outlier 717\n",
      "top 957:  \toutlier 237 \t not outlier 720\n",
      "top 959:  \toutlier 239 \t not outlier 720\n",
      "top 967:  \toutlier 239 \t not outlier 728\n",
      "top 968:  \toutlier 240 \t not outlier 728\n",
      "top 983:  \toutlier 240 \t not outlier 743\n",
      "top 987:  \toutlier 244 \t not outlier 743\n",
      "top 995:  \toutlier 244 \t not outlier 751\n",
      "top 996:  \toutlier 245 \t not outlier 751\n",
      "top 1010:  \toutlier 245 \t not outlier 765\n",
      "top 1012:  \toutlier 247 \t not outlier 765\n",
      "top 1019:  \toutlier 247 \t not outlier 772\n",
      "top 1020:  \toutlier 248 \t not outlier 772\n",
      "top 1028:  \toutlier 248 \t not outlier 780\n",
      "top 1030:  \toutlier 250 \t not outlier 780\n",
      "top 1049:  \toutlier 250 \t not outlier 799\n",
      "top 1050:  \toutlier 251 \t not outlier 799\n",
      "top 1060:  \toutlier 251 \t not outlier 809\n",
      "top 1062:  \toutlier 253 \t not outlier 809\n",
      "top 1066:  \toutlier 253 \t not outlier 813\n",
      "top 1067:  \toutlier 254 \t not outlier 813\n",
      "top 1072:  \toutlier 254 \t not outlier 818\n",
      "top 1074:  \toutlier 256 \t not outlier 818\n",
      "top 1087:  \toutlier 256 \t not outlier 831\n",
      "top 1089:  \toutlier 258 \t not outlier 831\n",
      "top 1094:  \toutlier 258 \t not outlier 836\n",
      "top 1095:  \toutlier 259 \t not outlier 836\n",
      "top 1118:  \toutlier 259 \t not outlier 859\n",
      "top 1121:  \toutlier 262 \t not outlier 859\n",
      "top 1132:  \toutlier 262 \t not outlier 870\n",
      "top 1134:  \toutlier 264 \t not outlier 870\n",
      "top 1137:  \toutlier 264 \t not outlier 873\n",
      "top 1140:  \toutlier 267 \t not outlier 873\n",
      "top 1142:  \toutlier 267 \t not outlier 875\n",
      "top 1143:  \toutlier 268 \t not outlier 875\n",
      "top 1152:  \toutlier 268 \t not outlier 884\n",
      "top 1156:  \toutlier 272 \t not outlier 884\n",
      "top 1160:  \toutlier 272 \t not outlier 888\n",
      "top 1161:  \toutlier 273 \t not outlier 888\n",
      "top 1190:  \toutlier 273 \t not outlier 917\n",
      "top 1192:  \toutlier 275 \t not outlier 917\n",
      "top 1206:  \toutlier 275 \t not outlier 931\n",
      "top 1207:  \toutlier 276 \t not outlier 931\n",
      "top 1209:  \toutlier 276 \t not outlier 933\n",
      "top 1211:  \toutlier 278 \t not outlier 933\n",
      "top 1214:  \toutlier 278 \t not outlier 936\n",
      "top 1215:  \toutlier 279 \t not outlier 936\n",
      "top 1226:  \toutlier 279 \t not outlier 947\n",
      "top 1228:  \toutlier 281 \t not outlier 947\n",
      "top 1233:  \toutlier 281 \t not outlier 952\n",
      "top 1234:  \toutlier 282 \t not outlier 952\n",
      "top 1237:  \toutlier 282 \t not outlier 955\n",
      "top 1239:  \toutlier 284 \t not outlier 955\n",
      "top 1243:  \toutlier 284 \t not outlier 959\n",
      "top 1245:  \toutlier 286 \t not outlier 959\n",
      "top 1249:  \toutlier 286 \t not outlier 963\n",
      "top 1250:  \toutlier 287 \t not outlier 963\n",
      "top 1262:  \toutlier 287 \t not outlier 975\n",
      "top 1268:  \toutlier 293 \t not outlier 975\n",
      "top 1277:  \toutlier 293 \t not outlier 984\n",
      "top 1279:  \toutlier 295 \t not outlier 984\n",
      "top 1284:  \toutlier 295 \t not outlier 989\n",
      "top 1285:  \toutlier 296 \t not outlier 989\n",
      "top 1288:  \toutlier 296 \t not outlier 992\n",
      "top 1290:  \toutlier 298 \t not outlier 992\n",
      "top 1310:  \toutlier 298 \t not outlier 1012\n",
      "top 1313:  \toutlier 301 \t not outlier 1012\n",
      "top 1324:  \toutlier 301 \t not outlier 1023\n",
      "top 1326:  \toutlier 303 \t not outlier 1023\n",
      "top 1334:  \toutlier 303 \t not outlier 1031\n",
      "top 1335:  \toutlier 304 \t not outlier 1031\n",
      "top 1338:  \toutlier 304 \t not outlier 1034\n",
      "top 1340:  \toutlier 306 \t not outlier 1034\n",
      "top 1342:  \toutlier 306 \t not outlier 1036\n",
      "top 1343:  \toutlier 307 \t not outlier 1036\n",
      "top 1346:  \toutlier 307 \t not outlier 1039\n",
      "top 1349:  \toutlier 310 \t not outlier 1039\n",
      "top 1367:  \toutlier 310 \t not outlier 1057\n",
      "top 1371:  \toutlier 314 \t not outlier 1057\n",
      "top 1377:  \toutlier 314 \t not outlier 1063\n",
      "top 1380:  \toutlier 317 \t not outlier 1063\n",
      "top 1392:  \toutlier 317 \t not outlier 1075\n",
      "top 1393:  \toutlier 318 \t not outlier 1075\n",
      "top 1409:  \toutlier 318 \t not outlier 1091\n",
      "top 1411:  \toutlier 320 \t not outlier 1091\n",
      "top 1416:  \toutlier 320 \t not outlier 1096\n",
      "top 1417:  \toutlier 321 \t not outlier 1096\n",
      "top 1418:  \toutlier 321 \t not outlier 1097\n",
      "top 1420:  \toutlier 323 \t not outlier 1097\n",
      "top 1425:  \toutlier 323 \t not outlier 1102\n",
      "top 1428:  \toutlier 326 \t not outlier 1102\n",
      "top 1455:  \toutlier 326 \t not outlier 1129\n",
      "top 1457:  \toutlier 328 \t not outlier 1129\n",
      "top 1472:  \toutlier 328 \t not outlier 1144\n",
      "top 1473:  \toutlier 329 \t not outlier 1144\n",
      "top 1478:  \toutlier 329 \t not outlier 1149\n",
      "top 1480:  \toutlier 331 \t not outlier 1149\n",
      "top 1494:  \toutlier 331 \t not outlier 1163\n",
      "top 1495:  \toutlier 332 \t not outlier 1163\n",
      "top 1508:  \toutlier 332 \t not outlier 1176\n",
      "top 1510:  \toutlier 334 \t not outlier 1176\n",
      "top 1544:  \toutlier 334 \t not outlier 1210\n",
      "top 1545:  \toutlier 335 \t not outlier 1210\n",
      "top 1571:  \toutlier 335 \t not outlier 1236\n",
      "top 1573:  \toutlier 337 \t not outlier 1236\n",
      "top 1582:  \toutlier 337 \t not outlier 1245\n",
      "top 1583:  \toutlier 338 \t not outlier 1245\n",
      "top 1585:  \toutlier 338 \t not outlier 1247\n",
      "top 1589:  \toutlier 342 \t not outlier 1247\n",
      "top 1608:  \toutlier 342 \t not outlier 1266\n",
      "top 1612:  \toutlier 346 \t not outlier 1266\n",
      "top 1617:  \toutlier 346 \t not outlier 1271\n",
      "top 1619:  \toutlier 348 \t not outlier 1271\n",
      "top 1622:  \toutlier 348 \t not outlier 1274\n",
      "top 1623:  \toutlier 349 \t not outlier 1274\n",
      "top 1643:  \toutlier 349 \t not outlier 1294\n",
      "top 1645:  \toutlier 351 \t not outlier 1294\n",
      "top 1648:  \toutlier 351 \t not outlier 1297\n",
      "top 1651:  \toutlier 354 \t not outlier 1297\n",
      "top 1656:  \toutlier 354 \t not outlier 1302\n",
      "top 1658:  \toutlier 356 \t not outlier 1302\n",
      "top 1668:  \toutlier 356 \t not outlier 1312\n",
      "top 1669:  \toutlier 357 \t not outlier 1312\n",
      "top 1672:  \toutlier 357 \t not outlier 1315\n",
      "top 1674:  \toutlier 359 \t not outlier 1315\n",
      "top 1687:  \toutlier 359 \t not outlier 1328\n",
      "top 1688:  \toutlier 360 \t not outlier 1328\n",
      "top 1704:  \toutlier 360 \t not outlier 1344\n",
      "top 1706:  \toutlier 362 \t not outlier 1344\n",
      "top 1720:  \toutlier 362 \t not outlier 1358\n",
      "top 1721:  \toutlier 363 \t not outlier 1358\n",
      "top 1731:  \toutlier 363 \t not outlier 1368\n",
      "top 1734:  \toutlier 366 \t not outlier 1368\n",
      "top 1736:  \toutlier 366 \t not outlier 1370\n",
      "top 1738:  \toutlier 368 \t not outlier 1370\n",
      "top 1739:  \toutlier 368 \t not outlier 1371\n",
      "top 1741:  \toutlier 370 \t not outlier 1371\n",
      "top 1759:  \toutlier 370 \t not outlier 1389\n",
      "top 1760:  \toutlier 371 \t not outlier 1389\n",
      "top 1765:  \toutlier 371 \t not outlier 1394\n",
      "top 1767:  \toutlier 373 \t not outlier 1394\n",
      "top 1773:  \toutlier 373 \t not outlier 1400\n",
      "top 1774:  \toutlier 374 \t not outlier 1400\n",
      "top 1776:  \toutlier 374 \t not outlier 1402\n",
      "top 1778:  \toutlier 376 \t not outlier 1402\n",
      "top 1786:  \toutlier 376 \t not outlier 1410\n",
      "top 1787:  \toutlier 377 \t not outlier 1410\n",
      "top 1793:  \toutlier 377 \t not outlier 1416\n",
      "top 1795:  \toutlier 379 \t not outlier 1416\n",
      "top 1808:  \toutlier 379 \t not outlier 1429\n",
      "top 1809:  \toutlier 380 \t not outlier 1429\n",
      "top 1814:  \toutlier 380 \t not outlier 1434\n",
      "top 1818:  \toutlier 384 \t not outlier 1434\n",
      "top 1824:  \toutlier 384 \t not outlier 1440\n",
      "top 1825:  \toutlier 385 \t not outlier 1440\n",
      "top 1827:  \toutlier 385 \t not outlier 1442\n",
      "top 1829:  \toutlier 387 \t not outlier 1442\n",
      "top 1831:  \toutlier 387 \t not outlier 1444\n",
      "top 1837:  \toutlier 393 \t not outlier 1444\n",
      "top 1838:  \toutlier 393 \t not outlier 1445\n",
      "top 1839:  \toutlier 394 \t not outlier 1445\n",
      "top 1851:  \toutlier 394 \t not outlier 1457\n",
      "top 1853:  \toutlier 396 \t not outlier 1457\n",
      "top 1859:  \toutlier 396 \t not outlier 1463\n",
      "top 1860:  \toutlier 397 \t not outlier 1463\n",
      "top 1866:  \toutlier 397 \t not outlier 1469\n",
      "top 1868:  \toutlier 399 \t not outlier 1469\n",
      "top 1877:  \toutlier 399 \t not outlier 1478\n",
      "top 1880:  \toutlier 402 \t not outlier 1478\n",
      "top 1881:  \toutlier 402 \t not outlier 1479\n",
      "top 1883:  \toutlier 404 \t not outlier 1479\n",
      "top 1886:  \toutlier 404 \t not outlier 1482\n",
      "top 1887:  \toutlier 405 \t not outlier 1482\n",
      "top 1929:  \toutlier 405 \t not outlier 1524\n",
      "top 1931:  \toutlier 407 \t not outlier 1524\n",
      "top 1944:  \toutlier 407 \t not outlier 1537\n",
      "top 1945:  \toutlier 408 \t not outlier 1537\n",
      "top 1968:  \toutlier 408 \t not outlier 1560\n",
      "top 1970:  \toutlier 410 \t not outlier 1560\n",
      "top 1992:  \toutlier 410 \t not outlier 1582\n",
      "top 1993:  \toutlier 411 \t not outlier 1582\n",
      "top 1997:  \toutlier 411 \t not outlier 1586\n",
      "top 1999:  \toutlier 413 \t not outlier 1586\n",
      "top 2018:  \toutlier 413 \t not outlier 1605\n",
      "top 2023:  \toutlier 418 \t not outlier 1605\n",
      "top 2050:  \toutlier 418 \t not outlier 1632\n",
      "top 2051:  \toutlier 419 \t not outlier 1632\n",
      "top 2053:  \toutlier 419 \t not outlier 1634\n",
      "top 2055:  \toutlier 421 \t not outlier 1634\n",
      "top 2060:  \toutlier 421 \t not outlier 1639\n",
      "top 2061:  \toutlier 422 \t not outlier 1639\n",
      "top 2078:  \toutlier 422 \t not outlier 1656\n",
      "top 2081:  \toutlier 425 \t not outlier 1656\n",
      "top 2088:  \toutlier 425 \t not outlier 1663\n",
      "top 2093:  \toutlier 430 \t not outlier 1663\n",
      "top 2117:  \toutlier 430 \t not outlier 1687\n",
      "top 2120:  \toutlier 433 \t not outlier 1687\n",
      "top 2122:  \toutlier 433 \t not outlier 1689\n",
      "top 2124:  \toutlier 435 \t not outlier 1689\n",
      "top 2132:  \toutlier 435 \t not outlier 1697\n",
      "top 2133:  \toutlier 436 \t not outlier 1697\n",
      "top 2139:  \toutlier 436 \t not outlier 1703\n",
      "top 2141:  \toutlier 438 \t not outlier 1703\n",
      "top 2164:  \toutlier 438 \t not outlier 1726\n",
      "top 2165:  \toutlier 439 \t not outlier 1726\n",
      "top 2179:  \toutlier 439 \t not outlier 1740\n",
      "top 2181:  \toutlier 441 \t not outlier 1740\n",
      "top 2196:  \toutlier 441 \t not outlier 1755\n",
      "top 2198:  \toutlier 443 \t not outlier 1755\n",
      "top 2209:  \toutlier 443 \t not outlier 1766\n",
      "top 2210:  \toutlier 444 \t not outlier 1766\n",
      "top 2215:  \toutlier 444 \t not outlier 1771\n",
      "top 2217:  \toutlier 446 \t not outlier 1771\n",
      "top 2228:  \toutlier 446 \t not outlier 1782\n",
      "top 2229:  \toutlier 447 \t not outlier 1782\n",
      "top 2302:  \toutlier 447 \t not outlier 1855\n",
      "top 2304:  \toutlier 449 \t not outlier 1855\n",
      "top 2323:  \toutlier 449 \t not outlier 1874\n",
      "top 2324:  \toutlier 450 \t not outlier 1874\n",
      "top 2339:  \toutlier 450 \t not outlier 1889\n",
      "top 2341:  \toutlier 452 \t not outlier 1889\n",
      "top 2352:  \toutlier 452 \t not outlier 1900\n",
      "top 2353:  \toutlier 453 \t not outlier 1900\n",
      "top 2358:  \toutlier 453 \t not outlier 1905\n",
      "top 2360:  \toutlier 455 \t not outlier 1905\n",
      "top 2382:  \toutlier 455 \t not outlier 1927\n",
      "top 2385:  \toutlier 458 \t not outlier 1927\n",
      "top 2395:  \toutlier 458 \t not outlier 1937\n",
      "top 2397:  \toutlier 460 \t not outlier 1937\n",
      "top 2400:  \toutlier 460 \t not outlier 1940\n",
      "top 2401:  \toutlier 461 \t not outlier 1940\n",
      "top 2430:  \toutlier 461 \t not outlier 1969\n",
      "top 2432:  \toutlier 463 \t not outlier 1969\n",
      "top 2439:  \toutlier 463 \t not outlier 1976\n",
      "top 2440:  \toutlier 464 \t not outlier 1976\n",
      "top 2443:  \toutlier 464 \t not outlier 1979\n",
      "top 2445:  \toutlier 466 \t not outlier 1979\n",
      "top 2446:  \toutlier 466 \t not outlier 1980\n",
      "top 2447:  \toutlier 467 \t not outlier 1980\n",
      "top 2449:  \toutlier 467 \t not outlier 1982\n",
      "top 2451:  \toutlier 469 \t not outlier 1982\n",
      "top 2453:  \toutlier 469 \t not outlier 1984\n",
      "top 2455:  \toutlier 471 \t not outlier 1984\n",
      "top 2471:  \toutlier 471 \t not outlier 2000\n",
      "top 2472:  \toutlier 472 \t not outlier 2000\n",
      "top 2489:  \toutlier 472 \t not outlier 2017\n",
      "top 2492:  \toutlier 475 \t not outlier 2017\n",
      "top 2497:  \toutlier 475 \t not outlier 2022\n",
      "top 2500:  \toutlier 478 \t not outlier 2022\n",
      "top 2508:  \toutlier 478 \t not outlier 2030\n",
      "top 2510:  \toutlier 480 \t not outlier 2030\n",
      "top 2512:  \toutlier 480 \t not outlier 2032\n",
      "top 2513:  \toutlier 481 \t not outlier 2032\n",
      "top 2519:  \toutlier 481 \t not outlier 2038\n",
      "top 2521:  \toutlier 483 \t not outlier 2038\n",
      "top 2549:  \toutlier 483 \t not outlier 2066\n",
      "top 2551:  \toutlier 485 \t not outlier 2066\n",
      "top 2581:  \toutlier 485 \t not outlier 2096\n",
      "top 2582:  \toutlier 486 \t not outlier 2096\n",
      "top 2587:  \toutlier 486 \t not outlier 2101\n",
      "top 2592:  \toutlier 491 \t not outlier 2101\n",
      "top 2602:  \toutlier 491 \t not outlier 2111\n",
      "top 2603:  \toutlier 492 \t not outlier 2111\n",
      "top 2627:  \toutlier 492 \t not outlier 2135\n",
      "top 2629:  \toutlier 494 \t not outlier 2135\n",
      "top 2647:  \toutlier 494 \t not outlier 2153\n",
      "top 2648:  \toutlier 495 \t not outlier 2153\n",
      "top 2680:  \toutlier 495 \t not outlier 2185\n",
      "top 2682:  \toutlier 497 \t not outlier 2185\n",
      "top 2697:  \toutlier 497 \t not outlier 2200\n",
      "top 2699:  \toutlier 499 \t not outlier 2200\n",
      "top 2703:  \toutlier 499 \t not outlier 2204\n",
      "top 2704:  \toutlier 500 \t not outlier 2204\n",
      "top 2717:  \toutlier 500 \t not outlier 2217\n",
      "top 2719:  \toutlier 502 \t not outlier 2217\n",
      "top 2723:  \toutlier 502 \t not outlier 2221\n",
      "top 2724:  \toutlier 503 \t not outlier 2221\n",
      "top 2738:  \toutlier 503 \t not outlier 2235\n",
      "top 2740:  \toutlier 505 \t not outlier 2235\n",
      "top 2747:  \toutlier 505 \t not outlier 2242\n",
      "top 2748:  \toutlier 506 \t not outlier 2242\n",
      "top 2764:  \toutlier 506 \t not outlier 2258\n",
      "top 2766:  \toutlier 508 \t not outlier 2258\n",
      "top 2785:  \toutlier 508 \t not outlier 2277\n",
      "top 2786:  \toutlier 509 \t not outlier 2277\n",
      "top 2809:  \toutlier 509 \t not outlier 2300\n",
      "top 2811:  \toutlier 511 \t not outlier 2300\n",
      "top 2835:  \toutlier 511 \t not outlier 2324\n",
      "top 2837:  \toutlier 513 \t not outlier 2324\n",
      "top 2863:  \toutlier 513 \t not outlier 2350\n",
      "top 2864:  \toutlier 514 \t not outlier 2350\n",
      "top 2865:  \toutlier 514 \t not outlier 2351\n",
      "top 2867:  \toutlier 516 \t not outlier 2351\n",
      "top 2880:  \toutlier 516 \t not outlier 2364\n",
      "top 2881:  \toutlier 517 \t not outlier 2364\n",
      "top 2925:  \toutlier 517 \t not outlier 2408\n",
      "top 2927:  \toutlier 519 \t not outlier 2408\n",
      "top 2930:  \toutlier 519 \t not outlier 2411\n",
      "top 2931:  \toutlier 520 \t not outlier 2411\n",
      "top 2932:  \toutlier 520 \t not outlier 2412\n",
      "top 2934:  \toutlier 522 \t not outlier 2412\n",
      "top 2955:  \toutlier 522 \t not outlier 2433\n",
      "top 2958:  \toutlier 525 \t not outlier 2433\n",
      "top 2974:  \toutlier 525 \t not outlier 2449\n",
      "top 2976:  \toutlier 527 \t not outlier 2449\n",
      "top 3002:  \toutlier 527 \t not outlier 2475\n",
      "top 3003:  \toutlier 528 \t not outlier 2475\n",
      "top 3039:  \toutlier 528 \t not outlier 2511\n",
      "top 3041:  \toutlier 530 \t not outlier 2511\n",
      "top 3046:  \toutlier 530 \t not outlier 2516\n",
      "top 3047:  \toutlier 531 \t not outlier 2516\n",
      "top 3056:  \toutlier 531 \t not outlier 2525\n",
      "top 3058:  \toutlier 533 \t not outlier 2525\n",
      "top 3086:  \toutlier 533 \t not outlier 2553\n",
      "top 3087:  \toutlier 534 \t not outlier 2553\n",
      "top 3096:  \toutlier 534 \t not outlier 2562\n",
      "top 3099:  \toutlier 537 \t not outlier 2562\n",
      "top 3122:  \toutlier 537 \t not outlier 2585\n",
      "top 3124:  \toutlier 539 \t not outlier 2585\n",
      "top 3156:  \toutlier 539 \t not outlier 2617\n",
      "top 3158:  \toutlier 541 \t not outlier 2617\n",
      "top 3181:  \toutlier 541 \t not outlier 2640\n",
      "top 3182:  \toutlier 542 \t not outlier 2640\n",
      "top 3198:  \toutlier 542 \t not outlier 2656\n",
      "top 3200:  \toutlier 544 \t not outlier 2656\n",
      "top 3337:  \toutlier 544 \t not outlier 2793\n",
      "top 3338:  \toutlier 545 \t not outlier 2793\n",
      "top 3375:  \toutlier 545 \t not outlier 2830\n",
      "top 3377:  \toutlier 547 \t not outlier 2830\n",
      "top 3382:  \toutlier 547 \t not outlier 2835\n",
      "top 3383:  \toutlier 548 \t not outlier 2835\n",
      "top 3386:  \toutlier 548 \t not outlier 2838\n",
      "top 3389:  \toutlier 551 \t not outlier 2838\n",
      "top 3392:  \toutlier 551 \t not outlier 2841\n",
      "top 3394:  \toutlier 553 \t not outlier 2841\n",
      "top 3404:  \toutlier 553 \t not outlier 2851\n",
      "top 3406:  \toutlier 555 \t not outlier 2851\n",
      "top 3419:  \toutlier 555 \t not outlier 2864\n",
      "top 3420:  \toutlier 556 \t not outlier 2864\n",
      "top 3460:  \toutlier 556 \t not outlier 2904\n",
      "top 3462:  \toutlier 558 \t not outlier 2904\n",
      "top 3504:  \toutlier 558 \t not outlier 2946\n",
      "top 3505:  \toutlier 559 \t not outlier 2946\n",
      "top 3521:  \toutlier 559 \t not outlier 2962\n",
      "top 3523:  \toutlier 561 \t not outlier 2962\n",
      "top 3536:  \toutlier 561 \t not outlier 2975\n",
      "top 3537:  \toutlier 562 \t not outlier 2975\n",
      "top 3661:  \toutlier 562 \t not outlier 3099\n",
      "top 3663:  \toutlier 564 \t not outlier 3099\n",
      "top 3681:  \toutlier 564 \t not outlier 3117\n",
      "top 3682:  \toutlier 565 \t not outlier 3117\n",
      "top 3730:  \toutlier 565 \t not outlier 3165\n",
      "top 3732:  \toutlier 567 \t not outlier 3165\n",
      "top 3743:  \toutlier 567 \t not outlier 3176\n",
      "top 3745:  \toutlier 569 \t not outlier 3176\n",
      "top 3747:  \toutlier 569 \t not outlier 3178\n",
      "top 3748:  \toutlier 570 \t not outlier 3178\n",
      "top 3756:  \toutlier 570 \t not outlier 3186\n",
      "top 3758:  \toutlier 572 \t not outlier 3186\n",
      "top 3855:  \toutlier 572 \t not outlier 3283\n",
      "top 3856:  \toutlier 573 \t not outlier 3283\n",
      "top 3865:  \toutlier 573 \t not outlier 3292\n",
      "top 3867:  \toutlier 575 \t not outlier 3292\n",
      "top 3885:  \toutlier 575 \t not outlier 3310\n",
      "top 3886:  \toutlier 576 \t not outlier 3310\n",
      "top 3964:  \toutlier 576 \t not outlier 3388\n",
      "top 3966:  \toutlier 578 \t not outlier 3388\n",
      "top 3978:  \toutlier 578 \t not outlier 3400\n",
      "top 3979:  \toutlier 579 \t not outlier 3400\n",
      "top 3981:  \toutlier 579 \t not outlier 3402\n",
      "top 3983:  \toutlier 581 \t not outlier 3402\n",
      "top 3994:  \toutlier 581 \t not outlier 3413\n",
      "top 3995:  \toutlier 582 \t not outlier 3413\n",
      "top 4021:  \toutlier 582 \t not outlier 3439\n",
      "top 4023:  \toutlier 584 \t not outlier 3439\n",
      "top 4025:  \toutlier 584 \t not outlier 3441\n",
      "top 4027:  \toutlier 586 \t not outlier 3441\n",
      "top 4030:  \toutlier 586 \t not outlier 3444\n",
      "top 4031:  \toutlier 587 \t not outlier 3444\n",
      "top 4036:  \toutlier 587 \t not outlier 3449\n",
      "top 4039:  \toutlier 590 \t not outlier 3449\n",
      "top 4065:  \toutlier 590 \t not outlier 3475\n",
      "top 4067:  \toutlier 592 \t not outlier 3475\n",
      "top 4073:  \toutlier 592 \t not outlier 3481\n",
      "top 4074:  \toutlier 593 \t not outlier 3481\n",
      "top 4079:  \toutlier 593 \t not outlier 3486\n",
      "top 4082:  \toutlier 596 \t not outlier 3486\n",
      "top 4148:  \toutlier 596 \t not outlier 3552\n",
      "top 4150:  \toutlier 598 \t not outlier 3552\n",
      "top 4168:  \toutlier 598 \t not outlier 3570\n",
      "top 4170:  \toutlier 600 \t not outlier 3570\n",
      "top 4195:  \toutlier 600 \t not outlier 3595\n",
      "top 4196:  \toutlier 601 \t not outlier 3595\n",
      "top 4208:  \toutlier 601 \t not outlier 3607\n",
      "top 4210:  \toutlier 603 \t not outlier 3607\n",
      "top 4211:  \toutlier 603 \t not outlier 3608\n",
      "top 4212:  \toutlier 604 \t not outlier 3608\n",
      "top 4230:  \toutlier 604 \t not outlier 3626\n",
      "top 4232:  \toutlier 606 \t not outlier 3626\n",
      "top 4239:  \toutlier 606 \t not outlier 3633\n",
      "top 4240:  \toutlier 607 \t not outlier 3633\n",
      "top 4262:  \toutlier 607 \t not outlier 3655\n",
      "top 4264:  \toutlier 609 \t not outlier 3655\n",
      "top 4295:  \toutlier 609 \t not outlier 3686\n",
      "top 4296:  \toutlier 610 \t not outlier 3686\n",
      "top 4313:  \toutlier 610 \t not outlier 3703\n",
      "top 4315:  \toutlier 612 \t not outlier 3703\n",
      "top 4324:  \toutlier 612 \t not outlier 3712\n",
      "top 4326:  \toutlier 614 \t not outlier 3712\n",
      "top 4413:  \toutlier 614 \t not outlier 3799\n",
      "top 4414:  \toutlier 615 \t not outlier 3799\n",
      "top 4436:  \toutlier 615 \t not outlier 3821\n",
      "top 4438:  \toutlier 617 \t not outlier 3821\n",
      "top 4440:  \toutlier 617 \t not outlier 3823\n",
      "top 4443:  \toutlier 620 \t not outlier 3823\n",
      "top 4446:  \toutlier 620 \t not outlier 3826\n",
      "top 4447:  \toutlier 621 \t not outlier 3826\n",
      "top 4460:  \toutlier 621 \t not outlier 3839\n",
      "top 4462:  \toutlier 623 \t not outlier 3839\n",
      "top 4472:  \toutlier 623 \t not outlier 3849\n",
      "top 4473:  \toutlier 624 \t not outlier 3849\n",
      "top 4479:  \toutlier 624 \t not outlier 3855\n",
      "top 4481:  \toutlier 626 \t not outlier 3855\n",
      "top 4484:  \toutlier 626 \t not outlier 3858\n",
      "top 4486:  \toutlier 628 \t not outlier 3858\n",
      "top 4547:  \toutlier 628 \t not outlier 3919\n",
      "top 4548:  \toutlier 629 \t not outlier 3919\n",
      "top 4561:  \toutlier 629 \t not outlier 3932\n",
      "top 4563:  \toutlier 631 \t not outlier 3932\n",
      "top 4571:  \toutlier 631 \t not outlier 3940\n",
      "top 4572:  \toutlier 632 \t not outlier 3940\n",
      "top 4590:  \toutlier 632 \t not outlier 3958\n",
      "top 4592:  \toutlier 634 \t not outlier 3958\n",
      "top 4595:  \toutlier 634 \t not outlier 3961\n",
      "top 4596:  \toutlier 635 \t not outlier 3961\n",
      "top 4621:  \toutlier 635 \t not outlier 3986\n",
      "top 4623:  \toutlier 637 \t not outlier 3986\n",
      "top 4643:  \toutlier 637 \t not outlier 4006\n",
      "top 4644:  \toutlier 638 \t not outlier 4006\n",
      "top 4651:  \toutlier 638 \t not outlier 4013\n",
      "top 4653:  \toutlier 640 \t not outlier 4013\n",
      "top 4656:  \toutlier 640 \t not outlier 4016\n",
      "top 4658:  \toutlier 642 \t not outlier 4016\n",
      "top 4663:  \toutlier 642 \t not outlier 4021\n",
      "top 4664:  \toutlier 643 \t not outlier 4021\n",
      "top 4677:  \toutlier 643 \t not outlier 4034\n",
      "top 4679:  \toutlier 645 \t not outlier 4034\n",
      "top 4751:  \toutlier 645 \t not outlier 4106\n",
      "top 4752:  \toutlier 646 \t not outlier 4106\n",
      "top 4760:  \toutlier 646 \t not outlier 4114\n",
      "top 4762:  \toutlier 648 \t not outlier 4114\n",
      "top 4772:  \toutlier 648 \t not outlier 4124\n",
      "top 4773:  \toutlier 649 \t not outlier 4124\n",
      "top 4802:  \toutlier 649 \t not outlier 4153\n",
      "top 4804:  \toutlier 651 \t not outlier 4153\n",
      "top 4835:  \toutlier 651 \t not outlier 4184\n",
      "top 4836:  \toutlier 652 \t not outlier 4184\n",
      "top 4978:  \toutlier 652 \t not outlier 4326\n",
      "top 4980:  \toutlier 654 \t not outlier 4326\n",
      "top 5010:  \toutlier 654 \t not outlier 4356\n",
      "top 5012:  \toutlier 656 \t not outlier 4356\n",
      "top 5014:  \toutlier 656 \t not outlier 4358\n",
      "top 5015:  \toutlier 657 \t not outlier 4358\n",
      "top 5021:  \toutlier 657 \t not outlier 4364\n",
      "top 5023:  \toutlier 659 \t not outlier 4364\n",
      "top 5049:  \toutlier 659 \t not outlier 4390\n",
      "top 5050:  \toutlier 660 \t not outlier 4390\n",
      "top 5052:  \toutlier 660 \t not outlier 4392\n",
      "top 5054:  \toutlier 662 \t not outlier 4392\n",
      "top 5076:  \toutlier 662 \t not outlier 4414\n",
      "top 5077:  \toutlier 663 \t not outlier 4414\n",
      "top 5082:  \toutlier 663 \t not outlier 4419\n",
      "top 5084:  \toutlier 665 \t not outlier 4419\n",
      "top 5091:  \toutlier 665 \t not outlier 4426\n",
      "top 5092:  \toutlier 666 \t not outlier 4426\n",
      "top 5141:  \toutlier 666 \t not outlier 4475\n",
      "top 5143:  \toutlier 668 \t not outlier 4475\n",
      "top 5158:  \toutlier 668 \t not outlier 4490\n",
      "top 5160:  \toutlier 670 \t not outlier 4490\n",
      "top 5162:  \toutlier 670 \t not outlier 4492\n",
      "top 5163:  \toutlier 671 \t not outlier 4492\n",
      "top 5172:  \toutlier 671 \t not outlier 4501\n",
      "top 5174:  \toutlier 673 \t not outlier 4501\n",
      "top 5181:  \toutlier 673 \t not outlier 4508\n",
      "top 5182:  \toutlier 674 \t not outlier 4508\n",
      "top 5233:  \toutlier 674 \t not outlier 4559\n",
      "top 5235:  \toutlier 676 \t not outlier 4559\n",
      "top 5239:  \toutlier 676 \t not outlier 4563\n",
      "top 5240:  \toutlier 677 \t not outlier 4563\n",
      "top 5298:  \toutlier 677 \t not outlier 4621\n",
      "top 5300:  \toutlier 679 \t not outlier 4621\n",
      "top 5311:  \toutlier 679 \t not outlier 4632\n",
      "top 5312:  \toutlier 680 \t not outlier 4632\n",
      "top 5370:  \toutlier 680 \t not outlier 4690\n",
      "top 5372:  \toutlier 682 \t not outlier 4690\n",
      "top 5378:  \toutlier 682 \t not outlier 4696\n",
      "top 5380:  \toutlier 684 \t not outlier 4696\n",
      "top 5384:  \toutlier 684 \t not outlier 4700\n",
      "top 5385:  \toutlier 685 \t not outlier 4700\n",
      "top 5467:  \toutlier 685 \t not outlier 4782\n",
      "top 5469:  \toutlier 687 \t not outlier 4782\n",
      "top 5472:  \toutlier 687 \t not outlier 4785\n",
      "top 5473:  \toutlier 688 \t not outlier 4785\n",
      "top 5486:  \toutlier 688 \t not outlier 4798\n",
      "top 5488:  \toutlier 690 \t not outlier 4798\n",
      "top 5518:  \toutlier 690 \t not outlier 4828\n",
      "top 5519:  \toutlier 691 \t not outlier 4828\n",
      "top 5539:  \toutlier 691 \t not outlier 4848\n",
      "top 5541:  \toutlier 693 \t not outlier 4848\n",
      "top 5613:  \toutlier 693 \t not outlier 4920\n",
      "top 5616:  \toutlier 696 \t not outlier 4920\n",
      "top 5634:  \toutlier 696 \t not outlier 4938\n",
      "top 5636:  \toutlier 698 \t not outlier 4938\n",
      "top 5665:  \toutlier 698 \t not outlier 4967\n",
      "top 5666:  \toutlier 699 \t not outlier 4967\n",
      "top 5734:  \toutlier 699 \t not outlier 5035\n",
      "top 5736:  \toutlier 701 \t not outlier 5035\n",
      "top 5739:  \toutlier 701 \t not outlier 5038\n",
      "top 5740:  \toutlier 702 \t not outlier 5038\n",
      "top 5748:  \toutlier 702 \t not outlier 5046\n",
      "top 5750:  \toutlier 704 \t not outlier 5046\n",
      "top 5774:  \toutlier 704 \t not outlier 5070\n",
      "top 5775:  \toutlier 705 \t not outlier 5070\n",
      "top 5783:  \toutlier 705 \t not outlier 5078\n",
      "top 5785:  \toutlier 707 \t not outlier 5078\n",
      "top 5818:  \toutlier 707 \t not outlier 5111\n",
      "top 5819:  \toutlier 708 \t not outlier 5111\n",
      "top 5869:  \toutlier 708 \t not outlier 5161\n",
      "top 5871:  \toutlier 710 \t not outlier 5161\n",
      "top 5879:  \toutlier 710 \t not outlier 5169\n",
      "top 5881:  \toutlier 712 \t not outlier 5169\n",
      "top 5943:  \toutlier 712 \t not outlier 5231\n",
      "top 5944:  \toutlier 713 \t not outlier 5231\n",
      "top 5949:  \toutlier 713 \t not outlier 5236\n",
      "top 5952:  \toutlier 716 \t not outlier 5236\n",
      "top 5959:  \toutlier 716 \t not outlier 5243\n",
      "top 5961:  \toutlier 718 \t not outlier 5243\n",
      "top 6004:  \toutlier 718 \t not outlier 5286\n",
      "top 6005:  \toutlier 719 \t not outlier 5286\n",
      "top 6012:  \toutlier 719 \t not outlier 5293\n",
      "top 6014:  \toutlier 721 \t not outlier 5293\n",
      "top 6115:  \toutlier 721 \t not outlier 5394\n",
      "top 6116:  \toutlier 722 \t not outlier 5394\n",
      "top 6119:  \toutlier 722 \t not outlier 5397\n",
      "top 6121:  \toutlier 724 \t not outlier 5397\n",
      "top 6221:  \toutlier 724 \t not outlier 5497\n",
      "top 6223:  \toutlier 726 \t not outlier 5497\n",
      "top 6231:  \toutlier 726 \t not outlier 5505\n",
      "top 6232:  \toutlier 727 \t not outlier 5505\n",
      "top 6261:  \toutlier 727 \t not outlier 5534\n",
      "top 6264:  \toutlier 730 \t not outlier 5534\n",
      "top 6318:  \toutlier 730 \t not outlier 5588\n",
      "top 6320:  \toutlier 732 \t not outlier 5588\n",
      "top 6344:  \toutlier 732 \t not outlier 5612\n",
      "top 6345:  \toutlier 733 \t not outlier 5612\n",
      "top 6353:  \toutlier 733 \t not outlier 5620\n",
      "top 6355:  \toutlier 735 \t not outlier 5620\n",
      "top 6358:  \toutlier 735 \t not outlier 5623\n",
      "top 6359:  \toutlier 736 \t not outlier 5623\n",
      "top 6454:  \toutlier 736 \t not outlier 5718\n",
      "top 6456:  \toutlier 738 \t not outlier 5718\n",
      "top 6464:  \toutlier 738 \t not outlier 5726\n",
      "top 6466:  \toutlier 740 \t not outlier 5726\n",
      "top 6486:  \toutlier 740 \t not outlier 5746\n",
      "top 6487:  \toutlier 741 \t not outlier 5746\n",
      "top 6509:  \toutlier 741 \t not outlier 5768\n",
      "top 6511:  \toutlier 743 \t not outlier 5768\n",
      "top 6561:  \toutlier 743 \t not outlier 5818\n",
      "top 6562:  \toutlier 744 \t not outlier 5818\n",
      "top 6598:  \toutlier 744 \t not outlier 5854\n",
      "top 6600:  \toutlier 746 \t not outlier 5854\n",
      "top 6693:  \toutlier 746 \t not outlier 5947\n",
      "top 6694:  \toutlier 747 \t not outlier 5947\n",
      "top 6812:  \toutlier 747 \t not outlier 6065\n",
      "top 6814:  \toutlier 749 \t not outlier 6065\n",
      "top 6838:  \toutlier 749 \t not outlier 6089\n",
      "top 6839:  \toutlier 750 \t not outlier 6089\n",
      "top 6845:  \toutlier 750 \t not outlier 6095\n",
      "top 6849:  \toutlier 754 \t not outlier 6095\n",
      "top 6886:  \toutlier 754 \t not outlier 6132\n",
      "top 6887:  \toutlier 755 \t not outlier 6132\n",
      "top 6916:  \toutlier 755 \t not outlier 6161\n",
      "top 6918:  \toutlier 757 \t not outlier 6161\n",
      "top 6936:  \toutlier 757 \t not outlier 6179\n",
      "top 6937:  \toutlier 758 \t not outlier 6179\n",
      "top 6942:  \toutlier 758 \t not outlier 6184\n",
      "top 6944:  \toutlier 760 \t not outlier 6184\n",
      "top 6983:  \toutlier 760 \t not outlier 6223\n",
      "top 6984:  \toutlier 761 \t not outlier 6223\n",
      "top 6995:  \toutlier 761 \t not outlier 6234\n",
      "top 6997:  \toutlier 763 \t not outlier 6234\n",
      "top 7010:  \toutlier 763 \t not outlier 6247\n",
      "top 7011:  \toutlier 764 \t not outlier 6247\n",
      "top 7037:  \toutlier 764 \t not outlier 6273\n",
      "top 7039:  \toutlier 766 \t not outlier 6273\n",
      "top 7053:  \toutlier 766 \t not outlier 6287\n",
      "top 7055:  \toutlier 768 \t not outlier 6287\n",
      "top 7065:  \toutlier 768 \t not outlier 6297\n",
      "top 7066:  \toutlier 769 \t not outlier 6297\n",
      "top 7109:  \toutlier 769 \t not outlier 6340\n",
      "top 7111:  \toutlier 771 \t not outlier 6340\n",
      "top 7163:  \toutlier 771 \t not outlier 6392\n",
      "top 7164:  \toutlier 772 \t not outlier 6392\n",
      "top 7175:  \toutlier 772 \t not outlier 6403\n",
      "top 7177:  \toutlier 774 \t not outlier 6403\n",
      "top 7180:  \toutlier 774 \t not outlier 6406\n",
      "top 7181:  \toutlier 775 \t not outlier 6406\n",
      "top 7193:  \toutlier 775 \t not outlier 6418\n",
      "top 7195:  \toutlier 777 \t not outlier 6418\n",
      "top 7241:  \toutlier 777 \t not outlier 6464\n",
      "top 7242:  \toutlier 778 \t not outlier 6464\n",
      "top 7326:  \toutlier 778 \t not outlier 6548\n",
      "top 7328:  \toutlier 780 \t not outlier 6548\n",
      "top 7365:  \toutlier 780 \t not outlier 6585\n",
      "top 7366:  \toutlier 781 \t not outlier 6585\n",
      "top 7400:  \toutlier 781 \t not outlier 6619\n",
      "top 7402:  \toutlier 783 \t not outlier 6619\n",
      "top 7462:  \toutlier 783 \t not outlier 6679\n",
      "top 7464:  \toutlier 785 \t not outlier 6679\n",
      "top 7467:  \toutlier 785 \t not outlier 6682\n",
      "top 7468:  \toutlier 786 \t not outlier 6682\n",
      "top 7505:  \toutlier 786 \t not outlier 6719\n",
      "top 7507:  \toutlier 788 \t not outlier 6719\n",
      "top 7515:  \toutlier 788 \t not outlier 6727\n",
      "top 7516:  \toutlier 789 \t not outlier 6727\n",
      "top 7529:  \toutlier 789 \t not outlier 6740\n",
      "top 7531:  \toutlier 791 \t not outlier 6740\n",
      "top 7542:  \toutlier 791 \t not outlier 6751\n",
      "top 7543:  \toutlier 792 \t not outlier 6751\n",
      "top 7558:  \toutlier 792 \t not outlier 6766\n",
      "top 7560:  \toutlier 794 \t not outlier 6766\n",
      "top 7595:  \toutlier 794 \t not outlier 6801\n",
      "top 7596:  \toutlier 795 \t not outlier 6801\n",
      "top 7614:  \toutlier 795 \t not outlier 6819\n",
      "top 7616:  \toutlier 797 \t not outlier 6819\n",
      "top 7653:  \toutlier 797 \t not outlier 6856\n",
      "top 7655:  \toutlier 799 \t not outlier 6856\n",
      "top 7687:  \toutlier 799 \t not outlier 6888\n",
      "top 7688:  \toutlier 800 \t not outlier 6888\n",
      "top 7774:  \toutlier 800 \t not outlier 6974\n",
      "top 7776:  \toutlier 802 \t not outlier 6974\n",
      "top 7779:  \toutlier 802 \t not outlier 6977\n",
      "top 7780:  \toutlier 803 \t not outlier 6977\n",
      "top 7882:  \toutlier 803 \t not outlier 7079\n",
      "top 7884:  \toutlier 805 \t not outlier 7079\n",
      "top 7925:  \toutlier 805 \t not outlier 7120\n",
      "top 7926:  \toutlier 806 \t not outlier 7120\n",
      "top 8023:  \toutlier 806 \t not outlier 7217\n",
      "top 8025:  \toutlier 808 \t not outlier 7217\n",
      "top 8045:  \toutlier 808 \t not outlier 7237\n",
      "top 8046:  \toutlier 809 \t not outlier 7237\n",
      "top 8115:  \toutlier 809 \t not outlier 7306\n",
      "top 8117:  \toutlier 811 \t not outlier 7306\n",
      "top 8162:  \toutlier 811 \t not outlier 7351\n",
      "top 8164:  \toutlier 813 \t not outlier 7351\n",
      "top 8341:  \toutlier 813 \t not outlier 7528\n",
      "top 8344:  \toutlier 816 \t not outlier 7528\n",
      "top 8426:  \toutlier 816 \t not outlier 7610\n",
      "top 8427:  \toutlier 817 \t not outlier 7610\n",
      "top 8429:  \toutlier 817 \t not outlier 7612\n",
      "top 8431:  \toutlier 819 \t not outlier 7612\n",
      "top 8454:  \toutlier 819 \t not outlier 7635\n",
      "top 8455:  \toutlier 820 \t not outlier 7635\n",
      "top 8477:  \toutlier 820 \t not outlier 7657\n",
      "top 8479:  \toutlier 822 \t not outlier 7657\n",
      "top 8507:  \toutlier 822 \t not outlier 7685\n",
      "top 8508:  \toutlier 823 \t not outlier 7685\n",
      "top 8530:  \toutlier 823 \t not outlier 7707\n",
      "top 8532:  \toutlier 825 \t not outlier 7707\n",
      "top 8572:  \toutlier 825 \t not outlier 7747\n",
      "top 8574:  \toutlier 827 \t not outlier 7747\n",
      "top 8597:  \toutlier 827 \t not outlier 7770\n",
      "top 8598:  \toutlier 828 \t not outlier 7770\n",
      "top 8650:  \toutlier 828 \t not outlier 7822\n",
      "top 8652:  \toutlier 830 \t not outlier 7822\n",
      "top 8671:  \toutlier 830 \t not outlier 7841\n",
      "top 8672:  \toutlier 831 \t not outlier 7841\n",
      "top 8680:  \toutlier 831 \t not outlier 7849\n",
      "top 8682:  \toutlier 833 \t not outlier 7849\n",
      "top 8701:  \toutlier 833 \t not outlier 7868\n",
      "top 8702:  \toutlier 834 \t not outlier 7868\n",
      "top 8730:  \toutlier 834 \t not outlier 7896\n",
      "top 8732:  \toutlier 836 \t not outlier 7896\n",
      "top 8740:  \toutlier 836 \t not outlier 7904\n",
      "top 8741:  \toutlier 837 \t not outlier 7904\n",
      "top 8821:  \toutlier 837 \t not outlier 7984\n",
      "top 8823:  \toutlier 839 \t not outlier 7984\n",
      "top 8841:  \toutlier 839 \t not outlier 8002\n",
      "top 8843:  \toutlier 841 \t not outlier 8002\n",
      "top 8885:  \toutlier 841 \t not outlier 8044\n",
      "top 8886:  \toutlier 842 \t not outlier 8044\n",
      "top 8909:  \toutlier 842 \t not outlier 8067\n",
      "top 8911:  \toutlier 844 \t not outlier 8067\n",
      "top 8957:  \toutlier 844 \t not outlier 8113\n",
      "top 8958:  \toutlier 845 \t not outlier 8113\n",
      "top 9126:  \toutlier 845 \t not outlier 8281\n",
      "top 9128:  \toutlier 847 \t not outlier 8281\n",
      "top 9233:  \toutlier 847 \t not outlier 8386\n",
      "top 9234:  \toutlier 848 \t not outlier 8386\n",
      "top 9253:  \toutlier 848 \t not outlier 8405\n",
      "top 9255:  \toutlier 850 \t not outlier 8405\n",
      "top 9332:  \toutlier 850 \t not outlier 8482\n",
      "top 9333:  \toutlier 851 \t not outlier 8482\n",
      "top 9361:  \toutlier 851 \t not outlier 8510\n",
      "top 9363:  \toutlier 853 \t not outlier 8510\n",
      "top 9476:  \toutlier 853 \t not outlier 8623\n",
      "top 9478:  \toutlier 855 \t not outlier 8623\n",
      "top 9484:  \toutlier 855 \t not outlier 8629\n",
      "top 9485:  \toutlier 856 \t not outlier 8629\n",
      "top 9577:  \toutlier 856 \t not outlier 8721\n",
      "top 9579:  \toutlier 858 \t not outlier 8721\n",
      "top 9584:  \toutlier 858 \t not outlier 8726\n",
      "top 9585:  \toutlier 859 \t not outlier 8726\n",
      "top 9586:  \toutlier 859 \t not outlier 8727\n",
      "top 9588:  \toutlier 861 \t not outlier 8727\n",
      "top 9595:  \toutlier 861 \t not outlier 8734\n",
      "top 9596:  \toutlier 862 \t not outlier 8734\n",
      "top 9660:  \toutlier 862 \t not outlier 8798\n",
      "top 9662:  \toutlier 864 \t not outlier 8798\n",
      "top 9716:  \toutlier 864 \t not outlier 8852\n",
      "top 9717:  \toutlier 865 \t not outlier 8852\n",
      "top 9734:  \toutlier 865 \t not outlier 8869\n",
      "top 9736:  \toutlier 867 \t not outlier 8869\n",
      "top 9904:  \toutlier 867 \t not outlier 9037\n",
      "top 9906:  \toutlier 869 \t not outlier 9037\n",
      "top 9998:  \toutlier 869 \t not outlier 9129\n",
      "top 9999:  \toutlier 870 \t not outlier 9129\n",
      "top 10047:  \toutlier 870 \t not outlier 9177\n",
      "top 10049:  \toutlier 872 \t not outlier 9177\n",
      "top 10051:  \toutlier 872 \t not outlier 9179\n",
      "top 10052:  \toutlier 873 \t not outlier 9179\n",
      "top 10055:  \toutlier 873 \t not outlier 9182\n",
      "top 10057:  \toutlier 875 \t not outlier 9182\n",
      "top 10080:  \toutlier 875 \t not outlier 9205\n",
      "top 10081:  \toutlier 876 \t not outlier 9205\n",
      "top 10097:  \toutlier 876 \t not outlier 9221\n",
      "top 10099:  \toutlier 878 \t not outlier 9221\n",
      "top 10123:  \toutlier 878 \t not outlier 9245\n",
      "top 10124:  \toutlier 879 \t not outlier 9245\n",
      "top 10130:  \toutlier 879 \t not outlier 9251\n",
      "top 10132:  \toutlier 881 \t not outlier 9251\n",
      "top 10140:  \toutlier 881 \t not outlier 9259\n",
      "top 10143:  \toutlier 884 \t not outlier 9259\n",
      "top 10208:  \toutlier 884 \t not outlier 9324\n",
      "top 10210:  \toutlier 886 \t not outlier 9324\n",
      "top 10276:  \toutlier 886 \t not outlier 9390\n",
      "top 10277:  \toutlier 887 \t not outlier 9390\n",
      "top 10301:  \toutlier 887 \t not outlier 9414\n",
      "top 10303:  \toutlier 889 \t not outlier 9414\n",
      "top 10447:  \toutlier 889 \t not outlier 9558\n",
      "top 10448:  \toutlier 890 \t not outlier 9558\n",
      "top 10457:  \toutlier 890 \t not outlier 9567\n",
      "top 10459:  \toutlier 892 \t not outlier 9567\n",
      "top 10462:  \toutlier 892 \t not outlier 9570\n",
      "top 10463:  \toutlier 893 \t not outlier 9570\n",
      "top 10484:  \toutlier 893 \t not outlier 9591\n",
      "top 10486:  \toutlier 895 \t not outlier 9591\n",
      "top 10549:  \toutlier 895 \t not outlier 9654\n",
      "top 10551:  \toutlier 897 \t not outlier 9654\n",
      "top 10596:  \toutlier 897 \t not outlier 9699\n",
      "top 10597:  \toutlier 898 \t not outlier 9699\n",
      "top 10649:  \toutlier 898 \t not outlier 9751\n",
      "top 10651:  \toutlier 900 \t not outlier 9751\n",
      "top 10667:  \toutlier 900 \t not outlier 9767\n",
      "top 10668:  \toutlier 901 \t not outlier 9767\n",
      "top 10736:  \toutlier 901 \t not outlier 9835\n",
      "top 10738:  \toutlier 903 \t not outlier 9835\n",
      "top 10810:  \toutlier 903 \t not outlier 9907\n",
      "top 10811:  \toutlier 904 \t not outlier 9907\n",
      "top 10863:  \toutlier 904 \t not outlier 9959\n",
      "top 10865:  \toutlier 906 \t not outlier 9959\n",
      "top 10886:  \toutlier 906 \t not outlier 9980\n",
      "top 10889:  \toutlier 909 \t not outlier 9980\n",
      "top 10929:  \toutlier 909 \t not outlier 10020\n",
      "top 10931:  \toutlier 911 \t not outlier 10020\n",
      "top 10938:  \toutlier 911 \t not outlier 10027\n",
      "top 10939:  \toutlier 912 \t not outlier 10027\n",
      "top 11288:  \toutlier 912 \t not outlier 10376\n",
      "top 11290:  \toutlier 914 \t not outlier 10376\n",
      "top 11321:  \toutlier 914 \t not outlier 10407\n",
      "top 11322:  \toutlier 915 \t not outlier 10407\n",
      "top 11330:  \toutlier 915 \t not outlier 10415\n",
      "top 11332:  \toutlier 917 \t not outlier 10415\n",
      "top 11472:  \toutlier 917 \t not outlier 10555\n",
      "top 11473:  \toutlier 918 \t not outlier 10555\n",
      "top 11567:  \toutlier 918 \t not outlier 10649\n",
      "top 11569:  \toutlier 920 \t not outlier 10649\n",
      "top 11712:  \toutlier 920 \t not outlier 10792\n",
      "top 11713:  \toutlier 921 \t not outlier 10792\n",
      "top 11729:  \toutlier 921 \t not outlier 10808\n",
      "top 11731:  \toutlier 923 \t not outlier 10808\n",
      "top 11733:  \toutlier 923 \t not outlier 10810\n",
      "top 11735:  \toutlier 925 \t not outlier 10810\n",
      "top 11936:  \toutlier 925 \t not outlier 11011\n",
      "top 11937:  \toutlier 926 \t not outlier 11011\n",
      "top 11970:  \toutlier 926 \t not outlier 11044\n",
      "top 11972:  \toutlier 928 \t not outlier 11044\n",
      "top 12052:  \toutlier 928 \t not outlier 11124\n",
      "top 12053:  \toutlier 929 \t not outlier 11124\n",
      "top 12108:  \toutlier 929 \t not outlier 11179\n",
      "top 12110:  \toutlier 931 \t not outlier 11179\n",
      "top 12200:  \toutlier 931 \t not outlier 11269\n",
      "top 12201:  \toutlier 932 \t not outlier 11269\n",
      "top 12309:  \toutlier 932 \t not outlier 11377\n",
      "top 12311:  \toutlier 934 \t not outlier 11377\n",
      "top 12361:  \toutlier 934 \t not outlier 11427\n",
      "top 12362:  \toutlier 935 \t not outlier 11427\n",
      "top 12396:  \toutlier 935 \t not outlier 11461\n",
      "top 12398:  \toutlier 937 \t not outlier 11461\n",
      "top 12503:  \toutlier 937 \t not outlier 11566\n",
      "top 12505:  \toutlier 939 \t not outlier 11566\n",
      "top 12506:  \toutlier 939 \t not outlier 11567\n",
      "top 12507:  \toutlier 940 \t not outlier 11567\n",
      "top 12625:  \toutlier 940 \t not outlier 11685\n",
      "top 12627:  \toutlier 942 \t not outlier 11685\n",
      "top 12669:  \toutlier 942 \t not outlier 11727\n",
      "top 12672:  \toutlier 945 \t not outlier 11727\n",
      "top 12735:  \toutlier 945 \t not outlier 11790\n",
      "top 12736:  \toutlier 946 \t not outlier 11790\n",
      "top 12757:  \toutlier 946 \t not outlier 11811\n",
      "top 12759:  \toutlier 948 \t not outlier 11811\n",
      "top 12997:  \toutlier 948 \t not outlier 12049\n",
      "top 12998:  \toutlier 949 \t not outlier 12049\n",
      "top 13058:  \toutlier 949 \t not outlier 12109\n",
      "top 13060:  \toutlier 951 \t not outlier 12109\n",
      "top 13234:  \toutlier 951 \t not outlier 12283\n",
      "top 13236:  \toutlier 953 \t not outlier 12283\n",
      "top 13320:  \toutlier 953 \t not outlier 12367\n",
      "top 13321:  \toutlier 954 \t not outlier 12367\n",
      "top 13334:  \toutlier 954 \t not outlier 12380\n",
      "top 13336:  \toutlier 956 \t not outlier 12380\n",
      "top 13355:  \toutlier 956 \t not outlier 12399\n",
      "top 13356:  \toutlier 957 \t not outlier 12399\n",
      "top 13483:  \toutlier 957 \t not outlier 12526\n",
      "top 13485:  \toutlier 959 \t not outlier 12526\n",
      "top 13692:  \toutlier 959 \t not outlier 12733\n",
      "top 13693:  \toutlier 960 \t not outlier 12733\n",
      "top 13735:  \toutlier 960 \t not outlier 12775\n",
      "top 13737:  \toutlier 962 \t not outlier 12775\n",
      "top 13756:  \toutlier 962 \t not outlier 12794\n",
      "top 13757:  \toutlier 963 \t not outlier 12794\n",
      "top 13844:  \toutlier 963 \t not outlier 12881\n",
      "top 13846:  \toutlier 965 \t not outlier 12881\n",
      "top 13970:  \toutlier 965 \t not outlier 13005\n",
      "top 13971:  \toutlier 966 \t not outlier 13005\n",
      "top 14005:  \toutlier 966 \t not outlier 13039\n",
      "top 14007:  \toutlier 968 \t not outlier 13039\n",
      "top 14067:  \toutlier 968 \t not outlier 13099\n",
      "top 14069:  \toutlier 970 \t not outlier 13099\n",
      "top 14115:  \toutlier 970 \t not outlier 13145\n",
      "top 14116:  \toutlier 971 \t not outlier 13145\n",
      "top 14252:  \toutlier 971 \t not outlier 13281\n",
      "top 14254:  \toutlier 973 \t not outlier 13281\n",
      "top 14334:  \toutlier 973 \t not outlier 13361\n",
      "top 14335:  \toutlier 974 \t not outlier 13361\n",
      "top 14356:  \toutlier 974 \t not outlier 13382\n",
      "top 14358:  \toutlier 976 \t not outlier 13382\n",
      "top 14389:  \toutlier 976 \t not outlier 13413\n",
      "top 14390:  \toutlier 977 \t not outlier 13413\n",
      "top 14443:  \toutlier 977 \t not outlier 13466\n",
      "top 14445:  \toutlier 979 \t not outlier 13466\n",
      "top 14619:  \toutlier 979 \t not outlier 13640\n",
      "top 14620:  \toutlier 980 \t not outlier 13640\n",
      "top 14769:  \toutlier 980 \t not outlier 13789\n",
      "top 14771:  \toutlier 982 \t not outlier 13789\n",
      "top 14772:  \toutlier 982 \t not outlier 13790\n",
      "top 14774:  \toutlier 984 \t not outlier 13790\n",
      "top 14800:  \toutlier 984 \t not outlier 13816\n",
      "top 14801:  \toutlier 985 \t not outlier 13816\n",
      "top 14853:  \toutlier 985 \t not outlier 13868\n",
      "top 14855:  \toutlier 987 \t not outlier 13868\n",
      "top 14974:  \toutlier 987 \t not outlier 13987\n",
      "top 14975:  \toutlier 988 \t not outlier 13987\n",
      "top 15060:  \toutlier 988 \t not outlier 14072\n",
      "top 15062:  \toutlier 990 \t not outlier 14072\n",
      "top 15067:  \toutlier 990 \t not outlier 14077\n",
      "top 15068:  \toutlier 991 \t not outlier 14077\n",
      "top 15094:  \toutlier 991 \t not outlier 14103\n",
      "top 15096:  \toutlier 993 \t not outlier 14103\n",
      "top 15097:  \toutlier 993 \t not outlier 14104\n",
      "top 15098:  \toutlier 994 \t not outlier 14104\n",
      "top 15282:  \toutlier 994 \t not outlier 14288\n",
      "top 15284:  \toutlier 996 \t not outlier 14288\n",
      "top 15289:  \toutlier 996 \t not outlier 14293\n",
      "top 15291:  \toutlier 998 \t not outlier 14293\n",
      "top 15499:  \toutlier 998 \t not outlier 14501\n",
      "top 15500:  \toutlier 999 \t not outlier 14501\n",
      "top 15518:  \toutlier 999 \t not outlier 14519\n",
      "top 15520:  \toutlier 1001 \t not outlier 14519\n",
      "top 15545:  \toutlier 1001 \t not outlier 14544\n",
      "top 15546:  \toutlier 1002 \t not outlier 14544\n",
      "top 15742:  \toutlier 1002 \t not outlier 14740\n",
      "top 15744:  \toutlier 1004 \t not outlier 14740\n",
      "top 15810:  \toutlier 1004 \t not outlier 14806\n",
      "top 15811:  \toutlier 1005 \t not outlier 14806\n",
      "top 15904:  \toutlier 1005 \t not outlier 14899\n",
      "top 15906:  \toutlier 1007 \t not outlier 14899\n",
      "top 15921:  \toutlier 1007 \t not outlier 14914\n",
      "top 15922:  \toutlier 1008 \t not outlier 14914\n",
      "top 15957:  \toutlier 1008 \t not outlier 14949\n",
      "top 15959:  \toutlier 1010 \t not outlier 14949\n",
      "top 16385:  \toutlier 1010 \t not outlier 15375\n",
      "top 16387:  \toutlier 1012 \t not outlier 15375\n",
      "top 16408:  \toutlier 1012 \t not outlier 15396\n",
      "top 16409:  \toutlier 1013 \t not outlier 15396\n",
      "top 16645:  \toutlier 1013 \t not outlier 15632\n",
      "top 16647:  \toutlier 1015 \t not outlier 15632\n",
      "top 16651:  \toutlier 1015 \t not outlier 15636\n",
      "top 16652:  \toutlier 1016 \t not outlier 15636\n",
      "top 16695:  \toutlier 1016 \t not outlier 15679\n",
      "top 16697:  \toutlier 1018 \t not outlier 15679\n",
      "top 16783:  \toutlier 1018 \t not outlier 15765\n",
      "top 16784:  \toutlier 1019 \t not outlier 15765\n",
      "top 16819:  \toutlier 1019 \t not outlier 15800\n",
      "top 16821:  \toutlier 1021 \t not outlier 15800\n",
      "top 16848:  \toutlier 1021 \t not outlier 15827\n",
      "top 16849:  \toutlier 1022 \t not outlier 15827\n",
      "top 16917:  \toutlier 1022 \t not outlier 15895\n",
      "top 16919:  \toutlier 1024 \t not outlier 15895\n",
      "top 16942:  \toutlier 1024 \t not outlier 15918\n",
      "top 16944:  \toutlier 1026 \t not outlier 15918\n",
      "top 17013:  \toutlier 1026 \t not outlier 15987\n",
      "top 17014:  \toutlier 1027 \t not outlier 15987\n",
      "top 17177:  \toutlier 1027 \t not outlier 16150\n",
      "top 17179:  \toutlier 1029 \t not outlier 16150\n",
      "top 17332:  \toutlier 1029 \t not outlier 16303\n",
      "top 17333:  \toutlier 1030 \t not outlier 16303\n",
      "top 17431:  \toutlier 1030 \t not outlier 16401\n",
      "top 17433:  \toutlier 1032 \t not outlier 16401\n",
      "top 17445:  \toutlier 1032 \t not outlier 16413\n",
      "top 17446:  \toutlier 1033 \t not outlier 16413\n",
      "top 17508:  \toutlier 1033 \t not outlier 16475\n",
      "top 17510:  \toutlier 1035 \t not outlier 16475\n",
      "top 17581:  \toutlier 1035 \t not outlier 16546\n",
      "top 17582:  \toutlier 1036 \t not outlier 16546\n",
      "top 17607:  \toutlier 1036 \t not outlier 16571\n",
      "top 17609:  \toutlier 1038 \t not outlier 16571\n",
      "top 17620:  \toutlier 1038 \t not outlier 16582\n",
      "top 17622:  \toutlier 1040 \t not outlier 16582\n",
      "top 17678:  \toutlier 1040 \t not outlier 16638\n",
      "top 17679:  \toutlier 1041 \t not outlier 16638\n",
      "top 17958:  \toutlier 1041 \t not outlier 16917\n",
      "top 17960:  \toutlier 1043 \t not outlier 16917\n",
      "top 18004:  \toutlier 1043 \t not outlier 16961\n",
      "top 18005:  \toutlier 1044 \t not outlier 16961\n",
      "top 18225:  \toutlier 1044 \t not outlier 17181\n",
      "top 18227:  \toutlier 1046 \t not outlier 17181\n",
      "top 18247:  \toutlier 1046 \t not outlier 17201\n",
      "top 18248:  \toutlier 1047 \t not outlier 17201\n",
      "top 18383:  \toutlier 1047 \t not outlier 17336\n",
      "top 18385:  \toutlier 1049 \t not outlier 17336\n",
      "top 18529:  \toutlier 1049 \t not outlier 17480\n",
      "top 18530:  \toutlier 1050 \t not outlier 17480\n",
      "top 18573:  \toutlier 1050 \t not outlier 17523\n",
      "top 18575:  \toutlier 1052 \t not outlier 17523\n",
      "top 18719:  \toutlier 1052 \t not outlier 17667\n",
      "top 18721:  \toutlier 1054 \t not outlier 17667\n",
      "top 18840:  \toutlier 1054 \t not outlier 17786\n",
      "top 18841:  \toutlier 1055 \t not outlier 17786\n",
      "top 18967:  \toutlier 1055 \t not outlier 17912\n",
      "top 18969:  \toutlier 1057 \t not outlier 17912\n",
      "top 19089:  \toutlier 1057 \t not outlier 18032\n",
      "top 19090:  \toutlier 1058 \t not outlier 18032\n",
      "top 19651:  \toutlier 1058 \t not outlier 18593\n",
      "top 19653:  \toutlier 1060 \t not outlier 18593\n",
      "top 19731:  \toutlier 1060 \t not outlier 18671\n",
      "top 19732:  \toutlier 1061 \t not outlier 18671\n",
      "top 19774:  \toutlier 1061 \t not outlier 18713\n",
      "top 19776:  \toutlier 1063 \t not outlier 18713\n",
      "top 19888:  \toutlier 1063 \t not outlier 18825\n",
      "top 19889:  \toutlier 1064 \t not outlier 18825\n",
      "top 19951:  \toutlier 1064 \t not outlier 18887\n",
      "top 19953:  \toutlier 1066 \t not outlier 18887\n",
      "top 19961:  \toutlier 1066 \t not outlier 18895\n",
      "top 19963:  \toutlier 1068 \t not outlier 18895\n",
      "top 20005:  \toutlier 1068 \t not outlier 18937\n",
      "top 20006:  \toutlier 1069 \t not outlier 18937\n",
      "top 20112:  \toutlier 1069 \t not outlier 19043\n",
      "top 20114:  \toutlier 1071 \t not outlier 19043\n",
      "top 20251:  \toutlier 1071 \t not outlier 19180\n",
      "top 20252:  \toutlier 1072 \t not outlier 19180\n",
      "top 20431:  \toutlier 1072 \t not outlier 19359\n",
      "top 20433:  \toutlier 1074 \t not outlier 19359\n",
      "top 20749:  \toutlier 1074 \t not outlier 19675\n",
      "top 20750:  \toutlier 1075 \t not outlier 19675\n",
      "top 21056:  \toutlier 1075 \t not outlier 19981\n",
      "top 21058:  \toutlier 1077 \t not outlier 19981\n",
      "top 21106:  \toutlier 1077 \t not outlier 20029\n",
      "top 21107:  \toutlier 1078 \t not outlier 20029\n",
      "top 21215:  \toutlier 1078 \t not outlier 20137\n",
      "top 21217:  \toutlier 1080 \t not outlier 20137\n",
      "top 21482:  \toutlier 1080 \t not outlier 20402\n",
      "top 21484:  \toutlier 1082 \t not outlier 20402\n",
      "top 21489:  \toutlier 1082 \t not outlier 20407\n",
      "top 21490:  \toutlier 1083 \t not outlier 20407\n",
      "top 21672:  \toutlier 1083 \t not outlier 20589\n",
      "top 21674:  \toutlier 1085 \t not outlier 20589\n",
      "top 21700:  \toutlier 1085 \t not outlier 20615\n",
      "top 21701:  \toutlier 1086 \t not outlier 20615\n",
      "top 21741:  \toutlier 1086 \t not outlier 20655\n",
      "top 21743:  \toutlier 1088 \t not outlier 20655\n",
      "top 21782:  \toutlier 1088 \t not outlier 20694\n",
      "top 21783:  \toutlier 1089 \t not outlier 20694\n",
      "top 21786:  \toutlier 1089 \t not outlier 20697\n",
      "top 21788:  \toutlier 1091 \t not outlier 20697\n",
      "top 21947:  \toutlier 1091 \t not outlier 20856\n",
      "top 21948:  \toutlier 1092 \t not outlier 20856\n",
      "top 21997:  \toutlier 1092 \t not outlier 20905\n",
      "top 21999:  \toutlier 1094 \t not outlier 20905\n",
      "top 22071:  \toutlier 1094 \t not outlier 20977\n",
      "top 22073:  \toutlier 1096 \t not outlier 20977\n",
      "top 22376:  \toutlier 1096 \t not outlier 21280\n",
      "top 22377:  \toutlier 1097 \t not outlier 21280\n",
      "top 22392:  \toutlier 1097 \t not outlier 21295\n",
      "top 22394:  \toutlier 1099 \t not outlier 21295\n",
      "top 22402:  \toutlier 1099 \t not outlier 21303\n",
      "top 22403:  \toutlier 1100 \t not outlier 21303\n",
      "top 22598:  \toutlier 1100 \t not outlier 21498\n",
      "top 22600:  \toutlier 1102 \t not outlier 21498\n",
      "top 22698:  \toutlier 1102 \t not outlier 21596\n",
      "top 22699:  \toutlier 1103 \t not outlier 21596\n",
      "top 23370:  \toutlier 1103 \t not outlier 22267\n",
      "top 23372:  \toutlier 1105 \t not outlier 22267\n",
      "top 23588:  \toutlier 1105 \t not outlier 22483\n",
      "top 23589:  \toutlier 1106 \t not outlier 22483\n",
      "top 23743:  \toutlier 1106 \t not outlier 22637\n",
      "top 23745:  \toutlier 1108 \t not outlier 22637\n",
      "top 23878:  \toutlier 1108 \t not outlier 22770\n",
      "top 23880:  \toutlier 1110 \t not outlier 22770\n",
      "top 23901:  \toutlier 1110 \t not outlier 22791\n",
      "top 23902:  \toutlier 1111 \t not outlier 22791\n",
      "top 24092:  \toutlier 1111 \t not outlier 22981\n",
      "top 24094:  \toutlier 1113 \t not outlier 22981\n",
      "top 24318:  \toutlier 1113 \t not outlier 23205\n",
      "top 24319:  \toutlier 1114 \t not outlier 23205\n",
      "top 24532:  \toutlier 1114 \t not outlier 23418\n",
      "top 24534:  \toutlier 1116 \t not outlier 23418\n",
      "top 24574:  \toutlier 1116 \t not outlier 23458\n",
      "top 24575:  \toutlier 1117 \t not outlier 23458\n",
      "top 24739:  \toutlier 1117 \t not outlier 23622\n",
      "top 24741:  \toutlier 1119 \t not outlier 23622\n",
      "top 24809:  \toutlier 1119 \t not outlier 23690\n",
      "top 24810:  \toutlier 1120 \t not outlier 23690\n",
      "top 25187:  \toutlier 1120 \t not outlier 24067\n",
      "top 25189:  \toutlier 1122 \t not outlier 24067\n",
      "top 25315:  \toutlier 1122 \t not outlier 24193\n",
      "top 25317:  \toutlier 1124 \t not outlier 24193\n",
      "top 25341:  \toutlier 1124 \t not outlier 24217\n",
      "top 25342:  \toutlier 1125 \t not outlier 24217\n",
      "top 25373:  \toutlier 1125 \t not outlier 24248\n",
      "top 25375:  \toutlier 1127 \t not outlier 24248\n",
      "top 25384:  \toutlier 1127 \t not outlier 24257\n",
      "top 25387:  \toutlier 1130 \t not outlier 24257\n",
      "top 25576:  \toutlier 1130 \t not outlier 24446\n",
      "top 25577:  \toutlier 1131 \t not outlier 24446\n",
      "top 25698:  \toutlier 1131 \t not outlier 24567\n",
      "top 25700:  \toutlier 1133 \t not outlier 24567\n",
      "top 25727:  \toutlier 1133 \t not outlier 24594\n",
      "top 25728:  \toutlier 1134 \t not outlier 24594\n",
      "top 25997:  \toutlier 1134 \t not outlier 24863\n",
      "top 25999:  \toutlier 1136 \t not outlier 24863\n",
      "top 26040:  \toutlier 1136 \t not outlier 24904\n",
      "top 26042:  \toutlier 1138 \t not outlier 24904\n",
      "top 26224:  \toutlier 1138 \t not outlier 25086\n",
      "top 26225:  \toutlier 1139 \t not outlier 25086\n",
      "top 26520:  \toutlier 1139 \t not outlier 25381\n",
      "top 26522:  \toutlier 1141 \t not outlier 25381\n",
      "top 26767:  \toutlier 1141 \t not outlier 25626\n",
      "top 26768:  \toutlier 1142 \t not outlier 25626\n",
      "top 27537:  \toutlier 1142 \t not outlier 26395\n",
      "top 27539:  \toutlier 1144 \t not outlier 26395\n",
      "top 27659:  \toutlier 1144 \t not outlier 26515\n",
      "top 27660:  \toutlier 1145 \t not outlier 26515\n",
      "top 27944:  \toutlier 1145 \t not outlier 26799\n",
      "top 27946:  \toutlier 1147 \t not outlier 26799\n",
      "top 28660:  \toutlier 1147 \t not outlier 27513\n",
      "top 28661:  \toutlier 1148 \t not outlier 27513\n",
      "top 28684:  \toutlier 1148 \t not outlier 27536\n",
      "top 28686:  \toutlier 1150 \t not outlier 27536\n",
      "top 28703:  \toutlier 1150 \t not outlier 27553\n",
      "top 28705:  \toutlier 1152 \t not outlier 27553\n",
      "top 28817:  \toutlier 1152 \t not outlier 27665\n",
      "top 28818:  \toutlier 1153 \t not outlier 27665\n",
      "top 28848:  \toutlier 1153 \t not outlier 27695\n",
      "top 28850:  \toutlier 1155 \t not outlier 27695\n",
      "top 28858:  \toutlier 1155 \t not outlier 27703\n",
      "top 28859:  \toutlier 1156 \t not outlier 27703\n",
      "top 28953:  \toutlier 1156 \t not outlier 27797\n",
      "top 28955:  \toutlier 1158 \t not outlier 27797\n",
      "top 28989:  \toutlier 1158 \t not outlier 27831\n",
      "top 28990:  \toutlier 1159 \t not outlier 27831\n",
      "top 29111:  \toutlier 1159 \t not outlier 27952\n",
      "top 29113:  \toutlier 1161 \t not outlier 27952\n",
      "top 29383:  \toutlier 1161 \t not outlier 28222\n",
      "top 29384:  \toutlier 1162 \t not outlier 28222\n",
      "top 29932:  \toutlier 1162 \t not outlier 28770\n",
      "top 29934:  \toutlier 1164 \t not outlier 28770\n",
      "top 30735:  \toutlier 1164 \t not outlier 29571\n",
      "top 30736:  \toutlier 1165 \t not outlier 29571\n",
      "top 30838:  \toutlier 1165 \t not outlier 29673\n",
      "top 30842:  \toutlier 1169 \t not outlier 29673\n",
      "top 30927:  \toutlier 1169 \t not outlier 29758\n",
      "top 30928:  \toutlier 1170 \t not outlier 29758\n",
      "top 31130:  \toutlier 1170 \t not outlier 29960\n",
      "top 31132:  \toutlier 1172 \t not outlier 29960\n",
      "top 31517:  \toutlier 1172 \t not outlier 30345\n",
      "top 31518:  \toutlier 1173 \t not outlier 30345\n",
      "top 31624:  \toutlier 1173 \t not outlier 30451\n",
      "top 31626:  \toutlier 1175 \t not outlier 30451\n",
      "top 31655:  \toutlier 1175 \t not outlier 30480\n",
      "top 31656:  \toutlier 1176 \t not outlier 30480\n",
      "top 32525:  \toutlier 1176 \t not outlier 31349\n",
      "top 32527:  \toutlier 1178 \t not outlier 31349\n",
      "top 32555:  \toutlier 1178 \t not outlier 31377\n",
      "top 32556:  \toutlier 1179 \t not outlier 31377\n",
      "top 32567:  \toutlier 1179 \t not outlier 31388\n",
      "top 32569:  \toutlier 1181 \t not outlier 31388\n",
      "top 33061:  \toutlier 1181 \t not outlier 31880\n",
      "top 33063:  \toutlier 1183 \t not outlier 31880\n",
      "top 33325:  \toutlier 1183 \t not outlier 32142\n",
      "top 33326:  \toutlier 1184 \t not outlier 32142\n",
      "top 33338:  \toutlier 1184 \t not outlier 32154\n",
      "top 33340:  \toutlier 1186 \t not outlier 32154\n",
      "top 33386:  \toutlier 1186 \t not outlier 32200\n",
      "top 33387:  \toutlier 1187 \t not outlier 32200\n",
      "top 33440:  \toutlier 1187 \t not outlier 32253\n",
      "top 33442:  \toutlier 1189 \t not outlier 32253\n",
      "top 33473:  \toutlier 1189 \t not outlier 32284\n",
      "top 33474:  \toutlier 1190 \t not outlier 32284\n",
      "top 33680:  \toutlier 1190 \t not outlier 32490\n",
      "top 33682:  \toutlier 1192 \t not outlier 32490\n",
      "top 33760:  \toutlier 1192 \t not outlier 32568\n",
      "top 33761:  \toutlier 1193 \t not outlier 32568\n",
      "top 33867:  \toutlier 1193 \t not outlier 32674\n",
      "top 33869:  \toutlier 1195 \t not outlier 32674\n",
      "top 34059:  \toutlier 1195 \t not outlier 32864\n",
      "top 34061:  \toutlier 1197 \t not outlier 32864\n",
      "top 34192:  \toutlier 1197 \t not outlier 32995\n",
      "top 34193:  \toutlier 1198 \t not outlier 32995\n",
      "top 35289:  \toutlier 1198 \t not outlier 34091\n",
      "top 35291:  \toutlier 1200 \t not outlier 34091\n",
      "top 35310:  \toutlier 1200 \t not outlier 34110\n",
      "top 35311:  \toutlier 1201 \t not outlier 34110\n",
      "top 35410:  \toutlier 1201 \t not outlier 34209\n",
      "top 35412:  \toutlier 1203 \t not outlier 34209\n",
      "top 35415:  \toutlier 1203 \t not outlier 34212\n",
      "top 35416:  \toutlier 1204 \t not outlier 34212\n",
      "top 35525:  \toutlier 1204 \t not outlier 34321\n",
      "top 35527:  \toutlier 1206 \t not outlier 34321\n",
      "top 35869:  \toutlier 1206 \t not outlier 34663\n",
      "top 35870:  \toutlier 1207 \t not outlier 34663\n",
      "top 36130:  \toutlier 1207 \t not outlier 34923\n",
      "top 36132:  \toutlier 1209 \t not outlier 34923\n",
      "top 36230:  \toutlier 1209 \t not outlier 35021\n",
      "top 36232:  \toutlier 1211 \t not outlier 35021\n",
      "top 36277:  \toutlier 1211 \t not outlier 35066\n",
      "top 36278:  \toutlier 1212 \t not outlier 35066\n",
      "top 36336:  \toutlier 1212 \t not outlier 35124\n",
      "top 36338:  \toutlier 1214 \t not outlier 35124\n",
      "top 36691:  \toutlier 1214 \t not outlier 35477\n",
      "top 36692:  \toutlier 1215 \t not outlier 35477\n",
      "top 36927:  \toutlier 1215 \t not outlier 35712\n",
      "top 36929:  \toutlier 1217 \t not outlier 35712\n",
      "top 37028:  \toutlier 1217 \t not outlier 35811\n",
      "top 37029:  \toutlier 1218 \t not outlier 35811\n",
      "top 37114:  \toutlier 1218 \t not outlier 35896\n",
      "top 37116:  \toutlier 1220 \t not outlier 35896\n",
      "top 37208:  \toutlier 1220 \t not outlier 35988\n",
      "top 37209:  \toutlier 1221 \t not outlier 35988\n",
      "top 37380:  \toutlier 1221 \t not outlier 36159\n",
      "top 37382:  \toutlier 1223 \t not outlier 36159\n",
      "top 37819:  \toutlier 1223 \t not outlier 36596\n",
      "top 37821:  \toutlier 1225 \t not outlier 36596\n",
      "top 37838:  \toutlier 1225 \t not outlier 36613\n",
      "top 37839:  \toutlier 1226 \t not outlier 36613\n",
      "top 37989:  \toutlier 1226 \t not outlier 36763\n",
      "top 37991:  \toutlier 1228 \t not outlier 36763\n",
      "top 38004:  \toutlier 1228 \t not outlier 36776\n",
      "top 38005:  \toutlier 1229 \t not outlier 36776\n",
      "top 38980:  \toutlier 1229 \t not outlier 37751\n",
      "top 38982:  \toutlier 1231 \t not outlier 37751\n",
      "top 39348:  \toutlier 1231 \t not outlier 38117\n",
      "top 39349:  \toutlier 1232 \t not outlier 38117\n",
      "top 39689:  \toutlier 1232 \t not outlier 38457\n",
      "top 39691:  \toutlier 1234 \t not outlier 38457\n",
      "top 39880:  \toutlier 1234 \t not outlier 38646\n",
      "top 39881:  \toutlier 1235 \t not outlier 38646\n",
      "top 40023:  \toutlier 1235 \t not outlier 38788\n",
      "top 40025:  \toutlier 1237 \t not outlier 38788\n",
      "top 40296:  \toutlier 1237 \t not outlier 39059\n",
      "top 40298:  \toutlier 1239 \t not outlier 39059\n",
      "top 40710:  \toutlier 1239 \t not outlier 39471\n",
      "top 40711:  \toutlier 1240 \t not outlier 39471\n",
      "top 41180:  \toutlier 1240 \t not outlier 39940\n",
      "top 41182:  \toutlier 1242 \t not outlier 39940\n",
      "top 41772:  \toutlier 1242 \t not outlier 40530\n",
      "top 41773:  \toutlier 1243 \t not outlier 40530\n",
      "top 41968:  \toutlier 1243 \t not outlier 40725\n",
      "top 41970:  \toutlier 1245 \t not outlier 40725\n",
      "top 42168:  \toutlier 1245 \t not outlier 40923\n",
      "top 42169:  \toutlier 1246 \t not outlier 40923\n",
      "top 42302:  \toutlier 1246 \t not outlier 41056\n",
      "top 42304:  \toutlier 1248 \t not outlier 41056\n",
      "top 42508:  \toutlier 1248 \t not outlier 41260\n",
      "top 42509:  \toutlier 1249 \t not outlier 41260\n",
      "top 42872:  \toutlier 1249 \t not outlier 41623\n",
      "top 42874:  \toutlier 1251 \t not outlier 41623\n",
      "top 43062:  \toutlier 1251 \t not outlier 41811\n",
      "top 43064:  \toutlier 1253 \t not outlier 41811\n",
      "top 43632:  \toutlier 1253 \t not outlier 42379\n",
      "top 43633:  \toutlier 1254 \t not outlier 42379\n",
      "top 44532:  \toutlier 1254 \t not outlier 43278\n",
      "top 44534:  \toutlier 1256 \t not outlier 43278\n",
      "top 44650:  \toutlier 1256 \t not outlier 43394\n",
      "top 44651:  \toutlier 1257 \t not outlier 43394\n",
      "top 45101:  \toutlier 1257 \t not outlier 43844\n",
      "top 45103:  \toutlier 1259 \t not outlier 43844\n",
      "top 45240:  \toutlier 1259 \t not outlier 43981\n",
      "top 45241:  \toutlier 1260 \t not outlier 43981\n",
      "top 45368:  \toutlier 1260 \t not outlier 44108\n",
      "top 45370:  \toutlier 1262 \t not outlier 44108\n",
      "top 45791:  \toutlier 1262 \t not outlier 44529\n",
      "top 45792:  \toutlier 1263 \t not outlier 44529\n",
      "top 46081:  \toutlier 1263 \t not outlier 44818\n",
      "top 46083:  \toutlier 1265 \t not outlier 44818\n",
      "top 46481:  \toutlier 1265 \t not outlier 45216\n",
      "top 46483:  \toutlier 1267 \t not outlier 45216\n",
      "top 46604:  \toutlier 1267 \t not outlier 45337\n",
      "top 46605:  \toutlier 1268 \t not outlier 45337\n",
      "top 47148:  \toutlier 1268 \t not outlier 45880\n",
      "top 47150:  \toutlier 1270 \t not outlier 45880\n",
      "top 47885:  \toutlier 1270 \t not outlier 46615\n",
      "top 47886:  \toutlier 1271 \t not outlier 46615\n",
      "top 48103:  \toutlier 1271 \t not outlier 46832\n",
      "top 48105:  \toutlier 1273 \t not outlier 46832\n",
      "top 48228:  \toutlier 1273 \t not outlier 46955\n",
      "top 48229:  \toutlier 1274 \t not outlier 46955\n",
      "top 48596:  \toutlier 1274 \t not outlier 47322\n",
      "top 48598:  \toutlier 1276 \t not outlier 47322\n",
      "top 48610:  \toutlier 1276 \t not outlier 47334\n",
      "top 48611:  \toutlier 1277 \t not outlier 47334\n",
      "top 48996:  \toutlier 1277 \t not outlier 47719\n",
      "top 48998:  \toutlier 1279 \t not outlier 47719\n",
      "top 49169:  \toutlier 1279 \t not outlier 47890\n",
      "top 49171:  \toutlier 1281 \t not outlier 47890\n",
      "top 49190:  \toutlier 1281 \t not outlier 47909\n",
      "top 49191:  \toutlier 1282 \t not outlier 47909\n",
      "top 49194:  \toutlier 1282 \t not outlier 47912\n",
      "top 49196:  \toutlier 1284 \t not outlier 47912\n",
      "top 49739:  \toutlier 1284 \t not outlier 48455\n",
      "top 49740:  \toutlier 1285 \t not outlier 48455\n",
      "top 49929:  \toutlier 1285 \t not outlier 48644\n",
      "top 49931:  \toutlier 1287 \t not outlier 48644\n",
      "top 51141:  \toutlier 1287 \t not outlier 49854\n",
      "top 51142:  \toutlier 1288 \t not outlier 49854\n",
      "top 51397:  \toutlier 1288 \t not outlier 50109\n",
      "top 51399:  \toutlier 1290 \t not outlier 50109\n",
      "top 51807:  \toutlier 1290 \t not outlier 50517\n",
      "top 51808:  \toutlier 1291 \t not outlier 50517\n",
      "top 52177:  \toutlier 1291 \t not outlier 50886\n",
      "top 52179:  \toutlier 1293 \t not outlier 50886\n",
      "top 52740:  \toutlier 1293 \t not outlier 51447\n",
      "top 52742:  \toutlier 1295 \t not outlier 51447\n",
      "top 53227:  \toutlier 1295 \t not outlier 51932\n",
      "top 53228:  \toutlier 1296 \t not outlier 51932\n",
      "top 53299:  \toutlier 1296 \t not outlier 52003\n",
      "top 53301:  \toutlier 1298 \t not outlier 52003\n",
      "top 53801:  \toutlier 1298 \t not outlier 52503\n",
      "top 53802:  \toutlier 1299 \t not outlier 52503\n",
      "top 54967:  \toutlier 1299 \t not outlier 53668\n",
      "top 54969:  \toutlier 1301 \t not outlier 53668\n",
      "top 55867:  \toutlier 1301 \t not outlier 54566\n",
      "top 55868:  \toutlier 1302 \t not outlier 54566\n",
      "top 56198:  \toutlier 1302 \t not outlier 54896\n",
      "top 56200:  \toutlier 1304 \t not outlier 54896\n",
      "top 58342:  \toutlier 1304 \t not outlier 57038\n",
      "top 58343:  \toutlier 1305 \t not outlier 57038\n",
      "top 59294:  \toutlier 1305 \t not outlier 57989\n",
      "top 59296:  \toutlier 1307 \t not outlier 57989\n",
      "top 60163:  \toutlier 1307 \t not outlier 58856\n",
      "top 60165:  \toutlier 1309 \t not outlier 58856\n",
      "top 60465:  \toutlier 1309 \t not outlier 59156\n",
      "top 60466:  \toutlier 1310 \t not outlier 59156\n",
      "top 61960:  \toutlier 1310 \t not outlier 60650\n",
      "top 61962:  \toutlier 1312 \t not outlier 60650\n",
      "top 62215:  \toutlier 1312 \t not outlier 60903\n",
      "top 62216:  \toutlier 1313 \t not outlier 60903\n",
      "top 62644:  \toutlier 1313 \t not outlier 61331\n",
      "top 62646:  \toutlier 1315 \t not outlier 61331\n",
      "top 62673:  \toutlier 1315 \t not outlier 61358\n",
      "top 62674:  \toutlier 1316 \t not outlier 61358\n",
      "top 63130:  \toutlier 1316 \t not outlier 61814\n",
      "top 63132:  \toutlier 1318 \t not outlier 61814\n",
      "top 63901:  \toutlier 1318 \t not outlier 62583\n",
      "top 63902:  \toutlier 1319 \t not outlier 62583\n",
      "top 66038:  \toutlier 1319 \t not outlier 64719\n",
      "top 66040:  \toutlier 1321 \t not outlier 64719\n",
      "top 66391:  \toutlier 1321 \t not outlier 65070\n",
      "top 66393:  \toutlier 1323 \t not outlier 65070\n",
      "top 66912:  \toutlier 1323 \t not outlier 65589\n",
      "top 66913:  \toutlier 1324 \t not outlier 65589\n",
      "top 68080:  \toutlier 1324 \t not outlier 66756\n",
      "top 68082:  \toutlier 1326 \t not outlier 66756\n",
      "top 68280:  \toutlier 1326 \t not outlier 66954\n",
      "top 68281:  \toutlier 1327 \t not outlier 66954\n",
      "top 68923:  \toutlier 1327 \t not outlier 67596\n",
      "top 68925:  \toutlier 1329 \t not outlier 67596\n",
      "top 69282:  \toutlier 1329 \t not outlier 67953\n",
      "top 69283:  \toutlier 1330 \t not outlier 67953\n",
      "top 69564:  \toutlier 1330 \t not outlier 68234\n",
      "top 69566:  \toutlier 1332 \t not outlier 68234\n",
      "top 71889:  \toutlier 1332 \t not outlier 70557\n",
      "top 71890:  \toutlier 1333 \t not outlier 70557\n",
      "top 73103:  \toutlier 1333 \t not outlier 71770\n",
      "top 73105:  \toutlier 1335 \t not outlier 71770\n",
      "top 73510:  \toutlier 1335 \t not outlier 72175\n",
      "top 73512:  \toutlier 1337 \t not outlier 72175\n",
      "top 73758:  \toutlier 1337 \t not outlier 72421\n",
      "top 73759:  \toutlier 1338 \t not outlier 72421\n",
      "top 82141:  \toutlier 1338 \t not outlier 80803\n",
      "top 82143:  \toutlier 1340 \t not outlier 80803\n",
      "top 82173:  \toutlier 1340 \t not outlier 80833\n",
      "top 82174:  \toutlier 1341 \t not outlier 80833\n",
      "top 83456:  \toutlier 1341 \t not outlier 82115\n",
      "top 83458:  \toutlier 1343 \t not outlier 82115\n",
      "top 86830:  \toutlier 1343 \t not outlier 85487\n",
      "top 86831:  \toutlier 1344 \t not outlier 85487\n",
      "top 87969:  \toutlier 1344 \t not outlier 86625\n",
      "top 87971:  \toutlier 1346 \t not outlier 86625\n",
      "top 91629:  \toutlier 1346 \t not outlier 90283\n",
      "top 91630:  \toutlier 1347 \t not outlier 90283\n",
      "top 94429:  \toutlier 1347 \t not outlier 93082\n",
      "top 94431:  \toutlier 1349 \t not outlier 93082\n",
      "top 96568:  \toutlier 1349 \t not outlier 95219\n",
      "top 96570:  \toutlier 1351 \t not outlier 95219\n",
      "top 115280:  \toutlier 1351 \t not outlier 113929\n",
      "top 115283:  \toutlier 1351 \t not outlier 113932\n",
      "top 123623:  \toutlier 1351 \t not outlier 122272\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fpr)):\n",
    "    real_outlier = int(tpr[i]*1351)\n",
    "    not_outlier = int(fpr[i]*122272)\n",
    "    total = real_outlier + not_outlier\n",
    "    print(f'top {total}:  \\toutlier {real_outlier} \\t not outlier {not_outlier}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_va_sort = y_va.copy()\n",
    "y_va_sort['pred_prob'] = prob\n",
    "y_va_sort = y_va_sort.sort_values('pred_prob', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.859505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116144</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.170125</td>\n",
       "      <td>0.840169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94554</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.425834</td>\n",
       "      <td>0.839344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56803</th>\n",
       "      <td>0</td>\n",
       "      <td>2.033892</td>\n",
       "      <td>0.837220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42753</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.836045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        outlier     target  pred_prob\n",
       "25347         1 -33.219281   0.859505\n",
       "116144        0  -1.170125   0.840169\n",
       "94554         0  -1.425834   0.839344\n",
       "56803         0   2.033892   0.837220\n",
       "42753         1 -33.219281   0.836045"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_va_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06602833315775794"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_va_sort.pred_prob.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010930233709890698"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b383f2f9e8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b383ef2358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_va_sort.pred_prob.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_param = {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 48,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = lgb.Dataset(X_tr, label=y_tr.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 3.6529 + 0.120686\n",
      "[400]\tcv_agg's rmse: 3.63521 + 0.118588\n",
      "[600]\tcv_agg's rmse: 3.6291 + 0.118203\n",
      "[800]\tcv_agg's rmse: 3.62684 + 0.118228\n",
      "[1000]\tcv_agg's rmse: 3.62651 + 0.118356\n",
      "[1200]\tcv_agg's rmse: 3.62603 + 0.11884\n",
      "[1400]\tcv_agg's rmse: 3.62662 + 0.118514\n",
      "[1600]\tcv_agg's rmse: 3.62699 + 0.118977\n"
     ]
    }
   ],
   "source": [
    "cv_score = lgb.cv(rg_param, tr_data, 10000, early_stopping_rounds=600, verbose_eval=200, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best num:  1149 \n",
      "best score: 3.625740361079412\n"
     ]
    }
   ],
   "source": [
    "print('best num: ', len(cv_score['rmse-mean']), '\\nbest score:', cv_score['rmse-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.4864\n",
      "[400]\ttraining's rmse: 3.36918\n",
      "[600]\ttraining's rmse: 3.28943\n",
      "[800]\ttraining's rmse: 3.22785\n",
      "[1000]\ttraining's rmse: 3.17405\n",
      "[1200]\ttraining's rmse: 3.12344\n",
      "[1400]\ttraining's rmse: 3.07776\n",
      "[1600]\ttraining's rmse: 3.03531\n",
      "[1800]\ttraining's rmse: 2.99583\n",
      "[2000]\ttraining's rmse: 2.95647\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(rg_param, tr_data, 2000, valid_sets=(tr_data), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_va, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7026626002538454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.859505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116144</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.170125</td>\n",
       "      <td>0.840169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94554</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.425834</td>\n",
       "      <td>0.839344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56803</th>\n",
       "      <td>0</td>\n",
       "      <td>2.033892</td>\n",
       "      <td>0.837220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42753</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.836045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        outlier     target  pred_prob\n",
       "25347         1 -33.219281   0.859505\n",
       "116144        0  -1.170125   0.840169\n",
       "94554         0  -1.425834   0.839344\n",
       "56803         0   2.033892   0.837220\n",
       "42753         1 -33.219281   0.836045"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_va_sort.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's see top20/50 stratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = y_va.copy()\n",
    "pred_df['pred_target'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['pred_prob'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 25347, 116144,  94554,  56803,  42753,  12602,  51267, 135378,\n",
       "             15933, 175726,  83942, 120610, 128262,  92357, 155132,   7071,\n",
       "             82035, 148428, 102057, 159259],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index_20=pred_df.sort_values('pred_prob', ascending=False).head(20).index\n",
    "index_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 25347, 116144,  94554,  56803,  42753,  12602,  51267, 135378,\n",
       "             15933, 175726,  83942, 120610, 128262,  92357, 155132,   7071,\n",
       "             82035, 148428, 102057, 159259],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.loc[pred_df.index.isin(index_20),'pred_target']=-33.21928095\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_target</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.859505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116144</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.170125</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.840169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94554</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.425834</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.839344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56803</th>\n",
       "      <td>0</td>\n",
       "      <td>2.033892</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.837220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42753</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.836045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.833862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51267</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.420850</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.832792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135378</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.831966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15933</th>\n",
       "      <td>0</td>\n",
       "      <td>0.204692</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.831036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175726</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.827946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83942</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.825590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120610</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.822992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128262</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.822607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92357</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.428425</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.822571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155132</th>\n",
       "      <td>0</td>\n",
       "      <td>2.944885</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.817069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.902819</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.816980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82035</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.043868</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.816631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148428</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.816506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102057</th>\n",
       "      <td>0</td>\n",
       "      <td>0.390960</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.816165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159259</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.815928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        outlier     target  pred_target  pred_prob\n",
       "25347         1 -33.219281   -33.219281   0.859505\n",
       "116144        0  -1.170125   -33.219281   0.840169\n",
       "94554         0  -1.425834   -33.219281   0.839344\n",
       "56803         0   2.033892   -33.219281   0.837220\n",
       "42753         1 -33.219281   -33.219281   0.836045\n",
       "12602         1 -33.219281   -33.219281   0.833862\n",
       "51267         0  -1.420850   -33.219281   0.832792\n",
       "135378        1 -33.219281   -33.219281   0.831966\n",
       "15933         0   0.204692   -33.219281   0.831036\n",
       "175726        1 -33.219281   -33.219281   0.827946\n",
       "83942         1 -33.219281   -33.219281   0.825590\n",
       "120610        0   0.001677   -33.219281   0.822992\n",
       "128262        1 -33.219281   -33.219281   0.822607\n",
       "92357         0  -0.428425   -33.219281   0.822571\n",
       "155132        0   2.944885   -33.219281   0.817069\n",
       "7071          0  -0.902819   -33.219281   0.816980\n",
       "82035         0  -0.043868   -33.219281   0.816631\n",
       "148428        1 -33.219281   -33.219281   0.816506\n",
       "102057        0   0.390960   -33.219281   0.816165\n",
       "159259        1 -33.219281   -33.219281   0.815928"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sort_values('pred_prob', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7147380551655145"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted test score\n",
    "get_lb(pred_df.pred_target.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This discrepancy for our original set might be due to mainly.Two reasons: 1) We have  smaller number of outliers in test set than in real test set. 2 ) our prediction is not so accurate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6111639666879538"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]/y_va.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7126880379636393"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so our threshould should be arround 16. Let's check it\n",
    "pred_df = y_va.copy()\n",
    "pred_df['pred_target'] = pred\n",
    "pred_df['pred_prob'] = prob\n",
    "index_16=pred_df.sort_values('pred_prob', ascending=False).head(16).index\n",
    "pred_df.loc[pred_df.index.isin(index_16),'pred_target']=-33.21928095\n",
    "get_lb(pred_df.pred_target.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's just try to iterate more for each treshould values and observe results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'RMSE')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b383f711d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=[]\n",
    "pred_df = y_va.copy()\n",
    "pred_df['pred_target'] = pred\n",
    "pred_df['pred_prob'] = prob\n",
    "for i in range(1,200):\n",
    "    index=pred_df.sort_values('pred_prob', ascending=False).head(i).index\n",
    "    pred_df.loc[pred_df.index.isin(index),'pred_target']=-33.21928095\n",
    "    results.append(get_lb(pred_df.pred_target.values))\n",
    "plt.figure()\n",
    "plt.plot(range(1,200),results)\n",
    "plt.xlabel('Treshold number')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We don't see any improvement at all. Probably, our outliers predictions are not so accurate. The reason why we can observe improvement in LB is due to more data for outliers prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, I will try to change our strategy for mixing with and without outliers. Instead of mixing prediction with and without outliers , I will separate dataset to two part so that together they will give best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start by using outliers predictions\n",
    "pred_df = y_va.copy()\n",
    "pred_df['pred_target'] = pred\n",
    "pred_df['pred_prob'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 257)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_param = {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9, #\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9, #\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 48,\n",
    "         \"scale_pos_weight\": 15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = lgb.Dataset(X_tr, label=y_tr.outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's auc: 0.902398 + 0.00697561\n",
      "[200]\tcv_agg's auc: 0.903697 + 0.00662913\n",
      "[300]\tcv_agg's auc: 0.903734 + 0.00670821\n",
      "[400]\tcv_agg's auc: 0.903137 + 0.00668533\n",
      "[500]\tcv_agg's auc: 0.902398 + 0.00650716\n",
      "[600]\tcv_agg's auc: 0.901779 + 0.00654513\n",
      "[700]\tcv_agg's auc: 0.901337 + 0.006394\n",
      "[800]\tcv_agg's auc: 0.900654 + 0.00646067\n"
     ]
    }
   ],
   "source": [
    "cv_score = lgb.cv(cl_param, tr_data, 10000, early_stopping_rounds=600, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best num:  232 \n",
      "best score: 0.9038768908290219\n"
     ]
    }
   ],
   "source": [
    "print('best num: ', len(cv_score['auc-mean']), '\\nbest score:', cv_score['auc-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.966905\n",
      "[200]\ttraining's auc: 0.974608\n",
      "[300]\ttraining's auc: 0.980398\n",
      "[400]\ttraining's auc: 0.984885\n"
     ]
    }
   ],
   "source": [
    "clf_outlier = lgb.train(cl_param, tr_data, 400, valid_sets=(tr_data), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code\n",
    "[100]\ttraining's auc: 0.966946\n",
    "[200]\ttraining's auc: 0.974508\n",
    "[300]\ttraining's auc: 0.980274\n",
    "[400]\ttraining's auc: 0.984884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_outlier.best_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train = clf_outlier.predict(X_tr, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_tr['prob_train']=prob_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier</th>\n",
       "      <th>target</th>\n",
       "      <th>prob_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88227</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.867037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45032</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.857329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100443</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.853597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13101</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.850782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22187</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>0.848931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        outlier     target  prob_train\n",
       "88227         1 -33.219281    0.867037\n",
       "45032         1 -33.219281    0.857329\n",
       "100443        1 -33.219281    0.853597\n",
       "13101         1 -33.219281    0.850782\n",
       "22187         1 -33.219281    0.848931"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Seems to really good! overfitting\n",
    "y_tr.sort_values('prob_train',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.outlier.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Test set')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl4leWd//H3N4GAbFkIayAJu7IKRETc16qtS1utS7W2dZmxP9vp6Dhj22nrtJ3pXutc40zrqGNtrcvYqoxFRS1uLLLKLhggIQGyko0A2c7398c5iTGG5KA5W/J5XVcuznPOc57zzQPkk/u+n+e+zd0REREBSIp1ASIiEj8UCiIi0kahICIibRQKIiLSRqEgIiJtFAoiItJGoSAiIm0UCtJnmNmhdl8BMzvSbvuLn+C4q8zshp6sNXTcvzWzV3v6uCJd6RfrAkSixd2HtD42swLgFnfXD12RdtRSEAkxs2Qz+66Z7TazCjN73MzSQq8NNrMnzeygmVWb2Ttmlm5mvwROAR4KtTh+2clxO31v6LUMM3vMzErMrMjMvm9mSWY2F/g1cE7ouCXRPBfSdykURD5wN3ARcAYwDmgC7gu9dgvBlnUWkAncATS6+13AGoKtjiGh7Y46fW/otceBGmAisAC4ErjR3TcA3wReDx13dA9/ryKdUiiIfOBvgHvcfb+7HwX+BbjGzIxgQIwAJrl7s7uvcff6MI/b6XvNLAc4C7jT3Q+7+wHg34Fre/w7EwmTxhREgNAP/vHAEjNrP0tkEjAceBgYDTxjZkOAx4DvuntLGIfv9L1ADjAQKA9+fNvn5X/y70jk41EoiADu7ma2D/icu687xm7fA75nZhOBl4GtBLt/upxq2N0bjvHeFcAhIN07n65YUxhL1Kn7SOQDvwF+YmbjAcxspJldFnp8gZlNN7MkoBZoBlpbCaUExwQ6daz3uvseYBXwMzMbGhpgnmJmZ7Q77ngz6x+B71WkUwoFkQ/8DHgV+KuZ1RH8TX5e6LUs4HmgDtgCLAGeDr12H/AlM6sys591ctyu3nsdkAa8BxwEngJGhV57CSgAysysuGe+RZGumRbZERGRVmopiIhIG4WCiIi0USiIiEgbhYKIiLRJuPsUMjMzPTc3N9ZliIgklHXr1lW4+4ju9ku4UMjNzWXt2rWxLkNEJKGYWWE4+6n7SERE2igURESkjUJBRETaKBRERKSNQkFERNpELBTM7BEzKzOzLcd43czs380s38w2mdm8zvYTEZHoiWRL4VHg4i5evwSYEvq6DfivCNYiIiJhiFgouPubBKcCPpYrgMc8aBWQZmZjIlWPiEiiamoJ8OMl29lYVB3xz4rlmEIWUNRuuzj03EeY2W1mttbM1paXl0elOBGReFFcdYTfvrmbHaV1Ef+sWIaCdfJcp4s7uPuD7p7n7nkjRnR7l7aISK9SUFEPwITMwRH/rFiGQjHBhdJbjQP2x6gWEZG4VVAZDIXc4b07FBYTXMLQzGwhUOPuB2JYj4hIXCqoqGdwSjKZQ1Ii/lkRmxDPzJ4AzgEyQ+vLfh/oD+DuvyG4Tu2lQD5wGPhKpGoREUlkeyoPk5s5GLPOet17VsRCwd2v6+Z1B/5fpD5fRKS3KKioZ9a41Kh8lu5oFhGJY43NAYqrDjMhCuMJoFAQEYlrRVWHCTjkRuHKI1AoiIjEtcLK1stRB0Xl8xQKIiJxbE/FYSA6l6OCQkFEJK4VVNQzdEA/MgZH/nJUUCiIiMS1gsr6qF2OCgoFEZG4tqeiPmqDzKBQEBGJWw3NLeyvPsKE4dEZZAaFgohI3Co6GN3LUUGhICIStwparzxSKIiI9C1b99fwnWc3c6ihue251tlRo3U3M0Rw7iMREQlPftkhbnx4NQfrG5k0YghfPWMCEBxkHjawH2mD+ketFrUURERiqLjqMDc+/A5JBtNGDeV3KwsIBILrjRVU1jMhipejgkJBRCRmyusauPHh1RxqaOaxr57KHedNprDyMMt2lAHBMYVojieAQkFEJCbcnVseW0tJzVEe/copTB87jItnjmb0sIE8uqKAo00t7K85ErXpLVopFEREYmBf9RE2FlVz10VTmZ+TAUD/5CRuPC2Ht96v4LXtZbhHZ13m9hQKIiIxsK6wCoDTJg3/0PPXLcgmpV8SP35xOxDdy1FBoSAiEhPrCqsYnJLMtFFDP/R8xuAUrjx5LMVVR4DoXo4KCgURkZhYV1jFydlp9Ev+6I/hLy8KXpKaNqg/qVG8HBUUCiIiUVff0Mz2A7XMz07v9PXpY4dx1tQRzMqKzrrM7enmNRGRKNtYVE3AYV5O56EA8OCN86NY0QcUCiIiUdY6yDz3GC0FgIH9k6NVzoeo+0hEJMrW7a1i6qghpJ4Q3fGCcCgURESiKBBw1hdWtd2bEG8UCiIiUbSr/BC1R5uZ38V4QiwpFEREoqh1PEGhICIirCusImNwCrlRXGLzeCgURESiaN3eKuZlp0d1OuzjoVAQEYmSg/WN7C6vj9uuI1AoiIhEzfo4H08AhYKISNSsKTxI/2Rj9rjoT18RroiGgpldbGY7zCzfzO7p5PVsM1tmZhvMbJOZXRrJekREYsXdeWVbKXk5GTG7WzkcEQsFM0sGHgAuAaYD15nZ9A67/TPwtLvPBa4F/jNS9YiIxNL7ZYfYXV7PpbPHxLqULkWypbAAyHf33e7eCDwJXNFhHweGhR6nAvsjWI+ISMws2XwAM/jUjFGxLqVLkZwQLwsoarddDJzaYZ97gaVm9nVgMHBBBOsREYmZFzeXcEpuBiOHDox1KV2KZEuhs4twvcP2dcCj7j4OuBT4vZl9pCYzu83M1prZ2vLy8giUKiISOfllh9hRWselM0fHupRuRTIUioHx7bbH8dHuoZuBpwHcfSUwEMjseCB3f9Dd89w9b8SIEREqV0QkMl7acgCAi2fG93gCRDYU1gBTzGyCmaUQHEhe3GGfvcD5AGZ2EsFQUFNARHqVJZtLmJ+TzujU+O46ggiGgrs3A3cALwPbCV5ltNXMfmBml4d2uwu41cw2Ak8AX3b3jl1MIiIJq6Cinm0HarkkAbqOIMIrr7n7EmBJh+e+1+7xNuD0SNYgIhJLL24pAeCSWfHfdQS6o1lEJKJe3HKAOePTyEo7IdalhEWhICISIUUHD7OpuCYhrjpqpVAQEYmQl1q7jhLgqqNWCgURkQh5ccsBpo8ZRnacLqjTGYWCiEgElNQcZf3e6oS56qiVQkFEJAJe3tp61ZFCQUSkz3txywEmjxzC5JFDY13KcVEoiIj0sMpDDazeczDhuo5AoSAi0uOWbisl4HCxQkFERF7cUkJ2xiCmjxnW/c5xRqEgItKDag43sSK/gktmjsassxUE4ptCQUSkB726vZTmgCfMXEcdKRRERHrQi1tKGJs6kDnjUmNdyseiUBAR6SH1Dc28+X45F81IzK4jUCiIiPSYt94vp7E5wEUzRsW6lI+t21Aws9PNbHDo8Q1m9iszy4l8aSIiiWXp1lJST+jPgtyMWJfysYXTUvgv4LCZzQH+ESgEHotoVSIiCaa5JcBr75Vx/kkj6ZecuJ0w4VTeHFoi8wrgfne/H0is+7ZFRCJsdcFBao40cdH0xLthrb1wluOsM7NvATcAZ5lZMtA/smWJiCSWpVtLGdAvibOmZsa6lE8knJbCNUADcLO7lwBZwM8jWpWISAJxd17ZVsqZU0YwKCWc37XjV5fVh1oFf3D3C1qfc/e9aExBRKTN1v217Ks+wt9dMCXWpXxiXbYU3L2F4CBzYt6FISISBUu3lZJkcP6JI2NdyicWTjvnKLDZzF4B6lufdPdvRKwqEZEEsnRrCXm5GQwfMiDWpXxi4YTCX0JfIiLSwd7Kw7xXUsc/f/qkWJfSI7oNBXf/nZmdAGS7+44o1CQikjBe2noAgAunJ+5dzO2Fc0fzZcC7wEuh7ZPNbHGkCxMRiXfuzp/W7WPO+DRyhg+OdTk9IpxLUu8FFgDVAO7+LjAhgjWJiCSErftr2VFax1Xzx8W6lB4T7h3NNR2e80gUIyKSSJ5ZV0xKchKXzU7MtRM6E85A8xYzux5INrMpwDeAFZEtS0QkvjU2B3j+3X1cOH0UaYNSYl1OjwmnpfB1YAbBu5qfAGqBb0ayKBGReLdsRxlVh5t6VdcRhHf10WHgO6EvEREh2HU0YugAzpyS2HMddXTMUDCzX7v7N83s/+hkDMHdL49oZSIicaryUAPL3ivjq2dMSOhpsjvTVUvh96E/f/FxD25mFwP3A8nAQ+7+k072+QLBK5wc2Oju13/czxMRiYbn391Pc8D5/Lze1XUEXYSCu68L/fnGxzlwaDK9B4ALgWJgjZktdvdt7faZAnwLON3dq8ws8ScOEZFe70/ri5mVlcq00b1vaZmuuo8208Wlp+4+u5tjLwDy3X136HhPElyoZ1u7fW4FHnD3qtAxy8KsW0QkJl7bXsrW/bX88IoZsS4lIrrqPvrMJzx2FlDUbrsYOLXDPlMBzGw5wS6me939pY4HMrPbgNsAsrOzP2FZIiIfT31DM997fitTRg7hmlN658+iY46QuHuhuxcCX2t93P65MI5tnR22w3Y/YApwDnAd8JCZpXVSy4PunufueSNGjAjjo0VEet59r+xkX/UR/u1zs0jp17sGmFuF811d2Mlzl4TxvmJgfLvtccD+TvZ53t2b3H0PsINgSIiIxJUt+2p4ZPkerluQzSm5GbEuJ2KOGQpmdntoXOFEM9vU7msPsCmMY68BppjZBDNLAa4FOk6k9xxwbujzMgl2J+3+ON+IiEiktAScbz+7mYzBA7jn4hNjXU5EdTWm8EfgReDHwD3tnq9z94PdHdjdm83sDuBlguMFj7j7VjP7AbDW3ReHXrvIzLYBLcDd7l75Mb8XEZGI+P3KAjYV1/Dv180ldVD/WJcTUebe9dx2ZtbpaEporeaoy8vL87Vr18bio0WkD2pobuH0nyxj6qghPH7LqZh1Nlwa/8xsnbvndbdfuCuvOcGB44EEp83eQXA+JBGRXm3xu/upONTAfdfMSdhAOB7hzH00q/22mc0D/iZiFYmIxAl35+G39zBt1FDOmNy75jg6luO+psrd1wOnRKAWEZG4smJXJe+V1HHzGRP6RCsBwmgpmNmd7TaTgHlAecQqEhGJEw+9tZvMISlcfvLYWJcSNeG0FIa2+xpAcIzhikgWJSISa/llh1i2o5wbFuYwsH9yrMuJmnDGFP4FwMyGBjf9UMSrEhGJsUeW7yGlXxI3LMyJdSlR1W1LwcxmmtkGYAuw1czWmdnMyJcmIhIbVfWN/Hl9MZ+bm0XmkAGxLieqwuk+ehC4091z3D0HuCv0nIhIr/TrV3fS0Bzgq2dMiHUpURdOKAx292WtG+7+OjA4YhWJiMTQpuJqHltVyJcW5jB1VO9bL6E74dy8ttvMvssHK7HdAOyJXEkiIrHR3BLg289uZsSQAdz1qWmxLicmwmkpfBUYAfw59JUJfCWSRYmIxMLvVxWyZV8t37tsOsMG9u45jo4lnKuPqoBvRKEWEZGYKak5yi+X7uSsqSP49KwxsS4nZnrnKhEiIsfpX/5vK00tAX50xcw+c/dyZxQKItLnvba9lBe3lPD18yaTPXxQrMuJqa4W2flp6M+ro1eOiEh0ta67PHXUEG47a1Ksy4m5rloKl5pZf+Bb0SpGRCTaftW67vJne++6y8ejq4Hml4AKYLCZ1RJcT6F1XQV392FRqE9EJGI2F9fwP8v3cP2p2eT14nWXj8cxY9Hd73b3VOAv7j7M3Ye2/zOKNYqI9LjmlgDfenYTw4cM4J96+brLxyOcS1KvMLNRfLCGwjvurqmzRSRhNbUE+PGS99iyr5b/uH4uqSf0zXsSOhPOhHhXA6uBq4EvAKvN7KpIFyYiEgm7yw9x1X+t4JFQt1FfviehM+FMc/HPwCnuXgZgZiOAV4FnIlmYiEhPcnf+uHovP3phOwP6J/GfX5zHpQqEjwgnFJJaAyGkEt3fICIJ5oVNB/jOs1s4c0omv7h6DqOGDYx1SXEpnFB4ycxeBp4IbV8DLIlcSSIiPav2aBM/eGEbs7JSefQrC0hO6rt3LHcnnIHmu83sc8AZBC9HfdDdn414ZSIiPeRXS3dScaiBh2/KUyB0I5yWAu7eOkOqiEhC2bKvhsdWFnDDqTnMHpcW63LinsYGRKTXagk433luCxmDB/APfXR9hOMVVktBRCTRHGls4ZHle9hYVM2vrzlZ9yKEKaxQMLMUYGpoc4e7N0WuJBGRj6e09ihPrN7Lil2VbNhbRVOLc+aUTK44eWysS0sY3YaCmZ0D/A4oIDjQPN7MbnL3NyNbmohIeNyd597dx/ef38qhhmZmZqXy1TMmsGhSJgsnZvTp9RGOVzgthV8CF7n7DgAzm0rw8tT5kSxMRCQc5XUNfOfZzSzdVkpeTjq/uHoOuZmDY11WwgonFPq3BgKAu+8MTaktIhIzLQHnqTVF/Pzl96hvbOHbl57IzWdM1CWnn1A4obDWzB4Gfh/a/iKwLpyDm9nFwP1AMvCQu//kGPtdBfwvwek01oZzbBHpu9bvreL7z29l874aFuRm8K+fncmUUUNjXVavEE4o3A78P+AbBMcU3gT+s7s3mVky8ABwIVAMrDGzxe6+rcN+Q0PHfuf4SheRvqIl4GzdX8PKXZUs31XJmzvLGTVsAPdfezKXzxmrMYMeFM4dzQ3Ar0Jfx2MBkO/uuwHM7EngCmBbh/1+CPwM+IfjPL6I9HKBgPPoigLuf+19ao4EL3qcNGIwd5w7mb89ZxJDBuiq+p52zDNqZk+7+xfMbDPBFdc+xN1nd3PsLKCo3XYxcGqHz5gLjHf3F8zsmKFgZrcBtwFkZ2d387Ei0hvsqajnH5/ZyJqCKs6eOoLPzcvitInDGamJ7CKqq5j9u9Cfn/mYx+6sPdcWLmaWBNwHfLm7A7n7g8CDAHl5eR8JKBHpHRqaW9i6v5Y3d5bzmzd2kZKcxC+vnsPn5mWpiyhKjhkK7n4g9PBr7v5P7V8zs58C//TRd31IMTC+3fY4YH+77aHATOD10F/2aGCxmV2uwWaRvqPuaBNPri7ixS0H2LKvlsaWAAAXnDSSf/3sLE1xHWXhdMhdyEcD4JJOnutoDTDFzCYA+4BrgetbX3T3GiCzddvMXgf+QYEg0jfsrz7CoysKeOKdvdQ1NDN7XCo3Lcphfk4687LT1U0UI12NKdwOfA2YaGab2r00FFje3YHdvdnM7gBeJnhJ6iPuvtXMfgCsdffFn6x0EUk0RxpbWLqthGc37OOt9ysAuHTWGG49c4JmMI0T5t55F72ZpQLpwI+Be9q9VOfuB6NQW6fy8vJ87Vo1JkQSycH6Rn796k7+tK6Y+sYWxqYO5Mq5WVx/ajbj0gfFurw+wczWuXted/t1NaZQA9QA14UOOBIYCAwxsyHuvrenihWR3qklEFwX+Rcv7+BQQzOfnZvF5+eN49QJGSTpzuO4FM6EeJcRvEdhLFAG5ADbgRmRLU1EEtnGomq+/exmtu6v5bSJw7n38hlMG627juNdOAPNPwIWAq+6+1wzO5dQ60FEpKMjjS3c9+pOHnprNyOHDuQ/rp/Lp2eN0SWlCSKcUGhy90ozSzKzJHdfFrokVUSkTVNLgFW7K/nuc1soqDzMdQuy+dalJzJsoObPTCThhEK1mQ0hOOfR42ZWBjRHtiwRiXeBgLNiVyWv7yjj3aJqtuyv4WhTgOyMQfzx1lNZNCmz+4NI3AknFK4AjgB/T3CG1FTgB5EsSkTiV82RJp5ZV8zjqwrZXVHPgH5JzMxK5Yun5jBnfBoXnDSSQSmakyhRhTMhXn3oYQD4XWj202uBxyNZmIjEl8bmAP/91m7+46/5HGlqYV52GvddM4dLZo5hYP/kWJcnPaSrm9eGEZwyOwtYDLwS2r4beBeFgkifsabgIN/+82beLzvExTNGc8d5k5mZlRrrsiQCumop/B6oAlYCtxAMgxTgCnd/Nwq1iUiMldUe5RdLd/D02mKy0k7g4ZvyOP+kUbEuSyKoq1CY6O6zAMzsIaACyHb3uqhUJiIxc6ihmQff2MV/v7WH5kCA286ayDcvmKKxgj6gq7/hptYH7t5iZnsUCCK9l7uzo7SOJZtLeHxVIZX1jXxm9hju/tQ0coYPjnV5EiVdhcIcM6sNPTbghNC2Ae7uwyJenYhEXNHBwzy1poglmw+wu6IeMzhjciZ3XTSNk8drkrq+pqu5j3Q5gUgv5e6s3F3Jo8sLeHV7KWbGaROHc/OZE7ho+mhGDB0Q6xIlRtRBKNKH1B1t4tkN+/jDqkJ2lh4ifVB/bj9nEjcszGFM6gmxLk/igEJBpJdzd7bsq+WJNXt5bsM+Dje2MCsrlZ9dNZvL54zVPQbyIQoFkV7qYH0jz23Yx9Nri3ivpI4B/ZK4bM5YblwYvPNYpDMKBZFeJBBw3s6v4Km1RSzdWkJTizN7XCo/vHIml88eS+ogTU4nXVMoiPQCtUeb+MOqQh5ftZd91UdIG9SfGxbm8IW88Zw0RhcKSvgUCiIJrKzuKP+zvIA/rCykrqGZRZOGc88lJ3LRjFEM6KexAjl+CgWRBNMS6iJ6Zl0xL28tobklwCWzxnD72ZM0H5F8YgoFkQRRXHWYP76zlz+tL6a0toG0Qf257pTxfPn0CUzI1B3H0jMUCiJxzN1Znl/J71YW8Nr2UgDOmTaSey8bx3knjVQXkfQ4hYJIHGpqCfB/G/fz2zd2s6O0jozBKdx+ziSuPzWHrDTdZCaRo1AQiSOHGpp5ek0RD7+9h33VR5g2aii/uHoOn5mthWwkOhQKInFgT0U9v1tRwDPrijnU0Mwpuen88MoZnDttJGYW6/KkD1EoiMRIVX0jL28t4YVNB3g7v4L+ycanZ43hpkW5zM1Oj3V50kcpFESi6GB9I69sK+Evm0tYnl9BS8DJGT6Ib14whetPzWbk0IGxLlH6OIWCSAS5O/llh1i1u5KXt5aycnclLQFnfMYJ3HrmRD4zewwzxg5TF5HEDYWCSA+rPdrEkk0HWLajjDUFVRysbwRgQuZg/vbsiVwyU0Eg8UuhINIDDjc2s3rPQf68fh8vby2hoTnAuPQTOO/EkSzIzeCUCRnkDh+kIJC4p1AQOU4tAef9sjo27K1mY1E17xZVs7O0joBD6gn9+ULeeD4/fxxzxqUqBCThRDQUzOxi4H4gGXjI3X/S4fU7gVuAZqAc+Kq7F0ayJpHj5e5s3V/L6zvKWLGrko1F1dQ3tgCQNqg/c8alcdGM0cwdn8aiycN1l7EktIiFgpklAw8AFwLFwBozW+zu29rttgHIc/fDZnY78DPgmkjVJBKukpqjvLOnkpW7Klm2o4zS2gYAZowdxufnj2Nudhpzx6eToy4h6WUi2VJYAOS7+24AM3sSuAJoCwV3X9Zu/1XADRGsR+SYGpsDrNxdySvbSlieX8meinoAhg7ox5lTMzl32kjOmTZSC9pLrxfJUMgCitptFwOndrH/zcCLnb1gZrcBtwFkZ2f3VH3Sx9U3NLNsRxkvbSnh9R3lHGpoZlBKMqdNHM4XT81m4cThnDRmGMlJaglI3xHJUOjsf5J3uqPZDUAecHZnr7v7g8CDAHl5eZ0eQyQc5XUNLM+vCAbBzjKONgXIHJLCZXPGcOH0USyalKk5hqRPi2QoFAPj222PA/Z33MnMLgC+A5zt7g0RrEf6oCONLazaU8ny9yt4O7+C90rqABg5dADX5I3n0lljyMvNUGtAJCSSobAGmGJmE4B9wLXA9e13MLO5wG+Bi929LIK1SB+SX3aIv75Xyps7K1hdcJDG5gAp/ZI4JTedf7x4GqdPymRWVipJCgKRj4hYKLh7s5ndAbxM8JLUR9x9q5n9AFjr7ouBnwNDgP8NXcGx190vj1RN0ju1BJz1e6t4ZVspr24rZXdokHjaqKF8aWEOZ00dwYIJGeoWEglDRO9TcPclwJIOz32v3eMLIvn50nvVHm1iRX4FS7eVsuy9MqoON9E/2ThtUiZfOT2X808axVgtRiNy3HRHsySExuYA7+ypZHl+JSt3VbB5X03bHcTnnTiSC04axVlTMxk6sH+sSxVJaAoFiVuHG5t5Y0c5L20t4a/by6hraKZ/snHy+DTuOHcyiyZnkpeTTr/kpFiXKtJrKBQkbrg775cd4o0d5by+s4w1e6pobAmQMTiFS2aN5lMzRnPapOEMStE/W5FI0f8uial91UdYkV/Bil2VLM+voKwueFXy1FFD+PLpuZw7bSSn5Ko1IBItCgWJGndn+4E63tlTybrCKtYXVrG/5igAwwencNqk4ZwxOZOzpo7QILFIjCgUJKIqDzXwdn4Fb+ws5633KygPtQSy0k5gfm4Gt2ansXDicKaNGqr7BkTigEJBelRLwNmwt4rXd5Tzxs5ytuyvwR3SB/XnjCkjOGtKJqdPzlRLQCROKRTkE6s+3Mjb+RW8tr2MZTvKqD7cRHKSMS87jTsvmMpZU0cwMytVU0mIJACFghy3Qw3NrNpVycrdwfUGtpfUtrUGzps2kvNPGsWZUzMZpnsGRBKOQkG61dwSYMv+Wt5+v5w3369gfWEVzQEnpV8S87PT+fsLprJo0nDmZqerNSCS4BQK8hEtAee9klpW7znI8vxK3tlTSd3RZgBmZg3j1rMmcubkTOblpGs+IZFeRqEgNDS3sLm4htUFB1m95yDrCqqoawiGQM7wQXxm9hgWTcrktEnDyRyilcdEejOFQh/U2Bzg3aJqludX8M6eSjbsraahOQDAlJFD+MycsSyYkM4puRmMSx8U42pFJJoUCn3AkcYWNhZXs66witV7DrKm4CCHG1swCy5Ef8PCHBZMyOCU3AwyBqfEulwRiSGFQi90tKmF9XurWJFfyYpdFWwqrqE5EFzFdPLIIVw1f1ywO2jicFIH6QohEfmAQqEXqDnSxPrCKtYVVrG28CDvFlVztClAcpIxe1wqt5w5kVNy05mfk07aILUEROTYFAoJxt0prjrC+r1VrCk4yNqCKnaU1uEOyUnG9DHDuG5BNqdPymTBxAzdKyAix0WhEOcamlvYur+2rSWwrrCqbSbRIQP6MS8nPbT4fDrana6iAAAKAklEQVQnj0/TtNIi8onoJ0icKas9yvq91WzYGwyATftqaAxdGTQ+4wQWTRrO/Jx05manc9KYYbpZTER6lEIhho42BVsB7xYFQ2DD3mr2VR8BICU5iZlZw7jptBzm56QzLzudkcMGxrhiEentFApR0hJwdpUfYmNRNZuKa9hYXM32A7U0tQSvCspKO4GTx6fxldNzmZeTzoyxwxjQT3cLi0h0KRQiJNgNVMX6vdVsLKpmy74a6htbgOBYwOxxqdx8xkTmZqcxd3yaWgEiEhcUCj3A3SmsPMyq3ZW8s+cgawsPUnTwg26gk8YO4/PzxzF7XBpzxqUyacQQLSgjInFJofAxFR08zMpdwZvDVu0+SEltcFnJzCEp5OVk8KWFuczPVTeQiCQWhUKYDjc2syK/kmU7ynjz/fK2lkDmkBQWThze9jVpxGDM1AoQkcSkUOhCae1RXtlWytJtpazaVUljS4DBKcksmpzJzadPYNHkTKaMHKIQEJFeQ6HQwb7qI/xl035e3FLChr3VAEzIHMyXTsvhvBNHkpebQUq/pBhXKSISGQoFoLyugRc27eeFTQdYV1gFBGcPvevCqXxq5mi1BkSkz+izoVDf0MzSbSU8u2E/y/MraAk4J44eyt2fmsanZ40hN3NwrEsUEYm6PhUKjc0B3thZzuKN+3l1WylHmlrISjuBvzlrIlfOzWLqqKGxLlFEJKb6TCg8uXovP37xPWqONJE+qD+fm5fFFSdnkZeTrnsGRERCIhoKZnYxcD+QDDzk7j/p8PoA4DFgPlAJXOPuBZGoZUzaCZx34kguP3ksZ0zOpH+yBotFRDqKWCiYWTLwAHAhUAysMbPF7r6t3W43A1XuPtnMrgV+ClwTiXrOnjqCs6eOiMShRUR6jUj+urwAyHf33e7eCDwJXNFhnyuA34UePwOcb7rMR0QkZiIZCllAUbvt4tBzne7j7s1ADTA8gjWJiEgXIhkKnf3G7x9jH8zsNjNba2Zry8vLe6Q4ERH5qEiGQjEwvt32OGD/sfYxs35AKnCw44Hc/UF3z3P3vBEjNC4gIhIpkQyFNcAUM5tgZinAtcDiDvssBm4KPb4K+Ku7f6SlICIi0RGxq4/cvdnM7gBeJnhJ6iPuvtXMfgCsdffFwMPA780sn2AL4dpI1SMiIt2L6H0K7r4EWNLhue+1e3wUuDqSNYiISPh0B5eIiLSxROvCN7NyoPA43pIJVESonN5A56d7Okdd0/npXjycoxx37/ZKnYQLheNlZmvdPS/WdcQrnZ/u6Rx1Teene4l0jtR9JCIibRQKIiLSpi+EwoOxLiDO6fx0T+eoazo/3UuYc9TrxxRERCR8faGlICIiYVIoiIhIm14RCmZ2sZntMLN8M7unk9cHmNlTodffMbPc6FcZW2GcozvNbJuZbTKz18wsJxZ1xkp356fdfleZmZtZQlxe2JPCOUdm9oXQv6OtZvbHaNcYS2H8H8s2s2VmtiH0/+zSWNTZLXdP6C+C8yrtAiYCKcBGYHqHfb4G/Cb0+FrgqVjXHYfn6FxgUOjx7X3pHIVzfkL7DQXeBFYBebGuO97OETAF2ACkh7ZHxrruODs/DwK3hx5PBwpiXXdnX72hpaAV3rrX7Tly92Xufji0uYrgVOd9RTj/hgB+CPwMOBrN4uJEOOfoVuABd68CcPeyKNcYS+GcHweGhR6n8tGlBOJCbwgFrfDWvXDOUXs3Ay9GtKL40u35MbO5wHh3fyGahcWRcP4NTQWmmtlyM1tlZhdHrbrYC+f83AvcYGbFBCcK/Xp0Sjs+EZ0lNUp6bIW3Xizs79/MbgDygLMjWlF86fL8mFkScB/w5WgVFIfC+TfUj2AX0jkEW5pvmdlMd6+OcG3xIJzzcx3wqLv/0sxOI7hswEx3D0S+vPD1hpZCj63w1ouFc44wswuA7wCXu3tDlGqLB92dn6HATOB1MysAFgKL+9hgc7j/z5539yZ33wPsIBgSfUE45+dm4GkAd18JDCQ4UV5c6Q2hoBXeutftOQp1j/yWYCD0pb5g6Ob8uHuNu2e6e6675xIcc7nc3dfGptyYCOf/2XMEL1jAzDIJdiftjmqVsRPO+dkLnA9gZicRDIW4W3Q+4UMhNEbQusLbduBpD63wZmaXh3Z7GBgeWuHtTuCYlxz2RmGeo58DQ4D/NbN3zazjP+heK8zz06eFeY5eBirNbBuwDLjb3StjU3F0hXl+7gJuNbONwBPAl+Pxl1NNcyEiIm0SvqUgIiI9R6EgIiJtFAoiItJGoSAiIm0UCiIi0kahIAnDzIaHLpd918xKzGxfu+2UT3DcP5jZlT1U49tmdnInz99iZr/u8NxkMyvsOA+XmW0xs3ldfMZHjiXSU3rDNBfSR4SueT8ZwMzuBQ65+y/a7xP6AWvxNnVAZ9w938zKgEXAcgAzmwH0d/f1MS1O+iy1FCThhX7j3mJmvwHWA2PM7BIzW2lm60NraQwO7fvzdutG/LTdYc41sxVmttvMPhvaN8nMfhU69mYzuyr0/AVm9ly7z/9NaM6ojnXdYmY7zex1glNjdOYJgne/trou9BxmdoUF1//YYGZLzWxkJ5/xoVaOmR1q9/geM1sd+l6/181pFAEUCtJ7TAcedve5QBPBu9bPd/d5wCbg78xsFHApMMPdZwM/bvf+kcDpwJXtnr86dNw5wIXAfZ39YO6MmY0DvgucBlxEcO6kzjwFfN7MkkPb1xCcdhmCazcsDH1PfyZ4R2xYQgu4ZAOnEmxdLTKzReG+X/oudR9Jb7HL3deEHi8i+MN8Rai7PgV4m+AkiAHgv83sL0D7abCfC005sMnMWqc8PgP4o7u3ACVm9jbBGWQbw6hnIfBa6zQPZvY0wR/SH+Lu+8xsJ3COmdUAde7+XujlbOBpMxsNDAB2hnMiQi4CLiG46A0EpzCZCqw4jmNIH6RQkN6ivt1jA15y9xs77hSa2fRCgl02txP84QnQflZY6/BnR818uJU98Bj7hTuHTGsXUk3ocasHgH9z9yWhGWw7m7OrrZZQa6P1/7QBP3L3h8OsQQRQ95H0TiuAs81sIoCZDTazKWY2FBgWWijn74G53RznTeBaM0sOdT2dDqwFCoEZZpZiZunAeZ28dxXBFf4yQldGXdXF5zwDXEawu+qpds+nAvtCg+c3dfZGoACYH3r8WYLLQkJwYrab242ljAvNXCrSJbUUpNdx91Izuxl4qt2lqt8GjgB/NrMBBH8hurObQz1DsBtoI8Hf+u9snVY8NNC8mWCXzkeuFHL3YjP7EcFw2E8wTI5Vb6WZrQNS3X1vu5fuBZ4lOFf/amBMJ2//LfC8mV0ILCXU4gm1Lk4EVoW60OqA64GKbr5n6eM0S6qIiLRR95GIiLRRKIiISBuFgoiItFEoiIhIG4WCiIi0USiIiEgbhYKIiLT5/xOdDmS7blOTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b383ecb160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob_outlier=[]\n",
    "for i in range(1,86):\n",
    "    i=i*0.01\n",
    "    prob_outlier.append(y_tr[y_tr.prob_train>i].outlier.sum()/y_tr[y_tr.prob_train>i].shape[0])\n",
    "plt.figure()\n",
    "plt.plot([i*0.01 for i in range(1,86)],prob_outlier)\n",
    "plt.xlabel(\"Treshould Value\")\n",
    "plt.ylabel(\"Ratio of outliers\")\n",
    "plt.title(\"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_target</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123115</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.638506</td>\n",
       "      <td>-0.548086</td>\n",
       "      <td>0.002294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87051</th>\n",
       "      <td>0</td>\n",
       "      <td>0.084343</td>\n",
       "      <td>-0.077139</td>\n",
       "      <td>0.032504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122987</th>\n",
       "      <td>0</td>\n",
       "      <td>2.318157</td>\n",
       "      <td>0.425544</td>\n",
       "      <td>0.181516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188373</th>\n",
       "      <td>0</td>\n",
       "      <td>0.338946</td>\n",
       "      <td>-1.383379</td>\n",
       "      <td>0.049641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>0</td>\n",
       "      <td>0.537236</td>\n",
       "      <td>-0.251507</td>\n",
       "      <td>0.006939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        outlier    target  pred_target  pred_prob\n",
       "123115        0 -0.638506    -0.548086   0.002294\n",
       "87051         0  0.084343    -0.077139   0.032504\n",
       "122987        0  2.318157     0.425544   0.181516\n",
       "188373        0  0.338946    -1.383379   0.049641\n",
       "2165          0  0.537236    -0.251507   0.006939"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(pred_df.pred_prob.max()*100+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Test set')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b383f9c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob_outlier=[]\n",
    "for i in range(1,int(round(pred_df.pred_prob.max()*100+1))):\n",
    "    i=i*0.01\n",
    "    prob_outlier.append(pred_df[pred_df.pred_prob>i].outlier.sum()/pred_df[pred_df.pred_prob>i].shape[0])\n",
    "plt.figure()\n",
    "plt.plot([i*0.01 for i in range(1,int(round(pred_df.pred_prob.max()*100+1)))],prob_outlier)\n",
    "plt.xlabel(\"Treshould Value\")\n",
    "plt.ylabel(\"Ratio of outliers\")\n",
    "plt.title(\"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\scale.py:111: RuntimeWarning: invalid value encountered in less_equal\n",
      "  out[a <= 0] = -1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b383f4eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot([i*0.01 for i in range(1,int(round(pred_df.pred_prob.max()*100+1)))],prob_outlier)\n",
    "plt.xlabel(\"Treshould Value\")\n",
    "plt.ylabel(\"Ratio of outliers\")\n",
    "plt.title(\"Test set\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Test set')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b39d39ca20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num=[]\n",
    "for i in range(1,int(round(pred_df.pred_prob.max()*100+1))):\n",
    "    i=i*0.01\n",
    "    num.append(pred_df[pred_df.pred_prob>i].shape[0]/pred_df.shape[0])\n",
    "plt.figure()\n",
    "plt.plot([i*0.01 for i in range(1,int(round(pred_df.pred_prob.max()*100+1)))],num)\n",
    "plt.xlabel(\"Treshould Value\")\n",
    "plt.ylabel(\"Ratio of samples\")\n",
    "plt.title(\"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[pred_df.pred_prob>0.1].outlier.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[pred_df.pred_prob<0.1].outlier.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[y_tr.prob_train>0.01].outlier.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[y_tr.prob_train<0.01].outlier.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73465, 51723)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of training examples\n",
    "y_tr[y_tr.prob_train>0.01].shape[0],y_tr[y_tr.prob_train<0.01].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12571, 64158)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of test examples\n",
    "pred_df[pred_df.pred_prob>0.1].shape[0],pred_df[pred_df.pred_prob<0.1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have some random idea! Let's try it. We know that outlier is equial -10log(10). So, probably, it features are incoded by this function which is nonlinear. Maybe linear features will give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_target=2**(y_tr.target/-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_param = {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 48,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = lgb.Dataset(X_tr, label=linear_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 0.895244 + 0.0368284\n",
      "[400]\tcv_agg's rmse: 0.893609 + 0.0359247\n",
      "[600]\tcv_agg's rmse: 0.893649 + 0.0357613\n",
      "[800]\tcv_agg's rmse: 0.893875 + 0.0357121\n",
      "[1000]\tcv_agg's rmse: 0.894176 + 0.0358264\n"
     ]
    }
   ],
   "source": [
    "cv_score = lgb.cv(rg_param, tr_data, 10000, early_stopping_rounds=600, verbose_eval=200, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best num:  466 \n",
      "best score: 0.8935534391583646\n"
     ]
    }
   ],
   "source": [
    "print('best num: ', len(cv_score['rmse-mean']), '\\nbest score:', cv_score['rmse-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 0.871901\n",
      "[200]\ttraining's rmse: 0.840926\n",
      "[300]\ttraining's rmse: 0.820992\n",
      "[400]\ttraining's rmse: 0.807409\n",
      "[500]\ttraining's rmse: 0.796093\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(rg_param, tr_data, 500, valid_sets=(tr_data), verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log = clf.predict(X_va, num_iteration=clf.best_iteration)\n",
    "pred_log=-10*np.log2(pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.661605717551893"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huge error! It was worst idea Haha\n",
    "get_lb(pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.534825533330481"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7026626002538454"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9272538581303857"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(np.array([0 for i in range(len(pred_lin))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_va2=y_va.copy()\n",
    "y_va2['pred_log_target']=pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-33.219280948873624, -33.21928095)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equal to outlier\n",
    "-10*np.log2(10),y_va2.target.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another, idea! Let's use outliers predictions as a feature for regression. It work for transperent conductor prediction maybe it can help to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125188,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.prob_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([140457, 179764,  22899, 160544, 171908, 105318,  25836, 150503,\n",
       "             50727, 127460,\n",
       "            ...\n",
       "            151181, 114565,  81844, 122929, 196886,  61872, 128963,  36482,\n",
       "             40177, 150781],\n",
       "           dtype='int64', length=125188)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_va, y_tr, y_va = train_test_split(train[feats].values, target_with_outlier, test_size=0.38, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125188, 253), (76729, 253), (125188, 2), (76729, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_va.shape, y_tr.shape, y_va.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['prob_outliers']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier</th>\n",
       "      <th>target</th>\n",
       "      <th>prob_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140457</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.320053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179764</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.946788</td>\n",
       "      <td>0.142976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22899</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.301051</td>\n",
       "      <td>0.002098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160544</th>\n",
       "      <td>0</td>\n",
       "      <td>1.036026</td>\n",
       "      <td>0.037259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171908</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.664374</td>\n",
       "      <td>0.018513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        outlier    target  prob_train\n",
       "140457        0  0.013333    0.320053\n",
       "179764        0 -0.946788    0.142976\n",
       "22899         0 -0.301051    0.002098\n",
       "160544        0  1.036026    0.037259\n",
       "171908        0 -0.664374    0.018513"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling prob_outliers for training set\n",
    "train2.loc[train2.index.isin(y_tr.index),'prob_outliers']=y_tr.prob_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.loc[train2.index.isin(y_va.index),'prob_outliers']=pred_df.pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2=feats[:]\n",
    "feats2.append('prob_outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr2, X_va2, y_tr2, y_va2 = train_test_split(train2[feats2], target_with_outlier, test_size=0.38, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_param = {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 48,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = lgb.Dataset(X_tr2, label=y_tr2.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 2.94532 + 0.104668\n",
      "[400]\tcv_agg's rmse: 2.84243 + 0.0937743\n",
      "[600]\tcv_agg's rmse: 2.81018 + 0.0920099\n",
      "[800]\tcv_agg's rmse: 2.79241 + 0.0897408\n",
      "[1000]\tcv_agg's rmse: 2.78168 + 0.0901444\n",
      "[1200]\tcv_agg's rmse: 2.77516 + 0.0903369\n",
      "[1400]\tcv_agg's rmse: 2.7693 + 0.0909188\n",
      "[1600]\tcv_agg's rmse: 2.76438 + 0.0908424\n",
      "[1800]\tcv_agg's rmse: 2.76036 + 0.090435\n",
      "[2000]\tcv_agg's rmse: 2.75683 + 0.0901886\n",
      "[2200]\tcv_agg's rmse: 2.75392 + 0.0898743\n",
      "[2400]\tcv_agg's rmse: 2.75158 + 0.0896558\n",
      "[2600]\tcv_agg's rmse: 2.74916 + 0.0888359\n",
      "[2800]\tcv_agg's rmse: 2.74747 + 0.0887952\n",
      "[3000]\tcv_agg's rmse: 2.74619 + 0.0886733\n",
      "[3200]\tcv_agg's rmse: 2.7446 + 0.0883913\n",
      "[3400]\tcv_agg's rmse: 2.74309 + 0.0881613\n",
      "[3600]\tcv_agg's rmse: 2.74221 + 0.0882948\n",
      "[3800]\tcv_agg's rmse: 2.74153 + 0.0885056\n",
      "[4000]\tcv_agg's rmse: 2.74093 + 0.0884648\n",
      "[4200]\tcv_agg's rmse: 2.74016 + 0.0882647\n",
      "[4400]\tcv_agg's rmse: 2.7397 + 0.0881054\n",
      "[4600]\tcv_agg's rmse: 2.73896 + 0.0880526\n",
      "[4800]\tcv_agg's rmse: 2.73819 + 0.0882019\n",
      "[5000]\tcv_agg's rmse: 2.73768 + 0.0880387\n",
      "[5200]\tcv_agg's rmse: 2.73727 + 0.0878322\n",
      "[5400]\tcv_agg's rmse: 2.73681 + 0.0877433\n",
      "[5600]\tcv_agg's rmse: 2.73631 + 0.0876904\n",
      "[5800]\tcv_agg's rmse: 2.73583 + 0.08753\n",
      "[6000]\tcv_agg's rmse: 2.73554 + 0.0877172\n",
      "[6200]\tcv_agg's rmse: 2.7354 + 0.0876775\n",
      "[6400]\tcv_agg's rmse: 2.7353 + 0.0875107\n",
      "[6600]\tcv_agg's rmse: 2.73516 + 0.0873496\n",
      "[6800]\tcv_agg's rmse: 2.73488 + 0.0872499\n",
      "[7000]\tcv_agg's rmse: 2.73464 + 0.0874222\n",
      "[7200]\tcv_agg's rmse: 2.7346 + 0.0871847\n",
      "[7400]\tcv_agg's rmse: 2.73447 + 0.0870753\n",
      "[7600]\tcv_agg's rmse: 2.73439 + 0.0870933\n",
      "[7800]\tcv_agg's rmse: 2.7342 + 0.0870423\n",
      "[8000]\tcv_agg's rmse: 2.73419 + 0.0870701\n",
      "[8200]\tcv_agg's rmse: 2.73407 + 0.0871809\n",
      "[8400]\tcv_agg's rmse: 2.7338 + 0.0871532\n",
      "[8600]\tcv_agg's rmse: 2.73357 + 0.0872704\n",
      "[8800]\tcv_agg's rmse: 2.7335 + 0.0873112\n",
      "[9000]\tcv_agg's rmse: 2.73343 + 0.0873398\n",
      "[9200]\tcv_agg's rmse: 2.73336 + 0.0872709\n",
      "[9400]\tcv_agg's rmse: 2.73335 + 0.0872149\n",
      "[9600]\tcv_agg's rmse: 2.73332 + 0.0871295\n",
      "[9800]\tcv_agg's rmse: 2.7333 + 0.0870671\n",
      "[10000]\tcv_agg's rmse: 2.73327 + 0.0870121\n"
     ]
    }
   ],
   "source": [
    "cv_score = lgb.cv(rg_param, tr_data, 10000, early_stopping_rounds=600, verbose_eval=200, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best num:  9949 \n",
      "best score: 2.7332440508881763\n"
     ]
    }
   ],
   "source": [
    "print('best num: ', len(cv_score['rmse-mean']), '\\nbest score:', cv_score['rmse-mean'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is really amazing! It can be still improved I am worried about overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 2.70743\n",
      "[400]\ttraining's rmse: 2.43657\n",
      "[600]\ttraining's rmse: 2.29031\n",
      "[800]\ttraining's rmse: 2.19129\n",
      "[1000]\ttraining's rmse: 2.11492\n",
      "[1200]\ttraining's rmse: 2.05255\n",
      "[1400]\ttraining's rmse: 2.00259\n",
      "[1600]\ttraining's rmse: 1.95584\n",
      "[1800]\ttraining's rmse: 1.91521\n",
      "[2000]\ttraining's rmse: 1.8778\n",
      "[2200]\ttraining's rmse: 1.84573\n",
      "[2400]\ttraining's rmse: 1.81538\n",
      "[2600]\ttraining's rmse: 1.79068\n",
      "[2800]\ttraining's rmse: 1.76536\n",
      "[3000]\ttraining's rmse: 1.7436\n",
      "[3200]\ttraining's rmse: 1.72352\n",
      "[3400]\ttraining's rmse: 1.70347\n",
      "[3600]\ttraining's rmse: 1.68511\n",
      "[3800]\ttraining's rmse: 1.6676\n",
      "[4000]\ttraining's rmse: 1.64996\n",
      "[4200]\ttraining's rmse: 1.6339\n",
      "[4400]\ttraining's rmse: 1.61922\n",
      "[4600]\ttraining's rmse: 1.60532\n",
      "[4800]\ttraining's rmse: 1.59158\n",
      "[5000]\ttraining's rmse: 1.57752\n",
      "[5200]\ttraining's rmse: 1.56379\n",
      "[5400]\ttraining's rmse: 1.55201\n",
      "[5600]\ttraining's rmse: 1.53979\n",
      "[5800]\ttraining's rmse: 1.52849\n",
      "[6000]\ttraining's rmse: 1.51667\n",
      "[6200]\ttraining's rmse: 1.50534\n",
      "[6400]\ttraining's rmse: 1.49374\n",
      "[6600]\ttraining's rmse: 1.48301\n",
      "[6800]\ttraining's rmse: 1.47235\n",
      "[7000]\ttraining's rmse: 1.46167\n",
      "[7200]\ttraining's rmse: 1.45184\n",
      "[7400]\ttraining's rmse: 1.4424\n",
      "[7600]\ttraining's rmse: 1.43282\n",
      "[7800]\ttraining's rmse: 1.42327\n",
      "[8000]\ttraining's rmse: 1.41411\n",
      "[8200]\ttraining's rmse: 1.40505\n",
      "[8400]\ttraining's rmse: 1.39569\n",
      "[8600]\ttraining's rmse: 1.387\n",
      "[8800]\ttraining's rmse: 1.37807\n",
      "[9000]\ttraining's rmse: 1.36946\n",
      "[9200]\ttraining's rmse: 1.361\n",
      "[9400]\ttraining's rmse: 1.35305\n",
      "[9600]\ttraining's rmse: 1.3449\n",
      "[9800]\ttraining's rmse: 1.33666\n",
      "[10000]\ttraining's rmse: 1.32891\n"
     ]
    }
   ],
   "source": [
    "# Let's try to fit until 10000 and 5000 and compare resutls\n",
    "clf10 = lgb.train(rg_param, tr_data, 10000, valid_sets=(tr_data), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 2.70743\n",
      "[400]\ttraining's rmse: 2.43657\n",
      "[600]\ttraining's rmse: 2.29031\n",
      "[800]\ttraining's rmse: 2.19129\n",
      "[1000]\ttraining's rmse: 2.11492\n",
      "[1200]\ttraining's rmse: 2.05255\n",
      "[1400]\ttraining's rmse: 2.00259\n",
      "[1600]\ttraining's rmse: 1.95584\n",
      "[1800]\ttraining's rmse: 1.91521\n",
      "[2000]\ttraining's rmse: 1.8778\n",
      "[2200]\ttraining's rmse: 1.84573\n",
      "[2400]\ttraining's rmse: 1.81538\n",
      "[2600]\ttraining's rmse: 1.79068\n",
      "[2800]\ttraining's rmse: 1.76536\n",
      "[3000]\ttraining's rmse: 1.7436\n",
      "[3200]\ttraining's rmse: 1.72352\n",
      "[3400]\ttraining's rmse: 1.70347\n",
      "[3600]\ttraining's rmse: 1.68511\n",
      "[3800]\ttraining's rmse: 1.6676\n",
      "[4000]\ttraining's rmse: 1.64996\n",
      "[4200]\ttraining's rmse: 1.6339\n",
      "[4400]\ttraining's rmse: 1.61922\n",
      "[4600]\ttraining's rmse: 1.60532\n",
      "[4800]\ttraining's rmse: 1.59158\n",
      "[5000]\ttraining's rmse: 1.57752\n"
     ]
    }
   ],
   "source": [
    "clf5 = lgb.train(rg_param, tr_data, 5000, valid_sets=(tr_data), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 2.70743\n",
      "[400]\ttraining's rmse: 2.43657\n",
      "[600]\ttraining's rmse: 2.29031\n",
      "[800]\ttraining's rmse: 2.19129\n",
      "[1000]\ttraining's rmse: 2.11492\n"
     ]
    }
   ],
   "source": [
    "clf1 = lgb.train(rg_param, tr_data, 1000, valid_sets=(tr_data), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred10 = clf10.predict(X_va2, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = clf5.predict(X_va2, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = clf1.predict(X_va2, num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.821413304057852"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.835911155470752"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8398787962019543"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(pred10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7026626002538454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All of the above results are extremely bad since we are overfitting to test set. Instead we need to devide our test set to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 255)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 258)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 257)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_va, y_tr, y_va = train_test_split(train[feats], target_with_outlier, test_size=0.38, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76729, 253)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_va.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.917183\tvalid_1's auc: 0.91992\n",
      "[200]\ttraining's auc: 0.924252\tvalid_1's auc: 0.921347\n",
      "[300]\ttraining's auc: 0.929413\tvalid_1's auc: 0.921534\n",
      "[400]\ttraining's auc: 0.933795\tvalid_1's auc: 0.921478\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttraining's auc: 0.931838\tvalid_1's auc: 0.921751\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.918611\tvalid_1's auc: 0.906582\n",
      "[200]\ttraining's auc: 0.925213\tvalid_1's auc: 0.908707\n",
      "[300]\ttraining's auc: 0.929988\tvalid_1's auc: 0.910282\n",
      "[400]\ttraining's auc: 0.934385\tvalid_1's auc: 0.911197\n",
      "[500]\ttraining's auc: 0.938165\tvalid_1's auc: 0.91164\n",
      "[600]\ttraining's auc: 0.941646\tvalid_1's auc: 0.91179\n",
      "[700]\ttraining's auc: 0.944731\tvalid_1's auc: 0.911839\n",
      "[800]\ttraining's auc: 0.947757\tvalid_1's auc: 0.911896\n",
      "Early stopping, best iteration is:\n",
      "[723]\ttraining's auc: 0.945501\tvalid_1's auc: 0.911964\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.921584\tvalid_1's auc: 0.894671\n",
      "[200]\ttraining's auc: 0.927941\tvalid_1's auc: 0.896916\n",
      "[300]\ttraining's auc: 0.93263\tvalid_1's auc: 0.898119\n",
      "[400]\ttraining's auc: 0.936422\tvalid_1's auc: 0.89872\n",
      "[500]\ttraining's auc: 0.939803\tvalid_1's auc: 0.898806\n",
      "Early stopping, best iteration is:\n",
      "[467]\ttraining's auc: 0.938829\tvalid_1's auc: 0.898898\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.922863\tvalid_1's auc: 0.886206\n",
      "[200]\ttraining's auc: 0.929262\tvalid_1's auc: 0.887556\n",
      "[300]\ttraining's auc: 0.933676\tvalid_1's auc: 0.888633\n",
      "[400]\ttraining's auc: 0.937544\tvalid_1's auc: 0.888959\n",
      "[500]\ttraining's auc: 0.940933\tvalid_1's auc: 0.889307\n",
      "[600]\ttraining's auc: 0.944266\tvalid_1's auc: 0.889255\n",
      "[700]\ttraining's auc: 0.947229\tvalid_1's auc: 0.889474\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttraining's auc: 0.946132\tvalid_1's auc: 0.889536\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.920755\tvalid_1's auc: 0.89927\n",
      "[200]\ttraining's auc: 0.92716\tvalid_1's auc: 0.901687\n",
      "[300]\ttraining's auc: 0.932321\tvalid_1's auc: 0.903097\n",
      "[400]\ttraining's auc: 0.936672\tvalid_1's auc: 0.903652\n",
      "[500]\ttraining's auc: 0.940363\tvalid_1's auc: 0.904135\n",
      "[600]\ttraining's auc: 0.943763\tvalid_1's auc: 0.90435\n",
      "[700]\ttraining's auc: 0.946816\tvalid_1's auc: 0.904303\n",
      "Early stopping, best iteration is:\n",
      "[658]\ttraining's auc: 0.945572\tvalid_1's auc: 0.904416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17040935323352144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=y_tr.outlier\n",
    "# From chau's kernel but Adam's parameters\n",
    "param =  {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 3,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9, #\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9, #\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"scale_pos_weight\": 15,\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "oof_out = np.zeros(len(X_tr))\n",
    "predictions_out = np.zeros(len(X_va))\n",
    "predictions_out_final = np.zeros(len(test))\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_tr,y_tr['outlier'].values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X_tr.iloc[trn_idx][feats], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(X_tr.iloc[val_idx][feats], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "    oof_out[val_idx] = clf.predict(X_tr.iloc[val_idx][feats], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions_out += clf.predict(X_va[feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    predictions_out_final += clf.predict(test[feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "\n",
    "np.sqrt(mean_squared_error(oof_out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17040935323352144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Large error\n",
    "np.sqrt(mean_squared_error(oof_out, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at relatio of predicted target to predicted outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_va, y_tr, y_va = train_test_split(train[feats], target_with_outlier, test_size=0.38, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140457</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179764</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.946788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22899</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.301051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160544</th>\n",
       "      <td>0</td>\n",
       "      <td>1.036026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171908</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.664374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        outlier    target\n",
       "140457        0  0.013333\n",
       "179764        0 -0.946788\n",
       "22899         0 -0.301051\n",
       "160544        0  1.036026\n",
       "171908        0 -0.664374"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.58046\tvalid_1's rmse: 3.66991\n",
      "[200]\ttraining's rmse: 3.46286\tvalid_1's rmse: 3.63273\n",
      "[300]\ttraining's rmse: 3.39054\tvalid_1's rmse: 3.61732\n",
      "[400]\ttraining's rmse: 3.33437\tvalid_1's rmse: 3.61146\n",
      "[500]\ttraining's rmse: 3.28756\tvalid_1's rmse: 3.60716\n",
      "[600]\ttraining's rmse: 3.24652\tvalid_1's rmse: 3.60529\n",
      "[700]\ttraining's rmse: 3.20942\tvalid_1's rmse: 3.60469\n",
      "[800]\ttraining's rmse: 3.17664\tvalid_1's rmse: 3.60481\n",
      "[900]\ttraining's rmse: 3.14277\tvalid_1's rmse: 3.60478\n",
      "[1000]\ttraining's rmse: 3.11189\tvalid_1's rmse: 3.60485\n",
      "Early stopping, best iteration is:\n",
      "[933]\ttraining's rmse: 3.1324\tvalid_1's rmse: 3.60412\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.5773\tvalid_1's rmse: 3.68439\n",
      "[200]\ttraining's rmse: 3.45854\tvalid_1's rmse: 3.65424\n",
      "[300]\ttraining's rmse: 3.38404\tvalid_1's rmse: 3.6419\n",
      "[400]\ttraining's rmse: 3.3258\tvalid_1's rmse: 3.63482\n",
      "[500]\ttraining's rmse: 3.27887\tvalid_1's rmse: 3.63126\n",
      "[600]\ttraining's rmse: 3.23798\tvalid_1's rmse: 3.62975\n",
      "[700]\ttraining's rmse: 3.20318\tvalid_1's rmse: 3.62844\n",
      "[800]\ttraining's rmse: 3.17136\tvalid_1's rmse: 3.62697\n",
      "[900]\ttraining's rmse: 3.14157\tvalid_1's rmse: 3.62619\n",
      "[1000]\ttraining's rmse: 3.11383\tvalid_1's rmse: 3.62602\n",
      "[1100]\ttraining's rmse: 3.08596\tvalid_1's rmse: 3.62599\n",
      "Early stopping, best iteration is:\n",
      "[1036]\ttraining's rmse: 3.10363\tvalid_1's rmse: 3.62556\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.57175\tvalid_1's rmse: 3.70007\n",
      "[200]\ttraining's rmse: 3.45258\tvalid_1's rmse: 3.6777\n",
      "[300]\ttraining's rmse: 3.37532\tvalid_1's rmse: 3.66977\n",
      "[400]\ttraining's rmse: 3.31725\tvalid_1's rmse: 3.66577\n",
      "[500]\ttraining's rmse: 3.27088\tvalid_1's rmse: 3.66423\n",
      "[600]\ttraining's rmse: 3.23104\tvalid_1's rmse: 3.66371\n",
      "[700]\ttraining's rmse: 3.19465\tvalid_1's rmse: 3.66357\n",
      "[800]\ttraining's rmse: 3.16219\tvalid_1's rmse: 3.66327\n",
      "[900]\ttraining's rmse: 3.13097\tvalid_1's rmse: 3.66273\n",
      "Early stopping, best iteration is:\n",
      "[885]\ttraining's rmse: 3.13525\tvalid_1's rmse: 3.66256\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.56478\tvalid_1's rmse: 3.71865\n",
      "[200]\ttraining's rmse: 3.44406\tvalid_1's rmse: 3.69546\n",
      "[300]\ttraining's rmse: 3.36856\tvalid_1's rmse: 3.68773\n",
      "[400]\ttraining's rmse: 3.31084\tvalid_1's rmse: 3.68233\n",
      "[500]\ttraining's rmse: 3.26154\tvalid_1's rmse: 3.67768\n",
      "[600]\ttraining's rmse: 3.22076\tvalid_1's rmse: 3.67562\n",
      "[700]\ttraining's rmse: 3.18466\tvalid_1's rmse: 3.67444\n",
      "[800]\ttraining's rmse: 3.1508\tvalid_1's rmse: 3.67392\n",
      "[900]\ttraining's rmse: 3.12056\tvalid_1's rmse: 3.67398\n",
      "Early stopping, best iteration is:\n",
      "[859]\ttraining's rmse: 3.13256\tvalid_1's rmse: 3.67335\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.58377\tvalid_1's rmse: 3.65931\n",
      "[200]\ttraining's rmse: 3.46831\tvalid_1's rmse: 3.62098\n",
      "[300]\ttraining's rmse: 3.39784\tvalid_1's rmse: 3.60767\n",
      "[400]\ttraining's rmse: 3.34115\tvalid_1's rmse: 3.6\n",
      "[500]\ttraining's rmse: 3.29467\tvalid_1's rmse: 3.59471\n",
      "[600]\ttraining's rmse: 3.25434\tvalid_1's rmse: 3.59063\n",
      "[700]\ttraining's rmse: 3.21885\tvalid_1's rmse: 3.58905\n",
      "[800]\ttraining's rmse: 3.18371\tvalid_1's rmse: 3.58801\n",
      "[900]\ttraining's rmse: 3.15344\tvalid_1's rmse: 3.58753\n",
      "[1000]\ttraining's rmse: 3.12455\tvalid_1's rmse: 3.58795\n",
      "Early stopping, best iteration is:\n",
      "[924]\ttraining's rmse: 3.14585\tvalid_1's rmse: 3.58735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.630738758585358"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target=y_tr.target\n",
    "# From chau's kernel but Adam's parameters\n",
    "param =  {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "oof_reg = np.zeros(len(X_tr))\n",
    "predictions_reg = np.zeros(len(X_va))\n",
    "predictions_final = np.zeros(len(test))\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_tr,y_tr['outlier'].values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X_tr.iloc[trn_idx][feats], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(X_tr.iloc[val_idx][feats], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "    oof_reg[val_idx] = clf.predict(X_tr.iloc[val_idx][feats], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions_reg += clf.predict(X_va[feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    predictions_final += clf.predict(test[feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.sqrt(mean_squared_error(oof_reg, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazing we have less error with smaller dataset.\n",
    "3.649012733482272 before splitting\n",
    "Now,\n",
    "3.6329832506410753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_va['predicted_target']=predictions_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7002935017637917"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Almost similar results for test set\n",
    "get_lb(y_va.predicted_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "y_tr['predicted_target']=oof_reg\n",
    "y_va['predicted_target']=predictions_reg\n",
    "y_tr['prob_out']=oof_out\n",
    "y_va['prob_out']=predictions_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_va_sorted=y_va.sort_values('prob_out',ascending=False)\n",
    "y_tr_sorted=y_tr.sort_values('prob_out',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_va_sorted=y_va_sorted[y_va_sorted.prob_out>0.5]\n",
    "y_tr_sorted=y_tr_sorted[y_tr_sorted.prob_out>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4050, 2495)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_sorted.shape[0],y_va_sorted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ratio_va=[]\n",
    "number_va=[]\n",
    "ratio_tr=[]\n",
    "number_tr=[]\n",
    "for i in range(0,-25,-1):\n",
    "    n_va=y_va_sorted[y_va_sorted.predicted_target<i].shape[0]\n",
    "    number_va.append(n_va)\n",
    "    ratio_va.append(y_va_sorted[y_va_sorted.predicted_target<i].outlier.sum()/n_va)\n",
    "    \n",
    "    n_tr=y_tr_sorted[y_tr_sorted.predicted_target<i].shape[0]\n",
    "    number_tr.append(n_tr)\n",
    "    ratio_tr.append(y_tr_sorted[y_tr_sorted.predicted_target<i].outlier.sum()/n_tr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x226873780b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(range(0,-25,-1),ratio_tr)\n",
    "plt.ylabel('Ratio of outliers')\n",
    "plt.xlabel('Predicted target')\n",
    "plt.title('Training set:Probability>0.5')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(range(0,-25,-1),ratio_va)\n",
    "plt.ylabel('Ratio of outliers')\n",
    "plt.xlabel('Predicted target')\n",
    "plt.title('Test set:Probability>0.5')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22688a27780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(range(0,-25,-1),number_tr)\n",
    "plt.ylabel('Total number of samples')\n",
    "plt.xlabel('Predicted target')\n",
    "plt.title('Validation set:Probability>0.5')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(range(0,-25,-1),number_va)\n",
    "plt.ylabel('Total number of samples')\n",
    "plt.xlabel('Predicted target')\n",
    "plt.title('Test set:Probability>0.5')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_target</th>\n",
       "      <th>prob_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140457</th>\n",
       "      <td>-2.384720</td>\n",
       "      <td>0.417188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179764</th>\n",
       "      <td>-1.318909</td>\n",
       "      <td>0.240523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22899</th>\n",
       "      <td>0.133268</td>\n",
       "      <td>0.007925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160544</th>\n",
       "      <td>0.827795</td>\n",
       "      <td>0.054423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171908</th>\n",
       "      <td>-0.150823</td>\n",
       "      <td>0.026663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted_target  prob_out\n",
       "140457         -2.384720  0.417188\n",
       "179764         -1.318909  0.240523\n",
       "22899           0.133268  0.007925\n",
       "160544          0.827795  0.054423\n",
       "171908         -0.150823  0.026663"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.loc[:,['predicted_target','prob_out']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09521932410967981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7000553656609774"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(y_tr.loc[:,['predicted_target','prob_out']],y_tr.loc[:,'target'])\n",
    "print(reg.score(y_tr.loc[:,['predicted_target','prob_out']],y_tr.loc[:,'target']))\n",
    "reg_pred=reg.predict(y_va.loc[:,['predicted_target','prob_out']])\n",
    "get_lb(reg_pred)\n",
    "#Almost no improvement haha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_score=[]\n",
    "test_score=[]\n",
    "for num in range(1,1000):\n",
    "    reg = LinearRegression().fit(y_tr_sorted.loc[:,['predicted_target','prob_out']].head(num),y_tr_sorted.loc[:,'target'].head(num))\n",
    "    reg_score.append(reg.score(y_tr_sorted.loc[:,['predicted_target','prob_out']].head(num),y_tr_sorted.loc[:,'target'].head(num)))\n",
    "    pred=reg.predict(y_va_sorted.loc[:,['predicted_target','prob_out']].head(num))\n",
    "    target=y_va.predicted_target.copy()\n",
    "    target.loc[target.index.isin(y_va_sorted.head(num).index)]=pred\n",
    "    test_score.append(get_lb(target))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2268c13cfd0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2268c0e0550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,50),reg_score[0:49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2268d053630>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2268c0ef860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,200),test_score[:199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=y_va.target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.loc[target.index.isin(y_va_sorted.head(20).index)]=-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7002935017637917"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lb(y_va.predicted_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in range(1000):\n",
    "    a+=random.choices([0,1],weights=[0.9,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_va, y_tr, y_va = train_test_split(train[feats], target_with_outlier, test_size=0.38, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76729, 253)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_va.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0671082\tvalid_1's binary_logloss: 0.0720479\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.0484886\tvalid_1's binary_logloss: 0.0502096\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0664381\tvalid_1's binary_logloss: 0.0720133\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.0483025\tvalid_1's binary_logloss: 0.0507281\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0655342\tvalid_1's binary_logloss: 0.0750983\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's binary_logloss: 0.0481346\tvalid_1's binary_logloss: 0.0516465\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0656604\tvalid_1's binary_logloss: 0.074284\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.0479491\tvalid_1's binary_logloss: 0.0514458\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0663054\tvalid_1's binary_logloss: 0.0720437\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.0482174\tvalid_1's binary_logloss: 0.0507467\n"
     ]
    }
   ],
   "source": [
    "target=y_tr.outlier\n",
    "# From chau's kernel but Adam's parameters\n",
    "param =  {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 20, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9, #\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9, #\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"scale_pos_weight\": 15,\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "oof_out_proba = np.zeros(len(X_tr))\n",
    "predictions_out_proba = np.zeros(len(X_va))\n",
    "predictions_out_final_proba = np.zeros(len(test))\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_tr,y_tr['outlier'].values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X_tr.iloc[trn_idx][feats], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(X_tr.iloc[val_idx][feats], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "    oof_out_proba[val_idx] = clf.predict(X_tr.iloc[val_idx][feats], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions_out_proba += clf.predict(X_va[feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    predictions_out_final_proba += clf.predict(test[feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "\n",
    "#np.sqrt(mean_squared_error(oof_out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_tr['pred_proba']=oof_out_proba\n",
    "y_va['pred_proba']=predictions_out_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted_target</th>\n",
       "      <th>prob_out</th>\n",
       "      <th>pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121556</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.330013</td>\n",
       "      <td>-15.395987</td>\n",
       "      <td>0.815893</td>\n",
       "      <td>0.104791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59156</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.076884</td>\n",
       "      <td>-13.947709</td>\n",
       "      <td>0.785804</td>\n",
       "      <td>0.104791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145192</th>\n",
       "      <td>0</td>\n",
       "      <td>0.381281</td>\n",
       "      <td>-7.360986</td>\n",
       "      <td>0.676012</td>\n",
       "      <td>0.104727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139384</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-14.083611</td>\n",
       "      <td>0.826792</td>\n",
       "      <td>0.104485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25347</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-22.582171</td>\n",
       "      <td>0.850167</td>\n",
       "      <td>0.104402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94554</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.425834</td>\n",
       "      <td>-19.563889</td>\n",
       "      <td>0.855501</td>\n",
       "      <td>0.104316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68825</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.553302</td>\n",
       "      <td>-12.175527</td>\n",
       "      <td>0.807013</td>\n",
       "      <td>0.103644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151711</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.399803</td>\n",
       "      <td>-10.127872</td>\n",
       "      <td>0.795408</td>\n",
       "      <td>0.103634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179088</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-12.416098</td>\n",
       "      <td>0.812498</td>\n",
       "      <td>0.103634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63172</th>\n",
       "      <td>0</td>\n",
       "      <td>1.455046</td>\n",
       "      <td>-12.974710</td>\n",
       "      <td>0.817353</td>\n",
       "      <td>0.103634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83617</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.017764</td>\n",
       "      <td>-16.957354</td>\n",
       "      <td>0.839625</td>\n",
       "      <td>0.103634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118071</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-7.509904</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.103634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-18.412681</td>\n",
       "      <td>0.823473</td>\n",
       "      <td>0.103551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.246415</td>\n",
       "      <td>-8.224965</td>\n",
       "      <td>0.683845</td>\n",
       "      <td>0.103428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141031</th>\n",
       "      <td>0</td>\n",
       "      <td>0.627857</td>\n",
       "      <td>-15.316464</td>\n",
       "      <td>0.812798</td>\n",
       "      <td>0.103388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166109</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.039552</td>\n",
       "      <td>-9.517937</td>\n",
       "      <td>0.791142</td>\n",
       "      <td>0.103328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100762</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-12.794973</td>\n",
       "      <td>0.787863</td>\n",
       "      <td>0.103264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54522</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.423813</td>\n",
       "      <td>-8.864725</td>\n",
       "      <td>0.749928</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31154</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-10.295580</td>\n",
       "      <td>0.735998</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187302</th>\n",
       "      <td>0</td>\n",
       "      <td>1.947471</td>\n",
       "      <td>-10.777127</td>\n",
       "      <td>0.752785</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15157</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.556898</td>\n",
       "      <td>-10.776649</td>\n",
       "      <td>0.782454</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110792</th>\n",
       "      <td>0</td>\n",
       "      <td>1.670460</td>\n",
       "      <td>-9.525850</td>\n",
       "      <td>0.714791</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156580</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-12.999452</td>\n",
       "      <td>0.770791</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22737</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-7.731703</td>\n",
       "      <td>0.682152</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116144</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.170125</td>\n",
       "      <td>-14.632374</td>\n",
       "      <td>0.804347</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15933</th>\n",
       "      <td>0</td>\n",
       "      <td>0.204692</td>\n",
       "      <td>-16.497099</td>\n",
       "      <td>0.787428</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150908</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.208852</td>\n",
       "      <td>-12.738650</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91777</th>\n",
       "      <td>0</td>\n",
       "      <td>0.250610</td>\n",
       "      <td>-7.654374</td>\n",
       "      <td>0.688427</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38746</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.236473</td>\n",
       "      <td>-10.697632</td>\n",
       "      <td>0.728339</td>\n",
       "      <td>0.103155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.219281</td>\n",
       "      <td>-6.447116</td>\n",
       "      <td>0.740969</td>\n",
       "      <td>0.103123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36393</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.421041</td>\n",
       "      <td>-0.141480</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.010970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23402</th>\n",
       "      <td>0</td>\n",
       "      <td>1.796522</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.010970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172454</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.054554</td>\n",
       "      <td>-0.247063</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.010970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91330</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.279970</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.010970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167136</th>\n",
       "      <td>0</td>\n",
       "      <td>0.964583</td>\n",
       "      <td>-0.195931</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.010970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120802</th>\n",
       "      <td>0</td>\n",
       "      <td>1.136638</td>\n",
       "      <td>-0.008707</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.010970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115997</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.265076</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.010970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78018</th>\n",
       "      <td>0</td>\n",
       "      <td>1.153378</td>\n",
       "      <td>0.483342</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54528</th>\n",
       "      <td>0</td>\n",
       "      <td>1.142054</td>\n",
       "      <td>-0.905164</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53987</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.278632</td>\n",
       "      <td>0.044994</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53786</th>\n",
       "      <td>0</td>\n",
       "      <td>0.516291</td>\n",
       "      <td>0.249835</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183473</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.456558</td>\n",
       "      <td>-0.729202</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30164</th>\n",
       "      <td>0</td>\n",
       "      <td>2.509208</td>\n",
       "      <td>0.184795</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36172</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.333559</td>\n",
       "      <td>0.215402</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192160</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.381945</td>\n",
       "      <td>-0.174493</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44277</th>\n",
       "      <td>0</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>0.293954</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59906</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.739262</td>\n",
       "      <td>-0.173082</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49279</th>\n",
       "      <td>0</td>\n",
       "      <td>1.986613</td>\n",
       "      <td>0.043638</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125034</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.559753</td>\n",
       "      <td>-0.075914</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55503</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.133668</td>\n",
       "      <td>-0.007259</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170744</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.821551</td>\n",
       "      <td>0.074173</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118833</th>\n",
       "      <td>0</td>\n",
       "      <td>0.057482</td>\n",
       "      <td>0.060190</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95519</th>\n",
       "      <td>0</td>\n",
       "      <td>0.189061</td>\n",
       "      <td>0.102206</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129990</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.124298</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490749</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>0.010966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68006</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.668287</td>\n",
       "      <td>-0.845199</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.010959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158066</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.188022</td>\n",
       "      <td>-0.003653</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.010952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156805</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.712292</td>\n",
       "      <td>-0.752603</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.010950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186449</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.085161</td>\n",
       "      <td>-0.323348</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.010949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66706</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.101904</td>\n",
       "      <td>-0.198926</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.010948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76729 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        outlier     target  predicted_target  prob_out  pred_proba\n",
       "121556        0  -0.330013        -15.395987  0.815893    0.104791\n",
       "59156         0  -3.076884        -13.947709  0.785804    0.104791\n",
       "145192        0   0.381281         -7.360986  0.676012    0.104727\n",
       "139384        1 -33.219281        -14.083611  0.826792    0.104485\n",
       "25347         1 -33.219281        -22.582171  0.850167    0.104402\n",
       "94554         0  -1.425834        -19.563889  0.855501    0.104316\n",
       "68825         0  -0.553302        -12.175527  0.807013    0.103644\n",
       "151711        0  -0.399803        -10.127872  0.795408    0.103634\n",
       "179088        1 -33.219281        -12.416098  0.812498    0.103634\n",
       "63172         0   1.455046        -12.974710  0.817353    0.103634\n",
       "83617         0  -1.017764        -16.957354  0.839625    0.103634\n",
       "118071        1 -33.219281         -7.509904  0.816853    0.103634\n",
       "12602         1 -33.219281        -18.412681  0.823473    0.103551\n",
       "7678          0  -0.246415         -8.224965  0.683845    0.103428\n",
       "141031        0   0.627857        -15.316464  0.812798    0.103388\n",
       "166109        0  -0.039552         -9.517937  0.791142    0.103328\n",
       "100762        1 -33.219281        -12.794973  0.787863    0.103264\n",
       "54522         0  -0.423813         -8.864725  0.749928    0.103155\n",
       "31154         1 -33.219281        -10.295580  0.735998    0.103155\n",
       "187302        0   1.947471        -10.777127  0.752785    0.103155\n",
       "15157         0  -2.556898        -10.776649  0.782454    0.103155\n",
       "110792        0   1.670460         -9.525850  0.714791    0.103155\n",
       "156580        1 -33.219281        -12.999452  0.770791    0.103155\n",
       "22737         1 -33.219281         -7.731703  0.682152    0.103155\n",
       "116144        0  -1.170125        -14.632374  0.804347    0.103155\n",
       "15933         0   0.204692        -16.497099  0.787428    0.103155\n",
       "150908        0  -0.208852        -12.738650  0.773008    0.103155\n",
       "91777         0   0.250610         -7.654374  0.688427    0.103155\n",
       "38746         0  -1.236473        -10.697632  0.728339    0.103155\n",
       "195608        1 -33.219281         -6.447116  0.740969    0.103123\n",
       "...         ...        ...               ...       ...         ...\n",
       "36393         0  -1.421041         -0.141480  0.003890    0.010970\n",
       "23402         0   1.796522          0.015543  0.004629    0.010970\n",
       "172454        0  -2.054554         -0.247063  0.001820    0.010970\n",
       "91330         0  -1.279970          0.029110  0.005303    0.010970\n",
       "167136        0   0.964583         -0.195931  0.008028    0.010970\n",
       "120802        0   1.136638         -0.008707  0.005362    0.010970\n",
       "115997        0  -0.265076          0.179867  0.004032    0.010970\n",
       "78018         0   1.153378          0.483342  0.003596    0.010969\n",
       "54528         0   1.142054         -0.905164  0.002137    0.010969\n",
       "53987         0  -0.278632          0.044994  0.001565    0.010969\n",
       "53786         0   0.516291          0.249835  0.001940    0.010969\n",
       "183473        0  -0.456558         -0.729202  0.001747    0.010969\n",
       "30164         0   2.509208          0.184795  0.004408    0.010969\n",
       "36172         0  -1.333559          0.215402  0.003448    0.010969\n",
       "192160        0  -0.381945         -0.174493  0.003120    0.010969\n",
       "44277         0   0.196873          0.293954  0.002251    0.010969\n",
       "59906         0  -0.739262         -0.173082  0.002301    0.010968\n",
       "49279         0   1.986613          0.043638  0.002099    0.010968\n",
       "125034        0  -0.559753         -0.075914  0.003531    0.010968\n",
       "55503         0  -0.133668         -0.007259  0.004409    0.010968\n",
       "170744        0  -0.821551          0.074173  0.003574    0.010968\n",
       "118833        0   0.057482          0.060190  0.002228    0.010968\n",
       "95519         0   0.189061          0.102206  0.004815    0.010968\n",
       "129990        0  -5.124298          0.008202  0.002263    0.010968\n",
       "4346          0   0.490749          0.001065  0.009077    0.010966\n",
       "68006         0  -3.668287         -0.845199  0.006113    0.010959\n",
       "158066        0  -1.188022         -0.003653  0.005339    0.010952\n",
       "156805        0  -1.712292         -0.752603  0.006598    0.010950\n",
       "186449        0  -0.085161         -0.323348  0.002174    0.010949\n",
       "66706         0  -2.101904         -0.198926  0.011796    0.010948\n",
       "\n",
       "[76729 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_va.sort_values('pred_proba',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(population, weights=None, *, cum_weights=None, k=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
