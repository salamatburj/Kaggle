{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6df55b542f152882e00385a0f73198f4e3bc4316"
   },
   "source": [
    "**FEEL FREE TO UPVOTE**  （＾ｖ＾）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b00db406434116eaef1206208331f97fe0542872"
   },
   "outputs": [],
   "source": [
    "\n",
    "#v20提交成绩得到了3.688， cv 成绩3.6519\n",
    "#使用authorized_flag 进行特征分别处理,收到了奇效\n",
    "#使用countVectorizer 对类别变量进行编码，内存存在压力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('df_train_2_extra.csv')\n",
    "df_test=pd.read_csv('df_test_2_extra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c4f20f27679889542acfd60d1f1ac381b201ac43"
   },
   "outputs": [],
   "source": [
    "exclude_features = []\n",
    "exclude_features += ['card_id', 'first_active_month','target','outliers']\n",
    "df_train_columns = [c for c in df_train.columns if c not in exclude_features ]\n",
    "target = df_train['target']\n",
    "# del df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "b7ff07b98323cf30f11ec6130f5c64e6c4db0aac",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns)\n",
    "len(exclude_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = df_train.copy()\n",
    "df_test2=df_test.copy()\n",
    "outlier = df_train2.outliers\n",
    "#删除异常值编码，下面是没有异常值的训练集\n",
    "#下面这个特征对于识别异常点有一定帮助，但是训练model_without_outliers的时候需要删除这几个特征。\n",
    "for f in ['feature_1','feature_2','feature_3','month','dayofweek']:\n",
    "    del df_train2[f + '_outliers_mean']\n",
    "    del df_train2[f + '_outliers_sum']\n",
    "    del df_test2[f + '_outliers_mean']\n",
    "    del df_test2[f + '_outliers_sum']\n",
    "exclude_features = []\n",
    "exclude_features += ['card_id', 'first_active_month','target','outliers']\n",
    "df_train_columns2 = [c for c in df_train2.columns if c not in exclude_features ]\n",
    "trn_data = lgb.Dataset(df_train[df_train_columns], label=target)#, categorical_feature=categorical_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dd3d768b0cad2f5460669484486a5a5a69e55a3"
   },
   "source": [
    "## Above is the same with wang, I call it wang's features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8577828c9d259644f1c90e1879de197abed86ca8"
   },
   "source": [
    "### I replace wang's stratified CV with normal lgb.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "d666d1510ad92d28727fc4a65112a97cf1f5bc65"
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 6,\n",
    "         \"random_state\": 4950}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "cb405f1dd7b2fd24ebe5c7330605c9ca84e564ec"
   },
   "outputs": [],
   "source": [
    "trn_data = lgb.Dataset(df_train[df_train_columns], label=target)#, categorical_feature=categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_data = lgb.Dataset(df_train[df_train_columns], label=target, categorical_feature=['month','dayofweek','weekofyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "bf6ec993c7ae6317851b21aca63be3b589219f6e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 3.68175 + 0.0289848\n",
      "[400]\tcv_agg's rmse: 3.66228 + 0.0272734\n",
      "[600]\tcv_agg's rmse: 3.65542 + 0.0265762\n",
      "[800]\tcv_agg's rmse: 3.65252 + 0.0261455\n",
      "[1000]\tcv_agg's rmse: 3.65146 + 0.0260665\n",
      "[1200]\tcv_agg's rmse: 3.6511 + 0.0258999\n",
      "[1400]\tcv_agg's rmse: 3.65081 + 0.0255834\n",
      "[1600]\tcv_agg's rmse: 3.65098 + 0.0253746\n",
      "[1800]\tcv_agg's rmse: 3.6508 + 0.0252724\n",
      "[2000]\tcv_agg's rmse: 3.65098 + 0.0252186\n",
      "[2200]\tcv_agg's rmse: 3.65135 + 0.0249002\n"
     ]
    }
   ],
   "source": [
    "lgb_cv = lgb.cv(param, trn_data, 10000, early_stopping_rounds=600, verbose_eval=200, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data2 = lgb.Dataset(df_train2[df_train_columns2], label=target)#, categorical_feature=categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 3.68112 + 0.0293679\n",
      "[400]\tcv_agg's rmse: 3.66178 + 0.0282259\n",
      "[600]\tcv_agg's rmse: 3.65495 + 0.0276025\n",
      "[800]\tcv_agg's rmse: 3.65234 + 0.0272248\n",
      "[1000]\tcv_agg's rmse: 3.65133 + 0.0271494\n",
      "[1200]\tcv_agg's rmse: 3.65085 + 0.0271195\n",
      "[1400]\tcv_agg's rmse: 3.65061 + 0.026787\n",
      "[1600]\tcv_agg's rmse: 3.65039 + 0.0265507\n",
      "[1800]\tcv_agg's rmse: 3.65051 + 0.0262945\n",
      "[2000]\tcv_agg's rmse: 3.65087 + 0.0263697\n",
      "[2200]\tcv_agg's rmse: 3.65096 + 0.0265505\n"
     ]
    }
   ],
   "source": [
    "lgb_cv2 = lgb.cv(param, trn_data2, 10000, early_stopping_rounds=600, verbose_eval=200, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_cv2['rmse-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.57441\n",
      "[400]\ttraining's rmse: 3.48674\n",
      "[600]\ttraining's rmse: 3.43079\n",
      "[800]\ttraining's rmse: 3.38841\n",
      "[1000]\ttraining's rmse: 3.35138\n",
      "[1200]\ttraining's rmse: 3.31784\n",
      "[1400]\ttraining's rmse: 3.28627\n",
      "[1600]\ttraining's rmse: 3.25528\n"
     ]
    }
   ],
   "source": [
    "clf2 = lgb.train(param, trn_data2, len(lgb_cv2['rmse-mean']), valid_sets=(trn_data2), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf2.predict(df_test2[df_train_columns2], num_iteration=clf2.best_iteration)\n",
    "\n",
    "pd.DataFrame({\n",
    "        'card_id': df_test.card_id,\n",
    "        'target': y_pred\n",
    "}).to_csv('wang_lgb_cv_pur_date_1_updated4.csv', index=False)\n",
    "#LB:3.678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.57441\n",
      "[400]\ttraining's rmse: 3.48674\n",
      "[600]\ttraining's rmse: 3.43079\n",
      "[800]\ttraining's rmse: 3.38841\n",
      "[1000]\ttraining's rmse: 3.35138\n",
      "[1200]\ttraining's rmse: 3.31784\n",
      "[1400]\ttraining's rmse: 3.28627\n",
      "[1600]\ttraining's rmse: 3.25528\n",
      "[1800]\ttraining's rmse: 3.22687\n",
      "[2000]\ttraining's rmse: 3.19972\n"
     ]
    }
   ],
   "source": [
    "clf3 = lgb.train(param, trn_data2, 2000, valid_sets=(trn_data2), verbose_eval=200) # let's overtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf3.predict(df_test2[df_train_columns2], num_iteration=clf3.best_iteration)\n",
    "\n",
    "pd.DataFrame({\n",
    "        'card_id': df_test.card_id,\n",
    "        'target': y_pred\n",
    "}).to_csv('wang_lgb_cv_pur_date_1_updated5.csv', index=False)\n",
    "#LB: 3.677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results without categorical_feature=['month','dayofweek','weekofyear'].\n",
    "[200]\tcv_agg's rmse: 3.69075 + 0.0319068\n",
    "[400]\tcv_agg's rmse: 3.6695 + 0.0304884\n",
    "[600]\tcv_agg's rmse: 3.66173 + 0.0294372\n",
    "[800]\tcv_agg's rmse: 3.65849 + 0.0290465\n",
    "[1000]\tcv_agg's rmse: 3.65738 + 0.0285758\n",
    "[1200]\tcv_agg's rmse: 3.65658 + 0.0280419\n",
    "[1400]\tcv_agg's rmse: 3.65644 + 0.0274495\n",
    "[1600]\tcv_agg's rmse: 3.65649 + 0.0271829\n",
    "[1800]\tcv_agg's rmse: 3.65663 + 0.0268914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1743"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_cv['rmse-mean'].index(min(lgb_cv['rmse-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6507604085335066"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(lgb_cv['rmse-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1744"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_cv['rmse-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rmse-mean', 'rmse-stdv'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_cv.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original wang results:\n",
    "\n",
    "[200]\tcv_agg's rmse: 3.68161 + 0.0299797\n",
    "[400]\tcv_agg's rmse: 3.66225 + 0.0286057\n",
    "[600]\tcv_agg's rmse: 3.65503 + 0.0277111\n",
    "[800]\tcv_agg's rmse: 3.65259 + 0.0276703\n",
    "[1000]\tcv_agg's rmse: 3.65156 + 0.027532\n",
    "[1200]\tcv_agg's rmse: 3.65109 + 0.0273339\n",
    "[1400]\tcv_agg's rmse: 3.65112 + 0.0268877\n",
    "[1600]\tcv_agg's rmse: 3.65121 + 0.0265736\n",
    "[1800]\tcv_agg's rmse: 3.65127 + 0.0266131"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1a06954b45d854a7ae886880422cc9aa812dddd"
   },
   "source": [
    "lgb.cv show's that num_boost_round is around 2000, so we train a model with num_boost_round=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "b9784b6a369ad5a7f9787bcaebc082d5b07f38ed",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.57365\n",
      "[400]\ttraining's rmse: 3.48585\n",
      "[600]\ttraining's rmse: 3.42889\n",
      "[800]\ttraining's rmse: 3.38562\n",
      "[1000]\ttraining's rmse: 3.34979\n",
      "[1200]\ttraining's rmse: 3.31615\n",
      "[1400]\ttraining's rmse: 3.28493\n",
      "[1600]\ttraining's rmse: 3.25431\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(param, trn_data, len(lgb_cv['rmse-mean']), valid_sets=(trn_data), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results without categorical_feature=['month','dayofweek','weekofyear'].\n",
    "\n",
    "[200]\ttraining's rmse: 3.58917\n",
    "[400]\ttraining's rmse: 3.49676\n",
    "[600]\ttraining's rmse: 3.43963\n",
    "[800]\ttraining's rmse: 3.39575\n",
    "[1000]\ttraining's rmse: 3.35879\n",
    "[1200]\ttraining's rmse: 3.32572\n",
    "[1400]\ttraining's rmse: 3.29513\n",
    "[1600]\ttraining's rmse: 3.26594\n",
    "[1800]\ttraining's rmse: 3.23792\n",
    "[2000]\ttraining's rmse: 3.21083"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Wang's results:\n",
    "[200]\ttraining's rmse: 3.57275\n",
    "[400]\ttraining's rmse: 3.48472\n",
    "[600]\ttraining's rmse: 3.42865\n",
    "[800]\ttraining's rmse: 3.3851\n",
    "[1000]\ttraining's rmse: 3.34906\n",
    "[1200]\ttraining's rmse: 3.3155\n",
    "[1400]\ttraining's rmse: 3.28252\n",
    "[1600]\ttraining's rmse: 3.25342\n",
    "[1800]\ttraining's rmse: 3.22531\n",
    "[2000]\ttraining's rmse: 3.19685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb9f94bcef907a07167af876fd584bbc56801163"
   },
   "source": [
    "predict and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "15612edf08d0fc342930a49c3da8cd76b7c81820"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration)\n",
    "\n",
    "pd.DataFrame({\n",
    "        'card_id': df_test.card_id,\n",
    "        'target': y_pred\n",
    "}).to_csv('wang_lgb_cv_pur_date_1_updated3.csv', index=False)\n",
    "#LB: 3.678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7fea4b319a7d2701ee1293029217831c437d6911"
   },
   "source": [
    "## Outlier detection using wang's features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b874860a47407bd79444bb78bfbf7f0e8eab0efe"
   },
   "source": [
    "the param is same as regression and just adjust to binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77d25ac4f7deba7a8d36d174a3010b506022507c"
   },
   "source": [
    "best num_boost_round is 500, so we use 500 to train a classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_3',\n",
       " 'auth_flag_purchase_amount_sum',\n",
       " 'auth_flag_authorized_flag_sum',\n",
       " 'auth_flag_authorized_flag_mean',\n",
       " 'auth_flag_authorized_flag_std',\n",
       " 'auth_flag_card_id_size',\n",
       " 'auth_encoder_category_2_auth_mean_mean',\n",
       " 'auth_encoder_category_2_auth_sum_sum',\n",
       " 'auth_encoder_category_3_auth_mean_mean',\n",
       " 'auth_encoder_category_3_auth_sum_sum',\n",
       " 'auth_encoder_state_id_auth_mean_mean',\n",
       " 'auth_encoder_state_id_auth_sum_sum',\n",
       " 'auth_encoder_subsector_id_auth_mean_mean',\n",
       " 'auth_encoder_subsector_id_auth_sum_sum',\n",
       " 'auth_encoder_merchant_category_id_auth_mean_mean',\n",
       " 'auth_encoder_merchant_category_id_auth_sum_sum',\n",
       " 'auth_encoder_city_id_auth_mean_mean',\n",
       " 'auth_encoder_city_id_auth_sum_sum',\n",
       " 'agg_per_month_totalmonth_lag_mean',\n",
       " 'agg_per_month_totalmonth_lag_std',\n",
       " 'agg_per_month_totalagg_per_month_totalauthorized_flag_sum_mean',\n",
       " 'agg_per_month_totalagg_per_month_totalauthorized_flag_sum_std',\n",
       " 'agg_per_month_totalagg_per_month_totalauthorized_flag_mean_mean',\n",
       " 'agg_per_month_totalagg_per_month_totalauthorized_flag_mean_std',\n",
       " 'agg_per_month_totalagg_per_month_totalauthorized_flag_median_mean',\n",
       " 'agg_per_month_totalagg_per_month_totalauthorized_flag_median_std',\n",
       " 'agg_per_month_authmonth_lag_mean',\n",
       " 'agg_per_month_authmonth_lag_std',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_sum_mean',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_sum_std',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_mean_mean',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_mean_std',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_min_mean',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_min_std',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_max_mean',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_max_std',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_std_mean',\n",
       " 'agg_per_month_authagg_per_month_authpurchase_amount_std_std',\n",
       " 'agg_per_month_histmonth_lag_mean',\n",
       " 'agg_per_month_histmonth_lag_std',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_sum_mean',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_sum_std',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_mean_mean',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_mean_std',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_min_mean',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_min_std',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_max_mean',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_max_std',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_std_mean',\n",
       " 'agg_per_month_histagg_per_month_histpurchase_amount_std_std',\n",
       " 'agg_per_month_hist_newmonth_lag_mean',\n",
       " 'agg_per_month_hist_newmonth_lag_std',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_sum_mean',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_sum_std',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_mean_mean',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_mean_std',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_min_mean',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_min_std',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_max_mean',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_max_std',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_std_mean',\n",
       " 'agg_per_month_hist_newagg_per_month_hist_newpurchase_amount_std_std',\n",
       " 'auth_hist_month_nunique',\n",
       " 'auth_hist_hour_nunique',\n",
       " 'auth_hist_weekofyear_nunique',\n",
       " 'auth_hist_dayofweek_nunique',\n",
       " 'auth_hist_year_nunique',\n",
       " 'auth_hist_subsector_id_nunique',\n",
       " 'auth_hist_merchant_id_nunique',\n",
       " 'auth_hist_merchant_category_id_nunique',\n",
       " 'auth_hist_state_id_nunique',\n",
       " 'auth_hist_city_id_nunique',\n",
       " 'auth_hist_purchase_amount_sum',\n",
       " 'auth_hist_purchase_amount_max',\n",
       " 'auth_hist_purchase_amount_min',\n",
       " 'auth_hist_purchase_amount_mean',\n",
       " 'auth_hist_purchase_amount_var',\n",
       " 'auth_hist_purchase_amount_median',\n",
       " 'auth_hist_installments_sum',\n",
       " 'auth_hist_installments_max',\n",
       " 'auth_hist_installments_min',\n",
       " 'auth_hist_installments_mean',\n",
       " 'auth_hist_installments_var',\n",
       " 'auth_hist_installments_median',\n",
       " 'auth_hist_purchase_date_max',\n",
       " 'auth_hist_purchase_date_min',\n",
       " 'auth_hist_month_lag_max',\n",
       " 'auth_hist_month_lag_min',\n",
       " 'auth_hist_month_lag_mean',\n",
       " 'auth_hist_month_lag_var',\n",
       " 'auth_hist_month_lag_median',\n",
       " 'auth_hist_month_diff_mean',\n",
       " 'auth_hist_month_diff_median',\n",
       " 'auth_hist_weekend_sum',\n",
       " 'auth_hist_weekend_mean',\n",
       " 'auth_hist_category_1_sum',\n",
       " 'auth_hist_category_1_mean',\n",
       " 'auth_hist_card_id_size',\n",
       " 'auth_hist_category_2_mean_mean',\n",
       " 'auth_hist_category_2_sum_sum',\n",
       " 'auth_hist_category_3_mean_mean',\n",
       " 'auth_hist_category_3_sum_sum',\n",
       " 'auth_hist_state_id_mean_mean',\n",
       " 'auth_hist_state_id_sum_sum',\n",
       " 'auth_hist_subsector_id_mean_mean',\n",
       " 'auth_hist_subsector_id_sum_sum',\n",
       " 'auth_hist_merchant_category_id_mean_mean',\n",
       " 'auth_hist_merchant_category_id_sum_sum',\n",
       " 'auth_hist_city_id_mean_mean',\n",
       " 'auth_hist_city_id_sum_sum',\n",
       " 'auth_hist_merchant_id_mean_mean',\n",
       " 'auth_hist_merchant_id_sum_sum',\n",
       " 'auth_hist_purchase_date_diff',\n",
       " 'auth_hist_purchase_date_average',\n",
       " 'auth_hist_purchase_date_uptonow',\n",
       " 'auth_hist_first_purchase',\n",
       " 'hist_month_nunique',\n",
       " 'hist_hour_nunique',\n",
       " 'hist_weekofyear_nunique',\n",
       " 'hist_dayofweek_nunique',\n",
       " 'hist_year_nunique',\n",
       " 'hist_subsector_id_nunique',\n",
       " 'hist_merchant_id_nunique',\n",
       " 'hist_merchant_category_id_nunique',\n",
       " 'hist_state_id_nunique',\n",
       " 'hist_city_id_nunique',\n",
       " 'hist_purchase_amount_sum',\n",
       " 'hist_purchase_amount_max',\n",
       " 'hist_purchase_amount_min',\n",
       " 'hist_purchase_amount_mean',\n",
       " 'hist_purchase_amount_var',\n",
       " 'hist_purchase_amount_median',\n",
       " 'hist_installments_sum',\n",
       " 'hist_installments_max',\n",
       " 'hist_installments_min',\n",
       " 'hist_installments_mean',\n",
       " 'hist_installments_var',\n",
       " 'hist_installments_median',\n",
       " 'hist_purchase_date_max',\n",
       " 'hist_purchase_date_min',\n",
       " 'hist_month_lag_max',\n",
       " 'hist_month_lag_min',\n",
       " 'hist_month_lag_mean',\n",
       " 'hist_month_lag_var',\n",
       " 'hist_month_lag_median',\n",
       " 'hist_month_diff_mean',\n",
       " 'hist_month_diff_median',\n",
       " 'hist_weekend_sum',\n",
       " 'hist_weekend_mean',\n",
       " 'hist_category_1_sum',\n",
       " 'hist_category_1_mean',\n",
       " 'hist_card_id_size',\n",
       " 'hist_category_2_mean_mean',\n",
       " 'hist_category_2_sum_sum',\n",
       " 'hist_category_3_mean_mean',\n",
       " 'hist_category_3_sum_sum',\n",
       " 'hist_state_id_mean_mean',\n",
       " 'hist_state_id_sum_sum',\n",
       " 'hist_subsector_id_mean_mean',\n",
       " 'hist_subsector_id_sum_sum',\n",
       " 'hist_merchant_category_id_mean_mean',\n",
       " 'hist_merchant_category_id_sum_sum',\n",
       " 'hist_city_id_mean_mean',\n",
       " 'hist_city_id_sum_sum',\n",
       " 'hist_merchant_id_mean_mean',\n",
       " 'hist_merchant_id_sum_sum',\n",
       " 'hist_purchase_date_diff',\n",
       " 'hist_purchase_date_average',\n",
       " 'hist_purchase_date_uptonow',\n",
       " 'hist_first_purchase',\n",
       " 'new_hist_month_nunique',\n",
       " 'new_hist_hour_nunique',\n",
       " 'new_hist_weekofyear_nunique',\n",
       " 'new_hist_dayofweek_nunique',\n",
       " 'new_hist_year_nunique',\n",
       " 'new_hist_subsector_id_nunique',\n",
       " 'new_hist_merchant_id_nunique',\n",
       " 'new_hist_merchant_category_id_nunique',\n",
       " 'new_hist_state_id_nunique',\n",
       " 'new_hist_city_id_nunique',\n",
       " 'new_hist_purchase_amount_sum',\n",
       " 'new_hist_purchase_amount_max',\n",
       " 'new_hist_purchase_amount_min',\n",
       " 'new_hist_purchase_amount_mean',\n",
       " 'new_hist_purchase_amount_var',\n",
       " 'new_hist_purchase_amount_median',\n",
       " 'new_hist_installments_sum',\n",
       " 'new_hist_installments_max',\n",
       " 'new_hist_installments_min',\n",
       " 'new_hist_installments_mean',\n",
       " 'new_hist_installments_var',\n",
       " 'new_hist_installments_median',\n",
       " 'new_hist_purchase_date_max',\n",
       " 'new_hist_purchase_date_min',\n",
       " 'new_hist_month_lag_max',\n",
       " 'new_hist_month_lag_min',\n",
       " 'new_hist_month_lag_mean',\n",
       " 'new_hist_month_lag_var',\n",
       " 'new_hist_month_lag_median',\n",
       " 'new_hist_month_diff_mean',\n",
       " 'new_hist_month_diff_median',\n",
       " 'new_hist_weekend_sum',\n",
       " 'new_hist_weekend_mean',\n",
       " 'new_hist_authorized_flag_sum',\n",
       " 'new_hist_authorized_flag_mean',\n",
       " 'new_hist_authorized_flag_median',\n",
       " 'new_hist_category_1_sum',\n",
       " 'new_hist_category_1_mean',\n",
       " 'new_hist_card_id_size',\n",
       " 'new_hist_category_2_mean_mean',\n",
       " 'new_hist_category_2_sum_sum',\n",
       " 'new_hist_category_3_mean_mean',\n",
       " 'new_hist_category_3_sum_sum',\n",
       " 'new_hist_state_id_mean_mean',\n",
       " 'new_hist_state_id_sum_sum',\n",
       " 'new_hist_subsector_id_mean_mean',\n",
       " 'new_hist_subsector_id_sum_sum',\n",
       " 'new_hist_merchant_category_id_mean_mean',\n",
       " 'new_hist_merchant_category_id_sum_sum',\n",
       " 'new_hist_city_id_mean_mean',\n",
       " 'new_hist_city_id_sum_sum',\n",
       " 'new_hist_merchant_id_mean_mean',\n",
       " 'new_hist_merchant_id_sum_sum',\n",
       " 'new_hist_purchase_date_diff',\n",
       " 'new_hist_purchase_date_average',\n",
       " 'new_hist_purchase_date_uptonow',\n",
       " 'new_hist_first_purchase',\n",
       " 'new_hist_unauthorized_number',\n",
       " 'dayofweek',\n",
       " 'weekofyear',\n",
       " 'month',\n",
       " 'elapsed_time',\n",
       " 'hist_first_buy',\n",
       " 'new_hist_first_buy',\n",
       " 'auth_hist_first_buy',\n",
       " 'feature_1_outliers_mean',\n",
       " 'feature_1_outliers_sum',\n",
       " 'feature_2_outliers_mean',\n",
       " 'feature_2_outliers_sum',\n",
       " 'feature_3_outliers_mean',\n",
       " 'feature_3_outliers_sum',\n",
       " 'month_outliers_mean',\n",
       " 'month_outliers_sum',\n",
       " 'dayofweek_outliers_mean',\n",
       " 'dayofweek_outliers_sum',\n",
       " 'feature_1_1',\n",
       " 'feature_1_2',\n",
       " 'feature_1_3',\n",
       " 'feature_1_4',\n",
       " 'feature_1_5',\n",
       " 'feature_2_1',\n",
       " 'feature_2_2',\n",
       " 'feature_2_3']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = df_train.copy()\n",
    "df_test2=df_test.copy()\n",
    "outlier = df_train2.outliers\n",
    "#删除异常值编码，下面是没有异常值的训练集\n",
    "#下面这个特征对于识别异常点有一定帮助，但是训练model_without_outliers的时候需要删除这几个特征。\n",
    "for f in ['feature_1','feature_2','feature_3','month','dayofweek']:\n",
    "    del df_train2[f + '_outliers_mean']\n",
    "    del df_train2[f + '_outliers_sum']\n",
    "    del df_test2[f + '_outliers_mean']\n",
    "    del df_test2[f + '_outliers_sum']\n",
    "exclude_features = []\n",
    "exclude_features += ['card_id', 'first_active_month','target','outliers']\n",
    "df_train_columns2 = [c for c in df_train2.columns if c not in exclude_features ]\n",
    "trn_data = lgb.Dataset(df_train[df_train_columns], label=target)#, categorical_feature=categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 6,\n",
    "         \"scale_pos_weight\": 15,\n",
    "         \"random_state\": 4950}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = lgb.Dataset(df_train2[df_train_columns2], label=outlier)#, categorical_feature=categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's auc: 0.904452 + 0.0048605\n",
      "[400]\tcv_agg's auc: 0.905061 + 0.00456461\n",
      "[600]\tcv_agg's auc: 0.904718 + 0.00484739\n",
      "[800]\tcv_agg's auc: 0.904136 + 0.00520001\n"
     ]
    }
   ],
   "source": [
    "lgb_cv = lgb.cv(param, trn_data, 10000, early_stopping_rounds=600, verbose_eval=200, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9051801367503455"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_cv['auc-mean'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_cv['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.954415\n",
      "[200]\ttraining's auc: 0.96213\n",
      "[300]\ttraining's auc: 0.967929\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(param, trn_data, len(lgb_cv['auc-mean']), verbose_eval=100, valid_sets=(trn_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_prob = clf.predict(df_test2[df_train_columns2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0010467757547024475, 0.8333526258519501)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_prob.min(), te_prob.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers=pd.DataFrame()\n",
    "df_outliers['card_id']=df_test['card_id']\n",
    "df_outliers['probability']=te_prob\n",
    "df_outliers.to_csv('wang_lgb_cv_pur_date_1_updated_outliers_pred_uodated3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "wang_out=pd.read_csv('wang_lgb_cv_pur_date_1_updated')\n",
    "wang_out['outlier_prob1'] = te_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "_40=wang_out.sort_values('outlier_prob1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20 = _40.card_id.values[:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "wang_out.loc[wang_out.card_id.isin(top20), 'target'] = -33.21928095\n",
    "wang_out[['card_id', 'target']].to_csv('wang_lgb_cv_pur_date_1_updated_top20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_50 = _40.card_id.values[20:50].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_50_df = wang_out[wang_out.card_id.isin(top20_50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_50_target = top20_50_df.outlier_prob1 * (-33.21928095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "wang_out.loc[wang_out.card_id.isin(top20_50), 'target'] = top20_50_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "wang_out[['card_id', 'target']].to_csv('wang_lgb_cv_pur_date_1_updated_top20_top20-50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try to merge results with the model without outliers.\n",
    "### First, predict without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target']=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2=df_train[df_train['outliers']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199710, 257)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2=df_train2.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 243)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_columns),len(df_train_columns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 48,\n",
    "         \"random_state\": 4950}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data2 = lgb.Dataset(df_train2[df_train_columns], label=target2)#, categorical_feature=categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's rmse: 1.58191 + 0.00883915\n",
      "[400]\tcv_agg's rmse: 1.56523 + 0.00798252\n",
      "[600]\tcv_agg's rmse: 1.55947 + 0.0075402\n",
      "[800]\tcv_agg's rmse: 1.5571 + 0.00732745\n",
      "[1000]\tcv_agg's rmse: 1.55593 + 0.0070912\n",
      "[1200]\tcv_agg's rmse: 1.55515 + 0.00691628\n",
      "[1400]\tcv_agg's rmse: 1.55474 + 0.00682905\n",
      "[1600]\tcv_agg's rmse: 1.55452 + 0.00677001\n",
      "[1800]\tcv_agg's rmse: 1.55431 + 0.00669755\n",
      "[2000]\tcv_agg's rmse: 1.55412 + 0.00663288\n",
      "[2200]\tcv_agg's rmse: 1.55398 + 0.00654708\n",
      "[2400]\tcv_agg's rmse: 1.55386 + 0.0064701\n",
      "[2600]\tcv_agg's rmse: 1.55382 + 0.00645527\n",
      "[2800]\tcv_agg's rmse: 1.55381 + 0.00636882\n",
      "[3000]\tcv_agg's rmse: 1.55379 + 0.00623851\n",
      "[3200]\tcv_agg's rmse: 1.55373 + 0.00625909\n",
      "[3400]\tcv_agg's rmse: 1.55379 + 0.00623813\n",
      "[3600]\tcv_agg's rmse: 1.55377 + 0.00623746\n"
     ]
    }
   ],
   "source": [
    "lgb_cv = lgb.cv(param, trn_data2, 10000, early_stopping_rounds=600, verbose_eval=200, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold10=pd.read_csv('threshold_feature_elimination10_8extra_test10_without_outliers.csv',squeeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_1_outliers_mean\n",
      "feature_1_outliers_sum\n",
      "feature_2_outliers_mean\n",
      "feature_2_outliers_sum\n",
      "feature_3_outliers_sum\n",
      "feature_1_1\n",
      "feature_1_3\n",
      "feature_1_4\n",
      "feature_2_2\n",
      "feature_2_3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(threshold10)):\n",
    "    if 'feature' in threshold10.loc[i].values[0]:\n",
    "        print(threshold10.loc[i].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01142752, 0.01028283])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['feature_3_outliers_mean'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['feature_2_3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auth_encoder_category_3_auth_mean_mean'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold10.loc[0].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.57441\n",
      "[400]\ttraining's rmse: 3.48674\n",
      "[600]\ttraining's rmse: 3.43079\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-d92f485eebf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_data2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_data2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    214\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1783\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1784\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1785\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1786\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = lgb.train(param, trn_data2, 3600, valid_sets=(trn_data2), verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration)\n",
    "\n",
    "pd.DataFrame({\n",
    "        'card_id': df_test.card_id,\n",
    "        'target': y_pred\n",
    "}).to_csv('wang_lgb_cv_pur_date_1_updated_without_outliers', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's combine models with and without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_outliers=pd.read_csv('wang_lgb_cv_pur_date_1_updated')\n",
    "model_without_outliers=pd.read_csv('wang_lgb_cv_pur_date_1_updated_without_outliers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_df=model_with_outliers.copy()\n",
    "probability_df['prob']=te_prob\n",
    "del probability_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1481680365769966"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_df.sort_values('prob',ascending=False).head(18000).prob.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333526258519501"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_df.sort_values('prob',ascending=False).head(18000).prob.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's use 18000 as threshould value as we have used before\n",
    "index_high_prob=probability_df.sort_values('prob',ascending=False).head(18000).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probability_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-88031888447f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mindex_high_prob2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobability_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prob'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'probability_df' is not defined"
     ]
    }
   ],
   "source": [
    "index_high_prob2=probability_df.sort_values('prob',ascending=False).head(25000).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 96354,  88754,  78078, 115682, 109960,   5008, 109705, 118268,\n",
       "              5707,  57626,\n",
       "            ...\n",
       "            116990,  53485,  88674,  88770,  52048, 115876,  51772,  26502,\n",
       "             11497,  66954],\n",
       "           dtype='int64', length=18000)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_high_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_model=model_without_outliers.copy()\n",
    "mixed_model.loc[index_high_prob,'target']=model_with_outliers.loc[index_high_prob,'target']\n",
    "mixed_model.to_csv('wang_lgb_cv_pur_date_1_updated_mixed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's use previous methods to change top 20 and top 20-50 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_model.loc[mixed_model.card_id.isin(top20),'target']=-33.21928095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_model.loc[mixed_model.card_id.isin(top20_50),'target']=top20_50_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_model.to_csv('wang_lgb_cv_pur_date_1_updated_mixed_top20_top20_50.csv',index=False)\n",
    "\n",
    "##LB score: 3.663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
